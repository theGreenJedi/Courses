{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous coin-flipping discussion, we discussed estimation of the\n",
    "underlying probability of getting a heads. There, we derived the\n",
    "estimator as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{p}_n = \\frac{1}{n}\\sum_{i=1}^n X_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where $X_i\\in \\lbrace 0,1 \\rbrace$. Confidence intervals allow us to\n",
    "estimate how close we can get to the true value that we are estimating.\n",
    "Logically, that seems strange, doesn't it? We really don't know the exact value\n",
    "of what we are estimating (otherwise, why estimate it?), and yet, somehow we\n",
    "know how close we can get to something we admit we don't know? Ultimately, we\n",
    "want to make statements like the *probability of the value in a certain\n",
    "interval is 90\\%*. Unfortunately, that is something we will not be able to say\n",
    "using our methods. Note that Bayesian estimation gets closer to this statement\n",
    "by using *credible intervals*, but that is a story for another day. In our\n",
    "situation, the best we can do is say roughly the following: *if we ran the\n",
    "experiment multiple times, then the confidence interval would trap the true\n",
    "parameter 90\\% of the time*.\n",
    "\n",
    "Let's return to our coin-flipping example and see this in action. One\n",
    "way to get at a confidence interval is to use Hoeffding's inequality\n",
    "from the section ref{ch:prob:sec:ineq}\n",
    "specialized to our Bernoulli variables as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(\\mid \\hat{p}_n-p\\mid >\\epsilon) \\leq 2 \\exp(-2n \\epsilon^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, we can form the interval\n",
    "$\\mathbb{I}=[\\hat{p}_n-\\epsilon_n,\\hat{p}_n+\\epsilon_n]$, where $\\epsilon_n$ is\n",
    "carefully constructed as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\epsilon_n = \\sqrt{ \\frac{1}{2 n}\\log\\frac{2}{\\alpha}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " which makes the right-side of the Hoeffding inequality equal to\n",
    "$\\alpha$. Thus, we finally have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(p \\notin \\mathbb{I}) = \\mathbb{P}\\left(\\mid \\hat{p}_n-p\\mid >\\epsilon_n\\right) \\leq \\alpha\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, $ \\mathbb{P}(p \\in \\mathbb{I})\n",
    "\\geq 1-\\alpha$. As a numerical example, let's take $n=100$, $\\alpha=0.05$, then plugging into everything we have gives $\\epsilon_n=0.136$.\n",
    "So, the 95\\% confidence interval here is therefore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{I}=[\\hat{p}_n-\\epsilon_n,\\hat{p}_n+\\epsilon_n] = [\\hat{p}_n-0.136,\\hat{p}_n+0.136]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code sample is a simulation to see if we can really trap\n",
    "the underlying parameter in our confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval trapped correct value  99.5 % of the time\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "b= stats.bernoulli(.5) # fair coin distribution\n",
    "nsamples = 100\n",
    "# flip it nsamples times for 200 estimates\n",
    "xs = b.rvs(nsamples*200).reshape(nsamples,-1) \n",
    "phat = np.mean(xs,axis=0) # estimated p\n",
    "# edge of 95% confidence interval\n",
    "epsilon_n=np.sqrt(np.log(2/0.05)/2/nsamples) \n",
    "pct=np.logical_and(phat-epsilon_n<=0.5, \n",
    "                   0.5 <= (epsilon_n +phat)\n",
    "                   ).mean()*100\n",
    "print 'Interval trapped correct value ', pct,'% of the time'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # @@@CODE src-statistics/Confidence_Intervals.py fromto: from scipy@#end -->\n",
    "\n",
    " The result shows that the estimator and the corresponding\n",
    "interval was able to trap the true value at least 95\\% of the time. This is how\n",
    "to interpret the action of confidence intervals.\n",
    "\n",
    "However, the usual practice is to not use Hoeffding's inequality and\n",
    "instead use arguments around asymptotic normality.\n",
    "The definition of the standard error is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\texttt{se} = \\sqrt{\\mathbb{V}(\\hat{\\theta}_n)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where $\\hat{\\theta}_n$ is the point-estimator for the parameter\n",
    "$\\theta$, given $n$ samples of data $X_n$, and $\\mathbb{V}(\\hat{\\theta}_n)$ is\n",
    "the variance of $\\hat{\\theta}_n$. Likewise, the estimated standard error is\n",
    "$\\widehat{\\texttt{se}}$. For example, in our coin-flipping example, the estimator\n",
    "was $\\hat{p}=\\sum X_i/n$ with corresponding variance\n",
    "$\\mathbb{V}(\\hat{p}_n)=p(1-p)/n$.  Plugging in the point estimate gives us the\n",
    "estimated standard error: $\\widehat{\\texttt{se}}=\\sqrt{\\hat{p}(1-\\hat{p})/n}$.\n",
    "Because maximum likelihood estimators are asymptotically normal [^mle], we know\n",
    "that $\\hat{p}_n \\sim \\mathcal{N}(p,\\widehat{\\texttt{se}}^2)$. Thus, if we want\n",
    "a $1-\\alpha$ confidence interval, we can compute\n",
    "\n",
    "[^mle]: Certain technical regularity conditions must hold for this property\n",
    "of maximum likelihood estimator to work. See \n",
    "[[wasserman2004all]](#wasserman2004all) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(\\mid \\hat{p}_n-p\\mid  < \\xi)> 1-\\alpha\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " but since we know that $ (\\hat{p}_n-p)$ is asymptotically normal,\n",
    "$\\mathcal{N}(0,\\widehat{\\texttt{se}}^2)$, we can instead compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\int_{-\\xi}^{\\xi} \\mathcal{N}(0,\\widehat{\\texttt{se}}^2) dx > 1-\\alpha\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This looks ugly to compute because we need to find $\\xi$, but\n",
    "Scipy has everything we need for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute estimated se for all trials\n",
    "se=np.sqrt(phat*(1-phat)/xs.shape[0]) \n",
    "# generate random variable for trial 0\n",
    "rv=stats.norm(0, se[0]) \n",
    "# compute 95% confidence interval for that trial 0\n",
    "np.array(rv.interval(0.95))+phat[0] \n",
    "def compute_CI(i):\n",
    "    return stats.norm.interval(0.95,loc=i,\n",
    "                              scale=np.sqrt(i*(1-i)/xs.shape[0]))\n",
    "\n",
    "lower,upper = compute_CI(phat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # @@@CODE src-statistics/Confidence_Intervals.py fromto: ^# compute estimated se for all trials@^#end -->\n",
    "\n",
    "<!-- dom:FIGURE: [fig-statistics/Confidence_Intervals_001.png, width=500 frac=0.75] The gray circles are the point estimates that are bounded above and below by both asymptotic confidence intervals and Hoeffding intervals. The asymptotic intervals are tighter because the underpinning asymptotic assumptions are valid for these estimates.  <div id=\"fig:Confidence_Intervals_001\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:Confidence_Intervals_001\"></div>\n",
    "\n",
    "<p>The gray circles are the point estimates that are bounded above and below by both asymptotic confidence intervals and Hoeffding intervals. The asymptotic intervals are tighter because the underpinning asymptotic assumptions are valid for these estimates.</p>\n",
    "<img src=\"fig-statistics/Confidence_Intervals_001.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "[Figure](#fig:Confidence_Intervals_001) shows the asymptotic\n",
    "confidence intervals and the Hoeffding-derived confidence intervals.\n",
    "As shown, the Hoeffding intervals are a bit more generous than the\n",
    "asymptotic estimates.  However, this is only true so long as the\n",
    "asympotic approximation is valid. In other words, there exists some\n",
    "number of $n$ samples for which the asymptotic intervals may not work.\n",
    "So, even though they may be a bit more generous, the Hoeffding\n",
    "intervals do not require arguments about asymptotic convergence. In\n",
    "practice, nonetheless, asymptotic convergence is always in play (even\n",
    "if not explicitly stated).\n",
    "\n",
    "### Confidence Intervals and Hypothesis testing\n",
    "\n",
    "It turns out that there is a close dual relationship between hypothesis testing\n",
    "and confidence intervals. To see this in action, consider the following\n",
    "hypothesis test for a normal distribution, $H_0 :\\mu=\\mu_0$ versus $H_1: \\mu\n",
    "\\neq \\mu_0$. A reasonable test has the following rejection region:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left\\{ x: \\mid \\bar{x}-\\mu_0\\mid  > z_{\\alpha/2}\\frac{\\sigma}{\\sqrt n} \\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where $\\mathbb{P}(Z > z_{\\alpha/2}) = \\alpha/2$ and\n",
    "$\\mathbb{P}(-z_{\\alpha/2}< Z < z_{\\alpha/2}) = 1-\\alpha$ and where $Z \\sim\n",
    "\\mathcal{N}(0,1)$. This is the same thing as saying that the region\n",
    "corresponding to acceptance of $H_0$ is then,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:ci\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\bar{x} -z_{\\alpha/2}\\frac{\\sigma}{\\sqrt n}  \\leq \\mu_0 \\leq \\bar{x} +z_{\\alpha/2}\\frac{\\sigma}{\\sqrt n} \n",
    "\\end{equation}\n",
    "\\label{eq:ci} \\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Because the test has size $\\alpha$, the false alarm probability, $\\mathbb{P}(H_0 \n",
    "\\texttt{  rejected}\\mid \\mu=\\mu_0)=\\alpha$.  Likewise, the $\\mathbb{P}(H_0 \n",
    "\\texttt{  accepted}\\mid \\mu=\\mu_0)=1-\\alpha$. Putting this all together with\n",
    "interval defined above means that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}\\left(\\bar{x} -z_{\\alpha/2}\\frac{\\sigma}{\\sqrt n} \\leq \\mu_0 \\leq \\bar{x}+z_{\\alpha/2}\\frac{\\sigma}{\\sqrt n} \\Big\\vert H_0\\right)=1-\\alpha\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Because this is valid for any $\\mu_0$, we can drop the $H_0$ condition\n",
    "and say the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}\\left(\\bar{x} -z_{\\alpha/2}\\frac{\\sigma}{\\sqrt n}  \\leq \\mu_0 \\leq \\bar{x} +z_{\\alpha/2}\\frac{\\sigma}{\\sqrt n} \\right) =1-\\alpha\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As may be obvious by now, the interval in Equation ref{eq:ci} above *is* the\n",
    "$1-\\alpha$ confidence interval! Thus, we have just obtained the confidence\n",
    "interval by inverting the acceptance region of the level $\\alpha$ test. The\n",
    "hypothesis test fixes the *parameter* and then asks what sample values\n",
    "(i.e., the acceptance region) are consistent with that fixed value.\n",
    "Alternatively, the confidence interval fixes the sample value and then asks\n",
    "what parameter values (i.e., the confidence interval) make this sample value\n",
    "most plausible. Note that sometimes this inversion method results in disjoint\n",
    "intervals (known as *confidence sets*)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
