{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python went mainstream years ago. It is now part of many undergraduate\n",
    "curricula in engineering and computer science.  Great books and interactive\n",
    "on-line tutorials are easy to find.  In particular, Python is well-established\n",
    "in web programming with frameworks such as Django and CherryPy, and is the\n",
    "back-end platform for many high-traffic sites.\n",
    "\n",
    "Beyond web programming, there is an ever-expanding list of third-party\n",
    "extensions that reach across many scientific disciplines, from linear algebra\n",
    "to visualization to  machine learning.  For these applications, Python is the\n",
    "software *glue* that permits easy exchange of methods and data across core\n",
    "routines typically written in Fortran or C. Scientific Python has been\n",
    "fundamental for almost two decades in government, academia, and industry. For\n",
    "example, NASA's Jet Propulsion Laboratory uses it for interfacing Fortran/C++\n",
    "libraries for planning and visualization of spacecraft trajectories. The\n",
    "Lawrence Livermore National Laboratory uses scientific Python for a wide\n",
    "variety of computing tasks, some involving routine text processing, and others\n",
    "involving advanced visualization of vast data sets (e.g. VISIT [[Visit]](#Visit)).\n",
    "Shell Research, Boeing, Industrial Light and Magic, Sony Entertainment, and\n",
    "Procter \\& Gamble use scientific Python on a daily basis for data processing\n",
    "and analysis. Python is thus well-established and continues to extend into many\n",
    "different fields.\n",
    "\n",
    "Python is a language geared towards scientists and engineers who may not have\n",
    "formal software development training. It is used to prototype, design, simulate,\n",
    "and test without *getting in the way* because Python provides an inherently\n",
    "easy and incremental development cycle, interoperability with existing codes,\n",
    "access to a large base of reliable open source codes, and a hierarchical\n",
    "compartmentalized design philosophy.  It is known that productivity is\n",
    "strongly influenced by the workflow of the user, (e.g., time spent running\n",
    "versus time spent programming) [[data2006interactive]](#data2006interactive).  Therefore, Python\n",
    "can dramatically enhance user-productivity.\n",
    "\n",
    "Python is an *interpreted* language. This means that Python codes run on a\n",
    "Python *virtual machine* that provides a layer of abstraction between the code\n",
    "and the platform it runs on, thus making codes portable across different\n",
    "platforms. For example, the same script that runs on a Windows laptop can also\n",
    "run on a Linux-based supercomputer or on a mobile phone. This makes programming\n",
    "easier because the virtual machine handles the low-level details of\n",
    "implementing the business logic of the script on the underlying platform.\n",
    "\n",
    "Python is a dynamically typed language, which means that the interpreter itself\n",
    "figures out the representative types (e.g., floats, integers) interactively or\n",
    "at run-time. This is in contrast to a language like Fortran that have compilers\n",
    "that study the code from beginning to end, perform many compiler-level\n",
    "optimizations, link intimately with the existing libraries on a specific\n",
    "platform, and then create an executable that is henceforth liberated from the\n",
    "compiler.  As you may guess, the compiler's access to the details of the\n",
    "underlying platform means that it can utilize optimizations that exploit\n",
    "chip-specific features and cache memory. Because the virtual machine abstracts\n",
    "away these details, it means that the Python language does not have\n",
    "programmable access to these kinds of optimizations.  So, where is the balance\n",
    "between the ease of programming the virtual machine and and these key\n",
    "numerical optimizations that are crucial for scientific work?\n",
    "\n",
    "The balance comes from Python's native ability to bind to compiled Fortran and\n",
    "C libraries. This means that you can send intensive computations to\n",
    "compiled libraries directly from the interpreter. This approach has two primary\n",
    "advantages.  First, it give you the fun of programming in Python, with its\n",
    "expressive syntax and lack of visual clutter.  This is a particular boon to\n",
    "scientists who typically want to *use* software as a tool as opposed\n",
    "to developing software as a product.  The second advantage is that you can\n",
    "mix-and-match different compiled libraries from diverse research areas that\n",
    "were not otherwise designed to work together.  This works because Python makes\n",
    "it easy to allocate and fill memory in the interpreter, pass it  as input to\n",
    "compiled libraries, and then retrieve the output back at the interpreter.\n",
    "\n",
    "Moreover, Python provides a multiplatform solution for\n",
    "scientific codes. As an open-source project, Python itself is\n",
    "available anywhere you can build it, even though it typically comes\n",
    "standard nowadays, as part of many operating systems.  This means that\n",
    "once you have written your code in Python, you can just transfer the\n",
    "script to another platform and run it, as long as the compiled\n",
    "libraries are also available there.  What if the compiled libraries\n",
    "are absent? Building and configuring compiled libraries across\n",
    "multiple systems used to be a painstaking job, but as scientific\n",
    "Python has matured, a wide range of libraries have now become\n",
    "available across all of the major platforms (i.e., Windows, MacOS,\n",
    "Linux, Unix) as prepackaged distributions.\n",
    "\n",
    "Finally, scientific Python facilitates maintainability of scientific\n",
    "codes because Python syntax is clean, free of semi-colon litter\n",
    "and other visual distractions that makes code hard to read and easy to\n",
    "obfuscate.  Python has many built-in testing, documentation,  and\n",
    "development tools that ease maintenance.  Scientific codes are usually\n",
    "written by scientists unschooled in software development, so\n",
    "having solid software development tools built into the language itself is a\n",
    "particular boon.\n",
    "\n",
    "# Installation and Setup\n",
    "<div id=\"sec:installation_and_setup\"></div>\n",
    "\n",
    "The easiest way to get started is to download the freely available Anaconda\n",
    "distribution provided by Continuum Analytics (`continuum.io`), which is available for all of the\n",
    "major platforms. On Linux, even though most of the toolchain is available via\n",
    "the built-in Linux package manager, it is still better to install the\n",
    "Anaconda distribution because it provides its own powerful package manager\n",
    "(i.e., `conda`)   that can keep track of changes in the software dependencies of\n",
    "the packages that it supports.  Note that if you do not have administrator\n",
    "privileges, there is also a corresponding `miniconda` distribution\n",
    "that does not require these privileges.\n",
    "\n",
    "Regardless of your platform, we recommend Python version 2.7.  Python 2.7 is\n",
    "the *last* of the Python 2.x series and guarantees backwards compatibility with\n",
    "legacy codes. Python 3.x makes no such guarantees.  Although all of the key\n",
    "components of scientific Python are available in version 3.x, the safest bet is\n",
    "to stick with version 2.7.  Alternatively, one compromise is to write in a\n",
    "hybrid dialect of Python that is the intersection of elements of versions 2.7\n",
    "and 3.x.  The `six`  module enables this transition by providing utility\n",
    "functions for 2.5 and newer codes.  There is also a Python 2.7 to 3.x converter\n",
    "available as the `2to3` module but it may be hard to debug or maintain the\n",
    "so-converted code; nonetheless, this might be a good option for small,\n",
    "self-contained libraries that do not require further development or\n",
    "maintenance.\n",
    "\n",
    "You may have encountered other Python variants on the web, such as `IronPython`\n",
    "(Python implemented in `C#`) and `Jython` (Python implemented in `Java`). In\n",
    "this text, we focus on the C-implementation of Python (i.e., known as\n",
    "*CPython*), which is, by far, the most popular implementation. These other\n",
    "Python variants permit specialized, native interaction with libraries in `C#`\n",
    "or `Java` (respectively), which is still possible (but clunky) using the\n",
    "CPython.  Even more Python variants exist that implement the low-level\n",
    "machinery of Python differently for various reasons, beyond interacting with\n",
    "native libraries in other languages. Most notable of these is `Pypy` that\n",
    "implements a just-in-time compiler (JIT) and other powerful optimizations that\n",
    "can substantially speed up *pure* Python codes. The downside of `Pypy` is that\n",
    "its coverage of some popular scientific modules (e.g., Matplotlib, Scipy) is\n",
    "limited or non-existent which means that you cannot use those modules in code\n",
    "meant for `Pypy`. \n",
    "\n",
    "You may later want to use a Python module that is not maintained by Anaconda's\n",
    "`conda` manager.  Because Anaconda comes with  the `pip` package manager, which\n",
    "is the main one used outside of scientific Python, you can simply do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Terminal> pip install package_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and `pip` will run out to the web and download the package you want\n",
    "and its dependencies and install them in the existing Anaconda directory tree.\n",
    "This works beautifully in the case where the package in question is\n",
    "pure-Python, without any system-specific dependencies.  Otherwise, this can be\n",
    "a real nightmare, especially on Windows, which lacks freely\n",
    "available Fortran compilers.  If the module in question is a\n",
    "C-library, one way to cope is to install the freely available Visual Studio\n",
    "Community Edition, which usually has enough to compile many C-codes. This\n",
    "platform dependency is the problem that `conda` was designed to solve\n",
    "by making the binary dependencies of the various platforms available instead of\n",
    "attempting to compile them. On a Windows system, if you installed Anaconda and\n",
    "registered it as the default Python installation (it asks during the install\n",
    "process), then you can use the high-quality Python *wheel* files on Christoph\n",
    "Gohlke's laboratory site at the University of California, Irvine where he\n",
    "kindly makes a long list of scientific modules available[^wheel].  Failing this, you can try the `binstar.org` site, which is a\n",
    "community-powered repository of modules that `conda` is capable of installing,\n",
    "but which are not formally supported by Anaconda. Note that `binstar` allows\n",
    "you to share scientific Python configurations with your remote colleagues using\n",
    "authentication so that you can be sure that you are downloading and running\n",
    "code from users you trust.\n",
    "\n",
    "[^wheel]: Wheel files are a Python distribution format that you download and\n",
    "install using `pip` as in `pip install file.whl`.  Christoph names files\n",
    "according to Python version (e.g., `cp27` means Python 2.7) and chipset (e.g.,\n",
    "`amd32` vs.  Intel `win32`). \n",
    "\n",
    "Again, if you are on Windows, and none of the above works, then you may want to\n",
    "consider installing a full virtual machine solution, as provided by VMWare's\n",
    "`Player` or Oracle's `VirtualBox` (both freely available under liberal terms).\n",
    "Using either of these, you can set up a Linux machine running on top of\n",
    "Windows, which should cure these problems entirely! The great part of this\n",
    "approach is that you can share directories between the virtual machine and the\n",
    "Windows system so that you don't have to maintain duplicate data files.\n",
    "Anaconda Linux images are also available on the cloud by IAAS providers like\n",
    "Amazon Web Services and Microsoft Azure.   Note that for the vast majority of users,\n",
    "especially newcomers to Python, the Anaconda distribution should be more than\n",
    "enough on any platform. It is just worth highlighting the Windows-specific\n",
    "issues and associated workarounds early on. Note that there are other\n",
    "well-maintained scientific Python Windows installers like `WinPython` and\n",
    "`PythonXY`. These provide the `spyder` integrated development environment, which\n",
    "is very Matlab-like environment for transitioning Matlab users.\n",
    "\n",
    "# Numpy\n",
    "<div id=\"sec:numpy\"></div>\n",
    "\n",
    "As we touched upon earlier, to use a compiled scientific library, the memory\n",
    "allocated in the Python interpreter must somehow reach this library as input.\n",
    "Furthermore, the output from these libraries must likewise return to the Python\n",
    "interpreter. This two-way exchange of memory is essentially the core function\n",
    "of the Numpy (numerical arrays in Python) module.  Numpy is the de-facto\n",
    "standard for numerical arrays in Python. It arose as an effort by Travis\n",
    "Oliphant and others to unify the numerical arrays in Python.\n",
    "In this section, we provide an overview and some tips for using Numpy\n",
    "effectively, but for much more detail, Travis' book [[oliphant2006guide]](#oliphant2006guide) is\n",
    "a great place to start and is available for free online.\n",
    "\n",
    "Numpy provides specification of byte-sized arrays in Python. For example, below\n",
    "we create an array of three numbers, each of four-bytes long (32 bits at 8 bits\n",
    "per byte) as shown by the `itemsize` property.  Line 1 imports Numpy as `np`,\n",
    "which is the recommended convention. The next line creates an array of 32 bit\n",
    "floating point numbers.  The `itemize` property shows the number of bytes per\n",
    "item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import numpy as np # recommended convention\n",
    ">>> x = np.array([1,2,3],dtype=np.float32)\n",
    ">>> x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x.itemsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to providing uniform containers for numbers, Numpy provides a comprehensive\n",
    "set of unary functions  (i.e., *ufuncs*) that process arrays element-wise without\n",
    "additional looping semantics.  Below, we show how to compute the element-wise\n",
    "sine using Numpy,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.84147096,  0.90929741,  0.14112   ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> np.sin(np.array([1,2,3],dtype=np.float32) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This computes the sine of the input array `[1,2,3]`, using Numpy's unary\n",
    "function, `np.sin`. There is another sine function in the built-in `math`\n",
    "module, but the Numpy version is faster because it does not require explicit\n",
    "looping (i.e., using a `for` loop)  over each of the elements in the array. That\n",
    "looping happens in the compiled `np.sin` function itself. Otherwise we would\n",
    "have to do looping explicitly as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8414709848078965, 0.9092974268256817, 0.1411200080598672]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from math import sin\n",
    ">>> [sin(i) for i in [1,2,3]] # list comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy uses common-sense casting rules to resolve the output types. For example,\n",
    "if the inputs had been an integer-type, the output would still have been a\n",
    "floating point type. In this example, we provided a Numpy array as input to\n",
    "the sine function. We could have also used a plain Python list instead and\n",
    "Numpy would have built the intermediate Numpy array (e.g.,\n",
    "`np.sin([1,1,1])`).  The Numpy documentation provides a comprehensive (and\n",
    "very long) list of available *ufuncs*.\n",
    "\n",
    "Numpy arrays come in many dimensions. For example, the following shows a\n",
    "two-dimensional `2x3` array constructed from two conforming Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x=np.array([ [1,2,3],[4,5,6] ])\n",
    ">>> x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that Numpy is limited to 32 dimensions unless you build it for\n",
    "more [^note]. Numpy arrays follow the usual Python slicing rules in multiple\n",
    "dimensions as shown below where the `:` colon character selects all elements\n",
    "along a particular axis.    \n",
    "\n",
    "[^note]: See `arrayobject.h` in the Numpy source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x=np.array([ [1,2,3],[4,5,6] ])\n",
    ">>> x[:,0] # 0th column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x[:,1] # 1st column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x[0,:] # 0th row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x[1,:] # 1st row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You can also select sub-sections of arrays by using slicing as shown\n",
    "below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    ">>> x=np.array([ [1,2,3],[4,5,6] ])\n",
    ">>> print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x[:,1:] # all rows, 1st thru last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [4, 6]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x[:,::2] # all rows, every other column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1],\n",
       "       [6, 5, 4]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x[:,::-1] # reverse order of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Arrays and Memory\n",
    "<div id=\"sub:numpy_arrays_and_memory\"></div>\n",
    "\n",
    "Some interpreted languages implicitly allocate memory. For example, in\n",
    "Matlab, you can extend a matrix by simply tacking on another dimension\n",
    "as in the following Matlab session:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        >> x=ones(3,3)\n",
    "        x =\n",
    "             1     1     1\n",
    "             1     1     1\n",
    "             1     1     1\n",
    "        >> x(:,4)=ones(3,1) % tack on extra dimension \n",
    "        x =\n",
    "             1     1     1     1\n",
    "             1     1     1     1\n",
    "             1     1     1     1\n",
    "        >> size(x)\n",
    "        ans =\n",
    "             3     4\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This works because Matlab arrays use pass-by-value semantics so that\n",
    "slice operations actually copy parts of the array as needed.  By contrast,\n",
    "Numpy uses pass-by-reference semantics so that slice operations are *views*\n",
    "into the array without implicit copying. This is particularly helpful with\n",
    "large arrays that already strain available memory. In\n",
    "Numpy terminology, *slicing* creates views (no copying) and\n",
    "advanced indexing creates copies. Let's start with advanced indexing.\n",
    "\n",
    "If the indexing object (i.e., the item between the brackets) is a non-tuple\n",
    "sequence object, another Numpy array (of type integer or boolean), or a tuple\n",
    "with at least one sequence object or Numpy array, then indexing creates copies.\n",
    "For the above example, to accomplish the same array extension in Numpy, you\n",
    "have to do something like the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x = np.ones((3,3))\n",
    ">>> x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x[:,[0,1,2,2]] # notice duplicated last dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> y=x[:,[0,1,2,2]] # same as above, but do assign it to y\n",
    ">>> y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Because of advanced indexing, the variable `y` has its own memory\n",
    "because the relevant parts of `x` were copied. To prove it, we assign a new\n",
    "element to `x` and see that  `y` is not updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 999.,    1.,    1.],\n",
       "       [   1.,    1.,    1.],\n",
       "       [   1.,    1.,    1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x[0,0]=999 # change element in x\n",
    ">>> x                         # changed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> y                         # not changed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " However, if we start over and construct `y` by slicing (which makes\n",
    "it a view) as shown below, then the change we made *does* affect `y` because\n",
    "a view is just a window into the same memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 999.,    1.,    1.],\n",
       "       [   1.,    1.,    1.],\n",
       "       [   1.,    1.,    1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x = np.ones((3,3))\n",
    ">>> y = x[:2,:2] # view of upper left piece\n",
    ">>> x[0,0] = 999 # change value\n",
    ">>> x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 999.,    1.],\n",
       "       [   1.,    1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> y# changed y also!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that if you want to explicitly force a copy without any indexing\n",
    "tricks, you can do `y=x.copy()`. The code below works through another example\n",
    "of advanced indexing versus slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x = np.arange(5) # create array\n",
    ">>> x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> y=x[[0,1,2]] # index by integer list to force copy\n",
    ">>> y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> z=x[:3]      # slice creates view\n",
    ">>> z            # note y and z have same entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([999,   1,   2,   3,   4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x[0]=999     # change element of x\n",
    ">>> x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> y            # note y is unaffected,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([999,   1,   2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> z            # but z is (it's a view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  In this example, `y` is a copy, not a view, because it was created\n",
    "using advanced indexing whereas `z` was created using slicing.  Thus, even\n",
    "though `y` and `z` have the same entries, only `z` is affected by changes to\n",
    "`x`. Note that the `flags.ownsdata` property of Numpy arrays can help sort this\n",
    "out until you get used to it.\n",
    "\n",
    "Manipulating memory using views is particularly powerful for signal and image\n",
    "processing algorithms that require overlapping fragments of memory.  The\n",
    "following is an example of how to use advanced Numpy to create overlapping\n",
    "blocks that do not actually consume additional memory,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 2,  3,  4,  5],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 6,  7,  8,  9],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [10, 11, 12, 13],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import arange\n",
    ">>> from numpy.lib.stride_tricks import as_strided\n",
    ">>> x = arange(16)\n",
    ">>> y=as_strided(x,(7,4),(8,4)) # overlapped entries\n",
    ">>> y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The above code creates a range of integers and then overlaps the\n",
    "entries to create a `7x4` Numpy array. The final argument in the `as_strided`\n",
    "function are the strides, which are the steps in bytes to move in the row and\n",
    "column dimensions, respectively. Thus, the resulting array steps four bytes in\n",
    "the column dimension and eight bytes in the row dimension. Because the integer\n",
    "elements in the Numpy array are four bytes, this is equivalent to moving by one\n",
    "element in the column dimension and by two  elements in the row dimension. The\n",
    "second row in the Numpy array starts at eight bytes (two elements) from the\n",
    "first entry (i.e., `2`) and then proceeds by four bytes (by one element) in the\n",
    "column dimension (i.e, `2,3,4,5`). The important part is that memory is re-used\n",
    "in the resulting `7x4` Numpy array. The code below demonstrates this by\n",
    "reassigning elements in the original `x` array. The changes show up in the `y`\n",
    "array because they point at the same allocated memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([99,  1, 99,  3, 99,  5, 99,  7, 99,  9, 99, 11, 99, 13, 99, 15])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x[::2]=99 # assign every other value\n",
    ">>> x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99,  1, 99,  3],\n",
       "       [99,  3, 99,  5],\n",
       "       [99,  5, 99,  7],\n",
       "       [99,  7, 99,  9],\n",
       "       [99,  9, 99, 11],\n",
       "       [99, 11, 99, 13],\n",
       "       [99, 13, 99, 15]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> y # the changes appear because y is a view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Bear in mind that `as_strided` does not\n",
    "check that you stay within memory block bounds. So, if the size of the target\n",
    "matrix is not filled by the available data, the remaining elements will come\n",
    "from whatever bytes are at that memory location. In other words, there is no\n",
    "default filling by zeros or other strategy that defends memory block bounds.\n",
    "One defense is to explicitly control the dimensions as in the following code,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [1, 2, 3, 4],\n",
       "       [2, 3, 4, 5],\n",
       "       [3, 4, 5, 6],\n",
       "       [4, 5, 6, 7]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> n = 8 # number of elements\n",
    "\n",
    ">>> x = arange(n) # create array\n",
    ">>> k = 5 # desired number of rows\n",
    ">>> y = as_strided(x,(k,n-k+1),(x.itemsize,)*2)\n",
    ">>> y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Matrices\n",
    "<div id=\"sub:numpy_matrices\"></div>\n",
    "\n",
    "Matrices in Numpy are similar to Numpy arrays but they can only have two\n",
    "dimensions. They implement row-column matrix multiplication as opposed to\n",
    "element-wise multiplication. If you have two matrices you want to multiply, you\n",
    "can either create them directly or convert them from Numpy arrays. For example,\n",
    "the following shows how to create two matrices and multiply them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1],\n",
       "        [4],\n",
       "        [7]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import numpy as np\n",
    ">>> A=np.matrix([[1,2,3],[4,5,6],[7,8,9]])\n",
    ">>> x=np.matrix([[1],[0],[0]])\n",
    ">>> A*x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This can also be done using arrays as shown below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [4],\n",
       "       [7]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> A=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    ">>> x=np.array([[1],[0],[0]])\n",
    ">>> A.dot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Numpy arrays support elementwise multiplication, not row-column\n",
    "multiplication.  You must use Numpy matrices for this kind of multiplication\n",
    "unless use the inner product `np.dot`, which also works in multiple dimensions\n",
    "(see `np.tensordot` for more general dot products). \n",
    "\n",
    "It is unnecessary to cast everything to matrices for multiplication. In the\n",
    "next example, everything until last line is a Numpy array and thereafter we\n",
    "cast the array as a matrix with `np.matrix` which then uses row-column\n",
    "multiplication.  Note that it is unnecessary to cast the `x` variable as a\n",
    "matrix because the left-to-right order of the evaluation takes care of that\n",
    "automatically.  If we need to use `A` as a matrix elsewhere in the code then we\n",
    "should bind it to another variable instead of re-casting it every time. If you\n",
    "find yourself casting back and forth for large arrays, passing the `copy=False`\n",
    "flag to `matrix` avoids the expense of making a copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> A=np.ones((3,3))\n",
    ">>> type(A) # array not matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x=np.ones((3,1)) # array not matrix\n",
    ">>> A*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 3.],\n",
       "        [ 3.],\n",
       "        [ 3.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> np.matrix(A)*x # row-column multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Broadcasting\n",
    "<div id=\"sub:numpy_broadcasting\"></div>\n",
    "\n",
    "Numpy broadcasting is a powerful way to make implicit multidimensional grids\n",
    "for expressions.  It is probably the single most powerful feature of Numpy and\n",
    "the most difficult to grasp. Proceeding by example, consider the vertices of\n",
    "a two-dimensional unit square as shown below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> X,Y=np.meshgrid(np.arange(2),np.arange(2))\n",
    ">>> X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy's `meshgrid` creates two-dimensional grids.  The `X` and `Y` arrays have\n",
    "corresponding entries match the coordinates of the vertices of the unit square\n",
    "(e.g., $(0,0),(0,1),(1,0),(1,1)$).  To add the x and y-coordinates, we  could\n",
    "use `X` and `Y` as in `X+Y` shown below, The output is the sum of the vertex\n",
    "coordinates of the unit square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> X+Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Because the two arrays have compatible shapes, they can be\n",
    "added together element-wise.  \n",
    "It turns out we can skip a step here and not bother with `meshgrid` to\n",
    "implicitly obtain the vertex coordinates by using broadcasting as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x = np.array([0,1])\n",
    ">>> y = np.array([0,1])\n",
    ">>> x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x + y[:,None] # add broadcast dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> X+Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On line 7 the `None` Python singleton tells Numpy to make copies of `y` along\n",
    "this dimension to create a conformable calculation. Note that `np.newaxis` can\n",
    "be used instead of `None` to be more explicit. The following lines show that we\n",
    "obtain the same output as when we used the `X+Y` Numpy arrays. Note that\n",
    "without broadcasting `x+y=array([0, 2])` which is not what we are trying to\n",
    "compute.  Let's continue with a more complicated example where we have\n",
    "differing array shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x = np.array([0,1])\n",
    ">>> y = np.array([0,1,2])\n",
    ">>> X,Y = np.meshgrid(x,y)\n",
    ">>> X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 1],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 2],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> X+Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 2],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x+y[:,None] # same as with meshgrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the array shapes are different, so the addition of `x` and `y`\n",
    "is not possible without Numpy broadcasting. The last line shows that\n",
    "broadcasting generates the same output as using the compatible array generated\n",
    "by `meshgrid`.  This shows that broadcasting works with different array shapes.\n",
    "For the sake of comparison, on line 3, `meshgrid` creates two conformable\n",
    "arrays, `X` and `Y`.  On the last line, `x+y[:,None]` produces the same output\n",
    "as `X+Y` without the `meshgrid`.  We can also put the `None` dimension on the\n",
    "`x` array as `x[:,None]+y` which would give the transpose of the result.\n",
    "\n",
    "Broadcasting works in multiple dimensions also.   The output shown has shape\n",
    "`(4,3,2)`.  On the last line,  the `x+y[:,None]` produces a two-dimensional\n",
    "array which is then broadcast against `z[:,None,None]`, which duplicates itself\n",
    "along the *two* added dimensions to accommodate the two-dimensional result on\n",
    "its left (i.e.,  `x` + `y[:,None]`).  The caveat about broadcasting is that it\n",
    "can potentially create large, memory-consuming, intermediate arrays. There are methods for\n",
    "controlling this by re-using previously allocated memory but that is beyond our\n",
    "scope here. Formulas in physics that evaluate functions on the vertices of high\n",
    "dimensional grids are great use-cases for broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]],\n",
       "\n",
       "       [[1, 2],\n",
       "        [2, 3],\n",
       "        [3, 4]],\n",
       "\n",
       "       [[2, 3],\n",
       "        [3, 4],\n",
       "        [4, 5]],\n",
       "\n",
       "       [[3, 4],\n",
       "        [4, 5],\n",
       "        [5, 6]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x = np.array([0,1])\n",
    ">>> y = np.array([0,1,2])\n",
    ">>> z = np.array([0,1,2,3])\n",
    ">>> x+y[:,None]+z[:,None,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Masked Arrays\n",
    "\n",
    "Numpy provides a powerful method to temporarily hide array elements without\n",
    "changing the shape of the array itself,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-- -- -- -- -- 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    ">>> from numpy import ma # import masked arrays\n",
    ">>> x = np.arange(10)\n",
    ">>> y = ma.masked_array(x, x<5)\n",
    ">>> print y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> print y.shape\n",
    "(10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that the elements in the array for which the logical condition\n",
    "(`x<5`) is true are masked, but the size of the array remains the same. This is\n",
    "particularly useful in plotting categorical data, where you may only want those\n",
    "values that correspond to a given category for part of the plot. Another common\n",
    "use is for image processing, wherein parts of the image may need to be excluded\n",
    "from subsequent processing. Note that creating a masked array does not force an\n",
    "implicit copy operation unless `copy=True` argument is used. For example,\n",
    "changing an element in `x` *does* change the corresponding element in `y`, even\n",
    "though `y` is a masked array,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8 99]\n"
     ]
    }
   ],
   "source": [
    ">>> x[-1] = 99 # change this\n",
    ">>> print x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-- -- -- -- -- 5 6 7 8 99]\n"
     ]
    }
   ],
   "source": [
    ">>> print y # masked array changed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Optimizations and Prospectus\n",
    "<div id=\"sub:numpy_optimizations\"></div>\n",
    "\n",
    "The scientific Python community continues to push the frontier of scientific\n",
    "computing.  Several important extensions to Numpy are under active\n",
    "development.  First, Numba is a compiler that generates optimized machine\n",
    "code from pure Python code using the LLVM compiler infrastructure. LLVM\n",
    "started as a research project at the University of Illinois to provide a\n",
    "target-independent compilation strategy for arbitrary programming languages\n",
    "and is now a well-established technology.  The combination of LLVM and Python\n",
    "via Numba means that accelerating a block of Python code can be as\n",
    "easy as putting a `@numba.jit` decorator above the function definition, but\n",
    "this doesn't work for all situations.  Numba can target general graphics\n",
    "processing units (GPGPUs) also.\n",
    "\n",
    "Blaze is considered the next generation of Numpy and generalizes the semantics\n",
    "of Numpy for very large data sets that exist on a variety of backend\n",
    "filesystems.  This means that Blaze is designed to handle out-of-core (i.e.,\n",
    "too big to fit in a single workstation's RAM) data manipulations and\n",
    "computations using the familiar operations from Numpy.  Further, Blaze offers\n",
    "tight integration with Pandas (see the section [Pandas](#sec:pandas)) dataframes. Roughly\n",
    "speaking, Blaze understands how to unpack Python expressions and translate them\n",
    "for a variety of distributed backend data services upon which the computing\n",
    "will actually happen (i.e., using `blaze.compute`). This means that Blaze\n",
    "separates the expression of the computation from the particular\n",
    "implementation on a given backend. \n",
    "\n",
    "Building on his amazing work on PyTables, Francesc Alted has\n",
    "been working on the `bcolz` module which is a compressed columnar data container.\n",
    "Also motivated by out-of-core data and computing, `bcolz` tries to relieve\n",
    "the stress of the memory subsystem by compressing data in memory and then\n",
    "interleaving computations on the compressed data in an intelligent way. This\n",
    "approach takes advantage of emerging architectures that have more cores and\n",
    "wider vector units.\n",
    "\n",
    "# Matplotlib\n",
    "<div id=\"sec:matplotlib\"></div>\n",
    "\n",
    "Matplotlib is the primary visualization tool for scientific graphics\n",
    "in Python. Like all great open-source projects, it originated to\n",
    "satisfy a personal need. At the time of its inception, John Hunter\n",
    "primarily used Matlab for scientific visualization, but as he began to\n",
    "integrate data from disparate sources \n",
    "using Python, he realized he needed a Python solution for\n",
    "visualization, so he single-handedly wrote Matplotlib. Since those\n",
    "early years, Matplotlib has displaced the other competing methods for\n",
    "two-dimensional scientific visualization and today is a very actively\n",
    "maintained project, even without John Hunter, who sadly passed away in\n",
    "2012.\n",
    "\n",
    "John had a few basic requirements for Matplotlib:\n",
    "\n",
    "* Plots should look publication quality with beautiful text.\n",
    "\n",
    "* Plots should output Postscript for inclusion within \\LaTeX{} documents and publication quality printing.\n",
    "\n",
    "* Plots should be embeddable in a Graphical User Interface (GUI) for application development.\n",
    "\n",
    "* The code should be mostly Python  to allow for users to become developers. \n",
    "\n",
    "* Plots should be easy to make with just a few lines of code for simple graphs.\n",
    "\n",
    "Each of these requirements has been completely satisfied and\n",
    "Matplotlib's capabilities have grown far beyond these requirements.  In\n",
    "the beginning, to ease the transition from Matlab to Python, many of the\n",
    "Matplotlib functions were closely named after the corresponding Matlab\n",
    "commands.  The community has moved away from this style and, even though you\n",
    "will still find the old Matlab-esque style used in the on-line Matplotlib\n",
    "documentation. \n",
    "\n",
    "The following shows the quickest way to draw a plot using Matplotlib and the\n",
    "plain Python interpreter. Later, we'll see how to do this even faster using\n",
    "IPython.  The first line imports the requisite module as `plt` which is the\n",
    "recommended convention. The next line plots a sequence of numbers generated\n",
    "using Python's `range` function. Note the output list contains a `Line2D`\n",
    "object. This is an *artist* in Matplotlib parlance. Finally, the `plt.show()`\n",
    "function draws the plot in a GUI figure window."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ">>> import matplotlib.pyplot as plt\n",
    ">>> plt.plot(range(10))\n",
    ">>> plt.show() # unnecessary in IPython (discussed later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try this in your own plain Python interpreter (and you should!), you\n",
    "will see that you cannot type in anything further in the interpreter until the\n",
    "figure window (i.e., something like [Figure](#fig:figwin)) is closed. This is because\n",
    "the `plt.show()` function preoccupies the interpreter with the controls in the\n",
    "GUI and *blocks* further interaction.  As we discuss below, IPython provides\n",
    "ways to get around this blocking so you can simultaneously interact with the\n",
    "interpreter and the figure window [^interactive].\n",
    "\n",
    "[^interactive]: You can also do this in the plain Python interpreter by doing\n",
    "`import matplotlib;matplotlib.interactive(True)`.\n",
    "\n",
    "<!-- dom:FIGURE: [fig-python_quick/figure_window.jpg, width=500 frac=0.75] The Matplotlib figure window. The icons on the bottom allow some limited plot-editing tools. <div id=\"fig:figwin\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:figwin\"></div>\n",
    "\n",
    "<p>The Matplotlib figure window. The icons on the bottom allow some limited plot-editing tools.</p>\n",
    "<img src=\"fig-python_quick/figure_window.jpg\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "As shown in [Figure](#fig:figwin), the `plot` function returns a list\n",
    "containing the `Line2D` object.  More complicated plots yield larger lists\n",
    "filled with *artists*. The suggestion is that artists\n",
    "draw on the *canvas* contained in the Matplotlib figure.  The final line is the\n",
    "`plt.show` function that provokes the embedded artists to render on the\n",
    "Matplotlib canvas. The reason this is a separate function is that plots may\n",
    "have dozens of complicated artists and rendering may be a time-consuming task\n",
    "to only be undertaken at the end, when all the artists have been mustered.\n",
    "Matplotlib supports plotting images, contours, and many others\n",
    "that we cover in detail in the following chapters.\n",
    "\n",
    "Even though this is the quickest way to draw a plot in Matplotlib, it is not\n",
    "recommended because there are no handles to the intermediate products of the\n",
    "plot such as the plot's axis. While this is okay for a simple plot like this,\n",
    "later on we will see how to construct complicated plots using the recommended\n",
    "method. There is a close working relationship between Numpy and Matplotlib and\n",
    "you can load Matplotlib's plotting functions and Numpy's functions\n",
    "simultaneously using `pylab` as `from matplotlib.pylab import *`. Although\n",
    "importing everything this way as a standard practice is not recommended because\n",
    "of namespace pollution.\n",
    "\n",
    "One of the best ways to get started with Matplotlib is to browse the extensive\n",
    "on-line gallery of plots on the main Matplotlib site.  Each plot comes\n",
    "with corresponding source code that you can use as a starting point for your\n",
    "own plots. In the section [IPython](#sec:ipython), we discuss special *magic* commands\n",
    "that make this particularly easy. The annual *John Hunter: Excellence in\n",
    "Plotting Contest* provides fantastic, compelling examples of \n",
    "scientific visualizations that are possible using Matplotlib.\n",
    "\n",
    "## Alternatives to Matplotlib\n",
    "<div id=\"sec:alternatives_to_matplotlib\"></div>\n",
    "\n",
    "Even though Matplotlib is unbeatable for script-based plotting, there\n",
    "are some alternatives for specialized scientific graphics that may be\n",
    "of interest. \n",
    "\n",
    "Chaco is part of the Enthought Tool-Suite (ETS) and implements many real-time\n",
    "data visualization concepts and corresponding widgets. It is available on all\n",
    "of the major platforms and is also actively maintained and well-documented.\n",
    "Chaco is geared towards GUI application development, rather than script-based\n",
    "data visualization.  It depends on the `Traits` package, which is also\n",
    "available in ETS and in the Enthought  Canopy.  If you don't want to use\n",
    "Canopy, then you have to build Chaco and its dependencies separately. On Linux,\n",
    "this should be straight-forward, but potentially a nightmare on Windows if not\n",
    "for Christoph Gohlke's installers or Anaconda's `conda` package\n",
    "manager.\n",
    "\n",
    "If you require real-time data display and tools for volumetric data rendering\n",
    "and complicated 3D meshes with isosurfaces, then PyQtGraph is an option.\n",
    "`PyQtGraph` is a pure-Python graphics and GUI library that depends on Python\n",
    "bindings for the Qt GUI library (i.e., `PySide` or `PyQt4`) and Numpy. This means\n",
    "that the `PyQtGraph` relies on these other libraries (especially Qt's `GraphicsView`\n",
    "framework) for the heavy-duty numbercrunching and rendering.  This package is\n",
    "actively maintained, but is still pretty new, with good (but not comprehensive)\n",
    "documentation.  You also need to grasp a few Qt-GUI development concepts to use\n",
    "this effectively.  Mayavi is another Enthought-supported 3D visualization\n",
    "package that sits on VTK (open-source C++ library for 3D visualization). Like\n",
    "Chaco, it is a toolkit for scientific GUI development as opposed to\n",
    "script-based plotting. To use it effectively, you need to already know (or be\n",
    "willing to learn) about graphics pipelines. This package is\n",
    "actively supported and well-documented.\n",
    "\n",
    "An alternative that comes from the `R` community is `ggplot` which is a Python\n",
    "port of the `ggplot2` package that is fundamental to statistical graphics in\n",
    "`R`.  From the Python standpoint, the main advantage of `ggplot` is the tight\n",
    "integration with the Pandas dataframe, which makes it easy to draw beautifully\n",
    "formatted statistical graphs. The downside of this package is  that it applies\n",
    "un-Pythonic semantics based on the *Grammer of Graphics*\n",
    "[[wilkinson2006grammar]](#wilkinson2006grammar), which is nonetheless a well-thought-out method for\n",
    "articulating complicated graphs. Of course, because there are two-way bridges\n",
    "between Python and `R` via the `R2Py` module (among others), it is workable to\n",
    "send Numpy arrays to `R` for native `ggplot2` rendering and then retrieve the\n",
    "so-computed graphic back into Python. This is a workflow that is lubricated by\n",
    "the IPython Notebook via the `rmagic` extension.  Thus, it is quite possible to\n",
    "get the best of both worlds via the IPython Notebook and this kind of\n",
    "multi-language workflow is quite common in data analysis communities.\n",
    "\n",
    "## Extensions to Matplotlib\n",
    "<div id=\"sec:extensions_to_matplotlib\"></div>\n",
    "\n",
    "Initially, to encourage adoption of Matplotlib from Matlab, many of the\n",
    "graphical sensibilities were adopted from Matlab to preserve the look and feel\n",
    "for transitioning users.  Modern sensibilities and prettier default plots are\n",
    "possible because Matplotlib provides the ability to drill down and tweak\n",
    "just about every element on the canvas. However, this can be tedious to do\n",
    "and several alternatives offer relief.  For\n",
    "statistical plots, the first place to look is the `seaborn` module that\n",
    "includes a vast array of beautifully formatted plots including violin plots,\n",
    "kernel density plots, and bivariate histograms.  The `seaborn` gallery\n",
    "includes samples of available plots and the corresponding code that\n",
    "generates them. Note that importing `seaborn` hijacks the default settings\n",
    "for all plots, so you have to coordinate this if you only want to use\n",
    "`seaborn` for some (not all) of your visualizations in a given session.\n",
    "Note that you can find the defaults for Matplotlib in the\n",
    "`matplotlib.rcParams` dictionary.\n",
    "\n",
    "The `prettyplotlib` module, like `seaborn`, provides an intelligent default\n",
    "color palate based on Cynthia Brewer's work on color perception (c.f.\n",
    "`colorbrewer2.org`). Unfortunately, this work is no longer supported by the\n",
    "author, but still provides a great set of plotting tools and designs for\n",
    "building beautiful data visualizations. \n",
    "\n",
    "\n",
    "# IPython\n",
    "<div id=\"sec:ipython\"></div>\n",
    "\n",
    "IPython [[IPython]](#IPython) originated as a way to enhance Python's basic interpreter\n",
    "for smooth interactive scientific development. In the early days, the most\n",
    "important enhancement was tab-completion for dynamic introspection of\n",
    "workspace variables. For example, you can start IPython at the commandline\n",
    "by typing `ipython` and then you should see something like the following in\n",
    "your terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Next, creating a string as shown and hitting the `TAB` key after the\n",
    "`dot` character initiates the introspection, showing all the functions and\n",
    "attributes of the `string` object in `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "x = 'this is a string'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "x.<TAB>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  To get help about any of these, you simply add the\n",
    "`?` character at the end as shown below,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "x.center?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  and IPython provides the built-in help documentation. Note\n",
    "that you can also get this documentation with `help(x.center)`\n",
    "which works in the plain Python interpreter as well. \n",
    "\n",
    "The combination of dynamic tab-based introspection and quick interactive help\n",
    "accelerates development because you can keep your eyes and fingers in one place\n",
    "as you work. This was the original IPython experience, but IPython has since\n",
    "grown into a complete framework for  delivering a rich scientific computing\n",
    "workflow that  retains and enhances these fundamental features.\n",
    "\n",
    "## IPython Notebook\n",
    "<div id=\"sub:ipython_notebook\"></div>\n",
    "\n",
    "<!-- # fix pylab=inline to matplotlib=inline for IPython 3.0 -->\n",
    "\n",
    "As you may have noticed investigating Python on the web, most Python users are\n",
    "web-developers, not scientific programmers, meaning that the Python stack is\n",
    "*very* well developed for web technologies.  The genius of the IPython\n",
    "development team was to leverage these technologies for scientific computing by\n",
    "embedding IPython in modern web-browsers.    In fact, this strategy has been so\n",
    "successful that IPython has moved into other languages beyond Python such as\n",
    "Julia and R as the *Jupyter* project [^jupyter]. \n",
    "\n",
    "[^jupyter]: Because we are primarily focused on Python in this text we will\n",
    "continue to refer to IPython and the IPython Notebook instead of to the more\n",
    "general Jupyter project. At the time of this writing, the re-factorization of\n",
    "IPython into Jupyter has not been completed.\n",
    "\n",
    "After starting the notebook, you should see something like the following in the\n",
    "terminal,"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "        [W 10:26:55.332 NotebookApp] ipywidgets package not installed.  Widgets \n",
    "        [I 10:26:55.348 NotebookApp] Serving notebooks from local directory: D:\\\n",
    "        [I 10:26:55.351 NotebookApp] 0 active kernels\n",
    "        [I 10:26:55.351 NotebookApp] The IPython Notebook is running at: http://\n",
    "        [I 10:26:55.351 NotebookApp] Use Control-C to stop this server and shut \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The first line reveals where IPython  looks for default settings. The\n",
    "next line shows where it looks for documents in the IPython Notebook format.\n",
    "The third line shows that the IPython Notebook started a web-server on the\n",
    "local machine (i.e., `127.0.0.1`) on port number `8888`. This is the address\n",
    "your browser needs to connect to the IPython session although your default\n",
    "browser should have opened automatically to this address.  The port number and\n",
    "other configuration options are available either on the commandline or in the\n",
    "profile file shown in the first line. If you are on a Windows platform and you\n",
    "do not get this far, then the Window's firewall is probably blocking the port.\n",
    "For additonal configuration help, see the main IPython site (`www.ipython.org`)\n",
    "or e-mail the very responsive IPython mailing list\n",
    "(`ipython-dev@scipy.org`).\n",
    "\n",
    "When IPython starts, it initiates many small Python processes that use the\n",
    "blazing-fast `ZeroMQ` message passing framework for interprocess-communication,\n",
    "along with the web-sockets protocol for back-and-forth communication with the\n",
    "browser.  To start IPython and get around your default browser, you can use the\n",
    "additonal `---no-browser` flag and then manually type in the local host address\n",
    "`http://127.0.0.1:8888` into your favorite browser to get started.  Once all\n",
    "that is settled, you should see something like the following [figure](#fig:ipn_001),\n",
    "\n",
    "\n",
    "<!-- dom:FIGURE: [fig-python_quick/ipn_001.png, width=500 frac=0.95]  The IPython Notebook dashboard. <div id=\"fig:ipn_001\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:ipn_001\"></div>\n",
    "\n",
    "<p>The IPython Notebook dashboard.</p>\n",
    "<img src=\"fig-python_quick/ipn_001.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "<!-- dom:FIGURE: [fig-python_quick/ipn_002.png, width=500 frac=0.95]  A new IPython Notebook. <div id=\"fig:ipn_002\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:ipn_002\"></div>\n",
    "\n",
    "<p>A new IPython Notebook.</p>\n",
    "<img src=\"fig-python_quick/ipn_002.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "You can create a new document by clicking the `New Notebook` button shown in\n",
    "[figure](#fig:ipn_001). Then, you should see something like [figure](#fig:ipn_002).  To start using the IPython Notebook, you just start typing\n",
    "code in the shaded textbox and then hit `SHIFT+ENTER` to execute the code in\n",
    "that IPython *cell*.  [Figure](#fig:ipn_003) shows the dynamic introspection\n",
    "in the pulldown menu when you type the `TAB` key after the `x.`. Context-based\n",
    "help is also available as before by using the `?` suffix which opens a help\n",
    "panel at the bottom of the browser window. There are many amazing features\n",
    "including the ability to share notebooks between different users  and to run\n",
    "IPython Notebooks in the Amazon cloud, but these features go beyond our scope\n",
    "here.  Check the `ipython.org` website or peek at the mailing list for the\n",
    "lastest work on these fronts.\n",
    "\n",
    "The IPython Notebook supports high-quality mathematical typesetting using\n",
    "MathJaX, which is a JavaScript implementation of most of \\LaTeX{}, as well as video\n",
    "and other rich content.  The concept of consolidating mathematical algorithm\n",
    "descriptions and the code that implements those algorithms into a shareable\n",
    "document is more important than all of these amazing features.  There is no\n",
    "understating the importance of this in practice because the algorithm\n",
    "documentation (if it exists) is usually in one format and completely separate\n",
    "from the code that implements it.  This common practice leads to\n",
    "un-synchronized documentation and code that renders one or the other useless.\n",
    "The IPython Notebook solves this problem by putting everything into a living\n",
    "shareable  document based upon  open standards and freely available software.\n",
    "IPython Notebooks can even be saved as static HTML documents for those  without\n",
    "Python!\n",
    "\n",
    "Finally, IPython  provides a large set of `magic` commands for creating\n",
    "macros,  profiling, debugging, and viewing codes. A full list of these can be\n",
    "found by typing in `%lsmagic` in IPython. Help on any of these is available\n",
    "using the `?` character suffix.  Some frequently used commands include the\n",
    "`%cd` command that changes the current working directory, the `%ls` command\n",
    "that lists the files in the current directory, and the `%hist` command that\n",
    "shows the history of previous commands (including optional searching).  The\n",
    "most important of these for new users is probably the `%loadpy` command that\n",
    "can load scripts from the local disk or from the web. Using this to explore the\n",
    "Matplotlib gallery is a great way to  experiment with and re-use the plots\n",
    "there.\n",
    "\n",
    "<!-- dom:FIGURE: [fig-python_quick/ipn_003.png, width=500 frac=0.95]  IPython Notebook pulldown completion menu. <div id=\"fig:ipn_003\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:ipn_003\"></div>\n",
    "\n",
    "<p>IPython Notebook pulldown completion menu.</p>\n",
    "<img src=\"fig-python_quick/ipn_003.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "# Scipy\n",
    "<div id=\"sec:scipy\"></div>\n",
    "\n",
    "Scipy was the first consolidated module for a wide range of\n",
    "compiled libraries,  all based on Numpy arrays.  Scipy includes numerous\n",
    "special functions (e.g., Airy, Bessel, elliptical) as well as powerful\n",
    "numerical quadrature routines via the QUADPACK Fortran library (see\n",
    "`scipy.integrate`), where you will also find other quadrature\n",
    "methods. Note that some of the same functions appear in multiple places\n",
    "within Scipy itself as well as in Numpy.  Additionally, Scipy provides\n",
    "access to the ODEPACK library for solving differential equations. Lots of\n",
    "statistical functions, including random number generators, and a wide\n",
    "variety of probability distributions are included in the `scipy.stats`\n",
    "module. Interfaces to the Fortran MINPACK optimization library are provided\n",
    "via `scipy.optimize`. These include methods for root-finding, minimization\n",
    "and maximization problems, with and without higher-order derivatives.\n",
    "Methods for interpolation are provided in the `scipy.interpolate` module via\n",
    "the FITPACK Fortran package.  Note that some of the modules are so big that\n",
    "you do not get all of them with `import scipy` because that would take too\n",
    "long to load. You may have to load some of these packages individually as\n",
    "\\texttt{import scipy.interpolate}, for example. \n",
    "\n",
    "As we discussed, the Scipy module is already packed with an extensive list\n",
    "of scientific codes. For that reason, the `scikits` modules  were originally\n",
    "established as a way to stage candidates that could  eventually make it into\n",
    "the already stuffed Scipy module, but it turns out that  many of these\n",
    "modules became so successful on their own that they  will never be\n",
    "integrated into Scipy  proper. Some examples include `sklearn` for machine\n",
    "learning and `scikit-image` for image processing. \n",
    "\n",
    "# Pandas\n",
    "<div id=\"sec:pandas\"></div>\n",
    "\n",
    "Pandas [[mckinney2012python]](#mckinney2012python) is a powerful module that is optimized on\n",
    "top of Numpy and provides a set of data structures particularly suited to\n",
    "time-series and spreadsheet-style data analysis (think of pivot tables in\n",
    "Excel). If you are familiar with the `R` statistical package, then you can\n",
    "think of Pandas as providing a Numpy-powered dataframe for Python.\n",
    "\n",
    "## Series\n",
    "\n",
    "There are two primary data structures in Pandas. The first is the `Series`\n",
    "object which combines an index and corresponding data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     3\n",
       "2     9\n",
       "3    11\n",
       "4    12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import pandas as pd # recommended convention\n",
    ">>> x=pd.Series(index = range(5),data=[1,3,9,11,12])\n",
    ">>> x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The main thing to keep in mind with Pandas is that these data\n",
    "structures were originally designed to work with time-series data. In that\n",
    "case, the `index` in the data structures corresponds to a sequence of ordered\n",
    "time-stamps. In the general case, the index must be a sort-able array-like\n",
    "entity.  For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     1\n",
       "b     3\n",
       "d     9\n",
       "z    11\n",
       "z    12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x=pd.Series(index = ['a','b','d','z','z'],data=[1,3,9,11,12])\n",
    ">>> x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note the duplicated `z` entries in the `index`.  We can get at the\n",
    "entries in the `Series` in a number of ways. First, we can used the *dot*\n",
    "notation to select as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "z    11\n",
       "z    12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x.z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can also use the indexed-position of the entries with `iloc` as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    3\n",
       "d    9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x.iloc[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " which uses the same slicing syntax as Numpy arrays. You can also\n",
    "slice across the `index`, even if it is not numeric with `loc` as in the\n",
    "following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    3\n",
       "d    9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x.loc['a':'d']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " which you can get directly from the usual slicing notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    3\n",
       "d    9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> x['a':'d']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, unlike Python, slicing this way includes the endpoints. While that\n",
    "is very interesting, the main power of Pandas comes from its power to aggregate\n",
    "and group data. In the following, we build a more interesting `Series` object,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> x = pd.Series(range(5),[1,2,11,9,10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and then group it in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     1\n",
       "10    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> grp=x.groupby(lambda i:i%2) # odd or even\n",
    ">>> grp.get_group(0) # even group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0\n",
       "11    2\n",
       "9     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> grp.get_group(1) # odd group\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The first line groups the elements of the `Series` object by whether\n",
    "or not the index is even or odd. The `lambda` function returns `0` or `1`\n",
    "depending on whether or not the corresponding index is even or odd,\n",
    "respectively. The next line shows the `0` (even) group and then the one\n",
    "after shows the `1` (odd) group. Now, that we have separate groups, we can\n",
    "perform a wide-variety of summarizations on the group.  You can think of these\n",
    "as reducing each group into a single value. For example, in the following, we\n",
    "get the maximum value of each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> grp.max() # max in each group\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that the operation above returns another `Series` object with an\n",
    "`index` corresponding to the `[0,1]` elements.\n",
    "\n",
    "## Dataframe\n",
    "\n",
    "The Pandas `DataFrame` is an encapsulation of the `Series` that extends to\n",
    "two-dimensions. One way to create a `DataFrame` is with dictionaries as in the\n",
    "following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "0     1     9\n",
       "1     3    23\n",
       "2    11     0\n",
       "3     2     2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> df = pd.DataFrame({'col1': [1,3,11,2], 'col2': [9,23,0,2]})\n",
    ">>> df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that the keys in the input dictionary are now the column-headings (labels)\n",
    "of the `DataFrame`, with each corresponding column matching the list of corresponding\n",
    "values from the dictionary. Like the `Series` object, the `DataFrame` also has in `index`,\n",
    "which is the `[0,1,2,3]` column on the far-left. We can extract elements\n",
    "from each column using the `iloc` method as discussed earlier as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "0     1     9\n",
       "1     3    23"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> df.iloc[:2,:2] # get section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " or by directly slicing or by using the *dot* notation as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     3\n",
       "2    11\n",
       "3     2\n",
       "Name: col1, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> df['col1'] # indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     3\n",
       "2    11\n",
       "3     2\n",
       "Name: col1, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> df.col1 # use dot notation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Subsequent operations on the `DataFrame` preserve its column-wise\n",
    "structure as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col1    17\n",
       "col2    34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> df.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where each column was totaled. Grouping and aggregating with the\n",
    "dataframe is even more powerful than with Series. Let's construct the following\n",
    "dataframe,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "0     1     1\n",
       "1     1     2\n",
       "2     0     3\n",
       "3     0     4"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> df = pd.DataFrame({'col1': [1,1,0,0], 'col2': [1,2,3,4]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In the above dataframe, note that the `col1` column has only\n",
    "two entries. We can group the data using this column as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "2     0     3\n",
       "3     0     4"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> grp=df.groupby('col1')\n",
    ">>> grp.get_group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "0     1     1\n",
       "1     1     2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> grp.get_group(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that each group corresponds to entries for which `col1` was\n",
    "either of its two values. Now that we have grouped on `col1`, as with the\n",
    "Series object, we can also functionally summarize each of the groups as in the\n",
    "following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      col2\n",
       "col1      \n",
       "0        7\n",
       "1        3"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> grp.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where the `sum` is applied across each of the Dataframes present in\n",
    "each group. Note that the `index` of the output above is each of the values in\n",
    "the original `col1`.\n",
    "\n",
    "The Dataframe can compute new columns based on existing columns using the\n",
    "`eval` method as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>sum_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2  sum_col\n",
       "0     1     1        2\n",
       "1     1     2        3\n",
       "2     0     3        3\n",
       "3     0     4        4"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> df['sum_col']=df.eval('col1+col2') \n",
    ">>> df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that you can assign the output to a new column to the Dataframe as \n",
    "shown [^numpy_note].  We can group by multiple columns as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> grp=df.groupby(['sum_col','col1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Doing the `sum` operation on each group gives the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_col</th>\n",
       "      <th>col1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              col2\n",
       "sum_col col1      \n",
       "2       1        1\n",
       "3       0        3\n",
       "        1        2\n",
       "4       0        4"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> res=grp.sum()\n",
    ">>> res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This output is much more complicated than anything we have seen so\n",
    "far, so let's carefully walk through it. Below the headers, the first row `2 1\n",
    "1` indicates that for `sum_col=2` and  for all values of `col1` (namely, just\n",
    "the value `1`), the value of `col2` is `1`. For the next row, the same pattern\n",
    "applies except that for `sum_col=3`, there are now two values for `col1`,\n",
    "namely `0` and `1`, which each have their corresponding two values for the\n",
    "`sum` operation in `col2`. This layered display is one way to look at the\n",
    "result. Note that the layers above are not uniform. Alternatively, we can\n",
    "`unstack` this result to obtain the following tabular view of the previous\n",
    "result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">col2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_col</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        col2    \n",
       "col1       0   1\n",
       "sum_col         \n",
       "2        NaN   1\n",
       "3          3   2\n",
       "4          4 NaN"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> res.unstack()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The `NaN` values indicate positions in the table where there is no\n",
    "entry. For example, for the pair `(sum_col=2,col2=0)`, there is no\n",
    "corresponding value in the Dataframe, as you may verify by looking at the\n",
    "penultimate code block. There is also no entry corresponding to the\n",
    "`(sum_col=4,col2=1)` pair. Thus, this shows that the original presentation in\n",
    "the penultimate code block is the same as this one, just without the\n",
    "above-mentioned missing entries indicated by `NaN`.\n",
    "\n",
    "We have barely scratched the surface of what Pandas is capable of and we have\n",
    "completely ignored its powerful features for managing dates and times. The text\n",
    "by Mckinney [[mckinney2012python]](#mckinney2012python) is a very complete and happily readable\n",
    "introduction to Pandas. The online documentation and tutorials at the main\n",
    "Pandas site are also great for diving deeper into Pandas.\n",
    "\n",
    "[^numpy_note]: Note this kind of on-the-fly memory extension is not possible in\n",
    "regular Numpy. For example, `x = np.array([1,2]); x[3]=3` generates\n",
    "an error.\n",
    "\n",
    "\n",
    "# Sympy\n",
    "<div id=\"sec:sympy\"></div>\n",
    "\n",
    "Sympy [[SymPy]](#SymPy) is the main computer algebra module in Python. It is a\n",
    "pure-Python package with no platform-dependencies. With the help of multiple\n",
    "*Google Summer of Code* sponsorships, it has grown into a powerful computer\n",
    "algebra system with many collateral projects that make it faster and\n",
    "integrate it tighter with Numpy and IPython (among others).  Sympy's on-line\n",
    "tutorial is excellent and allows interacting with its embedded code samples\n",
    "in the browser by running the code on the Google App Engine behind the\n",
    "scenes. This provides an excellent way to interact and experiment with\n",
    "Sympy.\n",
    "\n",
    "If you find Sympy too slow or need algorithms that it does not\n",
    "implement, then SAGE is your next stop. The SAGE project is a consolidation of\n",
    "over 70 of the best open source packages for computer algebra and related\n",
    "computation. Although Sympy and SAGE share code freely between them, SAGE is a\n",
    "specialized build of the Python kernel to facilitate deep integration with the\n",
    "underlying libraries.  Thus, it is not a pure-Python solution for computer\n",
    "algebra (i.e., not as portable) and  it is a proper superset of Python with its\n",
    "own extended syntax.  The choice between SAGE and Sympy really depends on\n",
    "whether or not you intend *primarily* work in SAGE or just need *occasional*\n",
    "computer algebra support in your existing Python code. \n",
    "\n",
    "An important new development regarding SAGE is the freely available SAGE Cloud\n",
    "(<https://cloud.sagemath.com/>), sponsored by University of Washington that\n",
    "allows you to use SAGE entirely in the browser with no additional setup.  Both\n",
    "SAGE and Sympy offer tight integration with the IPython Notebook for\n",
    "mathematical typesetting in the browser using MathJaX.\n",
    "\n",
    "To get started with Sympy, you must import the module as usual,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> import sympy as S # might take awhile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " which may take a bit because it is a big package. The next step is\n",
    "to create a Sympy variable as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> x = S.symbols('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we can manipulate this using Sympy functions and Python logic as\n",
    "shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x**2 + x + 1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> p=sum(x**i for i in range(3)) # 2nd order polynomial\n",
    ">>> p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, we can find the roots of this polynomial using Sympy functions,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1/2 - sqrt(3)*I/2, -1/2 + sqrt(3)*I/2]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> S.solve(p) # solves p == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There is also a `sympy.roots` function that provides the same output but as\n",
    "a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1/2 - sqrt(3)*I/2: 1, -1/2 + sqrt(3)*I/2: 1}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> S.roots(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can also have more than one symbolic element in any expression as\n",
    "in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-b + sqrt(-4*a*c + b**2))/(2*a), -(b + sqrt(-4*a*c + b**2))/(2*a)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sympy.abc import a,b,c  # quick way to get common symbols\n",
    ">>> p = a* x**2 + b*x + c \n",
    ">>> S.solve(p,x) # specific solving for x-variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " which is the usual quadratic formula for roots. Sympy also provides\n",
    "many mathematical functions designed to work with Sympy variables. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exp(I*a)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> S.exp(S.I*a) #using Sympy exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can expand this using `expand_complex` to obtain the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I*exp(-im(a))*sin(re(a)) + exp(-im(a))*cos(re(a))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> S.expand_complex(S.exp(S.I*a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " which gives us Euler's formula for the complex exponential. Note that\n",
    "Sympy does not know whether or not `a` is itself a complex number. We can\n",
    "fix this by making that fact part of the construction of `a` as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I*sin(a) + cos(a)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> a = S.symbols('a',real=True)\n",
    ">>> S.expand_complex(S.exp(S.I*a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note the much simpler output this time because we have forced the\n",
    "additional condition on `a`.\n",
    "\n",
    "A powerful way to use Sympy is to construct complicated expressions that you\n",
    "can later evaluate using Numpy via the `lambdify` method. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0200334672085451"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> y = S.tan(x) * x + x**2\n",
    ">>> yf= S.lambdify(x,y,'numpy')\n",
    ">>> y.subs(x,.1) # evaluated using Sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020033467208545055"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> yf(.1) # evaluated using Numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " After creating the Numpy function with `lambdify`, you can use Numpy\n",
    "arrays as input as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  2.55740772, -0.37007973])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> yf(np.arange(3)) # input is Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2.55740772465490, -0.370079726523038]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> [ y.subs(x,i).evalf() for i in range(3) ] # need extra work for Sympy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can get the same output using Sympy, but that requires the extra\n",
    "programming logic shown to do the vectorizing that Numpy performs natively.\n",
    "\n",
    "Once again, we have merely scratched the surface of what Sympy is capable of\n",
    "and the on-line interactive tutorial is the best place to learn more. Sympy\n",
    "also allows automatic mathematical typesetting within the IPython Notebook\n",
    "using \\LaTeX{} so the so-constructed notebooks look almost publication-ready\n",
    "(see `sympy.latex`) and can be made so with the `ipython nbconvert` command.\n",
    "This makes it easier to jump the cognitive gap between the Python code and\n",
    "the symbology of traditional mathematics.\n",
    "\n",
    "# Interfacing with Compiled Libraries\n",
    "<div id=\"sec:interfacing_with_compiled_libraries\"></div>\n",
    "\n",
    "As we have discussed, Python for scientific computing really consists of gluing\n",
    "together different scientific libraries written in a  compiled language like C\n",
    "or Fortran. Ultimately, you may want to use libraries not available with\n",
    "existing Python bindings.  There are many, many options for doing this. The\n",
    "most direct way is to use the built-in `ctypes` module which provides tools for\n",
    "providing input/output pointers to the library's functions just as if you were\n",
    "calling them from a compiled language. This means that you have to know the\n",
    "function signatures in the library *exactly* --- how many bytes for each input\n",
    "and how many bytes for the output. You are responsible for building the inputs\n",
    "exactly the way the library expects and collecting the resulting outputs. Even\n",
    "though this seems tedious, Python bindings for vast libraries have been built\n",
    "this way.\n",
    "\n",
    "If you want an easier way, then `SWIG` is an automatic wrapper generating tool\n",
    "that can provide bindings to a long list of languages, not just Python; so if\n",
    "you need bindings for multiple languages, then this is your best and only\n",
    "option. Using `SWIG` consists of writing an interface file so that the compiled\n",
    "Python dynamically linked library (Python PYD) can be readily imported into the\n",
    "Python interpreter.  Huge and complex libraries like Trilinos (Sandia National\n",
    "Labs) have been interfaced to Python using `SWIG`, so it is a well-tested\n",
    "option. `SWIG` also supports Numpy arrays.\n",
    "\n",
    "However, the `SWIG` model assumes that you want to continue developing\n",
    "primarily in C/Fortran and you are hooking into Python for usability or other\n",
    "reasons. On the other hand, if you start developing algorithms in Python and\n",
    "then want to speed them up, then `Cython` is an excellent option because it\n",
    "provides a mixed language that allows you to have both C-language and Python\n",
    "code intermixed.  Like `SWIG`, you have to write additional files in this\n",
    "hybrid Python/C dialect to have `Cython` generate the C-code that you will\n",
    "ultimately compile. The best part of `Cython` is the profiler that can generate\n",
    "an HTML report showing where the code is slow and could benefit from\n",
    "translation to `Cython`.  The IPython Notebook integrates nicely with `Cython`\n",
    "via its `%cython` magic command. This means you can write `Cython` code in a\n",
    "cell in IPython Notebook and the notebook will handle all of the tedious\n",
    "details like setting up the intermediate files to actually compile the `Cython`\n",
    "extension. `Cython` also supports Numpy arrays.\n",
    "\n",
    "`Cython` and `SWIG` are just two of the ways to create Python bindings for your\n",
    "favorite compiled libraries. Other notable (but less popular) options include\n",
    "`FWrap`, `f2py`, `CFFI`, and `weave`. It is also possible to use Python's own\n",
    "API directly, but this is a difficult undertaking that is hard to justify given the\n",
    "existence of so many well-developed alternatives.  \n",
    "\n",
    "# Integrated Development Environments\n",
    "\n",
    "For those who prefer Integrated Development Environments (IDEs), there is a lot\n",
    "to choose from. The most comprehensive is Enthought Canopy, which includes a\n",
    "rich, syntax-highlighted editor, integrated help, debugger, and even integrated\n",
    "training.  If you are already familiar with Eclipse from other\n",
    "projects, or do mixed-language programming, then there is a Python plugin\n",
    "called `PyDev` that contains all usual features from Eclipse with a Python\n",
    "debugger. Wingware provides an affordable professional-level IDE with\n",
    "multi-project management support and unusually clairvoyant code-completion that\n",
    "works even in debug-mode. Another favorite is PyCharm, which also supports\n",
    "multiple languages and is particularly popular among Python web-developers\n",
    "because it provides powerful templates for popular web frameworks like Django.\n",
    "NinjaIDE is relatively new, but has quickly developed a strong following among\n",
    "Python newcomers because of its beautiful interface and easy-to-get-started\n",
    "framework. If you are a VIM user, then the Jedi plugin provides excellent\n",
    "code-completion that works well with `pylint`, which provides static code\n",
    "analysis (i.e., identifies missing modules and typos). Naturally, `emacs` has\n",
    "many related plugins for developing in Python.  Note that are many other\n",
    "options, but I have tried to emphasize those most suitable for Python\n",
    "beginners. \n",
    "\n",
    "# Quick Guide to Performance and Parallel Programming\n",
    "\n",
    "There are many options available to improve the performance of your Python\n",
    "codes.  The first thing to determine is what is limiting your computation. It\n",
    "could be CPU speed (unlikely), memory limitations (out-of-core computing), or\n",
    "it could be data transfer speed (waiting on data to arrive for processing).  If\n",
    "your code is pure-Python, then you can try running it with `Pypy`, which is is\n",
    "an alternative Python implementation that employs a just-in-time compiler. If\n",
    "your code does not experience a massive speed-up with `Pypy`, then there is\n",
    "probably something external to the code that is slowing it down (e.g., disk\n",
    "access or network access). If `Pypy`  doesn't make any sense because you are\n",
    "using many compiled modules that `Pypy` does not support, then there are many\n",
    "diagnostic tools available.\n",
    "\n",
    "Python has its own built-in profiler `cProfile` you can invoke from the command\n",
    "line as in the following"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "python -m cProfile -o program.prof my_program.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The output of the profiler is saved to the `program.prof` file. This\n",
    "file can be visualized in `runsnakerun` to get a nice graphical picture of\n",
    "where the code is spending the most time. The task manager on your operating\n",
    "system can also provide clues as your program runs to see how it is consuming\n",
    "resources.  The `line_profiler` by Robert Kern provides an excellent way to see\n",
    "how the code is spending its time by annotating each line of the code by its\n",
    "timings.  In combination with `runsnakerun`, this narrows down problems to the\n",
    "line-level from the function-level.\n",
    "\n",
    "The most common situation is that your program is waiting on data from disk or\n",
    "from some busy network resource. This is a common situation in web programming\n",
    "and there are lots of well-established tools to deal with this. Python has a\n",
    "`multiprocessing` module  that is part of the standard library. This makes it\n",
    "easy to spawn child worker processes that can break off and individually\n",
    "process small parts of a big job. However, it is still your responsibility as\n",
    "the programmer to figure out how to distribute the data for your algorithm.\n",
    "Using this module means that the individual processes are to be managed by the\n",
    "operating system, which will be in charge of balancing the load.\n",
    "\n",
    "The basic template for using `multiprocessing` is the following:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# filename multiprocessing_demo.py\n",
    "import multiprocessing\n",
    "import time\n",
    "def worker(k):\n",
    "   'worker function'\n",
    "   print 'am starting process %d' % (k)\n",
    "   time.sleep(10) # wait ten seconds\n",
    "   print 'am done waiting!'\n",
    "   return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   for i in range(10):\n",
    "       p = multiprocessing.Process(target=worker, args=(i,))\n",
    "       p.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then, you run this program at the terminal as in the following,"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "        Terminal> python multiprocessing_demo.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is crucially important that you run the program from the terminal\n",
    "this way. It is not possible to do this interactively from within IPython, say.\n",
    "If you look at the process manager on the operating system, you should see a\n",
    "number of new Python processes loitering for ten seconds. You should also see\n",
    "the output of the `print` statements above. Naturally, in a real application,\n",
    "you would be assigning some meaningful work for each of the workers and\n",
    "figuring out how to send partially finished pieces between individual workers.\n",
    "Doing this is complex and easy to get wrong, so \n",
    "Python 3.2 has the helpful  `concurrent.futures` module that has\n",
    "thankfully been back-ported to Python 2.7 and is available on `pypi`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# filename: concurrent_demo.py\n",
    "import futures\n",
    "import time\n",
    "\n",
    "def worker(k):\n",
    "   'worker function'\n",
    "   print 'am starting process %d' % (k)\n",
    "   time.sleep(10) # wait ten seconds\n",
    "   print 'am done waiting!'\n",
    "   return\n",
    "\n",
    "def main():\n",
    "   with futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "      list(executor.map(worker,range(10)))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Terminal> python concurrent_demo.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You should see something like the following in the terminal. Note that\n",
    "we explicitly restricted the number of processes to three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        am starting process 0\n",
    "        am starting process 1\n",
    "        am starting process 2\n",
    "        am done waiting!\n",
    "        am done waiting!\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `futures` module is built on top of `multiprocessing` and makes it easier to use\n",
    "for this kind of simple task. Note that there are also versions of both that\n",
    "use threads instead of processes while maintaining the same usage pattern.\n",
    "The main difference between threads and processes is that processes have\n",
    "their own compartmentalized resources. The C-language Python (i.e., CPython)\n",
    "implementation uses a Global Interpreter Lock (GIL) that prevents threads from\n",
    "locking up on internal data structures.  This is a \n",
    "course-grained locking mechanism where one thread may individually run\n",
    "faster because it does not have to keep track of all the bookkeeping\n",
    "involved in running multiple threads simultaneously. The downside is that\n",
    "you cannot run multiple threads simultaneously to speed up certain tasks.\n",
    "\n",
    "There is no corresponding locking problem with processes but these are\n",
    "somewhat slower to start up because each process has to create its own\n",
    "private workspace for data structures that may be transferred between them.\n",
    "However, each process can certainly run independently and simultaneously\n",
    "once all that is set up. Note that certain alternative implementations of\n",
    "Python like IronPython use a finer-grain threading design rather than a GIL\n",
    "approach. As a final comment, on modern systems with multiple cores, it\n",
    "could be that multiple threads actually slow things down because the\n",
    "operating system may have to switch threads between different cores. This\n",
    "creates  additional overheads in the thread switching mechanism that\n",
    "ultimately slow things down.\n",
    "\n",
    "IPython  itself has a parallel programming framework built into it that is\n",
    "powerful and easy-to-use. The first step is to fire up separate IPython engines\n",
    "at the terminal as in the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Terminal> ipcluster start --n=4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then, in an IPython window, you can get the client,"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In [1]: from IPython.parallel import Client\n",
    "   ...: rc = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The client has a connection to each of the processes we started\n",
    "before using `ipcluster`. To use all of the engines, we assign the\n",
    "`DirectView` object from the client as in the following,"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In [2]: dview = rc[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, we can apply functions for each of the engines. For example,\n",
    "we can get the process identifiers using the `os.getpid` function,"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In [3]: import os\n",
    "In [4]: dview.apply_sync(os.getpid)\n",
    "Out[4]: [6824, 4752, 8836, 3124]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Once the engines are up and running, data can be distributed to\n",
    "them using `scatter`,"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In [5]: dview.scatter('a',range(10))\n",
    "Out[5]: <AsyncResult: finished>\n",
    "In [6]: dview.execute('print a').display_outputs()\n",
    "[stdout:0] [0, 1, 2]\n",
    "[stdout:1] [3, 4, 5]\n",
    "[stdout:2] [6, 7]\n",
    "[stdout:3] [8, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Note that the `execute` method evaluates the given string in each\n",
    "engine. Now that the data have been sprinkled among the active engines, we can\n",
    "do further computing on them,"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In [7]: dview.execute('b=sum(a)')\n",
    "Out[7]: <AsyncResult: finished>\n",
    "In [8]: dview.execute('print b').display_outputs()\n",
    "[stdout:0] 3\n",
    "[stdout:1] 12\n",
    "[stdout:2] 13\n",
    "[stdout:3] 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this example, we added up the individual `a` sub-lists\n",
    "available on each of the engines. We can gather up the individual results\n",
    "into a single list as in the following,"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In [9]: dview.gather('b').r\n",
    "Out[9]: [3, 12, 13, 17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This is one of the simplest mechanisms for distributing work to  the\n",
    "individual engines and collecting the results. Unlike the\n",
    "other methods we discussed, you can do this iteratively, which\n",
    "makes it easy to experiment with how you want to distribute and\n",
    "compute with the data.  The IPython documentation has\n",
    "many more examples of parallel programming styles that include running the\n",
    "engines on cloud resources, supercomputer clusters, and across disparate\n",
    "networked computing resources.  Although there are many other specialized\n",
    "parallel programming packages, IPython provides the best trade-off for\n",
    "generality against complexity across all of the major platforms.\n",
    "\n",
    "# Other Resources\n",
    "\n",
    "The Python community is filled with super-smart and amazingly helpful people.\n",
    "One of the best places to get help with scientific Python is the\n",
    "`www.stackoverflow.com` site which hosts a competitive Q\\&A forum that is\n",
    "particularly welcoming for Python newbies.  Several of the key Python\n",
    "developers regularly participate there and the quality of the answers is very\n",
    "high.  The mailing lists for any of the key tools (e.g., Numpy, IPython,\n",
    "Matplotlib) are also great for keeping up with the newest developments.\n",
    "Anything written by Hans Petter Langtangen [[TCSE3]](#TCSE3) is excellent, especially\n",
    "if you have a physics background. The Scientific Python conference held\n",
    "annually in Austin is also a great place to see your favorite developers in\n",
    "person, ask questions, and participate in the many interesting sub-groups\n",
    "organized around niche topics. The `PyData` workshop is a semi-annual\n",
    "meeting focused on Python for large-scale data-intensive processing.  The\n",
    "`PyVideo` site provides links to videos of talks and tutorials related to\n",
    "Python from around the world. A great article that summarizes best practices\n",
    "in Python for science is [[abs-1210-0530]](#abs-1210-0530)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
