{
 "metadata": {
  "name": "",
  "signature": "sha256:8c43cbb07ca71966152c95e40d34835d917bf1d5217c45f54c30814c9ac5512d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": [],
     "source": [
      "> This is one of the 100 recipes of the [IPython Cookbook](http://ipython-books.github.io/), the definitive guide to high-performance scientific computing and data science in Python."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 8.7. Reducing the dimensionality of a data with a Principal Component Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. We import NumPy, matplotlib, and scikit-learn."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import sklearn\n",
      "import sklearn.decomposition as dec\n",
      "import sklearn.datasets as ds\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2. The Iris flower dataset is available in the *datasets* module of scikit-learn."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris = ds.load_iris()\n",
      "X = iris.data\n",
      "y = iris.target\n",
      "print(X.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3. Each row contains four parameters related to the morphology of the flower. Let's display the first two components in two dimensions. The color reflects the iris variety of the flower (the label, between 0 and 2)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(6,3));\n",
      "plt.scatter(X[:,0], X[:,1], c=y,\n",
      "            s=30, cmap=plt.cm.rainbow);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "4. We now apply PCA on the dataset to get the transformed matrix. This operation can be done in a single line with scikit-learn: we instantiate a `PCA` model, and call the `fit_transform` method. This function computes the principal components first, and projects the data then."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_bis = dec.PCA().fit_transform(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "5. We now display the same dataset, but in a new coordinate system (or equivalently, a linearly transformed version of the initial dataset)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(6,3));\n",
      "plt.scatter(X_bis[:,0], X_bis[:,1], c=y,\n",
      "            s=30, cmap=plt.cm.rainbow);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Points belonging to the same classes are now grouped together, even though the `PCA` estimator dit *not* use the labels. The PCA was able to find a projection maximizing the variance, which corresponds here to a projection where the classes are well separated."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "6. The `scikit.decomposition` module contains several variants of the classic `PCA` estimator: `ProbabilisticPCA`, `SparsePCA`, `RandomizedPCA`, `KernelPCA`... As an example, let's take a look at `KernelPCA`, a non-linear version of PCA."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_ter = dec.KernelPCA(kernel='rbf').fit_transform(X)\n",
      "plt.figure(figsize=(6,3));\n",
      "plt.scatter(X_ter[:,0], X_ter[:,1], c=y, s=30, cmap=plt.cm.rainbow);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> You'll find all the explanations, figures, references, and much more in the book (to be released later this summer).\n",
      "\n",
      "> [IPython Cookbook](http://ipython-books.github.io/), by [Cyrille Rossant](http://cyrille.rossant.net), Packt Publishing, 2014 (400 pages). [Get a 50% discount by pre-ordering now](http://www.packtpub.com/ipython-interactive-computing-and-visualization-cookbook/book) with the code `PICVCEB` (time-limited offer)!"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}