{
 "metadata": {
  "name": "",
  "signature": "sha256:eb852859f6a9c341172dc0a05da625b48842368b8175052cfc4eff51289f36e3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this recipe we'll do exhaustive grid search though scikit-learn.  This is basically the same thing we did in the previous recipe but we'll utilize built-in methods.\n",
      "\n",
      "We'll also walk though an example of doing randomized optimization.  This is an alternative to brute force search.  Essentially we're trading computer cycles for make sure we search the entire space.  We were fairly calm in the last recipe.  But you could imagine a model that has several steps, Imputation to PCA to Classification.  That parameter space could get very large very fast, therefore it can be adventagous to only search part of that space."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Getting Ready"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get started we'll need to\n",
      "\n",
      "1. Create a some classifiaction data.\n",
      "2. We'll then create a LogisticRegression object that will be the model we're fitting\n",
      "3. After that we'll create the search objects, `GridSearch` and `RandomizedSearchCV`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# How to do it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import make_classification"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = make_classification(1000, n_features=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, so no we'll create our logistic regression object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr = LogisticRegression(class_weight='auto')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, so no we need to specify the parameters we want to search.  For `GridSearch` we can just specify the ranges that we care about, but for `RandomizedSearchCV` we'll use need to actually specify the distribution over the same space from which to sample."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "LogisticRegression(C=1.0, class_weight={0: 0.25, 1: 0.75}, dual=False,\n",
        "          fit_intercept=True, intercept_scaling=1, penalty='l2',\n",
        "          random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_search_params = {\n",
      "    'penalty': ['l1', 'l2'],\n",
      "    'C': [1, 2, 3, 4]\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The only change we'll need to make is to describe the `C` parameter as a probability distribution.  We'll keep it simple right now.  Though we will use scipy to describe the distribution."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.stats as st\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random_search_params = {\n",
      "    'penalty': ['l1', 'l2'],\n",
      "    'C': st.randint(1, 4)\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#How it works"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So now we'll fit the classifier.   This works by passing `lr` to the parameter search objects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs = GridSearchCV(lr, grid_search_params)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "GridSearchCV implements the same API as the other models."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=LogisticRegression(C=1.0, class_weight='auto', dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'penalty': ['l1', 'l2'], 'C': [1, 2, 3, 4]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we can see with the `param_grid` parameter, our `penalty` and `C` are both arrays.\n",
      "\n",
      "To access the scores we can use the `grid_scores_` attribute of the grid search.  We also will want to find the optimimal set of parameters.  We can also look at the marginal performance of the "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "[mean: 0.90300, std: 0.01192, params: {'penalty': 'l1', 'C': 1},\n",
        " mean: 0.90100, std: 0.01258, params: {'penalty': 'l2', 'C': 1},\n",
        " mean: 0.90200, std: 0.01117, params: {'penalty': 'l1', 'C': 2},\n",
        " mean: 0.90100, std: 0.01258, params: {'penalty': 'l2', 'C': 2},\n",
        " mean: 0.90200, std: 0.01117, params: {'penalty': 'l1', 'C': 3},\n",
        " mean: 0.90100, std: 0.01258, params: {'penalty': 'l2', 'C': 3},\n",
        " mean: 0.90100, std: 0.01258, params: {'penalty': 'l1', 'C': 4},\n",
        " mean: 0.90100, std: 0.01258, params: {'penalty': 'l2', 'C': 4}]"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So now we might want to get the max score."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.grid_scores_[1][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "0.90100000000000002"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max(gs.grid_scores_, key=lambda x: x[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "mean: 0.90300, std: 0.01192, params: {'penalty': 'l1', 'C': 1}"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The parameters then are the best choices for our logistic regression."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}