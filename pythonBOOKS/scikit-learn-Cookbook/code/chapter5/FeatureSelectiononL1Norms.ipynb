{
 "metadata": {
  "name": "",
  "signature": "sha256:a9f5c9c1a85db3d2a429e26a81e7b747c4575cec7773e530fbd859abfcd7b169"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We're going to work with some similar ideas as we talked about in the recipe on Lasso Regression.  In that recipe we looked at the number of features that had zero coefficients.\n",
      "\n",
      "Now we're going to take this a step further and use the spareness associated with l1 norms to preprocess the features."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Getting Ready"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll use the diabetes dataset to fit a regression.  First we'll fit a basic `LinearRegression` model with a `ShuffleSplit` cross validation.  After we do that we'll use `LassoRegression` to find the coefficients that are 0 when using an `l1` penalty.  This hopefully will help to avoid overfitting.\n",
      "\n",
      "We're going to\n",
      "\n",
      "1. Load the dataset\n",
      "2. Fit a basic Linear Regression Model\n",
      "3. Use Feature Selection to remove uninformative features.\n",
      "4. Refit the Linear Regression and check to see how well it fits verse the fully featured model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#How to do it"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First let's get the dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.datasets as ds\n",
      "diabetes = ds.load_diabetes()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok let's create the `LinearRegression` object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model\n",
      "lr = linear_model.LinearRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's also import the metrics module for the `mean_squared_error` function, and the `cross_validation` module for the `ShuffleSplit` cross validation scheme."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "from sklearn import cross_validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "shuff = cross_validation.ShuffleSplit(diabetes.target.size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's fit the model, and we'll keep track of the mean squared error for each iteration of `ShuffleSplit`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mses = []\n",
      "for train, test in shuff:\n",
      "    train_X = diabetes.data[train]\n",
      "    train_y = diabetes.target[train]\n",
      "    \n",
      "    test_X = diabetes.data[~train]\n",
      "    test_y = diabetes.target[~train]\n",
      "    \n",
      "    lr.fit(train_X, train_y)\n",
      "    \n",
      "    mses.append(metrics.mean_squared_error(test_y, lr.predict(test_X)))\n",
      "    \n",
      "np.mean(mses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "2856.366626198198"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So now that we have the regular fit, let's check it after we elimate any features with a zero for the coefficient.  Let's fit the Lasso Regression."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import feature_selection\n",
      "from sklearn import cross_validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = linear_model.LassoCV()\n",
      "cv.fit(diabetes.data, diabetes.target)\n",
      "cv.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 76,
       "text": [
        "array([  -0.        , -226.2375274 ,  526.85738059,  314.44026013,\n",
        "       -196.92164002,    1.48742026, -151.78054083,  106.52846989,\n",
        "        530.58541123,   64.50588257])"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So we'll remove the first feature, I'll use a numpy array to represent the \"columns\" that are to be included in the model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "columns = np.arange(diabetes.data.shape[1])[cv.coef_ != 0]\n",
      "columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 77,
       "text": [
        "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, so now we'll fit the model with the specific features (see the `columns` in teh following code block)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l1mses = []\n",
      "\n",
      "for train, test in shuff:\n",
      "    train_X = diabetes.data[train][:, columns]\n",
      "    train_y = diabetes.target[train]\n",
      "    \n",
      "    test_X = diabetes.data[~train][:, columns]\n",
      "    test_y = diabetes.target[~train]\n",
      "    \n",
      "    lr.fit(train_X, train_y)\n",
      "    \n",
      "    l1mses.append(metrics.mean_squared_error(test_y, lr.predict(test_X)))\n",
      "\n",
      "np.mean(l1mses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 78,
       "text": [
        "2861.0763924492171"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(l1mses) - np.mean(mses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "4.7097662510191185"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we can see even though uninformative feature the model still fits worse.  This isn't always the case.  In the next section we'll compare a fit between models were there are very many uniformative features."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# How it works"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First we're going to create a regression dataset with many unformative features."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = ds.make_regression(noise=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So now if we fit a normal regression."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mses = []\n",
      "\n",
      "shuff = cross_validation.ShuffleSplit(y.size)\n",
      "\n",
      "for train, test in shuff:\n",
      "    train_X = X[train]\n",
      "    train_y = y[train]\n",
      "    \n",
      "    test_X = X[~train]\n",
      "    test_y = y[~train]\n",
      "    \n",
      "    lr.fit(train_X, train_y)\n",
      "    \n",
      "    mses.append(metrics.mean_squared_error(test_y, lr.predict(test_X)))\n",
      "    \n",
      "np.mean(mses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 101,
       "text": [
        "879.75447864034209"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can walk through the same process for `LassoRegression`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "LassoCV(alphas=None, copy_X=True, cv=None, eps=0.001, fit_intercept=True,\n",
        "    max_iter=1000, n_alphas=100, n_jobs=1, normalize=False, positive=False,\n",
        "    precompute='auto', tol=0.0001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll create the columns again.  This is a nice pattern that will allow use to specify the features we want to include."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "columns = np.arange(X.shape[1])[cv.coef_ != 0]\n",
      "columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 103,
       "text": [
        "array([11, 15, 17, 20, 21, 25, 30, 33, 35, 36, 40, 45, 46, 49, 51, 56, 60,\n",
        "       61, 69, 72, 82, 85, 87, 88, 90, 91, 92, 99])"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mses = []\n",
      "\n",
      "shuff = cross_validation.ShuffleSplit(y.size)\n",
      "\n",
      "for train, test in shuff:\n",
      "    train_X = X[train][:, columns]\n",
      "    train_y = y[train]\n",
      "    \n",
      "    test_X = X[~train][:, columns]\n",
      "    test_y = y[~train]\n",
      "    \n",
      "    lr.fit(train_X, train_y)\n",
      "    \n",
      "    mses.append(metrics.mean_squared_error(test_y, lr.predict(test_X)))\n",
      "    \n",
      "np.mean(mses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 106,
       "text": [
        "15.755403220117708"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we can see we get an extreme improvement in the fit of model.  The just exemplfies that we need to be cognazant that not all the models need or should be thrown into the model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}