{
 "metadata": {
  "name": "",
  "signature": "sha256:58abded986a8732c95cdef46495816841d6f1de3ff0867dab379a3fc4239c9eb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We've hinted at this in some of the earlier chapters, but in this chapter we are going to fomalize some perviously seen metrics, and expand upon them."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Getting Ready"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to do that we're going to\n",
      "\n",
      "1. Create a function that generates random predictions (though tunable)\n",
      "2. Show the metrics of the fake fit\n",
      "3. Use our function to show how the metrics change at various tunings of the random guess"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# How to do it"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It's often very difficult to write good code while also doing good exploratory analysis.  It's important (especially if you're mainly a programmer) to try to retain good habits."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "def fake_preditions(accuracy, class_percent, N=int(1e3)):\n",
      "    \"\"\" Generate a tuple of (y_preds, y_actuals) that \n",
      "    agree at the accuracy.  class_percent is the\n",
      "    percentage of class the predictions are made up of\n",
      "    each class.\n",
      "    \"\"\"\n",
      "    \n",
      "    actuals = np.random.binomial(1, class_percent, N).astype(np.bool)\n",
      "    preds = actuals.copy()\n",
      "    \n",
      "    wrong_count = int((1 - accuracy) * N)\n",
      "    \n",
      "    preds[:wrong_count] = ~preds[:wrong_count]\n",
      "    \n",
      "    return actuals, preds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This'll actually return boolean values, but the thing with numpy arrays and booleans, is that most of the time we deal with booleans we can deal with integers the same way, so we can take the mean all the same."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "actuals, preds = fake_preditions(.5, .5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's test that our function does what we expect."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(actuals == preds).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "0.5"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(actuals) # for variety"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "0.48699999999999999"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can start to use the built in metrics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    }
   ],
   "metadata": {}
  }
 ]
}