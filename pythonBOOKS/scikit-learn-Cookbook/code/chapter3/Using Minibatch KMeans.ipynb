{
 "metadata": {
  "name": "",
  "signature": "sha256:d937945e43e263ebb089d4c4ec58fb53ef90def64b8ef9d3d950a92497a137ef"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.set_option('display.max_columns', 500)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Getting Ready\n",
      "\n",
      "Minibatch KMeans is a faster implementation of KMeans.  KMeans is very computationally expensive, the solution is NP-Hard.\n",
      "\n",
      "However, by using Minibatch KMeans we can speed up KMeans by orders of magnitude.  This is acheived by taking many subsamples - minibatches - and given the convergence properties of subsampling, a close approximation to regular KMeans acheived given good initial conditions."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#How to do it"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's do some very high level profiling of Minibatch Clustering.  First we'll look at the overall speed difference, and second we'll look at the error in the estimates.\n",
      "\n",
      "Please understand that these metrics are meant to expose the issue, therefore great care is not taken to ensure the highest accuracy of the benchmarks."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import make_blobs\n",
      "blobs, labels = make_blobs(int(1e6), 3)\n",
      "from sklearn.cluster import KMeans, MiniBatchKMeans "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kmeans = KMeans(n_clusters=3)\n",
      "minibatch = MiniBatchKMeans(n_clusters=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time kmeans.fit(blobs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 8.8 s, sys: 848 ms, total: 9.65 s\n",
        "Wall time: 12.1 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=3, n_init=10,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=0)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time minibatch.fit(blobs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4.04 s, sys: 90.1 ms, total: 4.13 s\n",
        "Wall time: 4.69 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
        "        init_size=None, max_iter=100, max_no_improvement=10, n_clusters=3,\n",
        "        n_init=3, random_state=None, reassignment_ratio=0.01, tol=0.0,\n",
        "        verbose=0)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There's as a huge difference in CPU times.  But what's the difference in clustering performance."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kmeans.cluster_centers_[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([ 1.10522173, -5.59610761, -8.35565134])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minibatch.cluster_centers_[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([ 1.12071187, -5.61215116, -8.32015587])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import pairwise"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pairwise.pairwise_distances(kmeans.cluster_centers_[0], minibatch.cluster_centers_[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([[ 0.04191979]])"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Those seems to be very close.  The diagionals the pairwise distance function matrix will contain the cluster center differences."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.diag?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.diag(pairwise.pairwise_distances(kmeans.cluster_centers_, minibatch.cluster_centers_))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "array([ 0.04191979,  0.03133651,  0.04342707])"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#How it works"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The batches here are key.  Batches are iterated through finding the batch mean, then for the next iteration the prior batch mean is updated in relation to the current iteration.  There are several options that dictate the general KMeans behavior, but also parameters that determine how Minibatch KMeans updates.\n",
      "\n",
      "`batch_size` determines how large the batches should be how big to create the batches.  Just for fun, let's run MiniBatch, but with the batch size teh same as the dataset size."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minibatch = MiniBatchKMeans(batch_size=len(blobs))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time minibatch.fit(blobs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 34.6 s, sys: 3.17 s, total: 37.8 s\n",
        "Wall time: 44.6 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "MiniBatchKMeans(batch_size=1000000, compute_labels=True, init='k-means++',\n",
        "        init_size=None, max_iter=100, max_no_improvement=10, n_clusters=8,\n",
        "        n_init=3, random_state=None, reassignment_ratio=0.01, tol=0.0,\n",
        "        verbose=0)"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Clearly this is against the spirit of the problem, but it does illustrate an important point.  Choosing poor initial conditions can affect how well models, and particualrily custering models, converge.  There is no guarentee with MiniBatch KMeans that the global omtimum will be acheived."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}