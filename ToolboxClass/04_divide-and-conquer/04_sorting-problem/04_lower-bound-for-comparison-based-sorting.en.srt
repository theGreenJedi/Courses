1
00:00:00,330 --> 00:00:05,420
In the previous video, we proved that
the running time of the Warshall

2
00:00:05,420 --> 00:00:10,510
algorithm on a sequence consisting
of n elements is big log of n.

3
00:00:10,510 --> 00:00:15,220
In this video we will show that
this bond is essentially optimal.

4
00:00:15,220 --> 00:00:19,370
We will do this by showing that
any correct sorting algorithm

5
00:00:19,370 --> 00:00:22,810
that sorts an object by
comparing pairs of them.

6
00:00:22,810 --> 00:00:29,170
Must make a clear stand log in operation
such as particularly in the worst case.

7
00:00:29,170 --> 00:00:33,950
Once again we say that the sorting
algorithm is comparison based

8
00:00:33,950 --> 00:00:39,310
if it sorts the given objects
just by comparing pairs of them.

9
00:00:39,310 --> 00:00:44,400
We can imagine the following situation, we
have add objects, that look the same, for

10
00:00:44,400 --> 00:00:47,730
example in walls, but
have different weights.

11
00:00:47,730 --> 00:00:49,420
And we also have pen balance.

12
00:00:49,420 --> 00:00:54,210
And this pen balance is, our only
way to compare pairs of these balls.

13
00:00:54,210 --> 00:00:59,040
And our goal is to rearrange these balls,
in order of increasing weights.

14
00:01:00,100 --> 00:01:05,280
So, for example, the two source and
algorithms that we'll already consider it,

15
00:01:05,280 --> 00:01:09,048
namely the selection sort algorithm and
the merge sort algorithm are both

16
00:01:09,048 --> 00:01:13,400
comparison based algorithms.

17
00:01:13,400 --> 00:01:18,182
So for example, the selection
sort algorithm at each region

18
00:01:18,182 --> 00:01:23,580
finds the minimum value in
the remaining part of the array.

19
00:01:23,580 --> 00:01:28,240
And it does so exactly by
comparing pairs of objects, right?

20
00:01:28,240 --> 00:01:32,150
Also, the merge sort algorithm is
also comparison based algorithm.

21
00:01:32,150 --> 00:01:35,020
So it first splits an array into halves.

22
00:01:35,020 --> 00:01:38,870
And then it needs to merge
the two results in arrays.

23
00:01:38,870 --> 00:01:44,050
And when merging the results in arrays,
it also uses comparisons, right?

24
00:01:44,050 --> 00:01:47,780
So we take the first two
elements of two sorted arrays.

25
00:01:47,780 --> 00:01:52,260
We compare them, and based on this
comparison we take one of these elements

26
00:01:52,260 --> 00:01:57,790
out of one of those two arrays and
put it to the result in the array.

27
00:01:57,790 --> 00:02:01,310
So this as a formal statement
that we're going to prove.

28
00:02:01,310 --> 00:02:06,000
It says that any
comparison based algorithm

29
00:02:06,000 --> 00:02:09,480
that sorts an object has running time.

30
00:02:09,480 --> 00:02:14,110
At least big and
n log n in the worst case.

31
00:02:14,110 --> 00:02:18,500
So but
in otherwise we can say the following.

32
00:02:18,500 --> 00:02:22,310
Assume that you have an algorithm
that sorts an object

33
00:02:22,310 --> 00:02:24,500
by comparing pairs of them.

34
00:02:24,500 --> 00:02:28,810
It can be the case that for
some given both sequences of an object,

35
00:02:28,810 --> 00:02:33,010
your algorithm performs less
than analog operations.

36
00:02:33,010 --> 00:02:35,370
Say, linear number of operations.

37
00:02:35,370 --> 00:02:41,420
However, it cannot be the case that
your algorithm always sorts in time,

38
00:02:41,420 --> 00:02:43,690
asymptotically less than n log n.

39
00:02:43,690 --> 00:02:49,330
Meaning that, there must exist, sequence
of objects, on which your algorithm

40
00:02:50,490 --> 00:02:57,780
will perform at least performing a login
comparison to sort such sequences.

41
00:02:57,780 --> 00:03:03,800
Any comparison based algorithm can be
shown as a huge tree that contains all

42
00:03:03,800 --> 00:03:09,330
possible sequences of comparisons
that can be made by this algorithm.

43
00:03:09,330 --> 00:03:11,810
For example, here on the slide.

44
00:03:11,810 --> 00:03:16,177
We show a simple algorithm
that sort three object.

45
00:03:16,177 --> 00:03:17,800
Three objects.

46
00:03:17,800 --> 00:03:22,110
So it starts by comparing a1 and a2.

47
00:03:22,110 --> 00:03:26,243
If a1 happens to be smaller than a2,

48
00:03:26,243 --> 00:03:31,492
then we proceed to comparing a2 and a3.

49
00:03:31,492 --> 00:03:36,810
If a2 is smaller than a3,
then we already know the permutation

50
00:03:36,810 --> 00:03:40,590
of the input three objects
in non-decreasing order.

51
00:03:40,590 --> 00:03:43,220
Namely, we know that
a1 is smaller than a2,

52
00:03:43,220 --> 00:03:45,550
and we know that a2 is smaller than a3.

53
00:03:45,550 --> 00:03:48,890
So we can just output
the following permutation.

54
00:03:49,940 --> 00:03:50,910
Right.

55
00:03:50,910 --> 00:03:55,691
If on the other hand,
a2 happened to be at least a3,

56
00:03:55,691 --> 00:04:01,340
then at this point we already
know that a2 is greater than a1.

57
00:04:01,340 --> 00:04:03,445
And a2 Is no smaller than a3.

58
00:04:03,445 --> 00:04:08,925
So at this point, we know that a2 is the
maximum element among our three elements.

59
00:04:08,925 --> 00:04:14,905
However, we still need to compare a1 and
a3, so we do this comparison,

60
00:04:14,905 --> 00:04:20,015
and based on its result, we output either
this permutation or this permutation.

61
00:04:21,400 --> 00:04:26,120
Well this was the case when a1
happened to be small as an a2.

62
00:04:26,120 --> 00:04:30,940
However we need also to consider the case
when a1 happened to be at least a2.

63
00:04:32,430 --> 00:04:34,620
So we proceed similarly in this case.

64
00:04:34,620 --> 00:04:38,510
So this is just a toy example for
an algorithm for

65
00:04:38,510 --> 00:04:42,940
a comparison based algorithm comparing
three objects, sorting three objects.

66
00:04:42,940 --> 00:04:49,140
However, such a huge tree can be drawn for
any comparison based health algorithm.

67
00:04:49,140 --> 00:04:52,590
So at the root of this tree
we have the first comparison.

68
00:04:52,590 --> 00:04:57,960
And its children will label just the next

69
00:04:57,960 --> 00:05:02,530
comparison that is made based on the
result of the first comparison and so on.

70
00:05:02,530 --> 00:05:06,030
So each internal node is
labeled with some comparison.

71
00:05:06,030 --> 00:05:11,230
And each leaf is labeled with
a permutation of m input objects.

72
00:05:12,320 --> 00:05:18,340
A simple but crucial for this argument
observation is that in this tree,

73
00:05:18,340 --> 00:05:22,020
we must have at least n factorial leaves.

74
00:05:22,020 --> 00:05:28,590
And this is because we have n factorial
different permutations of n input objects.

75
00:05:28,590 --> 00:05:33,720
Where n factorial is defined to be
the product of n and minus one and

76
00:05:33,720 --> 00:05:35,720
minus two and so on.

77
00:05:35,720 --> 00:05:37,210
So why is that?

78
00:05:37,210 --> 00:05:42,100
Why we must have any possible
permutation as a leaf in our tree?

79
00:05:42,100 --> 00:05:47,540
Well, this is just because it is possible
that this permutation is a lead output,

80
00:05:47,540 --> 00:05:49,520
is the right output of our algorithm.

81
00:05:49,520 --> 00:05:55,670
So for example on our previous slide, on
our toy example, we have three objects and

82
00:05:55,670 --> 00:05:59,250
there are six possible permutations
of these three objects, and

83
00:05:59,250 --> 00:06:01,230
there are six leaves in our tree.

84
00:06:01,230 --> 00:06:06,540
For example one of them is 213 and
it says that the second element

85
00:06:06,540 --> 00:06:11,080
is the smallest one, then goes the first
element, and then goes the third element.

86
00:06:11,080 --> 00:06:14,690
And indeed there are cases
when this is the right answer.

87
00:06:14,690 --> 00:06:15,200
Right?

88
00:06:15,200 --> 00:06:17,960
So when the input data
consists of three objects,

89
00:06:17,960 --> 00:06:21,000
such that the second element
is the smallest one,

90
00:06:21,000 --> 00:06:26,770
the first one is the next one, and
the third element is the largest one.

91
00:06:26,770 --> 00:06:27,500
Right?

92
00:06:27,500 --> 00:06:34,450
So once again, you have a huge tree which
carries a comparison based algorithm.

93
00:06:34,450 --> 00:06:37,670
There must be at least n factorial leaves,

94
00:06:37,670 --> 00:06:42,730
because each possible permutation must
be present as a leaf in our tree.

95
00:06:44,360 --> 00:06:49,140
So on the other hand the maximal number of

96
00:06:49,140 --> 00:06:54,650
comparisons made by our algorithm
corresponds to the depths of our tree.

97
00:06:54,650 --> 00:06:59,520
So the depths is defined as
the maximal number of edges run away

98
00:06:59,520 --> 00:07:04,620
from the root to the leaf,
to some leaf of our tree.

99
00:07:04,620 --> 00:07:09,350
So and this is exactly the maximal
possible number of comparisons

100
00:07:09,350 --> 00:07:11,400
which our algorithm makes.

101
00:07:11,400 --> 00:07:16,600
So now we would like to show that
d must be large in our case,

102
00:07:16,600 --> 00:07:19,420
must be at least be big
O omega of analog n.

103
00:07:19,420 --> 00:07:23,660
And we know already that our
tree contains many, many leaves.

104
00:07:23,660 --> 00:07:28,220
Mean n factorial is a function
that grows extremely fast.

105
00:07:28,220 --> 00:07:32,340
Okay so, intuitively we would like
to show that if a tree has many,

106
00:07:32,340 --> 00:07:36,240
many leaves, then it has a large depth.

107
00:07:36,240 --> 00:07:38,840
And at least intuitively this clear.

108
00:07:38,840 --> 00:07:46,560
If you have a tree of very small depths
then it must just a few leaves, right?

109
00:07:46,560 --> 00:07:49,660
But, we know that it has many, many,

110
00:07:49,660 --> 00:07:52,940
many leaves,
in fact at least ten factorial leaves.

111
00:07:52,940 --> 00:07:57,995
To formally show this we need the
following, we need the following estimate.

112
00:07:57,995 --> 00:08:03,445
The depths of a binary tree is at
least a binary algorithm of its number

113
00:08:03,445 --> 00:08:08,955
of leaves or equivalently 2 to the depths
is at least its number of leaves.

114
00:08:08,955 --> 00:08:14,830
Well this can be proved formally, but
let me just show you this informally.

115
00:08:14,830 --> 00:08:18,710
Let's concede a tree for
example of depth 1.

116
00:08:18,710 --> 00:08:22,470
So in this case, d is equal to 1.

117
00:08:22,470 --> 00:08:26,800
And it is clear that the maximal
possible number of leaves

118
00:08:26,800 --> 00:08:29,600
in a tree of depth 1 is equal to 2.

119
00:08:29,600 --> 00:08:33,980
So now, let's try to understand
what is the maximal possible

120
00:08:33,980 --> 00:08:37,850
number of leaves in a depth
of In a tree of depth 2.

121
00:08:37,850 --> 00:08:40,130
For example, this is a tree of depth 2.

122
00:08:40,130 --> 00:08:43,550
This is another tree of depth 2,
it has has three leaves.

123
00:08:43,550 --> 00:08:48,050
And this is a tree of depth 2 that has
maximal possible number of leaves,

124
00:08:48,050 --> 00:08:49,320
in this case it is 4.

125
00:08:49,320 --> 00:08:51,700
It is 2 to the d indeed.

126
00:08:51,700 --> 00:08:56,480
And intuitively it is clear that
to have a tree of depth d that has

127
00:08:56,480 --> 00:08:58,380
maximal possible number of leaves.

128
00:08:58,380 --> 00:09:05,500
We need to take a tree which has
a full binary tree of depth d, right?

129
00:09:05,500 --> 00:09:08,990
And this tree has exactly
2 to the d leaves.

130
00:09:08,990 --> 00:09:14,620
So the maximal number of leaves in
a tree of depth d is 2 to the d.

131
00:09:15,720 --> 00:09:18,110
Which proves that 2 to
the d is at least l.

132
00:09:20,160 --> 00:09:25,640
Okay, so the last step that we need to
show is that if we have n factorial

133
00:09:25,640 --> 00:09:31,110
leaves, then the depths of our
tree is at least big log n again.

134
00:09:31,110 --> 00:09:33,520
And we will show this on the next slide.

135
00:09:34,560 --> 00:09:38,830
It remains to estimate log of n factorial.

136
00:09:38,830 --> 00:09:44,930
We're going to show here that log of n
factorial is at least c times n log n.

137
00:09:44,930 --> 00:09:51,230
Which means as it works that log of
n factorial is big log of n log n.

138
00:09:51,230 --> 00:09:56,260
To do this, we express n
factorial as a product of 1, 2, 3.

139
00:09:56,260 --> 00:09:58,260
And so on n minus 1, and

140
00:09:58,260 --> 00:10:03,730
then right algorithm of product of these
numbers as a sum of their algorithm.

141
00:10:03,730 --> 00:10:08,990
So, log of n factorial is equal to log
of 1 plus log of 2 plus log of 3 and

142
00:10:08,990 --> 00:10:10,820
so on plus log of n.

143
00:10:10,820 --> 00:10:12,760
So, this is a sum of an object.

144
00:10:12,760 --> 00:10:17,380
Let's just throw away the first
half of this and elements,

145
00:10:17,380 --> 00:10:19,550
and leave only the second half.

146
00:10:19,550 --> 00:10:23,700
So in this second half,
we have n over two elements and

147
00:10:23,700 --> 00:10:27,530
each of them is at least
log of n over two, right?

148
00:10:27,530 --> 00:10:32,220
So this has algorithms of numbers
which are at least n over two.

149
00:10:32,220 --> 00:10:34,390
So we have n over two.

150
00:10:34,390 --> 00:10:38,100
Elements, each of them is at
least algorithms of n over 2.

151
00:10:38,100 --> 00:10:43,870
This allows us to conclude that log sum is
at least 10 over 2 times log of n over 2.

152
00:10:43,870 --> 00:10:48,530
And this in turn be big log of n for
a simple reason.

153
00:10:48,530 --> 00:10:53,210
So log n over 2 is equal to log n minus 1.

154
00:10:53,210 --> 00:10:56,518
Well, this grows like log n, right?

155
00:10:56,518 --> 00:11:00,646
Because log n is a growing function and
one is a constant so

156
00:11:00,646 --> 00:11:02,796
again minus one goes as log n.

157
00:11:02,796 --> 00:11:04,340
And over grows as n, right?

158
00:11:04,340 --> 00:11:09,560
So, this is up to constant factors,
this is just n.

159
00:11:09,560 --> 00:11:13,940
So, n over two times log n
over two grows like n log n.

160
00:11:16,080 --> 00:11:18,620
Okay so this concludes our proof, and

161
00:11:18,620 --> 00:11:24,610
this concludes the proof of
the fact that any comparison based

162
00:11:24,610 --> 00:11:30,038
algorithm must make at least n log
n adorations in the worst case.

163
00:11:30,038 --> 00:11:34,620
Once again, another conclusion is that
when merged sort algorithms that we

164
00:11:34,620 --> 00:11:39,910
considered in the previous lecture
e is asymmetrically optimal.

165
00:11:39,910 --> 00:11:44,120
In the next video we will see
an algorithm that actually sorts

166
00:11:44,120 --> 00:11:47,300
n given objects in time less than n log n.

167
00:11:47,300 --> 00:11:50,610
Actually in time just in linear time.

168
00:11:50,610 --> 00:11:53,050
In time big log of n however,

169
00:11:53,050 --> 00:11:58,530
it will sort the n given objects,
knowing something about these objects.

170
00:11:58,530 --> 00:12:03,460
It will only sort the given objects
if the subject has small integers.

171
00:12:03,460 --> 00:12:07,020
And we will sort them without actually
comparing them to each other.