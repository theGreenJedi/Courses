Привет! На этом видео мы посмотрим на время выполнения функции бинарного поиска, а также его итеративной версии. Итак, вот наш алгоритм бинарного поиска. Мы смотрим на середину, если ключ не найден, то мы либо ищем в нижней, либо в верхней половине. Тогда как выглядит наше рекуррентное соотношение для худшего случая времени выполнения? Собственно, худший случай - это если мы не нашли элемент. Посмотрим на T(n), равное T от приблизительно n/2 плюс c. n/2 округляется вниз, поскольку, если n нечётное, допустим, в массиве 5 элементов, то вопрос стоит так: каков объём задачи при следующем вызове? Если у нас 5 элементов, мы будем искать либо в верхней половине массива. эти два элемента, либо в нижней половине, вот эти два элемента. Так как мы пропускаем середину, мы уже проверили её. Плюс определённый константный объём работы для вычисления середины, а также для проверки середины на равенство ключу. И затем наш базовый случай, когда имеем пустой массив. И это просто константное время выполнения проверки. Тогда как выглядит время выполнения? У нас есть наш исходный размер n, и мы будем разбивать его, n на 2, n на 4. И так далее, до самого низа. Как много здесь таких задач? В целом, если мы разбиваем что-либо на 2 части снова и снова, на это понадобится логарифм по основанию 2 таких итераций, пока мы не дойдём до 1. Итого, получаем двоичный логарифм от n + 1. Объём выполняемой работы равен c. Значит, на каждом уровне мы выполняем c работы. То есть полный объём работы, если мы суммируем её, это сумма с по индексу i от 0 до двоичного логарифма n. Это то же, что двоичный логарифм n + 1, что равно двоичному логарифму n, это количество, плюс 1, умноженное на с. И это равно тета от двоичного логарифма n, но мы обычно говорим тета от логарифма n, поскольку основание логарифма не имеет значения. Это просто константный множитель. Хорошо, как будет выглядеть итеративная версия? Итеративная версия принимает те же параметры: низ, верх и ключ. И у нас есть цикл, подобный тому, который был в базовом случае, в базовом случае в рекурсивной версии мы останавливались, когда верх был меньше низа. Теперь у нас цикл while, который завершается при условии, что верх меньше низа. Мы вычисляем середину и проверяем ключ. Если он совпадает со средним элементом, возвращаем середину. В ином случае, если ключ меньше элемента, мы знаем, что нам нужна первая половина массива, и поэтому, вместо следующего рекурсивного вызова, как в рекурсивной версии, мы берём исходный массив. И мы хотим проверить его первую половину, поэтому мы меняем значение верхней границы и устанавливаем его равным середине минус 1,
потому что мы уже проверили середину. В ином случае, мы хотим проверить вторую
 половину массива, поэтому сдвигаем нижнюю границу вверх. Если мы дошли до конца цикла, То есть если мы вышли из цикла while, поскольку верх стал меньше низа, это означает, что нам больше негде вести поиск. Наш массив пуст. И, следовательно,
мы не нашли нужный элемент в массиве. Мы возвратим низ минус 1. То есть тот же результат, что и в рекурсивной версии. Отличие в том, что мы не будем
использовать память в стеке, которую использует рекурсивная версия. Как вы помните, два видео назад мы говорили
 о примере из реальной жизни, где у нас было пять языков, и мы переводили
слова с одного из этих языков на любой другой. Это было представлено в виде
параллельных массивов, таким образом, что под любым заданным индексом
соответствующие элементы в массивах являлись переводами одного и того же слова
на все эти языки. Например, "chair"
в английском стоит под индексом 2, а в испанском это "silla", а
в итальянском - "sedia". Проблемой было то, что поиск в этой структуре занимал долгое время, так? У нас было по 50 тысяч элементов в массивах, и поиск занимал около 10 секунд, Потому что нам приходилось действительно просматривать все слова, если там не было нужного, а в среднем,
половину из них, 25 тысяч. Поэтому мог бы возникнуть вопрос: почему мы не использовали отсортированный массив? Верно? Представьте себе, к примеру, сортировку этих массивов. Вот они в отсортированном виде. Хорошо то, что теперь легко найти конкретное слово в конкретном языке. Так, я могу найти "house" (дом) в английском,
например, и очень быстро определить, под каким оно индексом,
 используя бинарный поиск. Проблема в том, что у меня больше нет того соответствия,
поскольку порядок отсортированных слов в английском языке отличается от
порядка отсортированных слов в испанском. Поэтому, если я посмотрю на слово "chair", например,
 в английском, оно уже не соответствует слову "silla". Вместо этого, оно соответствует слову "casa". Поэтому, хоть мы и можем найти определённое
 слово в нашем исходном языке, мы не знаем соответствующего
 слова в языке перевода. Поэтому решением было попробовать
найти какой-то способ отсортировать данные, но при этом сохранить связь, 
при которой все элементы под одним индексом представляли одно и то же переведенное слово. Это было сделано
путём добавления ещё одного набора массивов. Вот что мы сделали: хранили эти
дополнительные массивы, которые представляли собой указатели на исходные
массивы в отсортированном порядке. Так у нас появляется что-то вроде уровня перенаправления. И если я, например, смотрю на английский,
то порядок слов в английском будет: chair, house, pimple. Тогда, какой порядок это означает
для исходного массива? Это значит: первый элемент 2,
затем элемент 1 и затем элемент 3. И если вы хотите произвести бинарный поиск,
вы можете воспользоваться этим отсортированным массивом. Когда вы хотите узнать, какой элемет в этом отсортированном массиве. Например, если мы посмотрим на средний элемент, который в отсортированном массиве второй, он имеет
значение 1, и это указывает на слово house. Поэтому мы можем сказать,
что house как бы находится в элементе 2, а chair - в элементе 1, а pimple - в элементе 3. В испанском, само собой, 
другое соответствие, поэтому в испанском первое по порядку сортировки слово
оказалось первым словом в массиве. Второе отсортированное слово - это третье
слово в испанском массиве, а третье отсортированное слово, silla, - это второй элемент. Так что же произошло, когда мы так поступили? Мы пошли на компромисс между временем выполнения и памятью. Нам пришлось заплатить дополнительным пространством памяти. И появились, конечно, не только английский
и испанский отсортированные массивы, но также французский, итальянский и немецкий. То есть 5 массивов, дополнительных массивов. Каждый массив содержит 50000 записей, а каков
размер каждого элемента массива? Собственно, он представляет собой номер
от 1 до 50000, что может быть представлено в
16 битах, что равно 2 байтам. То есть у нас 50000 элементов, умноженных на 2 байта, это 100 тысяч байтов,
умноженных на 5, что равно 500 тысячам байтов. То есть примерно полмегабайта,
что в наши дни практически ничто. И даже в то время, 20 лет назад,
это было вполне выполнимо. Такова цена, которую мы платим в отношении пространства. Какой мы получаем выигрыш? Собственно, вместо того, чтобы сделать, скажем,
50000 проверок в худшем случае, нам придётся сделать двоичный логарифм
от 50000 проверок. Двоичный логарифм от 50000 - это около, давайте посмотрим,
двоичный логарифм от 1000 - это около 10, поскольку 2 в 10 степени равно 1024, тогда
у нас ещё остаётся множитель 50. Двоичный логарифм 50 - это около, скажем, 6, потому что я знаю, что 2 в
5 степени равно 32, 2 в 6 - 64. Тогда, это значит, что мы получаем 16 обращений к массиву
вместо 50000. Это улучшение почти в 1000 раз, то есть в итоге это означало, что
когда пользователь нажимал "перевести", вместо того, чтобы занять 10 секунд,
перевод выполнялся почти мгновенно. Это было менее 1/10 секунды. Итак, подводя итог, Мы увидели, что время выполнения
бинарного поиска - тета от логарифма n. Существенно быстрее, чем тета от n, требуемое для линейного поиска. Следовательно, отсортированные массивы действительно эффективны. На следующем уроке мы
рассмотрим более сложное применение подхода "разделяй и властвуй", где у нас будет несколько
подзадач вместо всего одной подзадачи.