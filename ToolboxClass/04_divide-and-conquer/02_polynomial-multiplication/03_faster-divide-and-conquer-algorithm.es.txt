En este video trataremos de crear un algoritmo de divide y vencerás más rápido, para resolver el problema de la multiplicación polinomial. Este problema, esta aproximación fue inventada
 por Karatsuba a principios de los 1960s. Él era un estudiante de posgrado  de Kolmogorov, un matemático ruso famoso. Y Kolmogorov teorizó que lo mejor que uno podía tener es n^2. Así que había una cota inferior de n^2 
al hacer la multiplicación polinomial. Karatsuba, un estudiante de posgrado, se enteró del problema, se fue y regresó una semana después con una solución. Entonces, veamos lo que hay aquí. Si vemos A(x), aquí es un polinomio muy simple, a1x+a0, y B(x)=b1x+b0, y entonces C(x) es, ¿qué sería? sería a1*b1x^2+(a1*b0+a0*b1)x+a0*b0. Notamos que necesitamos 4 multiplicaciones. Necesitamos multiplicar a1 por b1. Necesitamos multiplicar a1 por b0, a0 por b1, y a0 por b0. Esto es como hicimos divide y vencerás en el video pasado. Así que necesitamos 4 multiplicaciones. La intuición de Karatsuba era que había una forma de reescribir C(x) de forma que sólo necesitaras 3 multiplicaciones. Así que básicamente lo que hizo fue reescribir el término medio, a1*b0+a0*b1, como algo un poco más complicado. Hizo (a1+a0)(b1+b0), y (a1+a0)(b1+b0) es igual a a1*b1+a0*b1+a1*b0+a0*b0. Y después restó a1*b1 y a0*b0, para quedarse sólo con a1*b0+a0*b1, que es exactamente lo que queremos. La clave aquí es, ¿cuántas multiplicaciones se necesitan? Sólo necesita tres multiplicaciones. Necesitamos calcular a1*b1, aunque lo usemos dos veces, necesitamos calcular a0*b0, aunque, de nuevo, lo usemos dos veces, y entonces necesitamos multiplicar (a1+a0) y (b1+b0). Así que hacemos sumas extras. Pero la clave es, que tenemos 3 multiplicaciones en lugar de 4. ¿Por qué esto importa? Bueno, importa porque estamos reduciendo el número de problemas en cada nivel. Pero primero veamos un ejemplo. Aquí tenemos A(x), vamos a tener 4x^3+3x^2+2x+1, B(x)=x^3+2x^2+3x+4, seguimos y extraemos D1 y D0 como lo hicimos antes, en nuestro previo divide y vencerás. La clave es lo que vamos a hacer en términos de los subproblemas. Entonces tenemos D1 y D0, E1 y E0, vamos a calcular D1*E1 otra vez, como ya lo habíamos hecho, vamos a calcular también D0*E0 como lo hicimos antes, pero ahora no calculamos D1*E0 y D0*E1. En su lugar, vamos a sumar D1 y D0, y lo mismo con E1 y E0. Aquí, D1+D0 es igual a 6x+4, E1+E0 es igual a 4x+6, y entonces multiplicamos éstos, dando 24x^2+52x+24. Entonces, hasta ahora, ¿cuántas multiplicaciones llevamos? Tercero Y entonces, nuestro resultado final para A(x)*B(x) es D1*E1 x^4 más, ¿ahora qué hacemos aquí? tomamos (D1+D0)(E1+E0), 24x^2+52x+24, ¿sí? Agregamos eso al segundo término y entonces sustraemos D1*E1 y D0*E0. Y nuestro término final es D0*E0. Si simplificamos la parte media, y luego todo, terminamos con 4x^6+11x^5+20x^4+3x^3+ +20x^2+11x+4, que es exactamente el mismo resultado que
 obtuvimos con el divide y triunfarás más ingenuo. Y también el mismo resultado que si lo hiciéramos directamente, ¿sí? Así que tenemos el mismo resultado, pero con 3 multiplicaciones en lugar de 4. La multiplicación extra hace una gran diferencia. Veamos nuestro tiempo. Entonces, nuestro problema inicial es de tamaño n. Cuando lo dividimos, tenemos 3 problemas de tamaño n/2, en lugar de 4. Así que, nivel 0, problema de tamaño n, nivel 1, tamaño n/2, en el nivel i, el tamaño de nuestros problemas es n/2^i, igual que como en el otro divide y vencerás. Y tenemos el mismo número de hojas. Así que en el nivel log_2(n), todos los problemas tienen tamaño 1. Y el número de problemas que tenemos, 1 en el nivel 0; 3, en lugar de 4, en el nivel 1; 3^i, en lugar de 4^i, en el nivel i; y 3 a la log_2(n), en lugar de 4 a la log_2(n) en el nivel de la base. ¿Cuánto trabajo? Vamos a multiplicar, para averiguar cuánto le lleva por cada problema. En este caso, en el nivel 0, es kn. En el nivel 1, cada problema lleva k(n/2) trabajo. Y son tres, así que son k(3/2)n. En el nivel i, terminamos con k(3/2)^i n. Y en el nivel del fondo, k por 3 a la log_2(n), a elevado a la log en base b de c, es
 lo mismo que c a la log en base b de a. Por tanto, esto es lo mismo que k por n a la log_2(3). Sumamos eso, suma desde i=0 hasta log _2(n) de 3^i k n/2^i. Esto está acotado, es la serie geométrica acotada por el último término, que es Theta grande de n a la log_2(3). El log_2(3) es de alrededor de 1.58. Entonces, ahora tenemos un problema donde nuestra
 solución es Theta grande de n^1.58. Comparado con nuestra problema original,
 que tenía una solución en Theta (n^2). Entonces esto hace una enorme diferencia conforme n aumenta, en términos de nuestros tiempos de ejecución finales. No es raro, para algoritmos de divide y vencerás, requerir algunas veces una forma de verlos en términos de dividir el problema, y lograr tener menos subproblemas. Y debido a la composición del hecho de que
 a más subproblemas en cada nivel, tienes más, y más, y más, el reducir el número de subproblemas, reduce el tiempo final de ejecución.