{
 "metadata": {
  "name": "",
  "signature": "sha256:4670922948ed93530a8c5ccbbf12490b7120ac27de9e7d7125837189709c2e77"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import make_regression\n",
      "reg_data, reg_target = make_regression(n_samples=2000, n_features=3, effective_rank=2, noise=10) #what happens w/o noise?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Getting Ready\n",
      "\n",
      "This is the first recipe were we'll tune a the parameters for a model.  This is typically done by cross validation.  There will be recipes laying out a more general way to do this in later recipes, but here we'll walk though enough to tune Ridge Regression.\n",
      "\n",
      "If you remember in Ridge Regression $\\Gamma$ is typically $\\alpha I$, so the question becomes, what is the best $\\alpha$?  Create a regression dataset, then let's get started."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import make_regression\n",
      "reg_data, reg_target = make_regression(n_samples=100, n_features=2, effective_rank=1, noise=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#How to do it\n",
      "\n",
      "In the `linear_models` module there is an object called `RidgeCV` which stands for Ridge Cross Validation.  This performs a cross validation similar to Leave-One-Out, which is often abbrevaited LOOCV.  Under the hood it's going to train the model for all the samples except one, then evaludate the error in predicting that one test case."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import RidgeCV\n",
      "import numpy as np\n",
      "rcv = RidgeCV(alphas=np.array([.1, .2, .3, .4]))\n",
      "rcv.fit(reg_data, reg_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "RidgeCV(alphas=array([ 0.1,  0.2,  0.3,  0.4]), cv=None, fit_intercept=True,\n",
        "    gcv_mode=None, loss_func=None, normalize=False, score_func=None,\n",
        "    scoring=None, store_cv_values=False)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After we've fit the regression the alpha\\_ attribute will be the \"best\" alpha choice."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rcv.alpha_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "0.10000000000000001"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In his example, it was the first choice.  We might want to hone in on something around .1."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rcv2 = RidgeCV(alphas=np.array([.08, .09, .1, .11, .12]))\n",
      "rcv2.fit(reg_data, reg_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "RidgeCV(alphas=array([ 0.08,  0.09,  0.1 ,  0.11,  0.12]), cv=None,\n",
        "    fit_intercept=True, gcv_mode=None, loss_func=None, normalize=False,\n",
        "    score_func=None, scoring=None, store_cv_values=False)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rcv2.alpha_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "0.080000000000000002"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We could continue this hunt, but hopefully the mechanics are clear."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#How it works\n",
      "\n",
      "The mechanics may be clear, but we should talk a little more about the why, and define the what was meant by \"best\".  At each step in the cross validation the model scores the error against the test sample.  By default it's essentially squared error.  See the \"There's More\" section for more details.\n",
      "\n",
      "We can force the RidgeCV object to store the cross validation values, this will let use visualize what it's doing under the hood."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alphas_to_test = np.linspace(0.01, 1)\n",
      "rcv3 = RidgeCV(alphas=alphas_to_test, store_cv_values=True)\n",
      "rcv3.fit(reg_data, reg_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "RidgeCV(alphas=array([ 0.01   ,  0.0302 ,  0.05041,  0.07061,  0.09082,  0.11102,\n",
        "        0.13122,  0.15143,  0.17163,  0.19184,  0.21204,  0.23224,\n",
        "        0.25245,  0.27265,  0.29286,  0.31306,  0.33327,  0.35347,\n",
        "        0.37367,  0.39388,  0.41408,  0.43429,  0.45449,  0.47469,\n",
        "        0.4949 ,  0.5151 ...3837,\n",
        "        0.85857,  0.87878,  0.89898,  0.91918,  0.93939,  0.95959,\n",
        "        0.9798 ,  1.     ]),\n",
        "    cv=None, fit_intercept=True, gcv_mode=None, loss_func=None,\n",
        "    normalize=False, score_func=None, scoring=None, store_cv_values=True)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see we're testing a a bunch of points (50 in total) between 0.01 and 1.  Because we've passed store_cv_values as true we can access those values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rcv3.cv_values_.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "(100, 50)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So we had 100 values in the initial regression, and tested 50 different alpha values.  So we know have access to the error of all 50 values.  We can now find the smallest mean error, and we'll choose that as alpha."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "smallest_idx = rcv3.cv_values_.mean(axis=0).argmin()\n",
      "alphas_to_test[smallest_idx]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "0.01"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The question, then, is does RidgeCV agree with our choice?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rcv3.alpha_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "0.01"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Beautiful!\n",
      "\n",
      "It's also worthwhile to visualize what's going on.  In order to do that we'll plot the mean for all 50 test alphas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "f, ax = plt.subplots(figsize=(7, 5))\n",
      "ax.set_title(r\"Various values of $\\alpha$\")\n",
      "#ax.set_ylim(100, 105)\n",
      "\n",
      "xy = (alphas_to_test[smallest_idx], rcv3.cv_values_.mean(axis=0)[smallest_idx])\n",
      "xytext = (xy[0] + .2, xy[1] + 2)\n",
      "\n",
      "ax.annotate(r'Chosen $\\alpha$', xy=xy, xytext=xytext,\n",
      "            arrowprops=dict(facecolor='black', shrink=0.02, width=.02)\n",
      "            )\n",
      "\n",
      "\n",
      "ax.plot(alphas_to_test, rcv3.cv_values_.mean(axis=0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[<matplotlib.lines.Line2D at 0x108448e10>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAbEAAAFDCAYAAAC0ijCjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x108343490>"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This kind of plot is commonly refered to as an elbow plot.  A common theme in parameter tuning is to look at the elbow plot and chose the value at the elbow (the minimum)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#There's more\n",
      "\n",
      "If we want to use your own scoring function we can do that as well.  Since we looked a MAD before, let's use that to score the differences.  First, we need to define our loss function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def MAD(target, predictions):\n",
      "    absolute_deviation = np.abs(target - predictions)\n",
      "    return absolute_deviation.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After we've defined the loss function, we can then employ the make_scorer function in sklearn.  This will take care of standardizing our function so sci-kit's objects know how to use it.  Also, because this is a loss function and not a score function, lower is better, and thus we need to let sklearn to flip the sign to turn this from a maximization problem into a minimization problem."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn\n",
      "MAD = sklearn.metrics.make_scorer(MAD, greater_is_better=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rcv4 = RidgeCV(alphas=alphas_to_test, store_cv_values=True, scoring=MAD)\n",
      "rcv4.fit(reg_data, reg_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "RidgeCV(alphas=array([ 0.01   ,  0.0302 ,  0.05041,  0.07061,  0.09082,  0.11102,\n",
        "        0.13122,  0.15143,  0.17163,  0.19184,  0.21204,  0.23224,\n",
        "        0.25245,  0.27265,  0.29286,  0.31306,  0.33327,  0.35347,\n",
        "        0.37367,  0.39388,  0.41408,  0.43429,  0.45449,  0.47469,\n",
        "        0.4949 ,  0.5151 ...3837,\n",
        "        0.85857,  0.87878,  0.89898,  0.91918,  0.93939,  0.95959,\n",
        "        0.9798 ,  1.     ]),\n",
        "    cv=None, fit_intercept=True, gcv_mode=None, loss_func=None,\n",
        "    normalize=False, score_func=None,\n",
        "    scoring=make_scorer(MAD, greater_is_better=False),\n",
        "    store_cv_values=True)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "smallest_idx = rcv4.cv_values_.mean(axis=0).argmin()\n",
      "alphas_to_test[smallest_idx]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "0.23224489795918368"
       ]
      }
     ],
     "prompt_number": 18
    }
   ],
   "metadata": {}
  }
 ]
}