{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy Statistics Module\n",
    "\n",
    "Although there are some basic statistical functions in Numpy (e.g.,\n",
    "`mean`, `std`, `median`), the real repository for statistical functions is in\n",
    "`scipy.stats`. There are over eighty continuous probability distributions\n",
    "implemented in `scipy.stats` and an additional set of more than\n",
    "ten discrete distributions, along with many other supplementary statistical\n",
    "functions that we will select from in what follows.\n",
    "\n",
    "To get started with `scipy.stats`, you have to load the module and create\n",
    "an object that has the distribution you're interested in. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> import scipy.stats # might take awhile\n",
    ">>> n = scipy.stats.norm(0,10) # create normal distrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The `n` variable is an object that represents a \n",
    "normally distributed random variable with mean zero and \n",
    "standard deviation, $\\sigma=10$. Note that the more general term\n",
    "for these two parameters is *location* and *scale*, respectively. Now\n",
    "that we have this defined, we can compute `mean`, as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> n.mean() # we already know this from its definition!\n",
    "0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can also compute higher order moments as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> n.moment(4)\n",
    "30000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The main public methods for continuous random variables are\n",
    "\n",
    "   * `rvs`: random variates\n",
    "\n",
    "   * `pdf`: probability density function\n",
    "\n",
    "   * `cdf`: cumulative distribution function\n",
    "\n",
    "   * `sf`: survival Function (1-CDF)\n",
    "\n",
    "   * `ppf`: percent point function (Inverse of CDF)\n",
    "\n",
    "   * `isf`: inverse survival function (Inverse of SF)\n",
    "\n",
    "   * `stats`: mean, variance, (Fisher's) skew, or (Fisher's) kurtosis\n",
    "\n",
    "   * `moment`: non-central moments of the distribution\n",
    "\n",
    "For example, we can compute the value of the pdf at a specific point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03989422804014327"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> n.pdf(0)\n",
    "0.039894228040143268"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " or, the `cdf` for the same random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> n.cdf(0)\n",
    "0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You can also create samples from this distribution as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -8.11311677,   1.48034316,   1.0824489 ,  -4.38642452,\n",
       "        23.69872505, -22.19428082,  -7.19207387,  10.6447697 ,\n",
       "         3.4549407 ,   1.67282213])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> n.rvs(10)\n",
    "array([ -8.11311677,   1.48034316,   1.0824489 ,  -4.38642452,\n",
    "        23.69872505, -22.19428082,  -7.19207387,  10.6447697,\n",
    "         3.4549407 ,   1.67282213])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Many common statistical tests are already built-in. For example,\n",
    "Shapiro-Wilks tests the null hypothesis that the data were drawn from a\n",
    "normal distribution [^hypo], as in the following:\n",
    "\n",
    "[^hypo]: We will explain null hypothesis and the rest of it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9914381504058838, 0.779195249080658)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> scipy.stats.shapiro(n.rvs(100))\n",
    "(0.9914381504058838, 0.779195249080658)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The second value in the tuple is the p-value.\n",
    "\n",
    "## Sympy Statistics Module\n",
    "\n",
    "Sympy has its own much smaller, but still extremely useful statistics  module\n",
    "that enables symbolic manipulation of statistical quantities.  For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> from sympy import stats\n",
    ">>> X = stats.Normal('x',0,10) # create normal random variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can obtain the probability density function as,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqrt(2)*exp(-x**2/200)/(20*sqrt(pi))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sympy.abc import x\n",
    ">>> stats.density(X)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and we can evaluate the cumulative density function as the following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> stats.cdf(X)(0)\n",
    "1/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that you can evaluate this numerically by using the `evalf()`\n",
    "method on the output. Sympy provides intuitive ways to consider standard\n",
    "probability questions by using the `stats.P` function, as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> stats.P(X>0) # prob X >0?\n",
    "1/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There is also a corresponding expectation function, `stats.E`\n",
    "you can use to compute complicated expectations using all of Sympy's powerful\n",
    "built-in integration machinery. For example we can compute,\n",
    "$\\mathbb{E}(\\sqrt{\\lvert X \\rvert})$ in the following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.59995815363879"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> stats.E(abs(X)**(1/2)).evalf()\n",
    "2.59995815363879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Unfortunately, there is very limited support for multivariate\n",
    "distributions at  the time of this writing.\n",
    "\n",
    "## Other Python Modules for Statistics\n",
    "\n",
    "There are many other important Python modules for statistical work. Two\n",
    "important modules are Seaborn and Statsmodels. As we discussed earlier,\n",
    "Seaborn is library built on top of Matplotlib for very detailed and expressive\n",
    "statistical visualizations, ideally suited for exploratory data analysis.\n",
    "Statsmodels is designed to complement Scipy with descriptive\n",
    "statistics, estimation, and inference for a large variety of statistical\n",
    "models. Statsmodels includes (among many others) generalized linear models,\n",
    "robust linear models, and methods for timeseries analysis, with an emphasis on\n",
    "econometric data and problems. Both these modules are well supported and very\n",
    "well documented and designed to integrate tightly into Matplotlib, Numpy,\n",
    "Scipy, and the rest of the scientific Python stack.  Because the focus of this\n",
    "text is more conceptual as opposed to domain-specific, I have chosen not to\n",
    "emphasize either of these, notwithstanding how powerful each is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
