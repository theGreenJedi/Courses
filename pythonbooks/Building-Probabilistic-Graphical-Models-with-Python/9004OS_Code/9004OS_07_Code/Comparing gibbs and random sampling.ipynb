{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this notebook, we shall look at the sampling process. We'll first understand what it means to 'arrive at the stationary distribution' for a discrete distribution, and what methods we can use to get there faster.\n",
      "\n",
      "We'll use the familiar job interview example to anchor the discussion.\n",
      "\n",
      "The Job interview network has 5 binary-valued variables, which means the joint distribution has 48 rows (2x2x3x3x2, the number of values each variable takes). We are interested in a marginal distribution over a subset of variables, and we have some observed evidence too. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from libpgm.graphskeleton import GraphSkeleton\n",
      "from libpgm.nodedata import NodeData\n",
      "from libpgm.discretebayesiannetwork import DiscreteBayesianNetwork\n",
      "from libpgm.tablecpdfactorization import TableCPDFactorization\n",
      "from libpgm.sampleaggregator import SampleAggregator\n",
      "from libpgm.pgmlearner import PGMLearner\n",
      "import itertools\n",
      "import pandas as pd \n",
      "import json\n",
      "\n",
      "def getTableCPD():\n",
      "    nd = NodeData()\n",
      "    skel = GraphSkeleton()\n",
      "    jsonpath=\"job_interview.txt\"\n",
      "    nd.load(jsonpath)\n",
      "    skel.load(jsonpath)\n",
      "    skel.toporder()\n",
      "    # load bayesian network\n",
      "    bn = DiscreteBayesianNetwork(skel, nd)\n",
      "    tablecpd=TableCPDFactorization(bn)\n",
      "    return tablecpd,bn,skel\n",
      "\n",
      "#a method that prints the distribution as a table.\n",
      "def printdist(jd,bn,normalize=False):\n",
      "    x=[bn.Vdata[i][\"vals\"] for i in jd.scope]\n",
      "    zipover=[i/sum(jd.vals) for i in jd.vals] if normalize else jd.vals\n",
      "    #creates the cartesian product\n",
      "    k=[a + [b] for a,b in zip([list(i) for i in itertools.product(*x[::-1])],zipover)]\n",
      "    df=pd.DataFrame.from_records(k,columns=[i for i in reversed(jd.scope)]+['probability'])\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are interested in the marginal probability $ P(Offer,Grades,Interview \\mid Admission,Experience) $, where we have observed the value of Admission and Experience.\n",
      "\n",
      "In the snippet below, we use exact inference (Variable Elimination) to determine the conditional probability, and then print the CPD for the same. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tcpd,bn,skel=getTableCPD()\n",
      "query={'Offer':'0','Grades':'0','Interview':'0'}\n",
      "evidence={'Admission':'0','Experience':'0'}\n",
      "fac=tcpd.condprobve(query,evidence)\n",
      "df=printdist(fac,bn)\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Offer</th>\n",
        "      <th>Interview</th>\n",
        "      <th>Grades</th>\n",
        "      <th>probability</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.641455</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.029455</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.064145</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.026182</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.000178</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.000109</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.071273</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.003273</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.096218</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.039273</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.017640</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.010800</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "   Offer Interview Grades  probability\n",
        "0      0         0      0     0.641455\n",
        "1      0         0      1     0.029455\n",
        "2      0         1      0     0.064145\n",
        "3      0         1      1     0.026182\n",
        "4      0         2      0     0.000178\n",
        "5      0         2      1     0.000109\n",
        "6      1         0      0     0.071273\n",
        "7      1         0      1     0.003273\n",
        "8      1         1      0     0.096218\n",
        "9      1         1      1     0.039273\n",
        "10     1         2      0     0.017640\n",
        "11     1         2      1     0.010800"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get the desired distribution $ P(Offer,Grades,Interview\u2223Admission=0,Experience=0) $, we first have to draw samples, reject those that do not satisfy the evidence. \n",
      "\n",
      "Libpgm allows us to draw samples using random sampling and gibbs sampling. In both cases, we can condition by evidence ( $ (Admission=0,Experience=0) $ ).\n",
      "\n",
      "In the code below, we draw 5000 samples using gibbs and random sampling, and compare the marginal probabilities that are learnt from the samples. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def estimate_distrib(skel,samples):\n",
      "    learner=PGMLearner()\n",
      "    #learn the parameters of the network from the samples, given skeleton\n",
      "    #returns a new bayes net.\n",
      "    bayesnet=learner.discrete_mle_estimateparams(skel,samples)\n",
      "    tablecpd=TableCPDFactorization(bayesnet)\n",
      "    #run a conditional probability query for\n",
      "    #P(Offer,Grades,Interview\u2223Admission=0,Experience=0)\n",
      "    fac=tablecpd.condprobve(query,evidence)\n",
      "    #create a dataframe listing the marginals \n",
      "    df2=printdist(fac,bayesnet)\n",
      "    return df2\n",
      "\n",
      "#learn the marginals from gibbs samples\n",
      "def gibbs_marginals(num_samples=5000):\n",
      "    tcpd,bn,skel=getTableCPD()\n",
      "    samples=tcpd.gibbssample(evidence,num_samples)\n",
      "    df2=estimate_distrib(skel,samples)\n",
      "    return df2['probability']\n",
      "\n",
      "#learn the marginals from random samples\n",
      "def random_sample_marginals(num_samples=5000):\n",
      "    tcpd,bn,skel=getTableCPD()\n",
      "    samples=bn.randomsample(num_samples,evidence)\n",
      "    df2=estimate_distrib(skel,samples)\n",
      "    return df2['probability']\n",
      "\n",
      "df['prob from gibbs']=gibbs_marginals()\n",
      "df['prob from random samples']=random_sample_marginals()\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Offer</th>\n",
        "      <th>Interview</th>\n",
        "      <th>Grades</th>\n",
        "      <th>probability</th>\n",
        "      <th>prob from gibbs</th>\n",
        "      <th>prob from random samples</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.641455</td>\n",
        "      <td> 0.645444</td>\n",
        "      <td> 0.078557</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.029455</td>\n",
        "      <td> 0.025156</td>\n",
        "      <td> 0.113443</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.064145</td>\n",
        "      <td> 0.065997</td>\n",
        "      <td> 0.058145</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.026182</td>\n",
        "      <td> 0.026203</td>\n",
        "      <td> 0.008655</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.000178</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.013869</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.000109</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.028531</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.071273</td>\n",
        "      <td> 0.072956</td>\n",
        "      <td> 0.048443</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.003273</td>\n",
        "      <td> 0.002844</td>\n",
        "      <td> 0.069957</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.096218</td>\n",
        "      <td> 0.096203</td>\n",
        "      <td> 0.504855</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.039273</td>\n",
        "      <td> 0.038197</td>\n",
        "      <td> 0.075145</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.017640</td>\n",
        "      <td> 0.016400</td>\n",
        "      <td> 0.000131</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.010800</td>\n",
        "      <td> 0.010600</td>\n",
        "      <td> 0.000269</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "   Offer Interview Grades  probability  prob from gibbs  \\\n",
        "0      0         0      0     0.641455         0.645444   \n",
        "1      0         0      1     0.029455         0.025156   \n",
        "2      0         1      0     0.064145         0.065997   \n",
        "3      0         1      1     0.026182         0.026203   \n",
        "4      0         2      0     0.000178         0.000000   \n",
        "5      0         2      1     0.000109         0.000000   \n",
        "6      1         0      0     0.071273         0.072956   \n",
        "7      1         0      1     0.003273         0.002844   \n",
        "8      1         1      0     0.096218         0.096203   \n",
        "9      1         1      1     0.039273         0.038197   \n",
        "10     1         2      0     0.017640         0.016400   \n",
        "11     1         2      1     0.010800         0.010600   \n",
        "\n",
        "    prob from random samples  \n",
        "0                   0.078557  \n",
        "1                   0.113443  \n",
        "2                   0.058145  \n",
        "3                   0.008655  \n",
        "4                   0.013869  \n",
        "5                   0.028531  \n",
        "6                   0.048443  \n",
        "7                   0.069957  \n",
        "8                   0.504855  \n",
        "9                   0.075145  \n",
        "10                  0.000131  \n",
        "11                  0.000269  "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can compare the true probability (obtained from exact inference), the probability from gibbs samples, and the probability from random samples. We can see that the probabilities from gibbs samples are reasonably close to the true marginals, and while the random samples differ quite a bit from the true probability. \n",
      "\n",
      "It is obvious that gibbs sampling is a much more efficient sampling process than random sampling. Yet, for larger dimensions, gibbs sampling too will struggle to obtain marginals that are 'close' to the true marginals."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}