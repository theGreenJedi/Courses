En este video hablaremos acerca del la ecuación normal, la que para algunos problemas de regresión lineal nos dará una mejor manera de resolver para el valor óptimo de los parámetros «theta». En concreto, el algoritmo que hasta ahora hemos usado para la regresión lineal es el gradiente de descenso para minimizar la función de costos J de «theta», usaríamos este algoritmo iterativo que requiere muchos pasos, múltiples iteraciones del de gradiente de descenso para converger con el mínimo global. En contraste, la ecuación normal nos daría un método para despejar «theta» de forma analítica para que en vez de tener que utilizar este algoritmo iterativo, podamos en cambio despejar el valor óptimo de «theta» de una sola vez, para que en prácticamente un paso obtengas el valor óptimo ahí mismo. Resulta que la ecuación normal tiene algunas ventajas y algunas desventajas, pero antes de llegar a ellas y de hablar sobre cuándo deberías usarlas, vamos a obtener un poco de intuición sobre lo que hace este modelo. Para el ejemplo planetario de esta semana, imaginemos, tomemos una muy simplificada función de costos J de «theta», que es la función de un número real «theta». Por ahora imaginemos que «theta» es solo un valor escalar o que «theta» es solo un valor de fila. Es solo un número, en lugar de un vector. Imagina que tenemos una función de costo J
que es una función cuadrática de este valor real que es parámetro de «theta», de tal forma que J de «theta»
se ve así. Bueno, ¿cómo minimizas
una función cuadrática? Para aquellos de ustedes que saben
un poco de cálculo, sabrán que la forma de minimizar una función es tomando las derivadas e igualar las derivadas a cero. Así que sacas la derivada de J
con respecto al parámetro de «theta». Obtienes una fórmula
que no voy a derivar, igualas la derivada a cero, y esto te permite despejar el valor de «theta» que
minimiza J de «theta». Ese era un caso más sencillo en el que los datos eran solo números reales. En el problema que nos
interesa, «theta» ya no es solamente un mero número real, sino que es este vector de parámetros de n+1 dimensiones y una función de costos J es una función de este valor del vector o de «theta»0 hasta «theta» m. Y, una función de costos se ve así,
como alguna función de costos cuadrática a la derecha. ¿Cómo minimizamos la función de costos J? El cálculo nos dice que, si tú, que una forma de hacerlo es tomando la derivada parcial de J con respecto a cada uno de los parámetros de «theta» J, y entonces igualarlos todos a 0. Si haces eso y resuelves para los valores de «theta»0, «theta»1, hasta «theta» n, entonces, tendrías los valores de «theta» para minimizar el costo de la función J. En cambio, si de verdad haces el cálculo para hallar la solución de los parámetros «theta»0 hasta «theta» n, la derivación se torna un tanto tediosa. Y, lo que voy a hacer en este video, en realidad es no pasar por la derivación, que es un poco larga y un poco tediosa, pero lo que quiero hacer solamente decirte lo que tienes que saber para que puedas implementar este proceso y puedas despejar los valores de «theta» que correspondan a los lugares en que las derivadas parciales sean igual a cero. O lo que equivale o en otras palabras, los valores de «theta» que minimizan la función de costos J de «theta». Soy consciente de que algunos de los comentarios que hice tienen sentido solo para aquellos de ustedes que tienen una noción de cálculo. Si no sabes, estás menos familiarizado con el cálculo, no te preocupes. Solo te voy a decir lo que necesitas para implementar este algoritmo y hacerlo funcionar. Para el ejemplo que quiero usar como ejemplo de funcionamiento digamos que tengo m= 4 ejemplos de entrenamiento. Para implementar esta ecuación normal a gran escala, haré
lo siguiente. Voy a tomar mi conjunto de datos, así que aquí están mis cuatro ejemplos de entrenamiento. En este caso supongamos que, como sabes, estos cuatro ejemplos son todos los datos que tengo. Lo que haré es tomar mi conjunto de datos y añadir una columna adicional que corresponde a mi variable adicional, x0, que siempre toma el valor de 1. Lo que haré es voy hacer es construir una matriz que se llame "X" que es una matriz que, básicamente, contiene todas las variables de mis datos de entrenamiento. Aquí está mi, aquí están todas mis variables y vamos a tomar todos esos números y vamos a ponerlos en esta matriz "X", ¿de acuerdo? Como sabes, simplemente copio los datos una columna a la vez y luego le hago
algo parecido a las "y". Voy a tomar los valores que estoy tratando de predecir y construyo un vector así y lo llamo vector "y". Así que "X" va a ser un matriz de dimensiones m multiplicado por (n+1). Y será un vector de m dimensiones donde m es la cantidad de
ejemplos de entrenamiento y n es, n es la cantidad de variables, n+1, a causa de la variable adicional x0 que tengo. Por último, si tomas tu matriz "X" y tomas tu vector "y", y si calculas esto y estableces que «theta» es igual a X transpuesta X inversa multiplicada por X transpuesta Y, esto te daría el valor de «theta» que minimiza tu función de costos. Esto es mucha información en la diapositiva y trabajé a través de ella usando
un ejemplo específico de un conjunto de datos. Permíteme escribirlo de una manera más general y luego, tan solo,
y más adelante en este video explicaré
esta ecuación con un poco más de detalle. Aún no queda totalmente claro cómo es que se hace esto. En un caso general, digamos que tenemos "m" ejemplos de entrenamiento por lo que x1, y1 hasta x n,y n y "n" variables. Cada uno de los ejemplos de entrenamiento x(i) parecerán vectores así, que es un vector de variables de n+1 dimensiones. La manera en que construiré la matriz "X", esto también es conocido como una matriz de diseño, es como sigue. Cada ejemplo de entrenamiento me da un vector de variables como este, una especie de vector de n+1 dimensiones. La manera en que voy a construir mi matriz de diseño "X" es simplemente construyéndola así. Lo que voy a hacer es tomar el primer ejemplo de entrenamiento, eso es un vector, tomar su transpuesta para que quede así, como sabes, una cosa larga y plana y hacer de x1 transpuesta la primera fila de mi matriz de diseño. Después tomaré mi segundo ejemplo de entrenamiento, x2, la transpuesta de eso y lo pongo como la segunda fila de "x" y así sigo hasta llegar al último de mis ejemplos de entrenamiento. Tomo la transpuesta de eso, y esa es la última fila de mi matriz "X". Y por eso tomo mi matriz "X", una matriz de m multiplicado por n+1 dimensiones. Para ver un ejemplo concreto, digamos que tengo una sola variable, de verdad, solo una variable además de x0, que siempre es igual a 1. Así que si mis vectores de variables xi son iguales a este 1, que es x0, entonces alguna variable real, como quizás sea el tamaño de la casa, entonces mi matriz de diseño "X", sería igual a eso. Para la primera fila, básicamente voy a tomar esto y su transpuesta. Así que me quedará 1 y luego X-1-1. Para la segunda fila, nos quedará 1 y luego X-1-2 y así bajando hasta 1 y X-1-m. Por lo que está será una matriz de m por 2 dimensiones. Así es como se construye la matriz "X". Y, el vector "y", a veces le dibujo una flecha en la parte superior para denotar que es un vector, pero muy a menudo escribo solo "y", da igual. El vector "y" se obtiene al tomar todos los valores, todos los precios correctos de las casas en mi conjunto de entrenamiento, y ponerlas unas sobre otras en un vector de m dimensiones, y eso es "y". Por fin, después de haber construido la matriz "X" y el vector "y", calculamos «theta» como 1/(X’X) * X’Y. Solo quiero, solo quiero asegurarme de que
esta ecuación te hace sentido y de que sepas cómo implementarla. Bueno, pero ¿qué es esta 1/(X’X) * X’Y en concreto? Bien, 1/(X’X) es la inversa de la matriz X’X. Específicamente, si fueran que el conjunto A es igual a X’X, X’ es una matriz, X’X es otra matriz y la llamamos matriz "A". Luego, ya sabes, 1/(X’X) es solo tomar esta matriz "A" e invertirla, ¿correcto?. Esto produce 1/A. Y así es como se calcula esto. Calculas X’X y luego calculas la inversa. Aun no hemos hablado de Octave. Lo haremos en los videos posteriores, sin embargo en el lenguaje de programación de Octave o en una vista parecida, también en el lenguaje de programación Matlab es muy parecido. El comando para calcular esta cantidad, X transpuesta X inversa multiplicada por X transpuesta Y, es así. En Octave, X prima es la notación que utilizas para denotar X transpuesta. Y bien, la expresión que está en la caja roja, calcula X transpuesta multiplicada por X. pinv es una función para calcular la inversa de una matriz, así que esto calcula X transpuesta X inversa, y después multiplicas eso por X transpuesta y multiplicas eso por "y". Y terminas calculando la fórmula que no demostré, pero que sí es posible probar matemáticamente, aunque no lo voy a hacer aquí, que esta fórmula te da el valor óptimo de «theta» en el sentido de que si igualas «theta» a esto, ese es el valor de «theta» que minimiza la función de costo J de «theta» para la nueva regresión. Un último detalle del video anterior. Hablé de la habilidad de variables y de la idea de hacer que las variables estén dentro de rangos similares de escalas, de rangos similares de valores parecidos entre sí. Si usas este método de la ecuación normal, entonces el escalamiento de variables no es del todo necesario y, de hecho, está bien si, digamos, alguna variable x1 está entre 0 y 1, y otra variable x2 está entre 0 y 1000 y otra variable x3 está entre 0 y 10 a la menos 5 y si usas el método de la ecuación normal esto está bien y no hay necesidad de aplicar el escalamiento de variables, aunque, por supuesto, si estas usando el gradiente de descenso, entonces, el ajuste de las escalas sigue siendo importante. Por último, dónde deberías usar el gradiente de descenso y dónde el método de la ecuación normal. Aquí presento algunas de sus ventajas y desventajas. Digamos que tienes "m" ejemplos de entrenamiento y "n" variables. Una desventaja del gradiente de descenso es que necesitas escoger la tasa de aprendizaje «alfa». Y, con frecuencia, esto significa tener que ejecutarlo varias veces con diferentes tasas de aprendizaje «alfa» para ver cuál funciona mejor. Y eso es trabajo adicional y más complicaciones. Otra desventaja del gradiente de descenso es que requiere muchas más iteraciones. Por lo que, depende de los detalles, podría hacerlo más lento, aunque ese no es el fin de la historia como veremos en un momento. En cuanto a la ecuación normal, no tienes que
escoger ninguna tasa de aprendizaje «alfa». Por eso, como ves, es muy conveniente,
hace que sea fácil de implementar. Simplemente la usas y por lo general funciona. Y no tienes que iterar, así que no tienes que trazar J de «theta» o revisar la convergencia ni realizar esos pasos adicionales Hasta aquí, todo parece favorecer la ecuación normal. Ahora presento algunas desventajas de la ecuación normal y algunas ventajas del gradiente de descenso. El gradiente de descenso funciona bastante bien, aun cuando tengas una gran cantidad de variables. Aunque tengas millones de variables puedes usar el gradiente de descenso y será razonablemente eficiente. Hará algo razonable. En contraste con la ecuación normal que para despejar los datos de los parámetros tenemos que despejar este término. Tenemos que calcular este término 1/(X’X). Esta matriz X transpuesta X. Esa es una matriz n por n
si tienes "n" variables porque si miras las dimensiones de X transpuesta y las dimensiones de X, multiplicas y averiguas cuáles son las dimensiones del producto. La matriz X transpuesta X es una matriz n por n donde "n" es la cantidad de variables y en la mayoría de las implementaciones el costo de invertir la matriz, aumentó aproximadamente como el cubo de la dimensión de la matriz. Pues bien, calcular esta inversa tiene un costo de orden y tiempo cúbicos. A veces es más rápido que "n" al cubo pero, es un buen aproximado
para nuestros propósitos. Luego si "n", el número de variables,
es muy grande calcular esta cifra puede ser lento y el método de la ecuación normal puede resultar mucho más lento. Pues si "n" es grande, entonces yo utilizaría el gradiente de descenso porque no queremos pagar todo esto en tiempo "q". Pero, si "n" es relativamente pequeña, entonces la ecuación normal pudiera darte una mejor manera de resolver los parámetros. ¿Qué es pequeño y qué es grande? Bueno, si "n" es del orden de cien, entonces invertir una matriz cien por cien no es problema para los estándares computacionales modernos. Si "n" es mil, yo todavía utilizaría
el método de la ecuación normal. Invertir una matriz mil por mil es en realidad muy rápido en una computadora moderna. Si "n" es diez mil, lo pensaría. Invertir una matriz diez mil por diez mil ya empieza a ser un tanto lento y quizás comience a inclinarme hacia el gradiente de descenso, pero quizás no del todo. Si "n" es diez mil, tu puedes más o menos convertir una matriz diez mil por diez mil. Pero si es mucho más grande que eso, entonces,
es probable que use el gradiente de descenso. Así que si "n" es igual a diez elevado a la seis con un millón de variables, entonces invertir una matriz de un millón por un millón será muy costoso y de seguro yo favorecería el gradiente de descenso si tienes esa cantidad de variables. Exactamente cuán grande tiene que ser un conjunto de variables para convertirlo a gradiente de descenso.
Es difícil dar un número exacto. Pero, para mí suele ser alrededor de diez mil cuando comienzo a considerar el cambio a gradientes de descenso o quizás, a otros de los algoritmos que veremos después en esta clase. En resumen, siempre y cuando la cantidad de variables no sea demasiado grande, la ecuación normal nos da un método alternativo
para resolver para los parámetros de «theta». En concreto, siempre y cuando el número de variables sea menor que 1000, bien, yo usaría, se suele usar el método de la ecuación normal en lugar del gradiente de descenso. Para adelantar algunas ideas que veremos más adelante en el curso a medida que lleguemos al algoritmo de aprendizaje más complejo, cuando hablemos, por ejemplo, de un algoritmo de clasificación, como un algoritmo de regresión logística. Veremos que esos algoritmos en realidad… El método de la ecuación normal
en realidad no funciona para esos algoritmos de aprendizaje más sofisticados y tendremos que recurrir al gradiente de descenso
para esos algoritmos. Es útil conocer el algoritmo del gradiente de descenso. Tanto para la regresión lineal donde tenemos una gran cantidad de variables y como para algunos de los otros algoritmos que veremos en este curso porque el método de la ecuación normal simplemente no les aplica o no funciona. Pero para este modelo específico de regresión lineal la ecuación normal puede darte una alternativa que puede ser mucho más rápida que el gradiente descendiente. Entonces, depende de tu algoritmo, depende de los detalles de los problemas y de cuántas variables tengas. Vale la pena conocer
estos dos algoritmos.