1
00:00:00,220 --> 00:00:05,060
이 번 비디오에서는, noramal equation과 
역행렬이 없는 경우에 대해 이야기해보겠습니다.

2
00:00:05,060 --> 00:00:07,640
좀 더 어려운 개념이지만,

3
00:00:07,640 --> 00:00:09,890
가끔 질문이 들어오곤 합니다.

4
00:00:09,890 --> 00:00:12,490
그래서 여기서 설명하고자 합니다.

5
00:00:12,490 --> 00:00:14,400
그래도, 다소 어려울수도 있으니

6
00:00:14,400 --> 00:00:17,550
부담없이 들으셔도 됩니다.

7
00:00:18,600 --> 00:00:23,210
이해하면 더 좋을 수도 있습니다.

8
00:00:23,210 --> 00:00:26,890
하지만, 이해를 못하더라도, normal equation이나

9
00:00:26,890 --> 00:00:29,610
선형회귀를 하는데에는 전혀 지장이 없습니다.

10
00:00:31,340 --> 00:00:32,030
문제를 보도록 하죠

11
00:00:33,470 --> 00:00:37,450
선형대수학에 익숙한 사람들이

12
00:00:37,450 --> 00:00:39,520
몇 몇 질문하는데,

13
00:00:39,520 --> 00:00:45,610
θ=(X'X)^-1 X'y를 계산할 때,

14
00:00:45,610 --> 00:00:49,580
행렬 X'X의 역행렬이 없으면 어떻게 되냐고 묻습니다.

15
00:00:49,580 --> 00:00:52,400
선형대수학을 배운 사람들은

16
00:00:52,400 --> 00:00:56,060
역행렬을 구할 수 있는 행렬은 한정되어 있고,

17
00:00:56,060 --> 00:01:00,680
그 외의 행렬은 역행렬이 없다는 것을 알고있을 것입니다.
이 때 그 행렬은 비가역행렬(non-invertible matrix),

18
00:01:00,680 --> 00:01:04,220
특이 행렬(singular matrix) 혹은
degenerate matrix라고 부릅니다.

19
00:01:04,220 --> 00:01:05,120
사실

20
00:01:05,120 --> 00:01:10,978
X'X의 역행렬이 없는 경우는 거의 없습니다.

21
00:01:10,978 --> 00:01:15,720
그리고 Octave에서는 이런 경우에 θ를 구할 때도,

22
00:01:15,720 --> 00:01:20,260
올바른 값을 구해줍니다.

23
00:01:20,260 --> 00:01:23,910
전문적인 내용이라, 자세히 설명할 수는 없지만,

24
00:01:23,910 --> 00:01:27,850
octave는 역행렬을 구하는데 두 개의 함수를 제공합니다.

25
00:01:27,850 --> 00:01:31,370
하나는 pinv(), 다른 하나는 inv()입니다.

26
00:01:31,370 --> 00:01:35,090
그리고 이 둘은 기술적으로 차이점을 가지고 있습니다.

27
00:01:35,090 --> 00:01:37,930
하나는 pseudo-inverse라 부르고, 하나는 inverse라 부릅니다.

28
00:01:37,930 --> 00:01:40,490
pinv 함수를 사용하면,

29
00:01:40,490 --> 00:01:45,430
X'X의 역행렬이 없더라도,

30
00:01:45,430 --> 00:01:51,000
θ값을 정확히 계산하는 것을 볼 수 있습니다.

31
00:01:51,000 --> 00:01:52,720
inv와

32
00:01:52,720 --> 00:01:54,450
pinv는

33
00:01:54,450 --> 00:01:55,690
무엇이 다른지

34
00:01:55,690 --> 00:01:59,090
상세한 차이에 대해서는 어려운 수치 계산에 관한 개념이라,

35
00:01:59,090 --> 00:02:00,740
여기서는 다루지 않을 것입니다.

36
00:02:00,740 --> 00:02:05,220
하지만, 다른 수업 비디오에서, X'X의 역행렬이 없을 때,

37
00:02:05,220 --> 00:02:08,982
의미하는게 무엇인지 직관적으로 다룰 것입니다.

38
00:02:08,982 --> 00:02:13,140
선형대수학을 배운 사람들에게는 흥미로울 것입니다.

39
00:02:13,140 --> 00:02:18,400
수학적으로 증명하지는 않겠지만,

40
00:02:18,400 --> 00:02:22,160
X'X가 역행렬이 없을 때 원인은, 대체로 두 개입니다.

41
00:02:22,160 --> 00:02:26,560
첫 번째 원인으로, 문제에서 불필요한 feature를

42
00:02:26,560 --> 00:02:27,710
가지고 있는 경우입니다

43
00:02:27,710 --> 00:02:32,140
구체적인 예로, 집값을 예측하려고 하는데, 
x_1은 집의 크기가

44
00:02:32,140 --> 00:02:37,940
피트, 평방 피트 단위이고, x_2도 집의 크기이며, 
단위는 제곱미터단위인 경우를 보죠.

45
00:02:37,940 --> 00:02:46,060
음, 1미터는 두 자리수까지 반올림하여, 3.28 피트입니다.

46
00:02:46,060 --> 00:02:49,720
그래서, 두 개의 feature는

47
00:02:49,720 --> 00:02:54,650
x_1=(3.28)^2 x_2라는 관계를 가집니다.

48
00:02:54,650 --> 00:02:58,730
선형대수학 전문가라면 알 수 있을 것입니다.

49
00:02:58,730 --> 00:03:02,753
두 feature가 서로 관련이 있고

50
00:03:02,753 --> 00:03:05,470
이와 같은 선형방정식이라면,

51
00:03:05,470 --> 00:03:08,770
행렬 X'X 역행렬이 없다는게 증명됩니다.

52
00:03:08,770 --> 00:03:13,430
X'X가 역행렬이 없는 두 번째 이유는,

53
00:03:13,430 --> 00:03:18,350
많은 feature를 가지고 학습 알고리즘을 사용 할 때입니다.

54
00:03:18,350 --> 00:03:22,520
구체적인 예를 들자면, m이 n보다 작거나 같을 때입니다.

55
00:03:22,520 --> 00:03:27,850
즉, m = 10 training example 이고,

56
00:03:27,850 --> 00:03:32,770
n이 100 feature라면,

57
00:03:32,770 --> 00:03:37,280
파라미터 벡터 θ는 (n+1)차원입니다.

58
00:03:37,280 --> 00:03:38,350
즉, 101차원이 되고,

59
00:03:38,350 --> 00:03:42,550
10개의 training example로 101개의 파라미터를 표현하려 하는 것입니다.

60
00:03:44,100 --> 00:03:48,490
이러면, 가끔은 잘 동작하겠지만, 좋지 않은 생각입니다.

61
00:03:48,490 --> 00:03:53,210
나중에 보게 되겠지만, 10개의 example을 가지고,

62
00:03:53,210 --> 00:03:58,060
100개나 101개의 파라미터를 표현하려한다면, data가 충분하지 않기 때문입니다.

63
00:03:58,060 --> 00:04:02,300
어째서 data가 적으면, 많은 파라미터를 표현할 수 없는지도 역시

64
00:04:02,300 --> 00:04:03,990
뒤에서 다루겠습니다.

65
00:04:03,990 --> 00:04:07,780
하지만 m이 n보다 작을 때는 보통,

66
00:04:07,780 --> 00:04:11,260
feature 몇 개를 없애거나

67
00:04:11,260 --> 00:04:15,450
egularization이라는 기술을 사용합니다.

68
00:04:15,450 --> 00:04:20,420
regularization 역시 나중에 배우겠지만, 
많은 feature로

69
00:04:20,420 --> 00:04:23,660
많은 파라미터를 표현하는 것을 
적은 training set으로도 가능하게 해주는 방법입니다.

70
00:04:23,660 --> 00:04:27,380
하지만, regularization은 강의 후반부에 배울 주제입니다.

71
00:04:27,380 --> 00:04:32,625
정리하자면, X'X가 특이행렬이거나

72
00:04:32,625 --> 00:04:37,930
역행렬이 없을 경우
제가 추천하는 방법은,

73
00:04:37,930 --> 00:04:43,400
feature를 보고 x_1, x_2같은 
불필요한 feature가 있는지 찾아보는 것입니다.

74
00:04:43,400 --> 00:04:47,300
선형적으로 종속성이면, 
서로 선형 함수가 되고 있다고 해도 무방합니다.

75
00:04:47,300 --> 00:04:51,290
불필요한 feature가 있으면 그것들 중 하나를 지우면 좋습니다.

76
00:04:51,290 --> 00:04:53,050
두 개를 지울 필요는 없어요.

77
00:04:53,050 --> 00:04:55,330
하나를 지우면,

78
00:04:55,330 --> 00:04:58,790
역행렬이 없는 문제가 해결될 것입니다.

79
00:04:58,790 --> 00:05:02,430
그래서 저같은 경우는 feature중에서 불필요한게 있는지부터 확인합니다.

80
00:05:02,430 --> 00:05:05,770
불필요한게 있으면 없어질때까지

81
00:05:05,770 --> 00:05:07,190
feature를 지웁니다.

82
00:05:07,190 --> 00:05:09,220
feature중에서 불필요한게 없다면,

83
00:05:09,220 --> 00:05:11,640
feature가 많은지 확인합니다.

84
00:05:11,640 --> 00:05:16,050
많다면, 없어도 상관 없는 feature 몇 개를 지우고,

85
00:05:16,050 --> 00:05:20,390
아니면 regularization을 사용해야할지 고려합니다.

86
00:05:20,390 --> 00:05:22,570
regularization에 대해서는 나중에 얘기하겠습니다.

87
00:05:24,050 --> 00:05:26,690
이상이 normal equation에서

88
00:05:26,690 --> 00:05:31,640
행렬 X'X가 역행렬이 없을 때 무엇을 의미하는지에 대한 이야기였습니다.

89
00:05:31,640 --> 00:05:35,700
하지만, 이러한 문제는 거의 나타나지 않을 것입니다.

90
00:05:35,700 --> 00:05:38,490
게다가 octave에서 구현할 때는, pinv가 있습니다.

91
00:05:38,490 --> 00:05:42,410
pinv 함수는 pseudo-inverse함수입니다.

92
00:05:42,410 --> 00:05:46,100
만약 다른 선형대수학 라이브러리를 사용한다면
 pseudo-inverse라 불리는 것을 사용하면 됩니다.

93
00:05:46,100 --> 00:05:49,180
어찌됫든 pinv는 X'X의 역행렬이 없더라도,

94
00:05:49,180 --> 00:05:52,420
올바르게 계산을 해줍니다.
사실 그런 경우가 거의 일어나지 않기 때문에

95
00:05:52,420 --> 00:05:58,450
선형회귀 구현에서 크게 문제가 되지는 않을 것입니다.