בסרטון הקודם, דיברנו על צורת ההשערה של רגרסיה ליניארית עם תכונות מרובות או משתנים מרובים. בסרטון הזה, נדבר על איך מכיילים את הפרמטרים של ההשערה. בפרט נדבר על איך משתמשים בירידה במדרון - גְרַדְיֵינְט דִיסֶנְט - עבור רגרסיה ליניארית מרובת תכונות. חזרה קצרה על הסימונים שלנו, זו ההשערה הרשמית שלנו ברגרסיה ליניארית מרובת משתנים שבה אימצנו את ההסכמה ש-x0=1. הפרמטרים של המודל הם תטא-1 עד תטא-n, אבל במקום לחשוב על n הפרמטרים הנפרדים האלה, שגם זה אפשרי, אני במקום זה חושב על הפרמטרים כתטא שהוא וקטור תטא n+1-מימדי. אנחנו נחשוב על הפרמטרים של המודל הזה כאילו הם בעצמם וקטור. פונקצית העלות שלנו היא j של תטא-0 עד תטא-n היא אותו סכום של ריבועי השגיאה. אבל שוב במקום לחשוב על j כפונקציה של n+1 המספרים, אני בדרך כלל אכתוב j כפונקציה של וקטור הפרמטרים תטא ולכן תטא כאן הוא וקטור. הנה איך נראה אלגוריתם הירידה במדרון - גְרַדְיֵינְט דִיסֶנְט.
אנחנו הולכים לעדכן כל אחד מהפרמטרים תטא-j שוב ושוב לפי הנוסחה הזו, תטא-j פחות אלפא כפול הנגזרת כאן. וגם כאן אנחנו פשוט נכתוב את זה כ-J של תטא. טוב, אז כל פרמטר תטא-j מתעדכן לתטא-j פחות מקדם הלימוד אלפא כפול הנגזרת החלקית הזו של פונקצית העלות ביחס לפרמטר תטא-j. בואו נראה איך זה נראה כאשר אנו מיישמים את הירידה בשיפוע, ובפרט, בואו נראה איך נראית הנגזרת החלקית. הנה איך נראית הירידה בשיפוע עבור המקרה של תכונה אחת, N = 1. היו לנו שני כללי עדכון נפרדים עבור הפרמטרים תטא-0 ותטא-1, ואני מקווה שזה נראה לכם מוכר. הביטוי הזה כאן הוא כמובן הנגזרת החלקית של פונקצית העלות ביחס לפרמטר תטא-0, ובדומה לכך יש לנו כלל עדכון אחר עבור הפרמטר תטא-1. יש הבדל אחד קטן, שהוא שכשהיתה לנו רק תכונה אחת קראנו לה התכונה (x(i
אבל בסימון החדש שלנו היינו כמובן קוראים לה (x(i סימן תחתון 1 כדי
<u>לציין את התכונה האחת שלנו.</u> זה היה כאשר היתה לנו תכונה אחת בלבד. בואו נסתכל על האלגוריתם החדש בו יש לנו יותר ממאפיין אחד, שבו מספר התכונות n יכול להיות הרבה יותר גדול מאשר אחת. אנחנו מקבלים את כלל העדכון הזה עבור הירידה בשיפוע, ואולי עבור אלה מכם שיודעים חשבון דיפרנציאלי, אם תקח את הגדרת פונקצית העלות ותגזור נגזרת חלקית של פונקצית העלות J ביחס לפרמטר תטא-j, תראה שהנגזרת החלקית היא בדיוק הביטוי כאן שסביבו ציירתי את המלבן הכחול. ואם תיישמו את זה תקבלו יישום עובד של הירידה בשיפוע עבור רגרסיה לינארית מרובת-משתנים. הדבר האחרון שאני רוצה לעשות בשקופית הזו הוא לתת לכם תחושה של למה שני האלגוריתמים החדש והישן הם בערך אותו דבר או למה הם דומים או למה הם שניהם אלגוריתמים של ירידה בשיפוע. הבה נבחן מקרה בו יש לנו שתי תכונות או אולי יותר משתי תכונות, נניח שלושה כללי עדכון עבור הפרמטרים תטא-0, תטא-1, תטא-2 ואולי עוד ערכים של תטא. אם תסתכל על כלל העדכון עבור תטא-0, תגלה שהוא זהה לכלל העדכון שהיה לנו מקודם עבור המקרה של n=1. והסיבה שהם זהים היא, כמובן, כי לפי ההסכמות שלנו   x(i)<u> של 0 שווה ל-1., וזו</u> הסיבה ששני הביטויים האלה שציירתי סביבם את המרובע הסגול הם שקולים. בדומה, אם תסתכלו על כלל העדכון עבור תטא-1, תגלו שהביטוי הזה כאן הוא שווה ערך לביטוי שהיה לנו בעבר, או למשוואה בה השתמשנו בעבר עבור תטא-1, אלא שכאן כמובן אנחנו משתמשים בכיתוב החדש x(i)<u>1 כדי לציין</u> את התכונה הראשונה שלנו, ועכשיו שיש לנו יותר ממאפיין אחד יכולים להיות לנו כללי עדכון דומים עבור פרמטרים אחרים כמו תטא-2 וכן הלאה. יש הרבה חומר בשקף הזה אז אני בהחלט ממליץ לכם, אם אתם צריכים להשהות את הוידאו ולבחון בעיון את כל המתמטיקה בשקף הזה כדי לוודא שאתם מבינים מה קורה כאן. אבל בכל אופן, אם תיישמו את האלגוריתם שנכתב כאן תקבלו יישום עובד של רגרסיה ליניארית רבת-תכונות.