Di video ini dan di video selanjutnya, saya ingin membahas tentang beberapa trik praktis untuk membuat gradient
descent bekerja dengan baik. Di video ini, saya ingin membahas
tentang skala parameter. kita menggunakan for loop Jika Anda punya kasus dimana Anda punya beberapa parameter, jika Anda memastikan bahwa parameter itu berskala sama, maksud saya memastikan bahwa parameter berbeda memiliki jangkauan nilai yang serupa, maka gradient descent bisa menemukan
hasilnya lebih cepat. Konkritnya, katakanlah Anda punya kasus dengan 2 parameter dimana x1 adalah ukuran rumah dan memiliki nilai antara 0 - 2000, dan x2 adalah jumlah kamar tidur, dan mungkin bernilai antara 1 - 5. Jika Anda plot kontur fungsi harga J(theta), maka konturnya terlihat seperti ini, dimana J(theta) merupakan fungsi dari parameter theta0, theta1, dan
theta2. Saya akan mengabaikan theta0 dan menganggap J(theta) sebagai fungsi theta1 dan theta2. Jika x1 memuat jangkauan nilai yang lebih besar dari x2, kontur fungsi harga J(theta) bisa berbentuk elips yang sangat pipih ini, dan dengan rasio 2000:5, bentuknya bisa lebih pipih lagi. Jadi, elips atau oval yang sangat tinggi dan pipih ini, membentuk kontur fungsi harga J(theta) ini. Dan jika Anda menjalankan gradient
descent pada fungsi harga ini, gradient Anda perlu waktu yang sangat lama dan bisa berosilasi bolak-balik sebelum akhirnya menemukan minimum global. Bahkan, jika kontur ini semakin tinggi pipih, maka gradient descent jalannya akan berliku-liku, dan perlu waktu lebih lama lagi menuju ke minimum
global. Pada kasus seperti ini, perlu untuk menskala parameternya. Konkritnya, jika Anda mendefinisikan parameter x1 sebagai ukuran rumah dibagi 2000, dan x2 sebagai jumlah kamar tidur dibagi 5, maka perhitungan fungsi harga J bisa lebih simetris sehingga konturnya seperti lingkaran. Jika Anda menjalankan gradient descent pada fungsi harga seperti ini, maka Anda dapat menemukan jalan langsung ke minimum global dan bukannya jalan yang berliku-liku. Jadi, dengan menskala parameternya, nilai x1 dan x2, pada contoh ini, antara 0 dan 1. Dengan gradient descent, Anda bisa mendapatkan hasilnya jauh lebih cepat. Umumnya, saat kita menskala parameter, kita membuat setiap parameter dijangkauan nilai -1 s/d 1, dan konkritnya, parameter x0 selalu bernilai 1. Jadi, selalu x0 = 1, tapi parameter lainnya dibagi dengan angka yang berbeda agar nilainya dikisaran -1 s/d 1. Angka -1 dan +1 tidak terlalu penting. Jadi, jika Anda punya 1 parameter x1 yang bernilai antara 0 dan 3, itu tidak masalah. Jika Anda punya parameter berbeda yang bernilai antara -2 dan +0.5, ini cukup dekat dengan -1 dan +1, yang berarti tidak masalah. Jika Anda punya parameter berbeda, x3 yang nilainya antara -100 s/d 100, maka nilai ini sangat berbeda dari -1 dan +1. Jadi, ini parameter yang tidak diskala dengan baik. Sama halnya, jika Anda punya parameter x4 yang bernilai sangat kecil antara -0.0001 dan +0.0001, maka ini jauh lebih kecil dari -1 dan +1. Penskalaan parameter ini sangat jelek. Jadi, Anda perlu jangkauan nilai yang bisa lebih besar atau lebih kecil dari +1, tapi tidak seperti +100 atau terlalu kecil seperti 0.0001. Lain orang, lain juga aturannya. Aturan yang saya gunakan adalah, jika parameter bernilai dari, katakanlah -3 s/d +3, itu tidak masalah, kecuali nilainya lebih besar dari +3 atau -3. Jika nilainya, katakanlah dari -1/3 s/d 1/3, itu juga tidak masalah, begitu juga 0 s/d 1/3 atau -1/3 s/d 0. Saya kira, nilai di sekitar sektor 0 itu
masih oke. Kecuali nilainya sangat kecil seperti x4 ini. Jadi pesannya adalah jangan khawatir bila parameter Anda tidak sama skala atau jarak nilainya. Selama semua nilainya cukup dekat dengan gradient descent ini,
itu akan bekerja. Selain membagi dengan nilai maksimum saat menskala parameter, kadang orang juga melakukan normalisasi nilai
tengah. Itu maksudnya Anda mengambil paramater xi dan menggantinya dengan xi - ui untuk membuat nilai tengah parameter
Anda sekitar 0. Dan kita tidak akan menerapkan ini ke parameter x0, karena parameter x0 selalu bernilai 1, jadi x0 tidak punya nilai rata-rata 0. Tapi untuk parameter lain, jika ukuran rumah bernilai antara 0 - 2000, dan jika Anda tahu ukuran rata2 sebuah rumah sama dengan 1000, maka Anda boleh menggunakan rumus ini. Parameter x1 = ukuran rumah - nilai rata2 dibagi 2000. Sama halnya, jika rumah Anda punya 1 - 5 kamar tidur, dan rata2 rumah punya 2 kamar tidur, maka Anda bisa menggunakan rumus ini untuk menormalisasi nilai tengah parameter x2. Pada kedua kasus ini, Anda mendapatkan nilai parameter x1 dan x2. Kasarnya, nilainya antara -0.5 dan +0.5. Yang kedua tidak benar, x2 bisa sedikit lebih besar dari 0.5. Aturan yang lebih umum adalah Anda bisa mengambil parameter x1 dan menggantinya dengan x1-u1 dibagi s1, dimana u1 adalah nilai rata2 x1 dalam set latihan dan s1 adalah jarak nilai parameter itu, maksudnya, nilai maksimumnya kurang nilai minimumnya atau bagi mereka yang tahu deviasi variabel bisa juga menset s1 sebagai deviasi standar variabel. Tapi boleh juga menggunakan nilai
max-min. Dan sama halnya untuk parameter kedua, x2, diganti dengan nilai tengah parameternya dan membaginya dengan selisih nilai parameternya yaitu nilai max-min. Rumus ini akan menghasilkan nilai bagi parameter Anda di jarak ini. Bagi mereka yang sangat hati2 saat mengambil jaraknya sebagai nilai max-min, 5 ini sebenarnya akan jadi 4. Jadi, jika max 5 min 1, maka jarak nilai sebenarnya adalah 4, tapi semua ini adalah perkiraan dan setiap nilai parameter yang mendekati jarak nilai ini akan bekerja dengan baik. Menskala parameter juga tidak harus sangat tepat, agar gradient descent bekerja dengan cepat. Sekarang Anda tahu tentang menskala parameter, dan jika Anda menggunakan trik ini, itu dapat membuat gradient descent bekerja jauh lebih cepat dan mendapat
hasilnya dgn iterasi yg lebih sedikit. Begitulah menskala parameter. Pada video berikut, saya akan membahas tentang trik lain
yang pada prakteknya membuat gradient descent bekerja dengan baik.