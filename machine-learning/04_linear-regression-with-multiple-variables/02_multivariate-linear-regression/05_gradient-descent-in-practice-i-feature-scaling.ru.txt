В этом и следующем видеоуроках я хочу рассказать вам о некоторых практических приемах, которые позволяют улучшить работу метода градиентного спуска. В этом видео я хочу рассказать вам о понятии масштабирования переменных. которой мы в Если у вас есть задача с многими переменными, и если вы убедитесь, что они имеют одинаковый масштаб (то есть, разные переменные принимают значения из одного диапазона), то метод градиентного спуска сходится быстрее. Допустим, у вас есть задача с двумя переменными, где x1 - это площадь дома, принимает значения, скажем, от нуля до двух тысяч, а x2 - это количество спален, и оно принимает значения от нуля до пяти. Если вы построите линии уровня функции потерь J от тета, они могут выглядеть примерно так, где, как вы видите, J от тета - это функция параметров тета ноль, тета один и тета два. Я пренебрегу тета ноль (так что забудем о нем) и буду считать, что это функция только тета 1 и тета 2. Но раз x1 может принимать значения из гораздо большего диапазона, чем x2, окажется, что линии уровня функции потерь J от тета примут такую очень очень асимметричную форму эллипса. Хотя, если учесть отношение между 2000 и 5, линии уровня могут быть еще более вытянутыми. Такими очень, очень длинными и узкими эллипсами (овалами), могут быть представлены линии уровня функции потерь J от тета. И если вы запустите метод градиентного спуска для этой функции потерь, может оказаться, что ваши градиенты будут долго колебаться туда-сюда и еще не скоро найдут дорогу к глобальному минимуму. На самом деле, вы можете себе представить, что если еще больше вытянуть эти линии уровня, нарисовать их еще длиннее и уже, методу градиентного спуска будет гораздо труднее достичь результата, он будет метаться из стороны в сторону, и ему потребуется немало времени, чтобы найти глобальный минимум. В таких условиях бывает полезно отмасштабировать переменные. Например, если вместо старой переменной вы определите, что переменная x1 - это размер дома, разделенный на две тысячи, а x2 определите как количество спален, разделённое на пять, то линии уровня функции потерь J могут стать гораздо менее вытянутыми, более похожими на окружности. А, если вы запустите метод градиентного спуска для такой функции потерь, то вместо сложной траектории, полученной без масштабирования переменных, вы сможете найти гораздо более прямой путь к глобальному минимуму, что можно обосновать математически. Итак, масштабируя переменные, чтобы они принимали значения в похожих диапазонах, в этом примере мы получаем, что значения обеих переменных, x1 и x2, лежат между нулем и единицей. Вы можете завершить реализацию метода градиентного спуска, которая сходится гораздо быстрее. Как правило, когда мы выполняем масштабирование переменных, чаще всего мы хотим получить для каждой переменной диапазон значений примерно от -1 до +1. В частности, переменная x0 всегда равна 1. Таким образом, она уже в этом диапазоне, но вам может понадобиться разделить другие переменные на разные числа, чтобы перевести их в этот диапазон. Не так важно, чтобы это были числа -1 и +1. Так, если у вас есть переменная x1, которая оказалась в диапазоне между 0 и 3, это не проблема. Если в итоге у вас есть другая переменная, которая оказалась в диапазоне между -2, и +0.5, опять же, это достаточно близко к -1 и +1, и понятно, что оба эти варианта нам подойдут. Только если еще одна ваша переменная, например, х3, принимает значения от -100 до +100, то такой диапазон сильно отличается от значений между -1 и +1. Такая переменная может считаться хуже отмасштабированной. И, аналогично, если ваши переменные принимают значения в очень, очень маленьком диапазоне, например, х4 принимает значения от -0.0001 до +0.0001, то, опять же, этот диапазон будет гораздо меньше, чем диапазон от -1 до +1. И снова я бы назвал такую переменную плохо отмасштабированной. Итак, целевой диапазон значений может быть больше или меньше, чем от -1 до +1, но не намного больше, как в случае с +100, и не намного меньше, как в случае с 0.0001. На практике разные люди по-разному определяют приемлемые диапазоны. Я же использую такое правило: если переменная принимает значение в диапазоне, скажем, от -3 до +3, я обычно считаю, что это просто отлично, но, возможно, она принимает гораздо большие значения, чем +3 или -3, то с этим нужно что-то делать. А если переменная принимает значения, например, от -1/3 до +1/3? Знаете, я думаю, что это тоже хорошо. Или от 0 до 1/3, или от -1/3 до 0. Такие диапазоны я обычно считаю приемлемыми. Но  может требоваться меньший диапазон значений как х4,но гораздо реже,так что не беспокойтесь. Итак, не стоит волноваться, если диапазоны значений или масштабы ваших переменных не совпадают идеально. Если они достаточно к вот этому, метод градиентного спуска будет работать хорошо. Вдобавок к делению на максимальную величину, когда производится масштабирование, иногда выполняют нормировку на среднее. Я подразумеваю, что если вы хотите взять xi  и заменить его xi минус что-то , чтобы сделать ваше значение близким к нулю. И очевидно,что мы хотим применить это к будущему х нулевому, потому что будущее х нулевое всегда равно одному, так как у нас не может быть среднее значение ноль. Конкретнее для других примеров. Если диапазон размеров домов принимает значения между 0 и 2000 и средний размер дома равен 1000, вы можете использовать эту формулу. Установим значение x1 равным размеру минус средняя величина, деленное на 2000 и, аналогично, если у ваших домов от одной до пяти спален, и если в среднем в доме две спальни, то вы можете использовать эту формулу для нормировки на среднее вашего второго параметра x2. В обоих случаях, вы, в результате, получаете параметры x1 и x2, которые могут принимать значения примерно от минус 0,5 до плюс 0,5. Это не совсем верно: x2 может принимать значения чуть больше чем 0,5, но достаточно близко. И более общее правило. Вы можете взять х1 и заменить его х1 минус мю1 на S1, где мю1 обозначили среднее значение х1 и и S1 является область значений этой величины и диапазона, или можно сказать максимальное значение минус минимальное или для тех,кто понимает, в разбросе переменных устанавливается S1 как стандартное отклонение,что также подходит. Но к слову, максимальное минус минимальное также подойдет. И, аналогично, второй параметр, х2, мы заменяем тем же методом, вычитая среднее и деля его на диапазон значений, который определен как максимум минус минимум. Благодаря этой формуле, значения ваших параметров окажутся, пусть не точно, пусть приблизительно, но в таких примерно диапазона. Кстати, для тех из вас кто особо любит точность, замечу, что если мы определяем диапазон как максимум минус минимум, то эта пятерка здесь - на самом деле четверка. То есть, если 5 - максимум, 1 - минимум, то диапазон этих значений равен 4. Но все это довольно приблизительно, и любое значение, которое сделает диапазон сколько-нибудь похожим на те, что мы обсудили, вполне годится. Масштабирование переменных не должно быть точным, для того чтобы градиентный спуск сходился достаточно быстро. Итак вы знаете о масштабировании переменных и если примените эту хитрость, это ускорит градиентный спуск и сходимость в гораздо меньшее число итераций. Это было масштабирование переменных. В следующем видеоуроке я расскажу вам еще об одном приеме, который позволит методу градиентного спуска лучше работать на практике.