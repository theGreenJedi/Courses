En este video y en el video que sigue después, quiero hablarte sobre algunos trucos prácticos para lograr que el gradiente de descenso funcione bien. En este video, quiero hablarte acerca de una idea llamada escalamiento de características. tenemos un ciclo for para la sumatoria Cuando tienes un problema en donde hay múltiples características, si te aseguras de que las características están en una escala similar, y me refiero a que te asegures que las diferentes características toman rangos de valores similares, entonces los gradientes de descenso pueden converger más rápidamente. Específicamente, digamos que tienes un problema con dos características en donde x1 es el tamaño de la casa y toma valores entre, digamos,  0 y 2,000 y x2 es el número de dormitorios, que tal vez toma valores entre 1 y 5. Si trazas el contorno de la función de coseno "J" de theta, entonces el contorno puede verse así, en donde, vamos a ver, "J" de theta es una función de parámetros theta 0, theta 1 y theta 2. Voy a ignorar theta 0, así que vamos a olvidarnos de theta 0 y pretender que es una función de sólo theta 1 y theta 2, pero si x1 puede tomar como sabes, un rango mucho más amplio de valores y x2, resulta que el contorno de la función de coseno "J" de theta puede tomar esta forma elíptica muy pero muy sesgada, salvo que con el rango de 2,000 a 5, puede ser aún más sesgado. Por lo tanto, estas elipses, muy altas y delgadas, o estos óvalos muy altos y delgados, pueden formar los contornos de la función de coseno "J" de theta. Y si ejecutas los gradientes de descenso en esta función de coseno, tus gradientes pueden terminar tomando mucho tiempo y pueden oscilar de ida y vuelta y tardar mucho antes de que finalmente puedan encontrar su camino hacia el mínimo global. De hecho, puedes imaginar que estos contornos son incluso más exagerados cuando dibujas contornos increíblemente delgados,contornos altos y delgados, y pueden ser incluso más extremos entonces, para el gradiente de descenso simplemente es más difícil encontrar la ruta, serpenteando alrededor, y puede tomar mucho tiempo encontrar el camino hacia el mínimo global. En esta configuración, una cosa útil es escalar las características. Específicamente, si por el contrario defines que la característica x1 sea el tamaño de la casa dividido entre 2,000, y defines que x2 sea el número de habitaciones dividido entre cinco, entonces los contornos de la función coseno "J" puede ser mucho más, mucho menos sesgada por lo que los contornos pueden parecer más circulares. Y si ejecutas el gradiente descendente en una función coseno como esta, entonces el gradiente de descenso, puede mostrarse matemáticamente, puedes encontrar una ruta más directa al mínimo global en lugar de tomar un camino mucho más complicado en donde estás tratando de seguir una trayectoria mucho más complicada para llegar al mínimo global. Así que, al escalar las características que existen, los rangos de valores del consumidor . En este ejemplo, terminamos con ambas características, x1 y x2, entre 0 y 1. Puedes concluir con una implementación de gradiente de descenso. Se pueden convertir mucho más rápido. De manera más general, cuando estamos realizando el escalamiento de características, lo que a menudo queremos es lograr que cada característica tenga un rango aproximado de -1 a +1 y que específicamente, tu característica x0 sea siempre igual a 1. Así, que ya está en ese rango, pero puedes terminar dividiendo otras características entre diferentes números para llevarlos a ese rango. Los números -1 y +1 no son muy importantes. Por lo que si tienes una característica, x1 que termina estando entre 0 y 3, no será un problema. Si terminas con una característica diferente que serpentea estando entre -2 y +0.5 de nuevo, está suficientemente cerca de -1 y +1 lo que, como sabes, está bien, y esto está bien. Es sólo que si tienes una característica diferente, digamos x3 que está entre, esos rangos de -100 a +100, entonces, estos son valores muy diferentes a -1 y +1. Por lo tanto, esta podría ser una característica no tan bien escalada y del mismo modo si tus características toman un rango muy pero muy pequeño de valores, por lo que x4 toma los valores entre -0.0001 y +0.0001, entonces de nuevo esto toma un rango de valores mucho menor que el rango de -1 a +1. Y de nuevo, yo consideraría esta característica muy mal escalada. Así es que queremos que el rango de valores, como sabes, pueda ser mayor que +1 o menor que +1, pero no mucho mayor,  +100 como aquí, y no mucho menor como el 0.001 de allá. Diferentes personas tienen diferentes reglas de oro. Pero la que yo utilizo es que si una función toma el rango de valores de digamos, -3 a +3 podrías pensar que debe estar bien, pero quizá tome valores mucho mayores que +3 o -3 a no ser que no haya de que preocuparse y si toma valores, por ejemplo, de menos un tercio a un tercio. Como sabes, creo que también está bien o de 0 a un tercio o de menos un tercio a 0. Pienso que es un rango típico de valores sector 0, OK. Pero si toma un rango de valores mucho más pequeño como x4 de aquí, entonces no hay de qué preocuparse. Así que, el mensaje para llevar a casa es que no debes preocuparte si tus características no están exactamente en la misma escala o exactamente en el mismo rango de valores. Pero mientras que todas estén lo suficientemente cerca a este gradiente de descenso debería funcionar bien. Además dividiendo así entre el máximo valor cuando se realiza el escalamiento de características a veces la gente también realiza lo que se conoce como normalización media. Y a lo que me refiero con eso, es que quieres tomar una característica xi y remplazarla con xi - «Mu» i para hacer que tus características tengan una media aproximada de 0. Y, obviamente, queremos aplicar esto a una futura x0, porque la futura x0 es siempre igual a 1, por lo que no puede tener un valor promedio de 0. Pero específicamente para otras características si el rango de tamaños de la casa toma valores de entre 0 y 2,000 y si sabes que el tamaño promedio de una casa es igual a 1,000 entonces es posible que debas usar esta fórmula. El tamaño establece la característica x1 al tamaño menos el valor promedio dividido entre 2,000 y de manera similar, en promedio si tus casas tienen de uno a cinco dormitorios y si las casas promedio tienen dos dormitorios, entonces podrías usar esta fórmula para normalizar la media de tu segunda característica x2. En ambos casos, terminarás por lo tanto con características x1 y x2. Pueden tomar valores más o menos de entre -.5 y +.5. No es exacto ya que -x2 puede en realidad ser ligeramente mayor que .5, pero estar lo suficientemente cerca. Y la regla más general es que puedes tomar una característica x1 y remplazarla con x1 - «Mu» 1 sobre s1 en donde para definir estos términos, «Mu» 1 es el valor promedio de x1 en los conjuntos de entrenamiento y s1 es el rango de valores de esa característica y por rango, quiero decir, el  valor máximo menos el valor mínimo o para aquellos de ustedes que entienden la desviación de la variable es establecer que s1 sea la desviación estándar de la variable estaría bien también. Tomar, como sabes, este máximo menos el mínimo estaría bien. Y de manera similar para la segunda característica, x2, reemplazas x2 con este tipo de resta, la media de la característica y la divides entre el rango de valores refiriéndonos al máximo menos el mínimo. Y este tipo de fórmula hará que tus características, como sabes, no exactamente, pero más o menos estén dentro de este tipo de rangos, y por cierto para aquellos de ustedes que están siendo muy cuidadosos técnicamente si estamos tomando el rango como máximo menos mínimo este 5 de aquí en realidad se convertirá en un 4. Así es que si el máximo es 5 menos 1 entonces el rango de sus propios valores es en realidad igual a 4, pero todos estos son aproximados y cualquier valor que hace que las características sean cercanas a cualquiera de estos rangos estará bien. Y el escalamiento de características no tiene que ser demasiado exacto, con el fin de lograr que el gradiente descendente se ejecute mucho más rápido. Así es que ahora sabes sobre el escalamiento de características y que si aplicas este simple truco, lograrás que el gradiente de descenso funcione mucho más rápido y converja en muchas menos otras iteraciones. Eso fue el escalamiento de características. En el siguiente video, te diré otro truco para hacer que el gradiente de descenso funcione bien en la práctica.