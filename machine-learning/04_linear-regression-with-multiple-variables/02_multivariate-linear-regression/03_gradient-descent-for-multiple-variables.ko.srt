1
00:00:00,220 --> 00:00:03,688
이전 영상에서 여러 요소들=feature과 변수들을 이용한

2
00:00:03,688 --> 00:00:07,246
선형회귀 추론=hypothesis 에 대해서 살펴보았습니다.

3
00:00:07,246 --> 00:00:11,912
이번 영상에서는 추론의 파라미터를 어떻게 지정하는 지 알아보도록 하죠.

4
00:00:11,912 --> 00:00:15,175
특히, 어떻게 여러 요소들의 선형 회귀에

5
00:00:15,175 --> 00:00:19,875
경사 하강법을 적용하는 지도 알아보도록 하겠습니다.

6
00:00:19,875 --> 00:00:24,802
빠르게 저번 시간에 지정한 변수명을 살펴보겠습니다.

7
00:00:24,802 --> 00:00:31,509
이는  x0=1의 공식을 적용한 다선량 선형 회귀의 형식입니다.

8
00:00:31,509 --> 00:00:37,505
해당 모델의 파라미터는 θ0 ~ θn까지 있지만 이 파라미터들이

9
00:00:37,505 --> 00:00:42,385
n으로 분리된 파라미터로 생각하는 대신에, 사실 이것도 맞는 것이지만, 파라미터들을

10
00:00:42,385 --> 00:00:51,175
θ로 여기도록 하겠습니다. 여기서의 θ는 n+1 차원의 벡터죠.

11
00:00:51,175 --> 00:00:55,498
이제 해당 모델의 파라미터들을

12
00:00:55,498 --> 00:00:58,674
벡터 그 자체라 하겠습니다.

13
00:00:58,674 --> 00:01:03,507
이 비용 함수는 j의 θ0~ θn이고 이것은 보통 오차항의 승의 합에서 구해지죠.

14
00:01:03,507 --> 00:01:08,983
그런데 다시 말하지만 j를 n+1 의 수의 함수로 생각하는 대신,

15
00:01:08,983 --> 00:01:14,016
j를 파라미터 벡터 θ의 함수라 하겠습니다

16
00:01:14,016 --> 00:01:22,275
그럼 θ가 벡터가 되겠지요.

17
00:01:22,275 --> 00:01:26,897
바로 이것을 경사 하강이라 볼 수 있습니다.

18
00:01:26,897 --> 00:01:32,142
이제 파라미터 θ j를 θj- α*파생되는 변수에 의해서 계속 덮어 쓸 것입니다.

19
00:01:32,142 --> 00:01:37,868
그리고 다시 이걸 j의 θ로 표현해서, θj가

20
00:01:37,868 --> 00:01:41,840
θj – α의 학습률 * 파생되는 변수로 계속 업데이트 될 것입니다.

21
00:01:41,840 --> 00:01:47,840
부분적 비용 함수의 파생변수는 각각의 θj 파라미터가 될 것입니다.

22
00:01:47,840 --> 00:01:51,305
이제 경사 강하를 적용했을 때 어떤 모습일 지 한 번 보겠습니다.

23
00:01:51,305 --> 00:01:55,985
그리고 특별히 부분 파생 변수도 함께 살펴보겠습니다.

24
00:01:55,985 --> 00:02:01,383
여기 n=1 요소가 있는 경우에 경사 하강을 하는 것을 볼 수 있습니다.

25
00:02:01,383 --> 00:02:06,782
그리고 각각의 θ0, θ1는 각각 분리된 업데이트 규칙=update rules들을 갖고 있습니다.

26
00:02:06,782 --> 00:02:12,779
화면이 여러분에게 친숙하셨으면 좋겠네요. 여기의 변수는 당연히

27
00:02:12,779 --> 00:02:17,672
θ0의 파라미터와 관련된 비용 함수의 부분 파생입니다.

28
00:02:17,672 --> 00:02:21,891
이와 유사하게 θ1 파라미터의 업데이트 규칙도 있습니다.

29
00:02:21,891 --> 00:02:26,259
우리가 앞서 단일 요소=feature만을 갖고 있었을 때와는 조금 다른 모습이지요.

30
00:02:26,259 --> 00:02:31,992
우리는 feature x(i)라 부르기로 했지만 새로운 명명에서는

31
00:02:31,992 --> 00:02:38,462
하나의 요소를 x(i)<u>1</u> 이라 불렀습니다.

32
00:02:38,462 --> 00:02:41,019
이게 요소 하나만 가지고 있는 경우이고요.

33
00:02:41,019 --> 00:02:44,496
그럼 이제 요소들의 개수인 n이 1 보다 큰 경우,

34
00:02:44,496 --> 00:02:47,350
즉 하나 이상의 요소를 가질 때의 알고리즘을 살펴보시겠습니다.

35
00:02:47,350 --> 00:02:53,158
이 업데이트 규칙을 경사 하강법으로 가져왔어요, 혹시 여러분 중

36
00:02:53,158 --> 00:02:57,781
미적분에 대해 아는 분은 비용 함수의 정의를 가질 때와

37
00:02:57,781 --> 00:03:03,312
θ0의 파라미터와 관련된 비용 함수의 부분 파생 θ1 을 가질 때

38
00:03:03,312 --> 00:03:08,119
여기 파란색 박스로 표시해 둔 부분의 부분 파생과

39
00:03:08,119 --> 00:03:10,665
동일한 것을 확인하실 수 있을 겁니다.

40
00:03:10,665 --> 00:03:14,837
다변수 선형 회귀의

41
00:03:14,837 --> 00:03:18,962
경사 하강를 적용할 수 있는 일을 한 것입니다.

42
00:03:18,962 --> 00:03:21,572
이번 슬라이드에서 마지막으로 제가 말하고 싶은 것은

43
00:03:21,572 --> 00:03:26,882
왜 새로 나오는 알고리즘이나 기존 알고리즘들이 결국에는 같거나 유사한 지,

44
00:03:26,882 --> 00:03:30,904
그리고 왜 이 두 알고리즘이 결국은 둘 다 경사 하강인지 그 느낌의 차이를 알려주고 싶습니다.

45
00:03:30,904 --> 00:03:34,363
자, 우리에게 두 개 또는 두 개 이상의

46
00:03:34,363 --> 00:03:37,488
요소가 있다고 가정해보겠습니다, 이제 우리는

47
00:03:37,488 --> 00:03:42,680
θ0, θ1, θ2 에 대응되는 세 개의 업데이트 규칙들이 있겠지요. 
다른 θ가 있을 수도 있겠고요.

48
00:03:42,680 --> 00:03:49,457
만약, θ0의 업데이트 규칙을 보면, 이 업데이트 규칙은

49
00:03:49,457 --> 00:03:55,300
앞서 가졌던 업데이트 규칙의,

50
00:03:55,300 --> 00:03:57,350
n = 1 인 경우의 업데이트 규칙과 동일하다는 것을 알 것입니다.

51
00:03:57,350 --> 00:04:00,203
그 이유는 이들이, 당연히,

52
00:04:00,203 --> 00:04:06,871
모두 명명 규칙에 따라 x(i)<u>0</u>~ = 1 를 따랐기 때문이고,

53
00:04:06,871 --> 00:04:12,003
이는 여기 자주색으로 표시한 박스 안의 두 변수가 동일한 이유입니다.

54
00:04:12,003 --> 00:04:16,010
이와 유사하게, θ1의 업데이트 규칙을 보면,

55
00:04:16,010 --> 00:04:21,540
여기 이 변수는 앞서 θ1에서 가졌던,

56
00:04:21,540 --> 00:04:25,020
공식 또는 θ1 에서 기존에 갖고있던 업데이트 규칙이고 이는

57
00:04:25,020 --> 00:04:30,222
첫 번째 요소를 부르기 위해 x(i)<u>1</u>로 새롭게 지정한 것이였지요.

58
00:04:30,222 --> 00:04:37,605
이제 우리는 하나 이상의 요소를 가진 것이고

59
00:04:37,605 --> 00:04:43,560
다음 θ2 파라미터에도 비슷한 업데이트 규칙을 갖도록 할 것입니다.

60
00:04:43,560 --> 00:04:48,219
해당 슬라이드에서 우리는 많은 것을 다뤘습니다. 그러니 잠시 영상을 멈추고

61
00:04:48,219 --> 00:04:52,020
여기 이 슬라이드에 있는 수학 공식들을 천천히 살펴보면서

62
00:04:52,020 --> 00:04:55,446
이해해 보는 시간을 갖도록 하십시오.

63
00:04:55,446 --> 00:05:00,440
만약 여기의 알고리즘을 이해하고 구현할 수 있다면

64
00:05:00,440 --> 00:05:51,300
다변수의 선형회귀의 구현이 동작하는 환경을 구축할 수 있을 것입니다.