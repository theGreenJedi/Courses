1
00:00:00,300 --> 00:00:02,220
在聚类问题中

2
00:00:02,360 --> 00:00:03,630
我们有未加标签的数据

3
00:00:03,950 --> 00:00:05,040
我们希望有一个算法

4
00:00:05,200 --> 00:00:06,480
能够自动的

5
00:00:07,320 --> 00:00:08,700
把这些数据分成

6
00:00:09,340 --> 00:00:11,000
有紧密关系的子集或是簇

7
00:00:12,380 --> 00:00:14,160
K均值 (K-means) 算法

8
00:00:14,310 --> 00:00:15,860
是现在最为广泛使用的

9
00:00:16,090 --> 00:00:17,410
聚类方法

10
00:00:17,780 --> 00:00:19,380
那么在这个视频中

11
00:00:19,550 --> 00:00:20,320
我将会告诉你

12
00:00:20,570 --> 00:00:23,400
什么是K均值算法以及它是怎么运作的

13
00:00:27,000 --> 00:00:29,310
K均值算法最好用图来表达

14
00:00:29,960 --> 00:00:30,770
如图所示

15
00:00:31,080 --> 00:00:32,330
现在我有一些

16
00:00:32,490 --> 00:00:34,040
没加标签的数据

17
00:00:34,100 --> 00:00:36,450
而我想将这些数据分成两个簇

18
00:00:37,710 --> 00:00:38,740
现在我执行K均值算法

19
00:00:39,080 --> 00:00:41,560
方法是这样的

20
00:00:41,910 --> 00:00:44,190
首先我随机选择两个点

21
00:00:44,410 --> 00:00:45,920
这两个点叫做聚类中心 (cluster centroids)

22
00:00:46,700 --> 00:00:48,170
就是图上边的两个叉

23
00:00:49,010 --> 00:00:51,730
这两个就是聚类中心

24
00:00:53,270 --> 00:00:54,320
为什么要两个点呢

25
00:00:55,100 --> 00:00:57,840
因为我希望聚出两个类

26
00:00:59,130 --> 00:01:02,400
K均值是一个迭代方法 它要做两件事情

27
00:01:03,480 --> 00:01:04,790
第一个是簇分配

28
00:01:05,330 --> 00:01:07,800
第二个是移动聚类中心

29
00:01:08,360 --> 00:01:09,630
我来告诉你这两个是干嘛的

30
00:01:11,170 --> 00:01:12,520
在K均值算法的每次循环中

31
00:01:12,700 --> 00:01:14,930
第一步是要进行簇分配

32
00:01:15,840 --> 00:01:17,070
这就是说

33
00:01:17,220 --> 00:01:18,360
我要遍历所有的样本

34
00:01:18,700 --> 00:01:19,880
就是图上所有的绿色的点

35
00:01:20,170 --> 00:01:22,120
然后依据

36
00:01:22,580 --> 00:01:24,140
每一个点

37
00:01:24,350 --> 00:01:25,530
是更接近红色的这个中心

38
00:01:25,620 --> 00:01:27,390
还是蓝色的这个中心

39
00:01:27,560 --> 00:01:28,570
来将每个数据点

40
00:01:28,670 --> 00:01:30,670
分配到两个不同的聚类中心中

41
00:01:32,040 --> 00:01:33,350
具体来讲

42
00:01:33,460 --> 00:01:34,610
我指的是

43
00:01:34,730 --> 00:01:36,930
对数据集中的所有点

44
00:01:37,130 --> 00:01:38,510
依据他们

45
00:01:38,810 --> 00:01:39,890
更接近红色这个中心

46
00:01:40,160 --> 00:01:41,060
还是蓝色这个中心

47
00:01:41,170 --> 00:01:42,150
进行染色

48
00:01:42,470 --> 00:01:45,210
染色之后的结果如图所示

49
00:01:46,930 --> 00:01:48,700
以上就是簇分配的步骤

50
00:01:49,780 --> 00:01:52,270
K均值的另一部分

51
00:01:52,410 --> 00:01:53,390
是要移动聚类中心

52
00:01:53,590 --> 00:01:54,860
具体的操作方法

53
00:01:55,020 --> 00:01:55,730
是这样的

54
00:01:55,800 --> 00:01:56,890
我们将两个聚类中心

55
00:01:57,390 --> 00:01:58,550
也就是说红色的叉

56
00:01:58,830 --> 00:02:00,270
和蓝色的叉

57
00:02:00,420 --> 00:02:01,420
移动到

58
00:02:02,070 --> 00:02:03,900
和它一样颜色的那堆点的均值处

59
00:02:04,880 --> 00:02:05,700
那么我们要做的是

60
00:02:05,730 --> 00:02:06,510
找出所有红色的点

61
00:02:06,630 --> 00:02:07,810
计算出它们的均值

62
00:02:08,240 --> 00:02:09,520
就是所有红色的点

63
00:02:10,080 --> 00:02:11,500
平均下来的位置

64
00:02:11,650 --> 00:02:13,690
然后我们就把红色点的聚类中心移动到这里

65
00:02:14,190 --> 00:02:15,260
蓝色的点也是这样

66
00:02:15,460 --> 00:02:16,370
找出所有蓝色的点

67
00:02:16,560 --> 00:02:17,720
计算它们的均值

68
00:02:17,840 --> 00:02:19,710
把蓝色的叉放到那里

69
00:02:20,320 --> 00:02:20,880
那我们现在就这么做

70
00:02:21,170 --> 00:02:22,990
我们将按照图上所示这么移动

71
00:02:24,590 --> 00:02:27,350
现在两个中心都已经移动到新的均值那里了

72
00:02:28,300 --> 00:02:29,760
你看

73
00:02:29,820 --> 00:02:31,350
蓝色的这么移动

74
00:02:31,510 --> 00:02:34,460
红色的这么移动

75
00:02:34,620 --> 00:02:35,460
然后我们就会进入下一个

76
00:02:35,910 --> 00:02:36,920
簇分配

77
00:02:37,190 --> 00:02:38,090
我们重新检查

78
00:02:38,160 --> 00:02:39,670
所有没有标签的样本

79
00:02:40,090 --> 00:02:42,840
依据它离红色中心还是蓝色中心更近一些

80
00:02:43,340 --> 00:02:45,150
将它染成红色或是蓝色

81
00:02:45,640 --> 00:02:47,160
我要将每个点

82
00:02:47,530 --> 00:02:48,550
分配给两个中心的某一个 就像这么做

83
00:02:51,450 --> 00:02:52,260
你看某些点的颜色变了

84
00:02:53,400 --> 00:02:55,690
然后我们又要移动聚类中心

85
00:02:56,040 --> 00:02:56,810
于是我计算

86
00:02:57,070 --> 00:02:57,880
蓝色点的均值

87
00:02:58,110 --> 00:02:59,000
还有红色点的均值

88
00:02:59,040 --> 00:03:00,360
然后就像图上所表示的

89
00:03:00,480 --> 00:03:03,770
移动两个聚类中心

90
00:03:03,930 --> 00:03:05,650
来我们再来一遍

91
00:03:06,160 --> 00:03:07,810
下面我还是要做一次簇分配

92
00:03:08,320 --> 00:03:09,450
将每个点

93
00:03:09,620 --> 00:03:10,840
染成红色或是蓝色

94
00:03:11,170 --> 00:03:13,070
依然根据它们离那个中心近

95
00:03:13,310 --> 00:03:20,000
然后是移动中心 你看就像这样

96
00:03:20,350 --> 00:03:21,230
实际上

97
00:03:21,290 --> 00:03:23,250
如果你从这一步开始

98
00:03:23,500 --> 00:03:26,020
一直迭代下去

99
00:03:26,160 --> 00:03:27,240
聚类中心是不会变的

100
00:03:27,540 --> 00:03:28,770
并且

101
00:03:28,830 --> 00:03:29,760
那些点的颜色也不会变

102
00:03:29,940 --> 00:03:31,520
在这时

103
00:03:31,810 --> 00:03:33,520
我们就能说

104
00:03:33,770 --> 00:03:35,290
K均值方法已经收敛了

105
00:03:35,400 --> 00:03:36,430
在这些数据中找到两个簇

106
00:03:37,470 --> 00:03:38,750
K均值表现的很好

107
00:03:39,360 --> 00:03:40,310
来我们用更加规范的格式描述K均值算法

108
00:03:42,150 --> 00:03:43,930
K均值算法接受两个输入

109
00:03:44,570 --> 00:03:46,200
第一个是参数K

110
00:03:46,450 --> 00:03:47,260
表示你想从数据中

111
00:03:47,830 --> 00:03:48,900
聚类出的簇的个数

112
00:03:49,640 --> 00:03:50,820
我一会儿会讲到

113
00:03:51,170 --> 00:03:53,290
我们可以怎样选择K

114
00:03:53,470 --> 00:03:54,600
这里呢 我们只是说

115
00:03:55,110 --> 00:03:56,210
我们已经确定了

116
00:03:56,360 --> 00:03:57,600
需要几个簇

117
00:03:57,690 --> 00:03:58,810
然后我们要告诉这个算法

118
00:03:59,040 --> 00:04:00,730
我们觉得在数据集里有多少个簇

119
00:04:01,170 --> 00:04:02,120
K均值同时要

120
00:04:02,490 --> 00:04:03,430
接收另外一个输入

121
00:04:03,880 --> 00:04:05,060
那就是只有 x 的

122
00:04:05,250 --> 00:04:06,530
没有标签 y 的训练集

123
00:04:06,710 --> 00:04:08,430
因为这是非监督学习

124
00:04:08,520 --> 00:04:10,690
我们用不着 y

125
00:04:10,980 --> 00:04:12,470
同时在非监督学习的

126
00:04:12,740 --> 00:04:14,020
K均值算法里

127
00:04:14,550 --> 00:04:16,160
我们约定

128
00:04:16,420 --> 00:04:17,750
x(i) 是一个n维向量

129
00:04:18,280 --> 00:04:19,190
这就是

130
00:04:19,750 --> 00:04:22,460
训练样本是 n 维而不是 n+1 维的原因

131
00:04:24,340 --> 00:04:25,430
这就是K均值算法

132
00:04:27,180 --> 00:04:28,630
第一步是

133
00:04:28,790 --> 00:04:31,170
随机初始化 K 个聚类中心

134
00:04:31,570 --> 00:04:33,550
记作

135
00:04:33,820 --> 00:04:34,610
μ1, μ2 一直到 μk

136
00:04:34,840 --> 00:04:36,250
就像之前

137
00:04:36,650 --> 00:04:38,450
图中所示

138
00:04:38,550 --> 00:04:40,770
聚类中心对应于

139
00:04:41,060 --> 00:04:42,240
红色叉和蓝色叉

140
00:04:42,660 --> 00:04:44,020
所在的位置

141
00:04:44,410 --> 00:04:45,640
于是我们有两个聚类中心

142
00:04:45,960 --> 00:04:47,000
按照这样的记法

143
00:04:47,170 --> 00:04:48,470
红叉是 μ1

144
00:04:48,650 --> 00:04:49,940
蓝叉是 μ2

145
00:04:50,300 --> 00:04:51,360
通常情况下

146
00:04:51,820 --> 00:04:53,830
我们可能会有比2要多的聚类中心

147
00:04:54,520 --> 00:04:56,240
K均值的内部循环

148
00:04:56,520 --> 00:04:57,360
是这样的

149
00:04:57,830 --> 00:04:59,020
我们会重复做下面的事情

150
00:05:00,070 --> 00:05:01,950
首先

151
00:05:02,160 --> 00:05:03,920
对于每个训练样本

152
00:05:04,110 --> 00:05:05,950
我们用变量 c(i) 表示

153
00:05:06,790 --> 00:05:07,960
K个聚类中心中最接近 x(i) 的

154
00:05:08,170 --> 00:05:10,520
那个中心的下标

155
00:05:11,170 --> 00:05:13,810
这就是簇分配

156
00:05:14,330 --> 00:05:16,870
这个步骤

157
00:05:17,000 --> 00:05:18,680
我先将每个样本

158
00:05:18,980 --> 00:05:20,740
依据它离那个聚类中心近

159
00:05:21,050 --> 00:05:22,050
将其染成

160
00:05:22,380 --> 00:05:23,940
红色或是蓝色

161
00:05:24,140 --> 00:05:25,090
所以 c(i) 是一个

162
00:05:25,280 --> 00:05:26,280
在1到 K 之间的数

163
00:05:26,380 --> 00:05:27,680
而且它表明

164
00:05:27,780 --> 00:05:28,760
这个点到底是

165
00:05:28,920 --> 00:05:29,820
更接近红色叉

166
00:05:29,900 --> 00:05:31,170
还是蓝色叉

167
00:05:32,200 --> 00:05:33,210
另一种表达方式是

168
00:05:33,580 --> 00:05:35,350
我想要计算 c(i)

169
00:05:35,620 --> 00:05:37,820
那么

170
00:05:37,890 --> 00:05:39,120
我要用第i个样本x(i)

171
00:05:39,380 --> 00:05:41,170
然后

172
00:05:41,360 --> 00:05:42,670
计算出这个样本

173
00:05:43,900 --> 00:05:44,860
距离所有K个聚类中心的距离

174
00:05:45,410 --> 00:05:46,690
这是 μ

175
00:05:47,060 --> 00:05:48,640
以及小写的k

176
00:05:48,890 --> 00:05:50,630
大写的 K 表示

177
00:05:50,910 --> 00:05:51,900
所有聚类中心的个数

178
00:05:52,100 --> 00:05:53,160
小写的 k 则是

179
00:05:53,770 --> 00:05:55,140
不同的中心的下标

180
00:05:56,240 --> 00:05:58,470
我希望的是

181
00:05:58,550 --> 00:06:00,110
在所有K个中心中

182
00:06:00,550 --> 00:06:01,930
找到一个k

183
00:06:02,120 --> 00:06:03,650
使得xi到μk的距离

184
00:06:03,900 --> 00:06:04,750
是xi到所有的聚类中心的距离中

185
00:06:04,800 --> 00:06:06,130
最小的那个

186
00:06:06,340 --> 00:06:08,990
也就是说

187
00:06:09,070 --> 00:06:10,350
k的值使这个最小

188
00:06:10,940 --> 00:06:12,160
这就是计算ci的方法

189
00:06:12,300 --> 00:06:14,100
这里还有

190
00:06:14,360 --> 00:06:16,470
另外的表示ci的方法

191
00:06:18,050 --> 00:06:19,150
我用xi减μk的范数

192
00:06:19,270 --> 00:06:21,500
来表示

193
00:06:23,000 --> 00:06:24,120
这是第i个训练样本

194
00:06:24,630 --> 00:06:26,040
到聚类中心μk

195
00:06:26,180 --> 00:06:27,350
的距离

196
00:06:28,140 --> 00:06:30,280
注意

197
00:06:31,150 --> 00:06:32,830
我这里用的是小写的k

198
00:06:33,320 --> 00:06:34,710
大写的K

199
00:06:34,980 --> 00:06:36,210
大写的k表示

200
00:06:36,450 --> 00:06:38,020
聚类中心的总数

201
00:06:38,770 --> 00:06:40,430
这个小写的k

202
00:06:40,790 --> 00:06:41,840
是第一个到第K个中心

203
00:06:41,960 --> 00:06:42,940
中的一个

204
00:06:43,210 --> 00:06:44,450
我用小写的k

205
00:06:44,930 --> 00:06:45,990
表示不同聚类中心的下标

206
00:06:47,130 --> 00:06:49,020
这是个小写k

207
00:06:50,050 --> 00:06:51,330
这就是某个样本到聚类中心的距离

208
00:06:51,490 --> 00:06:52,810
接下来

209
00:06:53,050 --> 00:06:54,330
我要做的是

210
00:06:55,250 --> 00:06:56,390
找出小写的k的值

211
00:06:56,710 --> 00:06:58,900
让这个式子最小

212
00:06:59,080 --> 00:07:00,320
那么

213
00:07:00,480 --> 00:07:02,100
接下来

214
00:07:02,280 --> 00:07:03,610
我就要将 c(i)

215
00:07:04,000 --> 00:07:06,560
赋值为k

216
00:07:06,760 --> 00:07:07,850
我这里按照惯例表示

217
00:07:08,190 --> 00:07:09,430
x(i) 和聚类中心的距离

218
00:07:09,480 --> 00:07:11,310
因为出于惯例

219
00:07:11,820 --> 00:07:13,330
人们更喜欢用距离的平方来表示

220
00:07:13,780 --> 00:07:15,370
所以我们可以认为

221
00:07:15,660 --> 00:07:16,860
c(i) 是距样本 x(i) 的距离的平方

222
00:07:17,450 --> 00:07:20,110
最小的那个聚类中心

223
00:07:20,750 --> 00:07:22,080
当然

224
00:07:22,500 --> 00:07:23,700
使距离的平方最小或是距离最小

225
00:07:23,880 --> 00:07:25,670
都能让我们得到相同的 c(i)

226
00:07:25,830 --> 00:07:26,670
但是我们通常还是

227
00:07:26,750 --> 00:07:28,120
写成距离的平方

228
00:07:28,430 --> 00:07:31,020
因为这是约定俗成的

229
00:07:31,170 --> 00:07:32,320
这就是簇分配

230
00:07:33,480 --> 00:07:34,750
K均值循环中的另一部分是

231
00:07:34,980 --> 00:07:37,740
移动聚类中心

232
00:07:40,540 --> 00:07:41,750
这是说

233
00:07:42,160 --> 00:07:43,460
对于每个聚类中心

234
00:07:43,550 --> 00:07:44,740
也就是说

235
00:07:44,870 --> 00:07:46,190
小写k从1循环到K

236
00:07:46,710 --> 00:07:48,460
将 μk 赋值为这个簇的均值

237
00:07:49,270 --> 00:07:50,720
举个栗子

238
00:07:50,910 --> 00:07:52,100
某一个聚类中心

239
00:07:52,340 --> 00:07:53,420
比如说是 μ2

240
00:07:53,750 --> 00:07:55,030
被分配了一些训练样本

241
00:07:55,820 --> 00:08:02,390
像是1,5,6,10

242
00:08:03,220 --> 00:08:04,270
这个表明

243
00:08:04,470 --> 00:08:05,510
c(1) 等于2

244
00:08:06,560 --> 00:08:09,180
c(5) 等于2

245
00:08:10,690 --> 00:08:12,180
c(6) 等于2

246
00:08:12,300 --> 00:08:13,730
同样的 c(10) 也是等于2 对吧?

247
00:08:14,970 --> 00:08:17,070
如果我们从上一步

248
00:08:17,160 --> 00:08:18,940
也就是簇分配那一步得到了这些

249
00:08:19,190 --> 00:08:21,250
这个表明

250
00:08:21,450 --> 00:08:22,960
样本1 5 6 10被分配给了聚类中心2

251
00:08:24,020 --> 00:08:25,210
然后在移动聚类中心这一步中

252
00:08:25,540 --> 00:08:26,580
我们要做的是

253
00:08:27,180 --> 00:08:29,290
计算出这四个的平均值

254
00:08:31,340 --> 00:08:33,950
即

255
00:08:34,270 --> 00:08:35,620
计算 x(1)+x(5)+x(6)+x(10)

256
00:08:35,890 --> 00:08:37,190
然后计算

257
00:08:37,380 --> 00:08:38,630
它们的平均值

258
00:08:38,920 --> 00:08:40,020
这里聚类中心有

259
00:08:40,100 --> 00:08:41,700
4个点

260
00:08:42,280 --> 00:08:43,240
那么我们要计算和的四分之一

261
00:08:43,980 --> 00:08:45,890
这时μ2就是一个

262
00:08:46,100 --> 00:08:47,910
n维的向量

263
00:08:48,420 --> 00:08:49,480
因为

264
00:08:49,700 --> 00:08:51,050
x(1) x(5) x(6) x(10) 都是

265
00:08:52,160 --> 00:08:53,170
n维的向量

266
00:08:53,700 --> 00:08:55,150
然后

267
00:08:55,240 --> 00:08:56,270
把这些相加

268
00:08:56,550 --> 00:08:57,870
再除以4

269
00:08:57,940 --> 00:08:59,320
因为

270
00:08:59,490 --> 00:09:00,730
有4个点分配到了这个聚类中心

271
00:09:01,280 --> 00:09:02,770
这样聚类中心μ2的移动

272
00:09:03,870 --> 00:09:05,260
就结束了

273
00:09:05,870 --> 00:09:06,850
这个作用是说

274
00:09:07,210 --> 00:09:08,950
将μ2移动到

275
00:09:09,130 --> 00:09:10,620
这四个点的均值处

276
00:09:12,430 --> 00:09:13,850
我要问的问题是

277
00:09:14,080 --> 00:09:16,600
既然我们要让μk移动到分配给它的那些点的均值处

278
00:09:17,500 --> 00:09:18,900
那么如果

279
00:09:18,960 --> 00:09:21,310
存在一个

280
00:09:21,690 --> 00:09:23,000
没有点分配给它的聚类中心 那怎么办?

281
00:09:23,280 --> 00:09:24,300
通常在这种情况下

282
00:09:24,650 --> 00:09:25,720
我们就直接移除

283
00:09:26,140 --> 00:09:27,220
那个聚类中心

284
00:09:27,830 --> 00:09:28,630
如果这么做了

285
00:09:28,840 --> 00:09:30,260
最终将会得到K-1个簇

286
00:09:31,350 --> 00:09:33,840
而不是K个簇

287
00:09:34,400 --> 00:09:35,620
如果就是要K个簇

288
00:09:35,830 --> 00:09:37,380
不多不少

289
00:09:37,490 --> 00:09:38,220
但是有个

290
00:09:38,290 --> 00:09:39,530
没有点分配给它的聚类中心

291
00:09:39,740 --> 00:09:41,170
你所要做的是

292
00:09:41,260 --> 00:09:42,590
重新随机找一个聚类中心

293
00:09:43,450 --> 00:09:44,870
但是直接移除那个中心

294
00:09:45,170 --> 00:09:46,590
是更为常见的方法

295
00:09:46,670 --> 00:09:48,210
当你遇到了一个

296
00:09:48,410 --> 00:09:49,690
没有分配点的

297
00:09:50,290 --> 00:09:52,020
聚类中心

298
00:09:52,140 --> 00:09:53,340
不过在实际过程中

299
00:09:53,820 --> 00:09:55,590
这个问题不会经常出现

300
00:09:55,810 --> 00:09:57,280
这就是K均值算法

301
00:09:59,330 --> 00:10:00,220
在这个视频结束之前

302
00:10:00,620 --> 00:10:01,290
我还想告诉你

303
00:10:01,350 --> 00:10:02,710
K均值的

304
00:10:03,350 --> 00:10:04,680
另外一个常见应用

305
00:10:04,920 --> 00:10:06,840
应对没有很好分开的簇

306
00:10:08,160 --> 00:10:08,640
比如说

307
00:10:09,280 --> 00:10:10,320
到目前为止

308
00:10:10,950 --> 00:10:12,090
我们的K均值算法

309
00:10:12,330 --> 00:10:13,520
都是基于一些像图中所示的数据

310
00:10:14,150 --> 00:10:15,590
有很好的隔离开来的

311
00:10:15,900 --> 00:10:17,380
三个簇

312
00:10:17,670 --> 00:10:19,930
然后我们就用这个算法找出三个簇

313
00:10:20,750 --> 00:10:21,840
但是事实是

314
00:10:21,980 --> 00:10:23,180
K均值经常会用于

315
00:10:23,600 --> 00:10:24,860
一些这样的数据

316
00:10:25,170 --> 00:10:26,240
看起来并没有

317
00:10:26,330 --> 00:10:28,300
很好的分来的

318
00:10:28,550 --> 00:10:30,250
几个簇

319
00:10:30,830 --> 00:10:32,960
这是一个应用的例子 关于T恤的大小

320
00:10:34,070 --> 00:10:34,650
假设你是T恤制造商

321
00:10:35,270 --> 00:10:37,360
你找到了一些人

322
00:10:38,030 --> 00:10:39,310
想把T恤卖给他们

323
00:10:39,380 --> 00:10:40,520
然后

324
00:10:40,800 --> 00:10:42,190
你搜集了一些

325
00:10:42,580 --> 00:10:43,770
这些人的

326
00:10:44,270 --> 00:10:45,350
身高和体重的数据

327
00:10:45,680 --> 00:10:46,740
我猜

328
00:10:47,220 --> 00:10:48,280
身高体重更重要一些

329
00:10:48,370 --> 00:10:50,310
然后你可能

330
00:10:50,540 --> 00:10:51,160
收集到了这样的样本

331
00:10:51,430 --> 00:10:52,590
一些关于

332
00:10:52,830 --> 00:10:53,910
人们身高和体重的样本

333
00:10:53,980 --> 00:10:56,000
就像这个图所表示的

334
00:10:56,530 --> 00:10:57,880
然后你想确定一下T恤的大小

335
00:10:58,570 --> 00:10:59,810
假设我们要设计

336
00:11:00,330 --> 00:11:01,480
三种不同大小的t恤

337
00:11:01,660 --> 00:11:03,970
小号 中号 和大号

338
00:11:04,660 --> 00:11:06,420
那么小号应该是多大的?

339
00:11:06,550 --> 00:11:07,320
中号呢?

340
00:11:07,690 --> 00:11:09,300
大号呢?

341
00:11:10,370 --> 00:11:11,290
有一种

342
00:11:11,410 --> 00:11:12,050
在这样的数据上

343
00:11:12,270 --> 00:11:13,570
使用K均值算法进行聚类

344
00:11:13,830 --> 00:11:14,640
的方法就像我展示的那样

345
00:11:14,820 --> 00:11:16,570
而且可能

346
00:11:16,770 --> 00:11:18,270
K均值可能将这些

347
00:11:18,600 --> 00:11:20,460
聚成一个簇

348
00:11:20,660 --> 00:11:22,120
把这些点

349
00:11:22,340 --> 00:11:24,150
聚成第二个簇

350
00:11:24,190 --> 00:11:25,530
然后把这些点

351
00:11:25,740 --> 00:11:28,080
聚成第三个簇

352
00:11:28,520 --> 00:11:29,870
所以说

353
00:11:30,020 --> 00:11:30,960
尽管这些数据

354
00:11:31,060 --> 00:11:31,990
原本看起来并没有

355
00:11:32,050 --> 00:11:33,920
三个分开的簇

356
00:11:34,050 --> 00:11:36,870
但是从某种程度上讲

357
00:11:37,320 --> 00:11:38,560
K均值仍然能将数据分成几个类

358
00:11:39,270 --> 00:11:40,220
然后你能做的就是

359
00:11:40,420 --> 00:11:42,010
看这第一群人

360
00:11:42,130 --> 00:11:44,340
然后

361
00:11:44,500 --> 00:11:45,590
查看他们的

362
00:11:45,780 --> 00:11:46,810
身高和体重

363
00:11:46,900 --> 00:11:47,900
试着去设计

364
00:11:48,350 --> 00:11:49,540
对这群人来说

365
00:11:49,710 --> 00:11:51,160
比较合身的小号衣服

366
00:11:51,310 --> 00:11:52,830
以及设计一个中号的衣服

367
00:11:53,150 --> 00:11:55,800
设计一个大号的衣服

368
00:11:56,510 --> 00:11:57,860
这就是一种

369
00:11:57,990 --> 00:11:59,740
市场细分的例子

370
00:12:01,140 --> 00:12:02,800
当你用K均值方法

371
00:12:02,940 --> 00:12:04,320
将你的市场分为三个不同的部分

372
00:12:05,220 --> 00:12:06,500
你就能够区别对待

373
00:12:07,000 --> 00:12:08,260
你三类不同的顾客群体

374
00:12:09,880 --> 00:12:11,230
更好的适应

375
00:12:11,650 --> 00:12:12,770
他们不同的需求

376
00:12:12,920 --> 00:12:15,310
就像大中小三种不同大小的衣服那样

377
00:12:16,220 --> 00:12:17,570
这就是K均值算法

378
00:12:18,240 --> 00:12:19,080
而且你现在应该

379
00:12:19,300 --> 00:12:20,500
已经知道如果去实现

380
00:12:20,630 --> 00:12:22,510
K均值算法并且利用它解决一些问题

381
00:12:23,420 --> 00:12:24,380
在下面的视频中

382
00:12:24,860 --> 00:12:26,430
我想把K均值算法

383
00:12:26,580 --> 00:12:27,690
研究的更深入一些

384
00:12:28,010 --> 00:12:29,210
然后讨论一下

385
00:12:29,510 --> 00:12:32,080
如何能让K均值表现得更好一些的问题【教育无边界字幕组】翻译:夕羽 校对/审核: 所罗门捷列夫