1
00:00:00,090 --> 00:00:02,320
このビデオでは、クラスタリングについて議論しはじめたい。

2
00:00:03,420 --> 00:00:04,850
これはエキサイティングな話だ、というのは

3
00:00:04,930 --> 00:00:06,910
これが我らの初めての教師なし学習の例だからだ。

4
00:00:07,350 --> 00:00:09,080
そこではラベル付けされたデータではなく、

5
00:00:09,840 --> 00:00:10,730
ラベル付けされていないデータから学習する。

6
00:00:11,900 --> 00:00:13,300
では、教師なし学習ってなんだろう？

7
00:00:14,390 --> 00:00:15,630
この講義の始めの所で

8
00:00:16,350 --> 00:00:17,470
簡単に述べたけど、

9
00:00:17,550 --> 00:00:18,560
ここで再び教師有り学習と対比してみるのは

10
00:00:19,030 --> 00:00:20,320
有益に思う。

11
00:00:21,760 --> 00:00:23,750
その為に、これは典型的な教師有り問題だ、

12
00:00:24,030 --> 00:00:25,470
そこではラベルづけされたトレーニングセットが与えられて

13
00:00:25,770 --> 00:00:27,470
ゴールは陽性の手本と陰性の手本を

14
00:00:27,980 --> 00:00:29,420
分離する決定境界を

15
00:00:29,530 --> 00:00:31,310
探す事。

16
00:00:33,100 --> 00:00:34,400
この場合、教師有り学習の問題は

17
00:00:34,460 --> 00:00:35,710
ラベルの集まりを与えられて、

18
00:00:35,850 --> 00:00:38,270
それに仮説をフィットさせる、という事になる。

19
00:00:39,160 --> 00:00:40,560
対して、教師なし学習では、

20
00:00:41,080 --> 00:00:42,420
関連したラベルが無い

21
00:00:42,710 --> 00:00:43,740
データが

22
00:00:43,890 --> 00:00:45,270
与えられる。

23
00:00:46,730 --> 00:00:47,940
つまりこんな感じのデータを与えられる。

24
00:00:48,100 --> 00:00:49,090
ここに点の集まりがあり、

25
00:00:49,180 --> 00:00:50,470
ラベルが無い。

26
00:00:51,800 --> 00:00:52,860
つまり、トレーニングセットは単に

27
00:00:53,220 --> 00:00:54,720
x(1)、x(2)、、、とx(m)まで

28
00:00:55,210 --> 00:00:56,890
書かれているだけで、

29
00:00:57,450 --> 00:00:58,720
いかなるラベルyも存在しない。

30
00:00:59,540 --> 00:01:00,800
だから上の図にプロットされた点は

31
00:01:01,160 --> 00:01:02,300
ラベルが

32
00:01:02,430 --> 00:01:04,330
無いのだ。

33
00:01:04,490 --> 00:01:05,510
つまり教師なし学習においては、

34
00:01:05,710 --> 00:01:06,860
こんな感じの

35
00:01:07,280 --> 00:01:09,150
ラベル付けされていないトレーニングセットがある時に、

36
00:01:09,250 --> 00:01:10,510
アルゴリズムに

37
00:01:10,600 --> 00:01:12,220
こう尋ねるのだ、

38
00:01:12,430 --> 00:01:14,130
データのある構造を探し出してちょうだいな、と。

39
00:01:15,420 --> 00:01:16,490
このデータセットがあった時に、

40
00:01:16,650 --> 00:01:17,810
アルゴリズムに探させる構造として

41
00:01:18,010 --> 00:01:19,540
一つ考えられるのは、

42
00:01:19,810 --> 00:01:21,440
データセットは点を

43
00:01:21,620 --> 00:01:23,740
2つのクラスタのグループに

44
00:01:24,030 --> 00:01:25,500
分けられそう。

45
00:01:25,800 --> 00:01:28,230
そこで今円でくくったような

46
00:01:28,360 --> 00:01:29,230
クラスタを探すのを

47
00:01:29,450 --> 00:01:30,610
クラスタリングアルゴリズムと

48
00:01:32,440 --> 00:01:32,440
呼ぶ。

49
00:01:33,160 --> 00:01:34,620
そしてこれは、我らの最初の教師なし学習の

50
00:01:34,720 --> 00:01:36,590
最初の例となるだろう。

51
00:01:36,790 --> 00:01:38,320
他の種類の教師なし学習、

52
00:01:39,020 --> 00:01:40,200
それはあとで扱うが、

53
00:01:40,320 --> 00:01:41,710
つまり別の種類の構造またはパターンを

54
00:01:42,130 --> 00:01:43,710
データから見つける物だ、

55
00:01:43,920 --> 00:01:46,000
クラスタ以外の。

56
00:01:46,900 --> 00:01:48,360
これについてはのちほど扱う。まずはクラスタリングから。

57
00:01:50,020 --> 00:01:51,210
では、クラスタリングは何に使える？

58
00:01:51,380 --> 00:01:54,350
このクラスの最初の方で、幾つかの応用例に触れた。

59
00:01:54,950 --> 00:01:56,540
一つはマーケットのセグメンテーション。

60
00:01:56,670 --> 00:01:57,690
そこでは顧客のデータベースがあって、

61
00:01:57,770 --> 00:01:58,840
彼らを異なるマーケットセグメントごとに

62
00:01:59,070 --> 00:02:00,380
グルーピングしたい。

63
00:02:00,950 --> 00:02:02,590
異なるセグメントごとに別々に売ったり、

64
00:02:02,720 --> 00:02:05,570
セグメントに合わせて対応する事でより良いサービスを提供したり出来るように。

65
00:02:06,730 --> 00:02:08,370
ソーシャル・ネットワーク分析、

66
00:02:08,580 --> 00:02:10,090
というのをやっている人々もいて、

67
00:02:10,320 --> 00:02:12,590
たとえば人々のグループを調べる、

68
00:02:12,730 --> 00:02:14,540
SNSつまり

69
00:02:15,070 --> 00:02:16,390
FacebookやGoogle+や

70
00:02:16,710 --> 00:02:18,260
あなたがもっともたくさんメールを

71
00:02:18,430 --> 00:02:19,710
送っているか、

72
00:02:20,030 --> 00:02:21,110
もっともemailを送り合っているのは誰か？

73
00:02:21,230 --> 00:02:22,170
という情報から

74
00:02:22,310 --> 00:02:23,600
人々の同質な

75
00:02:23,750 --> 00:02:25,400
グループを見つけ出す。

76
00:02:26,500 --> 00:02:27,600
これもある種のクラスタリングの

77
00:02:28,180 --> 00:02:28,850
アルゴリズムと言えるかもしれない、そこでは

78
00:02:29,080 --> 00:02:32,200
ソーシャル・ネットワークの中の友達の同質なグループを見つけ出したい、という。

79
00:02:33,140 --> 00:02:33,990
これは私の友人が

80
00:02:34,140 --> 00:02:35,170
実際にやってる例で、

81
00:02:35,920 --> 00:02:37,200
コンピュータのクラスタやデータセンターを

82
00:02:37,670 --> 00:02:39,220
より良く構成する為に

83
00:02:39,440 --> 00:02:40,600
クラスタリングを使う。

84
00:02:40,800 --> 00:02:42,450
というのはどのコンピュータが

85
00:02:42,520 --> 00:02:44,990
データセンターにある他のクラスタと一緒に仕事をする傾向にある、と分かれば、

86
00:02:45,400 --> 00:02:46,270
それを用いてリソースや

87
00:02:46,950 --> 00:02:48,390
ネットワークのレイアウトや

88
00:02:48,570 --> 00:02:50,120
データセンターやそのコミュニケーションのデザインをするのに

89
00:02:50,260 --> 00:02:52,040
使えるからだ。

90
00:02:53,140 --> 00:02:54,540
最後にもう一つ、

91
00:02:54,850 --> 00:02:55,910
実際に私がやってた仕事で、

92
00:02:56,130 --> 00:02:57,810
銀河の形成を理解するのに

93
00:02:58,400 --> 00:03:00,030
クラスタリングアルゴリズムを使う、というのがある。

94
00:03:00,280 --> 00:03:02,260
それを用いて、天文学的な詳細を

95
00:03:02,600 --> 00:03:03,860
理解する方法。

96
00:03:06,550 --> 00:03:08,580
以上がクラスタリング、

97
00:03:08,890 --> 00:03:10,450
我らの最初の教師なし学習の例となる

98
00:03:10,530 --> 00:03:12,650
アルゴリズムだ。

99
00:03:13,090 --> 00:03:14,200
次のビデオでは、具体的なクラスタリングアルゴリズムについて

100
00:03:14,370 --> 00:03:16,250
扱っていく。