このビデオでは、 最後に残った一つの K-meansについての詳細である どうやってクラスタの数を選ぶのか、 またはパラメータの大文字Kを どうやって選ぶのか、という事を議論する。 正直に言うと、 これについての素晴らしい解答は 存在していない。 これを自動で解決するような方法も。 現在の所、もっとも一般的な クラスタ数の選び方は 可視化した結果を見てか、 クラスタアルゴリズムの結果を見てか、その他何かを見て、 手動で選ぶという方法だ。 だがどうやってクラスタ数を選ぶか という質問を ほんとに良く受けるので、 現在のところの 人々のこの件に関する考えを お話したい。 といっても一番 一般的に使われている方法は クラスタの総数を手動で選ぶ、という物だろうが。 何故クラスタの総数を 選ぶのがいつも簡単にはいかないかというと、 その理由の大部分は そもそもにデータに幾つのクラスタがあるのか、というのは 曖昧な事があるからだ。 このデータセットを見てくれ。 何人かは4つのクラスタに 見えるかもしれない、その場合は K=4を提案する事になる。 またある人々には 二つのクラスタに見えるかもしれない。 その場合はK=2を提案する事になる。 または3つのクラスタに見えるかもしれない。 つまり、こんなデータセットを 見てみる場合、 クラスタの総数は、 これは本質的に曖昧に見える。 そして一つの正しい正解があるようには思えない。 これは教師無し学習という物の一部だ。 ラベルが与えられていないので、 明確な答えがいつもあるとは限らない。 そしてこれが、 幾つのクラスタが望ましいかを 自動で決めるアルゴリズムを作るのが より難しい理由の一つである。 人々がクラスタの総数を 選ぶ方法を議論している時に、 ちょくちょく出てくる方法に エルボー（肘）法というのがある。 それについてちょっと説明しよう。 そしてその後にその利点と欠点についても言及する。 さて、エルボー法。 我らがやる事は、 Kを変化させていって、、、ここでKはクラスタの総数だ。 そしてまず、K-meansを、1個のクラスタで実行する、 それはつまり、全てを 一つのクラスタにグルーピングして、 そしてコスト関数または ディストーション関数であるJを計算して ここにプロットする、という事。 次にK-meansを 二つのクラスタに対して実行する、 ランダムの初期化に対してかもしれないし、そうで無いかもしれない。 なんにせよ、 二つのクラスタに対しての方が ディストーションは小さくなる事が期待される、 だからこんな感じにプロットしておく。 そして次にK-meansを3つのクラスタに対して 実行すると、期待される事としては より小さなディストーションとなる。それをここにプロットしておく。 さらにK-meansを4、5などに対して走らせていく。 最終的には、クラスタ数を 増加させていくと、 ディストーションが どう現象していくかを示す曲線となる。 だから、こんな曲線が得られる。 そしてこのカーブを見てみると、 エルボー法がやる事は、 「あー、このプロットを見て見てくれ、 ここにエルボー（肘）っぽい形がはっきり見えるだろ？」と言ってる訳だ。 つまり、これは人間の 手みたいだ、という事だ。 手を伸ばした所を 想像してみると、 これが肩の関節、 これがエルボーの関節、 そして手はここで終わる。 だからこれはエルボー法と呼ばれる。 そしてこの手のパターンが見つかったら、 つまりディストーションが1から2、 2から3へと急激に変化したら、 そして3で肘に到達したら、 そしてそこからディストーションが とてもゆっくりに低下したら、 その場合はどうやら、 三つのクラスタを使うのが クラスタの正しい 総数かもしれない。 何故ならそれがこの曲線の肘（エルボー）だからだ。でしょ？ そこではディストーションは Kが3になるまで急激に減少していて、 そこからはとても緩慢にしか減少しなくなる。 だからK=3を選ぶ事としよう。 もしエルボー法を適用して 実際にこんな見た目の プロットが得られたなら、 それはとてもグッド！ これは合理的な クラスタの総数の決め方となる。 実のところ、エルボー法は、 そんなに良くは使われていない。 その理由の一つには、 実際にこれをクラスタの問題に 使ってみると、 かなりしばしば、 もっと曖昧な、こんな感じの 曲線が得られる事がある。 もしこれを見たら、 良く分からない。どうも、 明確なエルボーは無く見える。 ディストーションは連続的に低下していってるように見える。 3が良い数かもしれないし、 4かもしれない。 5だって悪くないかもしれない。 だからこれを実際に やってみると、 もしプロットした結果が左側みたいだったら、それは素晴らしい。 割と明確な答えを提供してくれている。 でも同じくらいしばしば、 右側みたいなプロットを 得るはめにもなり、 そこではどこが エルボーの場所なのか、あまりはっきりしない。 その場合はこの手法を使って クラスタの数を決めるのはより難しい。 つまり簡単にエルボー法について要約すると、 一発試してみる価値はある、 だがどんな問題にも とてもうまくいく、などと 期待はしない方がいい。 最後に、Kの値を決定する のに考えられる 別の方法がある。 だいたいは、人々は K-meansを、のちの問題で使う為の クラスタを得る為に用いる。 言い換えるとある種の下流の目的の為に。 K-meansを、マーケットの セグメンテーションの為に使いたいのかもしれない。 ここまで話してきたTシャツの例のように。 K-meansをコンピュータのクラスタを より良く構成する為に使いたいのかもしれない。 または別の目的の為に クラスタを学習させたいのかもしれない。 もしもあとに続く、下流の目的、 マーケットのセグメンテーションのような物、 もしそれが評価指標を与えてくれるなら、 その場合はより良い クラスタ総数の決定方法は それぞれのクラスタ数が どれだけ下流の目的に うまく貢献出来るかを見てみる事だ。 具体例を見ていこう。 ここでもTシャツのサイズの例を 見ていく事にする。 三つのTシャツのサイズにしたいのか？ そうなら、K=3を選ぶ、 たぶんsmall、medium、largeのTシャツとなるだろう。 またはK=5を選ぶかもしれない、 その時は、 extra small、small、 medium、largeと extra largeのTシャツサイズとなるだろう。 つまり、3つとか4つとか5つのTシャツサイズがあり得る。 4つのTシャツのサイズはあり得るのだが、 しかし便宜上、 だが簡単の為、ここでは3と5を スライドをシンプルにする為見せておく。 すると、K-MeansをK=3で 走らせると、 結果としては例えば ここがsmallで、 ここがmedium、ここがlargeという感じになる。 一方、5クラスタでK-meansを実行すると、 結局得られるのは たとえば、 これらがextra smallのTシャツ、 これらがsmall、これらがmedium、 これらがlarge、 これらがextra largeだ。 そしてこの例で良い事として、 これはまた、 3か4か5個のクラスターを 選ぶ、もう一つの方法を 与える。 具体的には、 行える事は、 Tシャツビジネスの観点から この事を考えてみて、 こう問うてみる事だ：「うーん、もし私が 5つの顧客セグメントを持ったとしたら、 どれだけの顧客に私のTシャツはフィットして、 どれだけの数私のTシャツは売れるのか？ 私の顧客は、どれだけ幸せだろうか？」と。 Tシャツビジネスの観点から 何が最も説得力があるか、 私は自分たちのTシャツが 顧客にフィットするように より多くのサイズがある事を望んでいるのか、 それともTシャツのサイズを少なくして 作らなくてはいけない Tシャツのサイズを減らしたいのか。 そうして顧客にTシャツをもっと安く売りたいのか。 つまり、Tシャツを売るビジネスという観点が 3つのクラスタと5つのクラスタの どちらを選ぶのかを決める方法を、提供してくれるかもしれない。 以上が、下流でどう使うかの目的が 例えばどんなTシャツを作るか、とかが、 クラスタ数を選ぶ為に クラスタの数を評価する 指標を与えてくれる事が どんな風にありうるかの例だ。 プログラムの課題を やってる人なら、 もし今週のK-meansに関する プログラムの課題を見てみたら、 そこにはK-meansを画像圧縮に使う例がある。 そこでは、どれだけの数のクラスタを その問題に使うべきかを 選ぼうとするなら、 そこでもまた、画像圧縮の 評価指標を使って、 クラスターの総数Kを選ぶ事になる。 つまり、どれだけ画像を 良く保ちたいかと、 どれだけ画像のファイルサイズを 圧縮したいのか。 実際にプログラムの 課題をやったら、 今私の言った事がもっと良く分かるだろう。 ではまとめだ。 大多数のケースで、 クラスター数Kを選ぶのは 未だに手動で、人間による入力または洞察によって為されている。 クラスター数を選ぶ一つの方法としては エルボー法を 使うという物だ。 だがそれはいつもうまくいく、と期待出来るほどの物じゃない。 それよりも、 クラスターの数を選ぶ より良い方法と考えられるのは、 どういう目的であなたが K-meansを実行しているのか、という事を問うてみる事だ。 そしてどんな クラスターの数Kが、 K-meansを走らせる目的となっている あとに続く問題にーーそれがなんであれーーうまく寄与するかを。