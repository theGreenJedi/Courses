La mayoría de los algoritmos de aprendizaje supervisado que hemos visto, como la regresión lineal, la regresión logística, etc., tienen un objetivo de optimización o una función de costos que el algoritmo intentaba minimizar. Resulta que K-means también tiene un objetivo de optimización o una función de costos que intenta minimizar. En este video me gustaría hablarles de qué es el objetivo de optimización. La razón por la que quiero hablar de esto es porque será útil para dos propósitos. Primero, conocer cuál es el objetivo de optimización de K-means nos ayuda a limpiar el algoritmo de aprendizaje y a asegurarnos de que K-means se está ejecutando correctamente y, segundo, y quizá más importante, en un video posterior hablaremos acerca de cómo podemos utilizar esto para ayudar a K-means buscar mejores agrupamientos y evitar las óptimas locales. Pero esto lo hablaremos en otro video después de este. Como recordatorio, mientras K-means se está ejecutando, llevaremos cuenta de los dos conjuntos de variables. La primera es “C(i)” que da seguimiento al índice o número de agrupamiento al cual un ejemplo “x(i)” está asignado. El otro conjunto de variables es “µ” subíndice “k”, que es la ubicación del centroide del agrupamiento K. Les recuerdo que para K-means utilizamos “K” mayúscula para denotar el número total de agrupamientos y “k” minúscula será nuestro índice en los centroides de agrupamiento. “k” minúscula será un número entre 1 y “K” mayúscula. Como parte de la notación, utilizaré “µ” subíndice “c(i)” para denotar el centroide del agrupamiento al que se asignó “x(i)”. Para explicar esta notación un poco más, digamos que “x(i)” fue asignado al agrupamiento número cinco. Esto significa que “c(i)”, es decir, el índice de “x(i)” es igual a 5. ¿cierto? porque cuando tenemos “c(i)” igual a 5, significa que el ejemplo “x(i)” estará asignado al agrupamiento número 5. Entonces, “µ” subíndice “c(i)” será igual a “µ” subíndice 5 porque “c(i)” es igual a 5. Este “c(i)” que sustituye a “µ” es el centroide del agrupamiento número 5, que es el agrupamiento al cual se asignó el ejemplo “x(i)”. Con esta notación, ya estamos listos para escribir cuál es el objetivo de optimización del algoritmo de optimización “Kµ” Aquí está. La función de costos que K-means intenta minimizar es la función “j” de todos los parámetros “c1” a “c(m)”, “µ1” hasta “µK” que k-means intenta variar a medida que ejecutamos el algoritmo. El objetivo de optimización se muestra a la derecha y es el promedio de 1 sobre “m” de la sumatoria de “i” igual a 1 a la “m” de este término de aquí, al que le dibujé un cuadro rojo. Ya se asignó la distancia cuadrada entre cada ejemplo “x(i)” y la ubicación del centroide de agrupamiento al que se asignó “x(i)”. Permítanme trazar esto para explicarlo. Aquí tenemos la ubicación del ejemplo de entrenamiento “x(i)” y aquí está la ubicación del centroide del agrupamiento al que se asignó “x(i)”. Para explicar esto en gráficas, puedes ver que aquí tengo “x1” y “x2” y un punto de aquí es mi ejemplo “x(i)”de manera que esto que señalo es igual a mi ejemplo “x(i)”, que ha sido asignado al centroide del agrupamiento que denotaré con una cruz que, a su vez, marca la ubicación de “µ5”. Digamos que “x(i)” fue asignado al centroide del agrupamiento 5 en mi ejemplo de aquí. Entonces, la distancia cuadrada es el cuadrado de la distancia entre el punto “x(i) y este centroide al que se asignó “x(i)”. Una cosa que puede hacer el K-means es tratar de encontrar parámetros “c(i)” y “µ(i)” o tratar de encontrar “C” en “µ” para minimizar esta función de costos “J”. A esta función de costos también se le llama a veces función de distorsión de costos o algoritmo de la distorsión de K-means. Para explicarles un poco más a detalle, aquí tenemos el algoritmo K-means exactamente como lo teníamos en la formulación anterior de la diapositiva anterior. El primer paso del algoritmo era el paso de asignación de agrupamiento, en el que asignamos cada punto a un centroide de agrupamiento. es posible demostrar matemáticamente que lo que hace exactamente el paso de asignación de agrupamiento es minimizar “j” con respecto a las variables “C1”, “C2”, etc., hasta “C(m)” mientras que mantenemos fijos los centroides “µ1” hasta “µK”. El primer paso de asignación no cambia los centroides de los agrupamientos sino que elige los valores “C1”, “C2” y hasta “CM” que minimizan la función de costos o la función de distorsión “J”. Es posible probar esto matemáticamente, pero no lo mostraré aquí. Esto tiene una consecuencia intuitiva. Si asignamos estos puntos al centroide del agrupamiento más cercano a ellos, minimizaremos la distancia cuadrada entre los puntos y el centroide del agrupamiento correspondiente. La segunda parte del K-means es este segundo paso de aquí arriba. Este segundo paso fue el paso de movimiento del centroide y, una vez más, no lo probaré, pero se puede comprobar matemáticamente que lo que hace el paso de movimiento del centroide es elegir los valores “µ” que minimicen “J”. Por lo tanto, minimiza la función de costos “J” con respecto a “wrt” es mi abreviatura para “con respecto a” las ubicaciones de los centroides de agrupamiento “µ1” a “µK”. Lo que está haciendo realmente K-means es hablar de dos conjuntos de variables y dividirlas en dos porciones por aquí. Primero el conjunto de variables “C” y luego el conjunto de variables “µ”. Lo primero que hace es minimizar “j” con respecto a la variable “C” y luego minimiza “J” con respecto a las variables “µ” y continúa repitiéndose. Esto es todo lo que hace K-means. Ahora que comprendemos K-means, intentemos minimizar la función de costos “J”: Podemos utilizar esto también para limpiar de errores nuestro algoritmo de aprendizaje y para asegurarnos que nuestra implementación de K-means es correcta. Ahora entendemos que el algoritmo K-means intenta optimizar la función de costos “J”, a la que también llamamos función de distorsión. Podemos utilizar esto para limpiar K-means de errores y para que me ayude a mostrar que K-means converge y que está ejecutándose correctamente. En el siguiente video veremos cómo podemos utilizar esto para ayudar a K-means buscar mejores agrupamientos y evitar óptimas locales.