En este y en el siguiente video quiero trabajar con un ejemplo detallado que muestra cómo una red neuronal puede calcular una función no lineal compleja de la entrada y, con suerte, esto te dará una buena idea de por qué las redes neuronales pueden usarse para aprender hipótesis no lineales complejas. Considere el siguiente problema en el que tenemos variables de entrada x1 y x2 que son valores binarios, así que son cero o uno. Entonces x1 y x2 pueden tomar sólo uno de dos valores posibles. En este ejemplo dibujé sólo dos ejemplos positivos y dos ejemplos negativos, pero puedes considerar esto como una versión simplificada de un problema de aprendizaje más complejo en el que pueden haber varios ejemplos positivos en la parte superior derecha y en la parte inferior izquierda y varios ejemplos negativos para notificar los círculos, lo que nos gustaría hacer es aprender un límite de decisión no lineal en el que debemos separar los ejemplos positivos y negativos. Entonces, ¿cómo puede una red neuronal hacer esto? Y, en lugar de usar uno de los ejemplos de la derecha, voy a usar éste que es quizás más sencillo para examinar el ejemplo de la izquierda. Específicamente, lo que ésto está calculando realmente es la etiqueta destino "y" es igual a x1 XOR x2. O esto es realmente la función x1 XNOR x2 en donde XNOR es la notación alternativa para "NOT x1 XOR  x2". Entonces x1, XOR o x2 - sólo es verdadero si exactamente uno de x1 o x2 es igual a 1. Sucede que el ejemplo específico que voy a utilizar funciona un poco mejor si usamos el ejemplo de XNOR. Ambos son lo mismo, desde luego. Esto significa NOT x1 XOR x2, así que vamos a tener ejemplos positivos si ambos son verdaderos o si ambos son falsos, y vamos a tener que "y"es igual a 1, "y" es igual a 1 y vamos a tener que "y" es igual a 0 si sólo uno de ellos es verdadero y queremos saber si podemos hacer que una red neuronal ajuste este tipo de conjuntos de aprendizaje. Con el fin de construir una red que ajuste el ejemplo XNOR, vamos a comenzar con uno ligeramente más simple y mostrar una red que se ajuste a la función AND. Concretamente, digamos que tenemos las entradas x1 y x2 que, de nuevo, son binarias. Entonces, son cero o uno. Y digamos que nuestras etiquetas destino "y" son iguales a x1 y x2. Éste es un AND lógico. Entonces, ¿podemos hacer que una red de una unidad calcule esta función lógica AND? Para hacer esto, voy, de hecho, a dibujar las unidades de oscilación también, la unidad más uno. Ahora, vamos a asignar algunos valores a los pesos o los parámetros de esta red. Voy a escribir los parámetros en este diagrama. Menos 30 aquí más 20 y más 20, y esto significa que estoy asignando un valor de menos de treinta al valor asociado a x0. Esto es más 1 yendo a esta unidad y un valor del parámetro de más 20 que se multiplica en x1 en un valor de más 20 para el parámetro que se multiplica en x2. Así, concretamente, esto está diciendo que mis hipótesis “h” de x es igual a g de  -30 + 20x1 + 20x2. Así que, a veces, es conveniente dibujar estos pesos y dibujar estos parámetros aquí, ya sabes, en el diagrama de la red neuronal. Y, por supuesto, este menos 30 es realmente «theta» 1 de 1, 0. Este es «theta» 1 de 1, 1 y este es «theta» 1 de 1, 2 pero es más fácil considerarlos como la asociación de estos parámetros con los bordes de la red. Veamos lo que calculará esta red con una sola neurona. Sólo para recordarte, la función de activación sigmoidea g de z se ve así. Comienza en 0, se eleva lentamente, pasa por 0.5 y tiene su asíntota en uno. Y para darte un punto de referencia, si el valor en el eje horizontal es igual a 4.6, entonces La función sigmoidea es igual a 0.99. Esto está muy cerca a 1 y es casi simétrico. Si es negativo 4.6, entonces la función sigmoidea es igual a 0.01, que está muy cerca de 0. Veamos los cuatro posibles valores de entrada para x1 y x2 y veamos si las hipótesis se abrirán en ese caso. Si ambas, x1 y x2 son iguales a 0 - si ves esto, si x1 y x2 son iguales a 0 entonces las hipótesis del punto g de -30. Entonces, está muy hacia la izquierda de este diagrama. Esto estará muy cerca de 0. Si x1 es igual a 0 y x2 es igual a 1, entonces esta fórmula aquí evalúa a g, por lo tanto la función sigmoidea aplicó a -10 y, otra vez, está en el extremo izquierdo de este diagrama y, por lo tanto, está nuevamente muy cerca de 0. Esta es también g de -10. Esto es si x1 es igual a 1 y x(2)0, esto es, -30 más 20, lo que es -10. Y, finalmente, si x1 es igual a 1, x2 es igual a 1, entonces tienes g de -30   +20   +20, y eso es g de +10, que, por lo tanto, está muy cerca de 1. Y si se observa esta columna, esta es exactamente la función lógica AND. Entonces, esto es calcular h de x, que es aproximadamente x1 y x2. En otras palabras, muestra 1 si y sólo si x1 y x2 son iguales a 1. Entonces, haciendo nuestra pequeña tabla de verdad de esta manera, podemos averiguar cuál es la función lógica que nuestra red neuronal calcula. La red que se muestra calcula la función OR, sólo para mostrarte cómo lo resolví, si escribes la hipótesis, encontrarás que está calculando g de -10  +20  x1 +20  x2. Y si completas estos valores encontrarás que g de -10, que es aproximadamente 0, g de 10 lo que es aproximadamente 1, y así sucesivamente. Estos son aproximadamente 1, y aproximadamente 1, y estos números son esencialmente, la función lógica OR.
 Entonces, espero que con esto ahora comprendas cómo neuronas individuales en una red neuronal pueden utilizarse para calcular funciones lógicas como AND y OR y así sucesivamente. En el siguiente video continuaremos avanzando con estos ejemplos y trabajaremos con un ejemplo más complejo. Vamos a llegar a mostrarte cómo una red neuronal, ahora con múltiples capas de unidades, puede usarse para calcular funciones más complejas como la función XOR o la función XNOR.