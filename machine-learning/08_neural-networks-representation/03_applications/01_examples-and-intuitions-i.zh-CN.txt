在接下来两节视频中 我要通过讲解 一个具体的例子来解释 神经网络是如何计算 关于输入的复杂的非线性函数 希望这个例子可以 让你了解为什么 神经网络可以用来 学习复杂的非线性假设 考虑下面的问题 我们有二进制的 输入特征 x1 x2 要么取0 要么取1 所以x1和x2只能 有两种取值 在这个例子中 我只画出了 两个正样本和 两个负样本 但你可以认为这是一个 更复杂的学习问题的 简化版本 在这个复杂问题中 我们可能 在右上角有一堆正样本 在左下方有 一堆用圆圈 表示的负样本 我们想要学习一种非线性的 决策边界来 区分正负样本 那么 神经网络是 如何做到的呢？ 为了描述方便我不用右边这个例子 我用左边这个例子 这样更容易说明 具体来讲 这里需要计算的是 目标函数y 等于x1异或x2 或者 y也可以等于 x1 异或非 x2 其中异或非表示 x1异或x2后取反 X1异或X2 为真当且仅当 这两个值 X1或者X2中有且仅有一个为1 如果我 用XNOR作为例子 比用NOT作为例子 结果会好一些 但这两个其实是相同的 这就意味着在x1 异或x2后再取反 即 当它们同时为真 或者同时为假的时候 我们将获得 y等于1 y为0的结果 如果它们中仅有一个 为真 y则为0 我们想要知道是否能 找到一个神经网络模型来拟合这种训练集 为了建立 能拟合XNOR运算 的神经网络 我们先 讲解一个稍微简单 的神经网络 它拟合了“且运算” 假设我们 有输入x1和 x2 并且都是二进制 即要么为0要么为1 我们的目标 函数y正如你所知道的 等于x1且x2 这是一个逻辑与 那么 我们怎样得到一个 具有单个神经元的神经网络来计算 这个逻辑与呢 为了做到这一点 我也需要画出偏置单元 即这个里面有个+1的单元 现在 让我给这个网络 分配一些权重 或参数 我在图上写出这些参数 这里是-30 正20 正20 即我给 x0前面的 系数赋值 为-30. 这个正1会 作为这个单元的值 关于20的参数值 且x1乘以+20 以及x2乘以+20 都是这个单元的输入 所以 我的假设ħ(x) 等于 g(-30 + 20x1 + 20x2) 在图上画出 这些参数和 权重是很方便很直观的 其实 在这幅神经网络图中 这个-30 其实是θ(1)10 这个是 θ(1)11 这是 θ(1)12 但把它想成 这些边的 权重会更容易理解 让我们来看看这个小神经元是怎样计算的 回忆一下 s型 激励函数g(z)看起来是这样的 它从0开始 光滑 上升 穿过0.5 渐进到1. 我们给出一些坐标 如果横轴值 z等于4.6 则 S形函数等于0.99 这是非常接近 1的 并且由于对称性 如果z为-4.6 S形函数 等于0.01 非常接近0 让我们来看看四种可能的输入值 x1和x2的四种可能输入 看看我们的假设 在各种情况下的输出 如果X1和X2均为 0  那么 你看看这个 如果 x1和x2都等于 为0 则假设会输出g(-30) g(-30)在图的 很左边的地方 非常接近于0 如果x1等于0且 x2等于1 那么 此公式等于 g关于 -10取值 也在很左边的位置 所以 也是非常接近0 这个也是g(-10) 也就是说 如果x1 等于1并且 x2等于0 这就是-30加20等于-10 最后 如​​果 x1等于1 x2等于 1 那么这等于 -30 +20 +20 所以这是 取+10时 非常接近1 如果你看看 在这一列 这就是 逻辑“与”的计算结果 所以 这里得到的h h关于x取值 近似等于x1和x2的与运算的值 换句话说 假设输出 1 当且仅当 x1 x2 都等于1 所以 通过写出 这张真值表 我们就弄清楚了 神经网络 计算出的逻辑函数 这里的神经网络 实现了或函数的功能 接下来我告诉你是怎么看出来的 如果你把 假设写出来 会发现它等于 g关于-10 +20x1 +20x2的取值 如果把这些值都填上 会发现 这是g(-10) 约等于0 这是g(10) 约等于1 这个也约等于1 这些数字 本质上就是逻辑或 运算得到的值 所以 我希望 通过这个例子 你现在明白了 神经网络里单个的 神经元在计算 如AND和OR逻辑运算时是怎样发挥作用的 在接下来的视频中 我们将继续 讲解一个更复杂的例子 我们将告诉你 一个多层的神经网络 怎样被用于 计算更复杂的函数 如 XOR 函数或 XNOR 函数【教育无边界字幕组】翻译:午后阳光  校对:逸の洛  审核:所羅門捷列夫