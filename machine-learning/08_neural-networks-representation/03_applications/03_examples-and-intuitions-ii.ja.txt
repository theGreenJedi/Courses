このビデオでは ニューラルネットワークが どのように複雑な 非線形の仮説を計算するかを見ていく。 前回のビデオでは ニューラルネットワークが どのように関数 x1 AND x2とか、 関数 x1 OR x2を計算するかを見てきた、 ここでx1とx2は二値の値をとる。 つまり、取りうる可能な値は0か1だけ。 また、我らは 否定を計算するネットワークも 持ちうる。つまりNOT x1関数。 このネットワークを 書き出してみよう。 たった一つだけの入力フィーチャーx1が この場合にはあり、 そしてバイアスユニットとして+1がある。 そしてこれに、 ウェイト+10と -20を付与すると、仮説はこれを計算する事になる。 hのxは、イコール、sigmoid関数の 10-20*x1 となる。 つまり、x1が 0の時には 仮説はgの 10-20*0を計算する事になり、 これはgの10となる。 つまりこれは、だいたい1だ。 そしてxが イコール1の時は gの-10となり これはだいたい0となる。 そしてこれらの値が何なのかを 眺めてみると、これはようするに NOT x1関数だ。 つまり否定を行うには 基本的には負の大きなウェイトを 否定したい変数の前に おけば良い。 この場合は-20を、x1に掛けてる。 これがx1を否定する やり方の 基本的な考え方。 以上で、例えば 以下のような関数を計算したい時に 自力で やり方を見つけ出せるだろう： (NOT x1) AND (NOT x2) 解答の一部分としては、 たぶん負の大きなウェイトを x1とx2に置く事になるだろう、 そしてそれを 出力が一つだけの ニューラルネットワークを得る為に 食わせる。 いいかい？ つまりこの大きな論理関数、 (NOT x1) AND (NOT x2)が イコール1 となるのは x1=x2=0の時で、 その時のみ1となる。 つまり、これは論理関数で、 これはNOT x1、つまりX1は0でなくてはいけない、という意味で、さらにNOT x2。 それはx2もまた0でなくてはならない、という意味だ。 だからこの論理関数が1となるのは、 x1とx2の両方が イコール0の時だけだ。 以上で、この論理関数を計算する 小さなニューラルネットワークを どうやって構築すれば良いかも 分かるだろう。 さて、今度はこの三つの部品を 一つに組み合わせて、 つまりx1 AND x2を 計算するネットワークと (NOT x1) AND (NOT x2)を計算する ネットワークと、最後は x1 OR x2を計算する為のネットワーク。 我らはこれら三つの要素を 組み合わせる事により、 この x1 XNOR x2関数が 計算出来るはずだ。 ここで再掲しておくと、 これがx1とx2とすると、 我らがこれから計算しようとしているこの関数は 陰性の手本が こことここに、そして 陽性の手本がこことここにあるような物だった。 これから、明らかに 陽性と陰性の手本を分離するには 非線型の決定境界が要る。 ネットワークを書き下してみよう。 入力として、+1, x1, x2を取り、 そして最初の隠れユニットを ここに作る。 これをa(2) 1と呼ぶ事にする、 何故ならこれは最初の隠れユニットだから。 そしてウェイトを赤のネットワークから、 つまり x1 AND x2のネットワークから コピーする。 つまり -30, 20, 20。 次に、二番目の隠れユニットを 作ろう。それを a(2) 2と呼ぶ事にする。 これはレイヤー2の二番目の隠れユニットだ。 そして真ん中の シアン色のネットワークをコピーする、 つまりウェイトとして 10, -20, -20 となる。 ここで真理値表から値をひっぱってこよう。 赤いネットワークは x1 AND x2を計算している事を知っている。 つまりこれは、 だいたい 0, 0, 0, 1となる、 x1とx2の値に応じて。 そしてa(2) 2については、シアン色のネットワークで、 これは (NOT x1) AND (NOT x2)関数だと 知っているから、出力は 4つのx1とx2の入力に対して 1, 0, 0, 0となる。 最後に、出力ノードを作る。 出力ユニットは a(3) 1だ。 これはh(x)の出力で、 ここにはORのネットワークから コピーして、 ここにはバイアスユニットの +1が必要だ。 だからそれを書きこむ、 緑のネットワークからウェイトをコピーする。 つまり、-10, 20, 20で、 これがOR関数を実装する事を前に見ている。 では真理値表を見ていこう。 最初のエントリでは、0 OR 1だから 1となる。 次は0 OR 0だから、 0となり、 0 OR 0は0。 1 OR 0は1で、 つまり、hのxが イコール1となるのは、 x1とx2がどちらも0の時か、 またはx1とx2が どちらも1の時だけだ。 具体的には、hのxは これら二つの位置の時には ぴったり1を出力し、 それ以外の場合は0を出力する。 かくして、このニューラルネットワークでもって、 それは入力レイヤーに 1つの隠れレイヤーと1つの出力レイヤーがあるような物だが、 これでXNOR関数のような 非線型の決定境界を計算出来る、 このような関数を。 そしてより一般的には 直感的には、入力レイヤーには 単に生の入力を置いて、 そして隠れレイヤーがあり、 そこでは、ここに示した もうちょっとだけ複雑な入力の関数を 計算している。 これらはさらにちょっとだけ 複雑な関数で、 さらにもう一つレイヤーを追加する事で、 さらに複雑な非線型の関数も計算する事が出来る。 以上が、 ニューラルネットワークを用いると、 極めて複雑な関数を計算しうるかの 直感的な説明だ。 複数のレイヤーがある時に、 二番目のレイヤーは 比較的単純な入力の関数でも、 三番目のレイヤーを足す事で さらに複雑な関数を計算する為に ネットワークを作りあげる事が出来、 そしてその次のレイヤーで、さらに複雑な関数を計算する事も出来る。 このビデオのまとめとして、 楽しい例を紹介したい、 これはニューラルネットワークを適用した例で、 より深い所のレイヤーがより複雑な計算をしていく、という 直感を捉えた物となっている。 私がお見せするビデオは 私の良き友人、Yon Khunから もらった物だ。 YonはNew York University、NYUの 教授だ。 彼はニューラルネットワークの 初期の頃の研究の パイオニアであり、 今ではこの分野での、ある種伝説になった男で、 彼のアイデアは今や 世界中のあらゆる所で あらゆる製品、アプリケーションに使われている。 さて、私があなたにお見せするのは、 彼の初期の頃の仕事の一つ、 手書き認識の為に ニューラルネットワークを用いる、 という物だ。手書きの数字認識の為に。 このクラスの最初の方で、 このクラスの最初で、 最初期のニューラルネットワークの 成功した使い道は それをzipコード（郵便番号）を読むのに 用いるという物だった、と言った。 郵便を送る助けとなるように、郵便番号を読む為に。 つまり、これがその試みの一種だ。 つまりこれこそがあの問題を解決しようとする アルゴリズムの一種だ。 ビデオでは、 みえているこの、ここの領域、 これがネットワークに入力する 手書きの文字がみえている領域だ。 このここの列は ネットワークの最初の隠れレイヤーによる 計算結果のフィーチャーを 可視化した物を表示している、 つまり最初の隠れレイヤだ。 この可視化は別々のフィーチャーを表示している、 検出された様々なエッジや線を。 これは次の隠れレイヤーを可視化した物だ。 より深い位置の隠れレイヤーは どう解釈したらいいか難しい。 そしてこれが、次の隠れレイヤーが計算している物を 可視化した物だ。 たぶん何が起こってるのか、 もう良く分からないだろう。 最初の隠れレイヤーよりもずっと分かりにくい。 だが、最後に、 これらの学習されたフィーチャーを全て 出力レイヤーに食わせて、 ここに最終的な答えを 表示する。 最終的な、ニューラルネットワークが見た 手書き文字が何なのかの予測を。 では、ビデオを見てみよう。 さて、 お楽しみいただけただろうか。 このビデオでニューラルネットワークが学習出来る 極めて複雑な関数が どんな感じかの感覚を つかめただろうか。そこでは、 この入力画像を取り、 この生のピクセルを入力に取り、 そして最初のレイヤーの終わりまでに 何らかのフィーチャーの集合を 計算し、次のレイヤーの終わりまでに さらに複雑なフィーチャーを計算し、 さらに複雑なフィーチャー、 これらのフィーチャーは 最後の、本質的にはロジスティック回帰の 分類器の入力として使われ、 その分類器が、ネットワークが見た数字がなんなのかを 正確に予測するのに使われる。