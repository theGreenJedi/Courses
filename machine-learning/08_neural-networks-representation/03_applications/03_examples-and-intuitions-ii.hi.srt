1
00:00:00,450 --> 00:00:04,310
इस वीडियो में मैं उन्ही हमारे उदाहरणों पर काम करूँगा दिखाने के लिए कैसे

2
00:00:04,310 --> 00:00:07,972
एक न्यूरल नेटवर्क कम्प्यूट कर सकता हैं एक जटिल नॉन-लिनीअर हायपॉथिसस.

3
00:00:10,160 --> 00:00:13,460
पिछले वीडियो में हमने देखा कैसे एक न्यूरल नेटवर्क इस्तेमाल किया जा सकता है

4
00:00:13,460 --> 00:00:17,640
कम्प्यूट करने के लिए फ़ंक्शंज़ x1 AND x2, और फ़ंक्शन x1 OR

5
00:00:17,640 --> 00:00:22,960
x2 जब x1 और x2 हैं बाइनरी, मतलब कि जब वे लेते हैं वैल्यूज़ 0, 1.

6
00:00:22,960 --> 00:00:27,270
हम बना सकते हैं एक नेटवर्क कम्प्यूट करने के लिए निगेशन,

7
00:00:27,270 --> 00:00:30,949
मतलब कि कम्प्यूट करने के लिए फ़ंक्शन NOT x1.

8
00:00:30,949 --> 00:00:33,465
मैं सिर्फ़ लिखता हूँ वेट्स इस नेटवर्क में.

9
00:00:33,465 --> 00:00:38,490
हमारे पास है केवल एक इनपुट फ़ीचर x1 इस केस में और यह बाइयस यूनिट +1.

10
00:00:38,490 --> 00:00:43,652
और यदि मैं जोड़ता हूँ इसे वेट्स प्लस 10 और -20 के साथ,

11
00:00:43,652 --> 00:00:50,516
तो मेरी हायपॉथिसस कम्प्यूट करती है यह h(x) बराबर सिग्मोईड(10 - 20 x1).

12
00:00:50,516 --> 00:00:55,529
तो जब x1 है 0, मेरी हायपॉथिसस

13
00:00:55,529 --> 00:01:00,808
कम्प्यूट करेगी g(10 - 20 x0) जो है सिर्फ़ 10.

14
00:01:00,808 --> 00:01:04,358
और वह है अलगभग 1, और जब x1 है बराबर 1,

15
00:01:04,358 --> 00:01:08,470
यह होगा g(1=-10) जो है लगभग बराबर 0 के.

16
00:01:08,470 --> 00:01:14,550
और यदि आप देखते हैं कि क्या ये वैल्यूज़ हैं, वह है अनिवार्यत: NOT x1 फ़ंक्शन.

17
00:01:14,550 --> 00:01:18,680
जो करता है निगेशन, सामान्य विचार है कि रखें

18
00:01:18,680 --> 00:01:22,910
बड़े नेगेटिव वेट सामने वेरीयबल के जो आप निगेट करना चाहते हैं.

19
00:01:22,910 --> 00:01:25,414
माइनस 20 गुणा x1 से और

20
00:01:25,414 --> 00:01:30,520
वह है आम विचार कि कैसे आप कर पाते हैं निगेट x1 को.

21
00:01:30,520 --> 00:01:34,686
और इसलिए एक उदाहरण में मैं आशा करता हूँ आप ख़ुद कर पाएँगे.

22
00:01:34,686 --> 00:01:38,796
यदि आप कम्प्यूट करना चाहते हैं एक फ़ंक्शन इस तरह का x1 AND NOT x2,

23
00:01:38,796 --> 00:01:44,016
हिस्सा उसका होगा शायद रखना बड़े नेगेटिव वेट्स सामने x1 के और

24
00:01:44,016 --> 00:01:46,790
x2 के, लेकिन यह सम्भव होना चाहिए.

25
00:01:46,790 --> 00:01:53,314
तो आपको मिलता है एक न्यूरल नेटवर्क केवल एक आउट्पुट यूनिट का कम्प्यूट करने के लिए इसे भी.

26
00:01:53,314 --> 00:01:58,018
ठीक है, तो यह लॉजिकल फ़ंक्शन, x1 AND

27
00:01:58,018 --> 00:02:02,390
NOT x2, होगा बराबर 1 के तभी और केवल तभी यदि

28
00:02:06,531 --> 00:02:09,710
x1 बराबर है x2 के बराबर है 0.

29
00:02:09,710 --> 00:02:13,900
ठीक है, क्योंकि यह है एक लॉजिकल फ़ंक्शन,यह बताता है NOT x1 का मतलब है x1 होना चाहिए

30
00:02:13,900 --> 00:02:17,820
0 और NOT x2, उसका मतलब है x2 भी होना चाहिए 0.

31
00:02:17,820 --> 00:02:22,180
तो यह लॉजिकल फ़ंक्शन होगा 1 केवल तभी जब दोनो x1 और

32
00:02:22,180 --> 00:02:26,540
x2 हैं बराबर 0 के और उम्मीद है आप समझ पाएँगे कि कैसे

33
00:02:26,540 --> 00:02:29,980
बनाना है एक छोटा न्यूरल नेटवर्क कम्प्यूट करने के लिए इस लॉजिकल फ़ंक्शन को भी.

34
00:02:33,470 --> 00:02:38,102
अब, लेते हुए तीनो हिस्से जो हमने साथ रखे नेटवर्क की तरह

35
00:02:38,102 --> 00:02:43,460
कम्प्यूट करने के लिए x1 AND x2, और नेटवर्क कम्प्यूट करने के लिए NOT x1 AND NOT x2.

36
00:02:43,460 --> 00:02:48,070
और एक आख़िरी नेटवर्क कम्प्यूट करने के लिए x1 OR x2, हमें कर पाना चाहिए

37
00:02:48,070 --> 00:02:53,840
इन तीन हिस्सों को एक साथ कम्प्यूट करने के लिए यह x1 XNOR x2 फ़ंक्शन.

38
00:02:53,840 --> 00:02:57,140
और सिर्फ याद दिलाने के लिए अगर यह है, x1, x2,

39
00:02:57,140 --> 00:03:01,870
यह फ़ंक्शन जो हम चाहते हैं कम्प्यूट करना उसमें होंगे नेगेटिव इग्ज़ाम्पल्ज़ यहाँ और

40
00:03:01,870 --> 00:03:04,490
यहाँ, और हमारे पास हैं पॉज़िटिव इग्ज़ाम्पल्ज़ वहाँ और वहाँ.

41
00:03:04,490 --> 00:03:07,470
और तो स्पष्ट रूप से इसे चाहिए एक नॉन-लिनीअर डिसीज़न सीमा रेखा

42
00:03:07,470 --> 00:03:10,829
अलग करने के लिए पॉज़िटिव और नेगेटिव इग्ज़ाम्पल को.

43
00:03:12,980 --> 00:03:14,330
चलो बनाते हैं नेटवर्क.

44
00:03:14,330 --> 00:03:20,740
मैं लूँगा मेरी इनपुट +1, x1, x2 और बनाऊँगा मेरी पहली हिडन यूनिट यहाँ.

45
00:03:20,740 --> 00:03:25,000
मैं कहूँगा उसे a21 क्योंकि वह है मेरी पहली हिडन यूनिट.

46
00:03:25,000 --> 00:03:29,586
और मैं कॉपी करूँगा वेट वहाँ लाल नेटवर्क से, x1 AND x2.

47
00:03:29,586 --> 00:03:35,120
भी ठीक है तब -30, 20, 20.

48
00:03:35,120 --> 00:03:40,790
इसके बाद मैं बनाता हूँ दूसरी हिडन यूनिट जिसे मैं कहूँगा a22.

49
00:03:40,790 --> 00:03:42,880
वह है दूसरी हिडन यूनिट लेयर दो की.

50
00:03:42,880 --> 00:03:47,320
मैं कॉपी करूँगा सायऐन नेटवर्क यहाँ मध्य में, तो

51
00:03:47,320 --> 00:03:52,180
मेरे पास वेट्स होंगे 10, -20, -20.

52
00:03:52,180 --> 00:03:56,120
और इसलिए, चलो लेते हैं कुछ ट्रूथ टेबल वैल्यूज़.

53
00:03:56,120 --> 00:04:00,664
लाल नेटवर्क के लिए, हम जानते हैं वह कम्प्यूट कर रहा था x1 AND

54
00:04:00,664 --> 00:04:04,649
x2, और इसलिए यह होगा लगभग 0 0 0 1,

55
00:04:04,649 --> 00:04:10,429
निर्भर करते हुए x1 और x2 की वैल्यूज़ पर, और a22 के लिए सायऐन नेटवर्क.

56
00:04:10,429 --> 00:04:11,190
हम क्या जानते हैं?

57
00:04:11,190 --> 00:04:16,000
फ़ंक्शन NOT x1 AND NOT x2, वह आउट्पुट करता है 1 0 0 0,

58
00:04:16,000 --> 00:04:17,470
चार वैल्यूज़ के लिए x1 और x2 की.

59
00:04:18,480 --> 00:04:24,875
अंत में मैं बनाऊँगा मेरा आउट्पुट नोड, मेरी आउट्पुट यूनिट जो है a31.

60
00:04:24,875 --> 00:04:31,971
यह है एक और आउट्पुट h(x) और मैं करूँगा कॉपी पुराना नेटवर्क उसके लिए.

61
00:04:31,971 --> 00:04:35,588
और मुझे चाहिए एक a +1 बाइयस यूनिट यहाँ, आप आप बनाते हैं उसे, और

62
00:04:35,588 --> 00:04:38,839
मैं कॉपी करूँगा वेट हरे नेटवर्क से.

63
00:04:38,839 --> 00:04:44,932
तो वह हैं -10, 20, 20 और हम पहले से जानते हैं कि यह कम्प्यूट करता है OR फ़ंक्शन.

64
00:04:46,682 --> 00:04:48,972
तो चलो भर लेते हैं ट्रूथ टेबल एंट्रीज़.

65
00:04:50,292 --> 00:04:55,209
तो पहली एंट्री है 0 OR 1 जो हो सकता है 1 जो बनाता है 0 OR

66
00:04:55,209 --> 00:05:00,755
0 जो है 0, 0 OR 0 जो है 0, 1 OR 0 और वह बनाता है 1.

67
00:05:00,755 --> 00:05:06,828
और इसलिए h(x) है बराबर 1 जब या दोनो x1 और x2 ज़ीरो हैं या

68
00:05:06,828 --> 00:05:12,251
जब दोनो x1 और x2 1 हैं और वास्तव में h(x) आउट्पुट करता है 1

69
00:05:12,251 --> 00:05:18,019
बिल्कुल इन दो स्थानो पर और फिर आउट्पुट करता है 0 अन्यथा.

70
00:05:19,100 --> 00:05:22,520
और ऐसा ही यह न्यूरल नेटवर्क करेगा, जिसमें है एक इनपुट लेयर,

71
00:05:22,520 --> 00:05:25,760
एक हिडन लेयर, और एक आउट्पुट लेयर,

72
00:05:25,760 --> 00:05:31,640
हमें मिलती है एक नॉन-लिनीअर निर्णायक सीमा रेखा जो कम्प्यूट करती है यह XNOR फ़ंक्शन.

73
00:05:31,640 --> 00:05:35,154
और अधिक सामान्य अनुभव है कि इनपुट लेयर में,

74
00:05:35,154 --> 00:05:36,954
हमारे पास सिर्फ़ हैं चार इन्पुट्स.

75
00:05:36,954 --> 00:05:38,302
फिर हमारे पास है एक हिडन लेयर,

76
00:05:38,302 --> 00:05:42,123
जिसने कम्प्यूट थोड़ा अधिक जटिल फ़ंक्शन इन्पुट्स का जो दिखाया है

77
00:05:42,123 --> 00:05:44,790
यहाँ यह है थोड़ा अधिक पेचीदा फ़ंक्शन्स

78
00:05:44,790 --> 00:05:45,730
और फिर जोड़ने से और

79
00:05:45,730 --> 00:05:49,490
एक अन्य लेयर हमें मिलता है एक और भी जटिल नॉन-लिनीअर फ़ंक्शन.

80
00:05:50,510 --> 00:05:54,743
और यह है एक तरह से अनुभव कि क्यों न्यूरल नेटवर्क्स कम्प्यूट कर सकते हैं

81
00:05:54,743 --> 00:05:56,829
बहुत जटिल फ़ंक्शन्स.

82
00:05:56,829 --> 00:06:00,251
वह जब आपके पास हैं कई लेयर्स आपके पास हैं अपेक्षाकृत सरल फ़ंक्शन

83
00:06:00,251 --> 00:06:02,190
दूसरी लेयर की इन्पुट्स के.

84
00:06:02,190 --> 00:06:06,040
लेकिन तीसरी लेयर बना सकती है उस पर पूरा करने के लिए और भी अधिक जटिल फ़ंक्शन्स, और

85
00:06:06,040 --> 00:06:09,360
फिर उसके बाद की लेयर कम्प्यूट कर सकती है और भी अधिक जटिल फ़ंक्शन्स.

86
00:06:10,390 --> 00:06:11,520
समाप्त करने के लिए इस वीडियो को,

87
00:06:11,520 --> 00:06:15,460
मैं आपको दिखाना चाहता हूँ एक मज़ेदार उदाहरण एक ऐप्लिकेशन का न्यूरल नेटवर्क की

88
00:06:15,460 --> 00:06:20,680
जो ले सकती है यह अनुभव गहरी लेयर्स का कम्प्यूट करते हुए अधिक जटिल फ़ीचर्ज़.

89
00:06:20,680 --> 00:06:23,565
मैं आपको दिखाना चाहता हूँ एक वीडियो उस ग्राहक का मेरा अच्छा मित्र है

90
00:06:23,565 --> 00:06:24,925
यान्न लेकुंज.

91
00:06:24,925 --> 00:06:28,870
यान्न एक प्रोफ़ेसर है न्यू यॉर्क यूनिवर्सिटी, एनवाययू में, और

92
00:06:28,870 --> 00:06:32,550
वे थे न्यूरल नेटवर्क में अनुसंधान के अगुआ लोगों में से एक और

93
00:06:32,550 --> 00:06:36,930
हैं एक तरह से प्रसिद्ध इस क्षेत्र में अब और उनके विचार इस्तेमाल किए जाते हैं

94
00:06:36,930 --> 00:06:40,459
हर तरह के प्रॉडक्ट्स और ऐप्लिकेशन्स में पूरे विश्व में अब.

95
00:06:41,470 --> 00:06:45,730
तो मैं आपको दिखाना चाहता हूँ एक वीडियो उनके कुछ शुरू के काम का जिसमें वे इस्तेमाल कर रहे थे

96
00:06:45,730 --> 00:06:51,400
एक न्यूरल नेटवर्क पहचानने के लिए लिखावट, करने के हस्तलिखित अंको की पहचान.

97
00:06:51,400 --> 00:06:54,940
आपको शायद याद हो शुरू में इस क्लास में, शुरुआत में इस क्लास में मैंने कहा था कि

98
00:06:54,940 --> 00:06:59,000
शूरु की न्यूरल नेटवर्क की सफलताओं में से एक था इस्तेमाल करना इसे पढ़ने के लिए ज़िप

99
00:06:59,000 --> 00:07:03,890
कोड्स मदद करने के लिए यूएसपीएस लॉज़ / क़ानून और पढ़ने के लिए पोस्टल कोड्स.

100
00:07:03,890 --> 00:07:05,460
तो यह है उनमें से एक प्रयास,

101
00:07:05,460 --> 00:07:09,400
यह है उन अल्गोरिद्म्स में से एक इस्तेमाल किया गया सम्बोधित करने के लिए उस प्रॉब्लम को.

102
00:07:09,400 --> 00:07:12,480
वीडियो में जो मैं दिखाऊँगा आपको यह क्षेत्र यहाँ

103
00:07:12,480 --> 00:07:17,840
है इनपुट एरिया जो दिखता हैं कॉरेस्पॉंडिंग अंक दिखाया गया नेटवर्क को.

104
00:07:17,840 --> 00:07:21,872
यह कॉलम यहाँ दिखाता है एक विज़ूअलाइज़ेशन फ़ीचर्ज़ का कम्प्यूट किए गए पहली

105
00:07:21,872 --> 00:07:23,324
हिडन लेयर से नेटवर्क की.

106
00:07:23,324 --> 00:07:27,142
तो वह है पहली हिडन लेयर नेटवर्क की और इसलिए पहली हिडन लेयर,

107
00:07:27,142 --> 00:07:29,685
यह विज़ूअलाइज़ेशन दिखाता है विभिन्न फ़ीचर्ज़.

108
00:07:29,685 --> 00:07:32,355
अलग किनारे और लाइने और इसी तरह कुछ कुछ चीज़ें पता चलीं.

109
00:07:32,355 --> 00:07:35,555
यह है विज़ूअलाइज़ेशन अगली हिडन लेयर की.

110
00:07:35,555 --> 00:07:39,175
यह एक तरह से थोड़ा कठिन है देखना, कठिन है समझना गहरी, हिडन लेयर्स, और

111
00:07:39,175 --> 00:07:42,585
वह है एक विज़ूअलाइज़ेशन कि क्यों अगली हिडन लेयर अस्पष्ट है.

112
00:07:42,585 --> 00:07:45,505
आपको शायद कठिन लगे देख पाना क्या हो रहा है

113
00:07:45,505 --> 00:07:47,785
पहली हिडन लेयर के आगे, लेकिन

114
00:07:47,785 --> 00:07:53,410
फिर अंत में, सारे ये लर्न किए हुए फ़ीचर्ज़ फ़ीड किए जाते हैं ऊपरी लेयर को.

115
00:07:53,410 --> 00:07:58,384
और यहाँ दिखाया गया है अंतिम उत्तर, यह अंतिम प्रिडिक्टेड वैल्यू

116
00:07:58,384 --> 00:08:02,832
क्या हस्तलिखित अंक के लिए न्यूरल नेटवर्क सोचता है यह दिखाया जा रहा है.

117
00:08:02,832 --> 00:08:07,437
तो चलो देखते हैं वीडियो.

118
00:08:07,437 --> 00:08:17,437
[संगीत]

119
00:09:49,712 --> 00:09:53,949
तो मैं उम्मीद करता हूँ आपको मज़ा आया होगा वीडियो में और कि यह शायद देगा आपको कुछ अनुभव

120
00:09:53,949 --> 00:09:58,350
कि काफ़ी जटिल फ़ंक्शंज़ के उदगम का जो न्यूरल नेटवर्क लर्न कर सकता है.

121
00:09:58,350 --> 00:10:02,445
जिसमें यह लेता है इसकी इनपुट यह इमिज, सिर्फ़ लेता है यह इनपुट, रॉ पिक्सेल्स और

122
00:10:02,445 --> 00:10:05,234
पहली हिडन लेयर कम्प्यूट करती है कुछ सेट फ़ीचर्ज़ का.

123
00:10:05,234 --> 00:10:07,754
अगली हिडन लेयर कम्प्यूट करती है थोड़े और जटिल फ़ीचर्ज़ और

124
00:10:07,754 --> 00:10:09,550
और भी अधिक जटिल फ़ीचर्ज़.

125
00:10:09,550 --> 00:10:12,980
और ये फ़ीचर्ज़ तब किए जा सकते हैं आवश्यक रूप से अंतिम

126
00:10:12,980 --> 00:10:17,600
लेयर में लॉजिस्टिक क्लैसिफ़ायअर की करने के लिए एकदम सही प्रिडिक्शन्स

127
00:10:17,600 --> 00:10:20,005
नम्बर्ज़ के बारे में जो नेटवर्क देखता है.