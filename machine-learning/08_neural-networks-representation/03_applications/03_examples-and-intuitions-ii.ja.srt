1
00:00:00,420 --> 00:00:01,540
このビデオでは

2
00:00:01,700 --> 00:00:02,680
ニューラルネットワークが

3
00:00:03,390 --> 00:00:04,480
どのように複雑な

4
00:00:04,730 --> 00:00:07,140
非線形の仮説を計算するかを見ていく。

5
00:00:10,110 --> 00:00:11,240
前回のビデオでは

6
00:00:11,490 --> 00:00:12,790
ニューラルネットワークが

7
00:00:13,020 --> 00:00:13,900
どのように関数 x1 AND x2とか、

8
00:00:14,420 --> 00:00:16,120
関数

9
00:00:16,230 --> 00:00:18,410
x1 OR x2を計算するかを見てきた、

10
00:00:18,750 --> 00:00:20,250
ここでx1とx2は二値の値をとる。

11
00:00:20,870 --> 00:00:23,080
つまり、取りうる可能な値は0か1だけ。

12
00:00:23,230 --> 00:00:24,580
また、我らは

13
00:00:24,620 --> 00:00:27,130
否定を計算するネットワークも

14
00:00:27,330 --> 00:00:30,040
持ちうる。つまりNOT x1関数。

15
00:00:30,280 --> 00:00:31,670
このネットワークを

16
00:00:31,890 --> 00:00:33,670
書き出してみよう。

17
00:00:33,970 --> 00:00:35,350
たった一つだけの入力フィーチャーx1が

18
00:00:35,450 --> 00:00:36,550
この場合にはあり、

19
00:00:36,620 --> 00:00:38,210
そしてバイアスユニットとして+1がある。

20
00:00:38,680 --> 00:00:40,130
そしてこれに、

21
00:00:41,070 --> 00:00:42,610
ウェイト+10と

22
00:00:43,120 --> 00:00:45,700
-20を付与すると、仮説はこれを計算する事になる。

23
00:00:46,080 --> 00:00:47,740
hのxは、イコール、sigmoid関数の

24
00:00:47,880 --> 00:00:49,600
10-20*x1 となる。

25
00:00:50,390 --> 00:00:51,710
つまり、x1が

26
00:00:51,940 --> 00:00:52,880
0の時には

27
00:00:52,960 --> 00:00:54,060
仮説はgの

28
00:00:55,160 --> 00:00:57,340
10-20*0を計算する事になり、

29
00:00:57,970 --> 00:00:59,910
これはgの10となる。

30
00:01:00,090 --> 00:01:01,600
つまりこれは、だいたい1だ。

31
00:01:02,440 --> 00:01:03,390
そしてxが

32
00:01:03,500 --> 00:01:04,300
イコール1の時は

33
00:01:04,380 --> 00:01:05,740
gの-10となり

34
00:01:06,210 --> 00:01:09,380
これはだいたい0となる。

35
00:01:09,550 --> 00:01:10,320
そしてこれらの値が何なのかを

36
00:01:10,450 --> 00:01:11,720
眺めてみると、これはようするに

37
00:01:12,230 --> 00:01:13,470
NOT x1関数だ。

38
00:01:14,560 --> 00:01:16,410
つまり否定を行うには

39
00:01:16,700 --> 00:01:18,640
基本的には負の大きなウェイトを

40
00:01:19,080 --> 00:01:20,460
否定したい変数の前に

41
00:01:20,650 --> 00:01:22,870
おけば良い。

42
00:01:23,100 --> 00:01:24,710
この場合は-20を、x1に掛けてる。

43
00:01:25,590 --> 00:01:26,780
これがx1を否定する

44
00:01:27,230 --> 00:01:28,110
やり方の

45
00:01:28,320 --> 00:01:30,500
基本的な考え方。

46
00:01:30,700 --> 00:01:32,210
以上で、例えば

47
00:01:32,580 --> 00:01:33,410
以下のような関数を計算したい時に

48
00:01:33,480 --> 00:01:35,090
自力で

49
00:01:35,280 --> 00:01:36,410
やり方を見つけ出せるだろう：

50
00:01:36,580 --> 00:01:38,870
(NOT x1) AND (NOT x2)

51
00:01:39,090 --> 00:01:40,100
解答の一部分としては、

52
00:01:40,390 --> 00:01:41,860
たぶん負の大きなウェイトを

53
00:01:42,290 --> 00:01:44,150
x1とx2に置く事になるだろう、

54
00:01:44,500 --> 00:01:45,330
そしてそれを

55
00:01:45,580 --> 00:01:47,320
出力が一つだけの

56
00:01:47,490 --> 00:01:49,910
ニューラルネットワークを得る為に

57
00:01:50,420 --> 00:01:52,810
食わせる。

58
00:01:52,990 --> 00:01:53,460
いいかい？

59
00:01:53,680 --> 00:01:55,130
つまりこの大きな論理関数、

60
00:01:55,300 --> 00:01:56,290
(NOT x1) AND (NOT x2)が

61
00:01:56,590 --> 00:01:57,990
イコール1

62
00:01:58,210 --> 00:02:00,450
となるのは

63
00:02:00,780 --> 00:02:06,960
x1=x2=0の時で、

64
00:02:07,350 --> 00:02:09,860
その時のみ1となる。

65
00:02:10,420 --> 00:02:11,480
つまり、これは論理関数で、

66
00:02:11,680 --> 00:02:14,290
これはNOT x1、つまりX1は0でなくてはいけない、という意味で、さらにNOT x2。

67
00:02:14,530 --> 00:02:17,130
それはx2もまた0でなくてはならない、という意味だ。

68
00:02:17,800 --> 00:02:19,210
だからこの論理関数が1となるのは、

69
00:02:19,450 --> 00:02:20,210
x1とx2の両方が

70
00:02:20,540 --> 00:02:22,900
イコール0の時だけだ。

71
00:02:23,910 --> 00:02:25,600
以上で、この論理関数を計算する

72
00:02:25,710 --> 00:02:26,630
小さなニューラルネットワークを

73
00:02:26,950 --> 00:02:28,240
どうやって構築すれば良いかも

74
00:02:28,640 --> 00:02:29,830
分かるだろう。

75
00:02:33,430 --> 00:02:34,350
さて、今度はこの三つの部品を

76
00:02:34,820 --> 00:02:36,720
一つに組み合わせて、

77
00:02:37,400 --> 00:02:38,710
つまりx1 AND x2を

78
00:02:38,910 --> 00:02:40,620
計算するネットワークと

79
00:02:40,960 --> 00:02:42,070
(NOT x1) AND (NOT x2)を計算する

80
00:02:42,340 --> 00:02:44,170
ネットワークと、最後は

81
00:02:44,620 --> 00:02:45,910
x1 OR x2を計算する為のネットワーク。

82
00:02:46,570 --> 00:02:47,700
我らはこれら三つの要素を

83
00:02:47,760 --> 00:02:49,420
組み合わせる事により、

84
00:02:49,840 --> 00:02:51,270
この x1 XNOR x2関数が

85
00:02:51,470 --> 00:02:52,810
計算出来るはずだ。

86
00:02:53,860 --> 00:02:54,930
ここで再掲しておくと、

87
00:02:55,100 --> 00:02:57,130
これがx1とx2とすると、

88
00:02:58,080 --> 00:02:58,830
我らがこれから計算しようとしているこの関数は

89
00:02:59,090 --> 00:03:00,900
陰性の手本が

90
00:03:01,520 --> 00:03:02,690
こことここに、そして

91
00:03:02,830 --> 00:03:04,370
陽性の手本がこことここにあるような物だった。

92
00:03:04,730 --> 00:03:06,270
これから、明らかに

93
00:03:06,570 --> 00:03:08,400
陽性と陰性の手本を分離するには

94
00:03:08,940 --> 00:03:10,540
非線型の決定境界が要る。

95
00:03:12,950 --> 00:03:13,460
ネットワークを書き下してみよう。

96
00:03:14,260 --> 00:03:15,820
入力として、+1, x1, x2を取り、

97
00:03:16,570 --> 00:03:18,610
そして最初の隠れユニットを

98
00:03:19,150 --> 00:03:20,390
ここに作る。

99
00:03:20,660 --> 00:03:22,010
これをa(2) 1と呼ぶ事にする、

100
00:03:22,770 --> 00:03:24,060
何故ならこれは最初の隠れユニットだから。

101
00:03:24,510 --> 00:03:25,660
そしてウェイトを赤のネットワークから、

102
00:03:25,920 --> 00:03:27,410
つまり x1 AND x2のネットワークから

103
00:03:27,740 --> 00:03:30,020
コピーする。

104
00:03:30,820 --> 00:03:32,410
つまり -30, 20, 20。

105
00:03:32,650 --> 00:03:36,060
次に、二番目の隠れユニットを

106
00:03:36,420 --> 00:03:37,700
作ろう。それを

107
00:03:37,930 --> 00:03:39,960
a(2) 2と呼ぶ事にする。

108
00:03:40,350 --> 00:03:42,610
これはレイヤー2の二番目の隠れユニットだ。

109
00:03:43,550 --> 00:03:44,590
そして真ん中の

110
00:03:44,740 --> 00:03:45,940
シアン色のネットワークをコピーする、

111
00:03:46,170 --> 00:03:47,080
つまりウェイトとして

112
00:03:47,130 --> 00:03:49,230
10, -20, -20

113
00:03:50,150 --> 00:03:51,060
となる。

114
00:03:52,150 --> 00:03:55,570
ここで真理値表から値をひっぱってこよう。

115
00:03:56,170 --> 00:03:57,350
赤いネットワークは

116
00:03:57,590 --> 00:03:59,340
x1 AND x2を計算している事を知っている。

117
00:03:59,690 --> 00:04:00,940
つまりこれは、

118
00:04:01,040 --> 00:04:02,460
だいたい 0, 0, 0, 1となる、

119
00:04:02,540 --> 00:04:05,030
x1とx2の値に応じて。

120
00:04:07,040 --> 00:04:09,560
そしてa(2) 2については、シアン色のネットワークで、

121
00:04:10,590 --> 00:04:11,750
これは (NOT x1) AND (NOT x2)関数だと

122
00:04:12,240 --> 00:04:13,640
知っているから、出力は

123
00:04:13,640 --> 00:04:15,610
4つのx1とx2の入力に対して

124
00:04:15,700 --> 00:04:17,830
1, 0, 0, 0となる。

125
00:04:18,480 --> 00:04:19,560
最後に、出力ノードを作る。

126
00:04:19,810 --> 00:04:21,300
出力ユニットは

127
00:04:21,490 --> 00:04:23,950
a(3) 1だ。

128
00:04:24,860 --> 00:04:26,230
これはh(x)の出力で、

129
00:04:26,590 --> 00:04:28,270
ここにはORのネットワークから

130
00:04:28,390 --> 00:04:30,030
コピーして、

131
00:04:30,320 --> 00:04:32,470
ここにはバイアスユニットの

132
00:04:32,860 --> 00:04:34,330
+1が必要だ。

133
00:04:34,810 --> 00:04:36,010
だからそれを書きこむ、

134
00:04:36,320 --> 00:04:38,360
緑のネットワークからウェイトをコピーする。

135
00:04:38,950 --> 00:04:39,750
つまり、-10, 20, 20で、

136
00:04:42,370 --> 00:04:44,460
これがOR関数を実装する事を前に見ている。

137
00:04:46,660 --> 00:04:48,200
では真理値表を見ていこう。

138
00:04:50,300 --> 00:04:51,660
最初のエントリでは、0 OR 1だから

139
00:04:51,720 --> 00:04:53,930
1となる。

140
00:04:54,140 --> 00:04:55,710
次は0 OR 0だから、

141
00:04:55,800 --> 00:04:57,280
0となり、

142
00:04:57,350 --> 00:04:58,920
0 OR 0は0。

143
00:04:58,960 --> 00:05:00,420
1 OR 0は1で、

144
00:05:00,600 --> 00:05:02,450
つまり、hのxが

145
00:05:02,640 --> 00:05:04,820
イコール1となるのは、

146
00:05:04,980 --> 00:05:06,270
x1とx2がどちらも0の時か、

147
00:05:06,780 --> 00:05:08,360
またはx1とx2が

148
00:05:08,590 --> 00:05:10,160
どちらも1の時だけだ。

149
00:05:10,900 --> 00:05:12,170
具体的には、hのxは

150
00:05:12,680 --> 00:05:15,340
これら二つの位置の時には

151
00:05:15,560 --> 00:05:16,850
ぴったり1を出力し、

152
00:05:17,230 --> 00:05:19,270
それ以外の場合は0を出力する。

153
00:05:19,570 --> 00:05:20,970
かくして、このニューラルネットワークでもって、

154
00:05:21,210 --> 00:05:23,030
それは入力レイヤーに

155
00:05:23,200 --> 00:05:24,560
1つの隠れレイヤーと1つの出力レイヤーがあるような物だが、

156
00:05:24,880 --> 00:05:25,920
これでXNOR関数のような

157
00:05:26,100 --> 00:05:28,450
非線型の決定境界を計算出来る、

158
00:05:29,120 --> 00:05:30,520
このような関数を。

159
00:05:31,640 --> 00:05:33,390
そしてより一般的には

160
00:05:33,710 --> 00:05:34,870
直感的には、入力レイヤーには

161
00:05:34,990 --> 00:05:35,780
単に生の入力を置いて、

162
00:05:36,060 --> 00:05:37,400
そして隠れレイヤーがあり、

163
00:05:37,610 --> 00:05:39,510
そこでは、ここに示した

164
00:05:39,680 --> 00:05:41,140
もうちょっとだけ複雑な入力の関数を

165
00:05:41,250 --> 00:05:42,080
計算している。

166
00:05:42,430 --> 00:05:43,410
これらはさらにちょっとだけ

167
00:05:43,550 --> 00:05:44,960
複雑な関数で、

168
00:05:45,250 --> 00:05:46,510
さらにもう一つレイヤーを追加する事で、

169
00:05:46,640 --> 00:05:49,030
さらに複雑な非線型の関数も計算する事が出来る。

170
00:05:50,550 --> 00:05:51,340
以上が、

171
00:05:51,450 --> 00:05:53,810
ニューラルネットワークを用いると、

172
00:05:54,100 --> 00:05:55,270
極めて複雑な関数を計算しうるかの

173
00:05:55,840 --> 00:05:57,270
直感的な説明だ。

174
00:05:57,340 --> 00:05:58,550
複数のレイヤーがある時に、

175
00:05:58,910 --> 00:06:00,300
二番目のレイヤーは

176
00:06:00,390 --> 00:06:01,500
比較的単純な入力の関数でも、

177
00:06:02,160 --> 00:06:03,110
三番目のレイヤーを足す事で

178
00:06:03,340 --> 00:06:04,590
さらに複雑な関数を計算する為に

179
00:06:04,820 --> 00:06:06,330
ネットワークを作りあげる事が出来、

180
00:06:06,790 --> 00:06:08,730
そしてその次のレイヤーで、さらに複雑な関数を計算する事も出来る。

181
00:06:10,340 --> 00:06:11,740
このビデオのまとめとして、

182
00:06:11,800 --> 00:06:13,330
楽しい例を紹介したい、

183
00:06:13,480 --> 00:06:14,650
これはニューラルネットワークを適用した例で、

184
00:06:14,880 --> 00:06:16,400
より深い所のレイヤーがより複雑な計算をしていく、という

185
00:06:17,260 --> 00:06:19,440
直感を捉えた物となっている。

186
00:06:19,900 --> 00:06:21,040
私がお見せするビデオは

187
00:06:21,200 --> 00:06:22,480
私の良き友人、Yon Khunから

188
00:06:22,930 --> 00:06:24,170
もらった物だ。

189
00:06:24,850 --> 00:06:26,240
YonはNew York University、NYUの

190
00:06:26,610 --> 00:06:27,680
教授だ。

191
00:06:28,230 --> 00:06:29,400
彼はニューラルネットワークの

192
00:06:29,470 --> 00:06:30,910
初期の頃の研究の

193
00:06:31,130 --> 00:06:32,590
パイオニアであり、

194
00:06:32,930 --> 00:06:34,610
今ではこの分野での、ある種伝説になった男で、

195
00:06:34,930 --> 00:06:36,520
彼のアイデアは今や

196
00:06:36,560 --> 00:06:38,340
世界中のあらゆる所で

197
00:06:38,980 --> 00:06:40,490
あらゆる製品、アプリケーションに使われている。

198
00:06:41,470 --> 00:06:42,230
さて、私があなたにお見せするのは、

199
00:06:42,380 --> 00:06:43,410
彼の初期の頃の仕事の一つ、

200
00:06:43,740 --> 00:06:44,890
手書き認識の為に

201
00:06:44,980 --> 00:06:46,110
ニューラルネットワークを用いる、

202
00:06:47,000 --> 00:06:50,300
という物だ。手書きの数字認識の為に。

203
00:06:51,370 --> 00:06:52,510
このクラスの最初の方で、

204
00:06:52,720 --> 00:06:53,630
このクラスの最初で、

205
00:06:53,730 --> 00:06:55,180
最初期のニューラルネットワークの

206
00:06:55,460 --> 00:06:56,720
成功した使い道は

207
00:06:57,140 --> 00:06:58,170
それをzipコード（郵便番号）を読むのに

208
00:06:58,320 --> 00:07:00,580
用いるという物だった、と言った。

209
00:07:00,850 --> 00:07:02,940
郵便を送る助けとなるように、郵便番号を読む為に。

210
00:07:03,880 --> 00:07:04,910
つまり、これがその試みの一種だ。

211
00:07:05,250 --> 00:07:06,220
つまりこれこそがあの問題を解決しようとする

212
00:07:06,650 --> 00:07:08,370
アルゴリズムの一種だ。

213
00:07:09,320 --> 00:07:10,420
ビデオでは、

214
00:07:11,060 --> 00:07:12,640
みえているこの、ここの領域、

215
00:07:12,910 --> 00:07:14,420
これがネットワークに入力する

216
00:07:14,980 --> 00:07:16,460
手書きの文字がみえている領域だ。

217
00:07:16,560 --> 00:07:18,610
このここの列は

218
00:07:19,490 --> 00:07:21,350
ネットワークの最初の隠れレイヤーによる

219
00:07:21,460 --> 00:07:23,550
計算結果のフィーチャーを

220
00:07:23,900 --> 00:07:24,760
可視化した物を表示している、

221
00:07:24,830 --> 00:07:26,090
つまり最初の隠れレイヤだ。

222
00:07:26,400 --> 00:07:28,420
この可視化は別々のフィーチャーを表示している、

223
00:07:28,720 --> 00:07:31,190
検出された様々なエッジや線を。

224
00:07:32,360 --> 00:07:35,260
これは次の隠れレイヤーを可視化した物だ。

225
00:07:35,530 --> 00:07:36,390
より深い位置の隠れレイヤーは

226
00:07:36,770 --> 00:07:38,170
どう解釈したらいいか難しい。

227
00:07:38,730 --> 00:07:39,680
そしてこれが、次の隠れレイヤーが計算している物を

228
00:07:40,460 --> 00:07:41,830
可視化した物だ。

229
00:07:42,140 --> 00:07:43,530
たぶん何が起こってるのか、

230
00:07:44,180 --> 00:07:45,550
もう良く分からないだろう。

231
00:07:45,700 --> 00:07:46,800
最初の隠れレイヤーよりもずっと分かりにくい。

232
00:07:47,640 --> 00:07:49,160
だが、最後に、

233
00:07:49,260 --> 00:07:51,110
これらの学習されたフィーチャーを全て

234
00:07:51,430 --> 00:07:52,590
出力レイヤーに食わせて、

235
00:07:53,260 --> 00:07:54,830
ここに最終的な答えを

236
00:07:55,030 --> 00:07:56,370
表示する。

237
00:07:56,800 --> 00:07:58,850
最終的な、ニューラルネットワークが見た

238
00:07:59,390 --> 00:08:02,150
手書き文字が何なのかの予測を。

239
00:08:03,130 --> 00:08:04,270
では、ビデオを見てみよう。

240
00:09:42,060 --> 00:09:44,370
さて、

241
00:09:50,610 --> 00:09:52,010
お楽しみいただけただろうか。

242
00:09:52,260 --> 00:09:53,480
このビデオでニューラルネットワークが学習出来る

243
00:09:53,670 --> 00:09:55,240
極めて複雑な関数が

244
00:09:55,450 --> 00:09:57,120
どんな感じかの感覚を

245
00:09:57,320 --> 00:09:58,420
つかめただろうか。そこでは、

246
00:09:58,740 --> 00:10:00,250
この入力画像を取り、

247
00:10:00,670 --> 00:10:01,510
この生のピクセルを入力に取り、

248
00:10:01,620 --> 00:10:03,140
そして最初のレイヤーの終わりまでに

249
00:10:03,310 --> 00:10:04,640
何らかのフィーチャーの集合を

250
00:10:04,770 --> 00:10:05,680
計算し、次のレイヤーの終わりまでに

251
00:10:05,740 --> 00:10:06,900
さらに複雑なフィーチャーを計算し、

252
00:10:07,330 --> 00:10:08,620
さらに複雑なフィーチャー、

253
00:10:09,560 --> 00:10:10,640
これらのフィーチャーは

254
00:10:10,780 --> 00:10:12,030
最後の、本質的にはロジスティック回帰の

255
00:10:12,940 --> 00:10:14,700
分類器の入力として使われ、

256
00:10:15,810 --> 00:10:17,550
その分類器が、ネットワークが見た数字がなんなのかを

257
00:10:17,880 --> 00:10:19,190
正確に予測するのに使われる。