इस वीडियो में मैं उन्ही हमारे उदाहरणों पर काम करूँगा दिखाने के लिए कैसे एक न्यूरल नेटवर्क कम्प्यूट कर सकता हैं एक जटिल नॉन-लिनीअर हायपॉथिसस. पिछले वीडियो में हमने देखा कैसे एक न्यूरल नेटवर्क इस्तेमाल किया जा सकता है कम्प्यूट करने के लिए फ़ंक्शंज़ x1 AND x2, और फ़ंक्शन x1 OR x2 जब x1 और x2 हैं बाइनरी, मतलब कि जब वे लेते हैं वैल्यूज़ 0, 1. हम बना सकते हैं एक नेटवर्क कम्प्यूट करने के लिए निगेशन, मतलब कि कम्प्यूट करने के लिए फ़ंक्शन NOT x1. मैं सिर्फ़ लिखता हूँ वेट्स इस नेटवर्क में. हमारे पास है केवल एक इनपुट फ़ीचर x1 इस केस में और यह बाइयस यूनिट +1. और यदि मैं जोड़ता हूँ इसे वेट्स प्लस 10 और -20 के साथ, तो मेरी हायपॉथिसस कम्प्यूट करती है यह h(x) बराबर सिग्मोईड(10 - 20 x1). तो जब x1 है 0, मेरी हायपॉथिसस कम्प्यूट करेगी g(10 - 20 x0) जो है सिर्फ़ 10. और वह है अलगभग 1, और जब x1 है बराबर 1, यह होगा g(1=-10) जो है लगभग बराबर 0 के. और यदि आप देखते हैं कि क्या ये वैल्यूज़ हैं, वह है अनिवार्यत: NOT x1 फ़ंक्शन. जो करता है निगेशन, सामान्य विचार है कि रखें बड़े नेगेटिव वेट सामने वेरीयबल के जो आप निगेट करना चाहते हैं. माइनस 20 गुणा x1 से और वह है आम विचार कि कैसे आप कर पाते हैं निगेट x1 को. और इसलिए एक उदाहरण में मैं आशा करता हूँ आप ख़ुद कर पाएँगे. यदि आप कम्प्यूट करना चाहते हैं एक फ़ंक्शन इस तरह का x1 AND NOT x2, हिस्सा उसका होगा शायद रखना बड़े नेगेटिव वेट्स सामने x1 के और x2 के, लेकिन यह सम्भव होना चाहिए. तो आपको मिलता है एक न्यूरल नेटवर्क केवल एक आउट्पुट यूनिट का कम्प्यूट करने के लिए इसे भी. ठीक है, तो यह लॉजिकल फ़ंक्शन, x1 AND NOT x2, होगा बराबर 1 के तभी और केवल तभी यदि x1 बराबर है x2 के बराबर है 0. ठीक है, क्योंकि यह है एक लॉजिकल फ़ंक्शन,यह बताता है NOT x1 का मतलब है x1 होना चाहिए 0 और NOT x2, उसका मतलब है x2 भी होना चाहिए 0. तो यह लॉजिकल फ़ंक्शन होगा 1 केवल तभी जब दोनो x1 और x2 हैं बराबर 0 के और उम्मीद है आप समझ पाएँगे कि कैसे बनाना है एक छोटा न्यूरल नेटवर्क कम्प्यूट करने के लिए इस लॉजिकल फ़ंक्शन को भी. अब, लेते हुए तीनो हिस्से जो हमने साथ रखे नेटवर्क की तरह कम्प्यूट करने के लिए x1 AND x2, और नेटवर्क कम्प्यूट करने के लिए NOT x1 AND NOT x2. और एक आख़िरी नेटवर्क कम्प्यूट करने के लिए x1 OR x2, हमें कर पाना चाहिए इन तीन हिस्सों को एक साथ कम्प्यूट करने के लिए यह x1 XNOR x2 फ़ंक्शन. और सिर्फ याद दिलाने के लिए अगर यह है, x1, x2, यह फ़ंक्शन जो हम चाहते हैं कम्प्यूट करना उसमें होंगे नेगेटिव इग्ज़ाम्पल्ज़ यहाँ और यहाँ, और हमारे पास हैं पॉज़िटिव इग्ज़ाम्पल्ज़ वहाँ और वहाँ. और तो स्पष्ट रूप से इसे चाहिए एक नॉन-लिनीअर डिसीज़न सीमा रेखा अलग करने के लिए पॉज़िटिव और नेगेटिव इग्ज़ाम्पल को. चलो बनाते हैं नेटवर्क. मैं लूँगा मेरी इनपुट +1, x1, x2 और बनाऊँगा मेरी पहली हिडन यूनिट यहाँ. मैं कहूँगा उसे a21 क्योंकि वह है मेरी पहली हिडन यूनिट. और मैं कॉपी करूँगा वेट वहाँ लाल नेटवर्क से, x1 AND x2. भी ठीक है तब -30, 20, 20. इसके बाद मैं बनाता हूँ दूसरी हिडन यूनिट जिसे मैं कहूँगा a22. वह है दूसरी हिडन यूनिट लेयर दो की. मैं कॉपी करूँगा सायऐन नेटवर्क यहाँ मध्य में, तो मेरे पास वेट्स होंगे 10, -20, -20. और इसलिए, चलो लेते हैं कुछ ट्रूथ टेबल वैल्यूज़. लाल नेटवर्क के लिए, हम जानते हैं वह कम्प्यूट कर रहा था x1 AND x2, और इसलिए यह होगा लगभग 0 0 0 1, निर्भर करते हुए x1 और x2 की वैल्यूज़ पर, और a22 के लिए सायऐन नेटवर्क. हम क्या जानते हैं? फ़ंक्शन NOT x1 AND NOT x2, वह आउट्पुट करता है 1 0 0 0, चार वैल्यूज़ के लिए x1 और x2 की. अंत में मैं बनाऊँगा मेरा आउट्पुट नोड, मेरी आउट्पुट यूनिट जो है a31. यह है एक और आउट्पुट h(x) और मैं करूँगा कॉपी पुराना नेटवर्क उसके लिए. और मुझे चाहिए एक a +1 बाइयस यूनिट यहाँ, आप आप बनाते हैं उसे, और मैं कॉपी करूँगा वेट हरे नेटवर्क से. तो वह हैं -10, 20, 20 और हम पहले से जानते हैं कि यह कम्प्यूट करता है OR फ़ंक्शन. तो चलो भर लेते हैं ट्रूथ टेबल एंट्रीज़. तो पहली एंट्री है 0 OR 1 जो हो सकता है 1 जो बनाता है 0 OR 0 जो है 0, 0 OR 0 जो है 0, 1 OR 0 और वह बनाता है 1. और इसलिए h(x) है बराबर 1 जब या दोनो x1 और x2 ज़ीरो हैं या जब दोनो x1 और x2 1 हैं और वास्तव में h(x) आउट्पुट करता है 1 बिल्कुल इन दो स्थानो पर और फिर आउट्पुट करता है 0 अन्यथा. और ऐसा ही यह न्यूरल नेटवर्क करेगा, जिसमें है एक इनपुट लेयर, एक हिडन लेयर, और एक आउट्पुट लेयर, हमें मिलती है एक नॉन-लिनीअर निर्णायक सीमा रेखा जो कम्प्यूट करती है यह XNOR फ़ंक्शन. और अधिक सामान्य अनुभव है कि इनपुट लेयर में, हमारे पास सिर्फ़ हैं चार इन्पुट्स. फिर हमारे पास है एक हिडन लेयर, जिसने कम्प्यूट थोड़ा अधिक जटिल फ़ंक्शन इन्पुट्स का जो दिखाया है यहाँ यह है थोड़ा अधिक पेचीदा फ़ंक्शन्स और फिर जोड़ने से और एक अन्य लेयर हमें मिलता है एक और भी जटिल नॉन-लिनीअर फ़ंक्शन. और यह है एक तरह से अनुभव कि क्यों न्यूरल नेटवर्क्स कम्प्यूट कर सकते हैं बहुत जटिल फ़ंक्शन्स. वह जब आपके पास हैं कई लेयर्स आपके पास हैं अपेक्षाकृत सरल फ़ंक्शन दूसरी लेयर की इन्पुट्स के. लेकिन तीसरी लेयर बना सकती है उस पर पूरा करने के लिए और भी अधिक जटिल फ़ंक्शन्स, और फिर उसके बाद की लेयर कम्प्यूट कर सकती है और भी अधिक जटिल फ़ंक्शन्स. समाप्त करने के लिए इस वीडियो को, मैं आपको दिखाना चाहता हूँ एक मज़ेदार उदाहरण एक ऐप्लिकेशन का न्यूरल नेटवर्क की जो ले सकती है यह अनुभव गहरी लेयर्स का कम्प्यूट करते हुए अधिक जटिल फ़ीचर्ज़. मैं आपको दिखाना चाहता हूँ एक वीडियो उस ग्राहक का मेरा अच्छा मित्र है यान्न लेकुंज. यान्न एक प्रोफ़ेसर है न्यू यॉर्क यूनिवर्सिटी, एनवाययू में, और वे थे न्यूरल नेटवर्क में अनुसंधान के अगुआ लोगों में से एक और हैं एक तरह से प्रसिद्ध इस क्षेत्र में अब और उनके विचार इस्तेमाल किए जाते हैं हर तरह के प्रॉडक्ट्स और ऐप्लिकेशन्स में पूरे विश्व में अब. तो मैं आपको दिखाना चाहता हूँ एक वीडियो उनके कुछ शुरू के काम का जिसमें वे इस्तेमाल कर रहे थे एक न्यूरल नेटवर्क पहचानने के लिए लिखावट, करने के हस्तलिखित अंको की पहचान. आपको शायद याद हो शुरू में इस क्लास में, शुरुआत में इस क्लास में मैंने कहा था कि शूरु की न्यूरल नेटवर्क की सफलताओं में से एक था इस्तेमाल करना इसे पढ़ने के लिए ज़िप कोड्स मदद करने के लिए यूएसपीएस लॉज़ / क़ानून और पढ़ने के लिए पोस्टल कोड्स. तो यह है उनमें से एक प्रयास, यह है उन अल्गोरिद्म्स में से एक इस्तेमाल किया गया सम्बोधित करने के लिए उस प्रॉब्लम को. वीडियो में जो मैं दिखाऊँगा आपको यह क्षेत्र यहाँ है इनपुट एरिया जो दिखता हैं कॉरेस्पॉंडिंग अंक दिखाया गया नेटवर्क को. यह कॉलम यहाँ दिखाता है एक विज़ूअलाइज़ेशन फ़ीचर्ज़ का कम्प्यूट किए गए पहली हिडन लेयर से नेटवर्क की. तो वह है पहली हिडन लेयर नेटवर्क की और इसलिए पहली हिडन लेयर, यह विज़ूअलाइज़ेशन दिखाता है विभिन्न फ़ीचर्ज़. अलग किनारे और लाइने और इसी तरह कुछ कुछ चीज़ें पता चलीं. यह है विज़ूअलाइज़ेशन अगली हिडन लेयर की. यह एक तरह से थोड़ा कठिन है देखना, कठिन है समझना गहरी, हिडन लेयर्स, और वह है एक विज़ूअलाइज़ेशन कि क्यों अगली हिडन लेयर अस्पष्ट है. आपको शायद कठिन लगे देख पाना क्या हो रहा है पहली हिडन लेयर के आगे, लेकिन फिर अंत में, सारे ये लर्न किए हुए फ़ीचर्ज़ फ़ीड किए जाते हैं ऊपरी लेयर को. और यहाँ दिखाया गया है अंतिम उत्तर, यह अंतिम प्रिडिक्टेड वैल्यू क्या हस्तलिखित अंक के लिए न्यूरल नेटवर्क सोचता है यह दिखाया जा रहा है. तो चलो देखते हैं वीडियो. [संगीत] तो मैं उम्मीद करता हूँ आपको मज़ा आया होगा वीडियो में और कि यह शायद देगा आपको कुछ अनुभव कि काफ़ी जटिल फ़ंक्शंज़ के उदगम का जो न्यूरल नेटवर्क लर्न कर सकता है. जिसमें यह लेता है इसकी इनपुट यह इमिज, सिर्फ़ लेता है यह इनपुट, रॉ पिक्सेल्स और पहली हिडन लेयर कम्प्यूट करती है कुछ सेट फ़ीचर्ज़ का. अगली हिडन लेयर कम्प्यूट करती है थोड़े और जटिल फ़ीचर्ज़ और और भी अधिक जटिल फ़ीचर्ज़. और ये फ़ीचर्ज़ तब किए जा सकते हैं आवश्यक रूप से अंतिम लेयर में लॉजिस्टिक क्लैसिफ़ायअर की करने के लिए एकदम सही प्रिडिक्शन्स नम्बर्ज़ के बारे में जो नेटवर्क देखता है.