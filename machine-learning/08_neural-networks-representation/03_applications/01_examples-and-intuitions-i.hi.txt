इस और अगले वीडियो में मैं चाहता हूँ एक विस्तृत उदाहरण के माध्यम से दिखाना कि कैसे एक न्यूरल नेटवर्क कम्प्यूट कर सकता हैं एक जटिल नॉन-लिनीअर फ़ंक्शन इनपुट का. और उम्मीद है कि यह आपको देगा एक बेहतर समझ कि क्यों न्यूरल नेटवर्क्स किए जा सकते हैं इस्तेमाल लर्न करने के लिए जटिल नॉन-लिनीअर हायपॉथिसस. विचार करें निम्न समस्या पर जहाँ हमारे पास हैं फ़ीचर्ज़ x1 और x2 जो बाइनरी वैल्यूज़ हैं. तो, या तो 0 या 1. तो, x1 और x2 प्रत्येक ले सकता हैं दो सम्भव वैल्यूज़. इस उदाहरण में, मैंने बनाए हैं केवल दो पॉज़िटिव इग्ज़ाम्पल्ज़ और दो नेगेटिव इग्ज़ाम्पल. जो आप सोच सकते हैं इसे एक सरलीकृत वर्ज़न एक अधिक जटिल लर्निंग प्रॉब्लम का जहाँ हमारे पास हो सकते हैं कुछ पॉज़िटिव इग्ज़ाम्पल्ज़ ऊपर दाईं तरफ़ और नीचे बाईं तरफ़ और कुछ नेगेटिव इग्ज़ाम्पल्ज़ डिनोट किए गए वृत्तों से. और हम क्या करना चाहते हैं कि लर्न करें एक नॉन-लिनीअर विभाजन सीमा रेखा का जो चाहिए अलग करने के लिए पॉज़िटिव या नेगेटिव इग्ज़ाम्पल को. तो, कैसे एक न्यूरल नेटवर्क कर सकता है इसे और बजाय इस्तेमाल करने के इग्ज़ाम्पल और वेरीयबल इसे करने के लिए शायद आसान होगा जाँचना इग्ज़ाम्पल बाईं तरफ़. वस्तुत:, यह क्या है, है वास्तव में कम्प्यूट करना टाइप लेबल y की जो बराबर है x1 XOR x2. या फिर वास्तव में यह है x1 XNOR x2 फ़ंक्शन जहाँ XNOR है वैकल्पिक नोटेशन NOT x1 OR x2 के लिए. तो x1 XOR x2 वह है सत्य/ ट्रू केवल तभी जब एक x1 या x2 में से बराबर है 1. ऐसा होता है कि ये ख़ास इग्ज़ाम्पल्ज़ काम कर पाते हैं थोड़ा बेहतर यदि हम इस्तेमाल करें XNOR इग्ज़ाम्पल इसके स्थान पर. ये दोनों निश्चित रूप से एक ही हैं. इस का मतलब है NOT x1 OR x2 और इसलिए, हमारे पास होंगे पॉज़िटिव इग्ज़ाम्पल्ज़ या तो दोनो ट्रू या दोनो फ़ॉल्स और दोनो का है y बराबर 1, y बराबर 1. और हमारे पास होगा y बराबर 0 यदि केवल एक उनमें से है ट्रू और हम करेंगे पता कि क्या हम करवा सकते हैं एक न्यूरल नेटवर्क फ़िट इस तरह के ट्रेनिंग सेट में. बनाने के लिए एक नेटवर्क जो फ़िट करता हैं XNOR उदाहरण को हम करेंगे शुरुआत एक थोड़े सरल केस से और दिखाएँगे एक नेटवर्क जो फ़िट होता है AND फ़ंक्शन को. वास्तव में मान लो हमारे पास है इनपुट x1 और x2 जो हैं फिर से बाइनरी तो, यह है या तो 0 या 1 और मान लो हमारे लेबल्ज़ हैं y= x1 AND x2. यह है एक लॉजिकल एंड. तो क्या हम बना सकते हैं एक एक-यूनिट का नेटवर्क कम्प्यूट करने के लिए इस लॉजिकल एंड को? ऐसा करने के लिए, मैं वास्तव में बनाऊँगा बाइयस यूनिट भी तथा एक और यूनिट. अब मैं सिर्फ़ देता हूँ कुछ वैल्यूज़ वेट्स को या पेरमिटर्स को इस नेटवर्क के. मैं लिखूँगा पेरमिटर्स इस चित्र पर यह, -30 यहाँ. +20 और +20. और इसका क्या मतलब हैं कि सिर्फ़ मैं दे रहा हूँ एक वैल्यू -30 की उस वैल्यू को जो संलग्न है x0 के साथ यह +1 जा रहा है इस यूनिट में और एक पेरामिटर वैल्यू +20 जो गुणा करता है x1 को और एक वैल्यू +20 पेरामिटर के लिए जो गुणा करता है x2 से. तो, वस्तुतः, यह है समान उस हायपॉथिसस से h(x) = g(-30+20 x1 + 20 x2). तो, कभी-कभी यह सिर्फ़ सुविधाजनक होता है बनाना इन वेट्स को. चित्रित कर देना इन पेरमिटर्स को ऊपर यहाँ चित्र में है और निश्चय ही यह -30. यह है वास्तव में थीटा 1, 1 0 का. यह है थीटा 1, 1 1 का और वह है थीटा 1, 1 2 का लेकिन यह सिर्फ़ आसान है सोचना इसे जैसे जोड़ना इन पेरमिटर्स को एजेज़ के साथ नेटवर्क के. चलो देखते हैं क्या यह छोटा अकेला न्यूरल नेटवर्क कम्प्यूट करेगा. बस आपको याद दिलाने के लिए कि सिग्मोईड फ़ंक्शन g(z) ऐसा दिखता है. यह शुरू होता है 0 से और धीरे-धीरे बढ़ता है क्रॉस करता है 0.5 और फिर यह पहुँचता है क़रीब 1 के और आपको देने के लिए कुछ सीमा चिन्ह, यदि हॉरिज़ॉंटल ऐक्सिस वैल्यू z है 4.6 तब सिग्मोईड फ़ंक्शन है बराबर 0.99 के. यह है काफ़ी नज़दीक 1 के और इसी प्रकार से, यदि यह है -4.6 तब सिग्मोईड फ़ंक्शन वहाँ है 0.01 जो काफ़ी नज़दीक है 0 के. चलो देखते हैं चार संभव इनपुट वैल्यूज़ को x1 और x2 की और देखते हैं हायपॉथिसस क्या आउट्पुट करेगी उस केस में. यदि x1 और x2 दोनो हैं बराबर 0. यदि आप देखें इसे, यदि x1 x2 दोनो हैं 0 तब हायपॉथिसस है g ऑफ़ -30. तो, वह है काफ़ी दूर बाईं तरफ़ इस चित्र में तो यह होगा बहुत क़रीब 0 के. यदि x1 है 0 और x2 है 1, तब यह फ़ॉर्म्युला यहाँ बनता है g जो है सिग्मोईड फ़ंक्शन अप्लाई किया -10 को, और फिर वह है आप जानते हैं काफ़ी दूर दाईं तरफ़ इस प्लॉट में और इसलिए, वह है फिर से काफ़ी क़रीब 0 के. यह भी है g माइनस 10 का जो है यदि x1 है 1 और x2 है 0, यह -30 प्लस 20 जो है माइनस 10 और अंत में यदि x1 बराबर है 1, x2 बराबर है 1 तब आपके पास है g माइनस 30 प्लस 20 प्लस 20 का. तो, वह है g पॉज़िटिव 10 का जो है काफ़ी क़रीब 1 के. और यदि आप देखते हैं इस कॉलम में यह है वही लॉजिकल एंड फ़ंक्शन. तो यह है कम्प्यूट करना h ऑफ़ x है लगभग x1 AND x2. दूसरे शब्दों में यह आउट्पुट करता है एक तभी और केवल तभी यदि x2, यदि x1 और x2 दोनो हैं बराबर 1. तो लिख लेने से हमारा छोटा ट्रूथ टेबल इस तरह हम समझ पाए कि कौन सा है लॉजिकल फ़ंक्शन जो हमारा न्यूरल नेटवर्क कम्प्यूट करता है. यह नेटवर्क दिखाया हुआ यहाँ कम्प्यूट करता है OR फ़ंक्शन. सिर्फ़ आपको दिखाने के लिए कि मैंने वह कैसे किया. यदि आप लिखते हैं हायपॉथिसस जो कम्प्यूट कर रही है g -10 + 20 x1 + 20 x2 और आप भर ले ये वैल्यूज़. आपको मिलेगा कि g माइनस 10 का जो है लगभग 0. g 10 का जो है लगभग 1 और इसी प्रकार आगे ये है लगभग 1 और लगभग 1 और ये नम्बर्ज़ है अनिवार्यत: लॉजिकल OR फ़ंक्शन. तो, उम्मीद है इसके साथ अब अप समझ गए होंगे कि कैसे अकेला न्यूरॉन एक न्यूरल नेटवर्क में इस्तेमाल किया जा सकता है कम्प्यूट करने के लिए लॉजिकल फ़ंक्शंज़ जैसे AND और OR और इसी तरह के और. अगले वीडियो में हम जारी रखेंगे इन उदाहरणों को आगे बढ़ाना और कि हल करेंगे विस्तार से एक अधिक जटिल उदाहरण हम दिखा पाएँगे आपको कैसे एक न्यूरल नेटवर्क अब यूनिट्स की बहुत सी लेयर्स के साथ किया जा सकता है इस्तेमाल कम्प्यूट करने के लिए अधिक जटिल फ़ंक्शंज़ जैसे XOR या XNOR फ़ंक्शन.