このビデオとこの次のビデオで 具体的な詳細例を やっていく事で、 ニューラルネットワークがどのように 入力の複雑な非線形の 関数を計算出来るのかを見ていき、 これを通して何故 ニューラルネットワークが複雑で 非線形な仮説を学習するのに用いる事が出来るか、その心を伝えたいと思う。 以下のような問題を考えてみよう。 二値の値のフィーチャー、 x1とx2があるとしよう。 値は0か1のどちらか。 つまりx1とx2は 2つの可能な値のどちらかしかとれない。 この例では、2つの陽性の 手本と2つの陰性の手本 だけを描いたが、 これを、より複雑な 学習問題を 単純化した物と考える事が出来て、 その複雑な問題では、たくさんの 陽性の手本が 右上と左下にあり、 そしてたくさんの陰性の手本が 丸で示されていて、 やりたい事は非線型の 陽性と陰性の手本を分離する為の 決定境界を学習させたい、という物。 では、どのようにニューラルネットワークが これを行う事が出来るだろうか？ そこで右の例をそのまま使うのでは無く、 この左側の、より簡単に精査出来る例を 使っていく。 具体的には、これが実際になんなのかというと、 ターゲットのラベルyを計算する物で、 それはイコール x1 XOR x2だ。 またはこれは実際には x1 XNOR x2関数だ、 ここでXNORはNOT x1 OR x2の 別の書き方に過ぎない。 つまり、 x1 XOR x2は、 x1とx2のどちらかだけが 1と等しい時だけ 1となる。 具体例としては 実はXNORを使う方が ちょっとだけ 良い事が判明している。 これら二つはもちろん等しい。 つまり、NOTのx1 XOR x2。 つまり陽性の手本となるのは 両方ともtrueか、 両方ともfalseの 時だけだ。そしてその場合に限り y=1, y=1となる。 そしてどちらかだけがtrueの時は y=0となる。 そして我らは この種のトレーニングセットにフィットするような ニューラルネットワークが得られるのか？という事を見出したい。 xnorの例に適合する ネットワークを構築する為に、 もう少し簡単な例である AND関数に適合するネットワークを 見る事から始めて行こう。 具体的には、 ふたたび二値の入力である x1とx2の入力があるとしよう。つまりそれは0か1だ。 そしてターゲットのラベルyは イコール x1 AND x2としよう。 これは論理積のANDだ。 さて、一ユニットの ネットワークで、 このAND関数を計算する物が得られるだろうか？ それを行う為に、 バイアスユニットも 描いておく、この+1のユニットを。 いま、単に適当な値を このネットワークのウェイト、あるいはパラメータに 割り振ってみよう。 この図にパラメータを書きこんでいく。 -30をここに書き、 +20、そして+20。 つまり 値、-30を x0の係数に 割り振ったという事。 このx0は+1で、 このユニットになる。 そしてパラメータの値+20は、 x1に掛ける物で、 そして+20は x2に掛けるパラメータだ。 具体的には、これは 仮説hのxが イコール g(-30 + 20x1 + 20x2) だと言っている訳だ。 つまり、こういう風に ニューラルネットワークの図の上に これらのウェイト、パラメータを、 書きこむコンベンションもある、という事だ。 そしてもちろん、この-30は これは実際は シータ1の1, 0だ。 これはシータ1の1, 1。 そしてこれは シータ1の1, 2。 だがそうするよりも、 これらのパラメータがネットワークのエッジに関連づけられている、と 考える方が分かりやすい。 ではこの小さな一つのニューロンのネットワークが何を計算しているか、見ていこう。 思い出せるように、sigmoidのアクティベーション関数である gのzはこんな物だった。 それは0から始まり、 スムースに上昇していき、0.5で交わり、 そして1に漸近していく。 目印になりそうな点を置いておくと、 横軸の値、 zがイコール4.6だと、 sigmoid関数はイコール0.99となる。 これはとても1に近い。 そしてある種対称的な位置として -4.6の時は、 sigmoid関数はイコール0.01となる、 これはとても0に近い。 x1とx2の、4つの可能な 入力値の組み合わせを見ていこう、 そしてそれぞれの場合に仮説が 何を出力するかを見ていこう。 x1とx2がどちらも0なら、 これを見ると、 x1とx2がどちらも イコール0なら、その場合は 仮説はgの-30の点となる。 つまり、これはこの図の 遥か左の彼方だ。 これはとても0に近い。 もしx1=0で x2=1なら、この式は 評価するとgとなる、 つまりsigmoid関数が-10に 適用される。そしてこれもまた、 このプロット上では 左の遥か彼方なので、 これもまたとても0に近い。 これもまたgの-10となる。 つまりx1が イコール1で、 x2が0だと、これは-30+20で、-10。 そして最後に、 x1=1でx2=1の時は、 その時はgの-30+20+20で、 つまりそれは gの+10となる、 それはとても1に 近い値となる。 そしてこの列を 見てみると、 これは論理積のAND関数だ。 つまり、これはhのxは、 だいたい x1 AND x2を 計算している。 言い換えると、 それはx1とx2の両方が 1の時にだけ、 1を出力する。 そこで簡単な真理値表を 書いてみると、 我らのニューラルネットワークが計算してる 論理関数が何か、が 分かりやすい。 ここのネットワークは OR関数を計算している。 どう機能するか見てみよう。 仮説を書き下してみれば それが計算する事は gの -10+20 x1 + 20 x2 だ。 つまり、 もしこれらの値を埋めれば、 gの-10は だいたい0となり、 gの10は だいたい1、という感じになる。 これらはだいたい1、そしてだいたい1、 そしてこれらの数は 本質的には論理和のOR関数となっている。 以上で、 いまやニューラルネットワークの 一つのニューロンが、 論理関数である所の ANDとかORを計算するのにどう使えるのか、分かったんじゃないかなぁ。 次のビデオでは、引き続きこれらの例を構築していき、 さらにより複雑な例を見ていく。 そこではニューラルネットワークが どのように、ユニットの複数のレイヤーで、 もっと複雑な関数を 計算する事が出来るのかを見ていく、 xor関数とかxnor関数のような。