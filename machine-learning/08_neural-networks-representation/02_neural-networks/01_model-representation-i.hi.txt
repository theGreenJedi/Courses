इस वीडियो में मैं बताना चाहता हूँ आपको कि कैसे हम दर्शाते हैं न्यूरल नेटवर्क्स को. दूसरे शब्दों में, कैसे हम दर्शाते हैं हमारी हायपॉथिसस या कैसे हम दर्शाते हैं हमारे मॉडल को जब इस्तेमाल कर रहे हैं न्यूरल नेटवर्क्स. न्यूरल नेटवर्क विकसित किए गए थे अनुकरण करते हुए न्यूरॉन्स का या दिमाग में न्यूरॉन्स के नेटवर्क का. अत:, समझाने के लिए हायपॉथिसस रेप्रेज़ेंटेशन चलो शुरू करते हैं देखते हुए कि मस्तिष्क में एक न्यूरॉन कैसा दिखता है. आपका मस्तिष्क और मेरा इन न्यूरॉन्स से पूरा पैक है इस तरह के और न्यूरॉन्स कोशिकाएँ मस्तिष्क में. और दो बातों पर ध्यान आकर्षित करने के लिए पहली बात है कि न्यूरॉन की एक सेल बॉडी है, इस तरह, और इसके अलावा न्यूरॉन में बहुत सी इनपुट तारों की संख्या, और इन्हे डेंड्रायट्स कहा जाता है. आप सोचें उन्हें इनपुट तारों की तरह, वे लेती हैं इनपुट अन्य स्थानों से. और न्यूरॉन में एक आउट्पुट तार भी होता है जिसे कहते हैं ऐक्सॉन, और यह आउट्पुट तार है जो यह इस्तेमाल करता है भेजने के लिए संकेत दूसरे न्यूरॉन्स को, इसलिए अन्य न्यूरॉन्स को संदेश भेजने के लिए. तो, एक साधारण स्तर पर क्या एक न्यूरॉन है, है एक कम्प्यूटेशनल इकाई जो लेती है इन्पुट्स, इनपुट तारों के माध्यम से और कुछ गणना करता है और फिर यह भेजता है आउट्पुट्स ऐक्सॉन्स के माध्यम से अन्य नोड्स को या अन्य न्यूरांस को मस्तिष्क में. यहाँ न्यूरॉन्स के एक समूह का एक उदाहरण है. जिस तरह से न्यूरॉन्स एक दूसरे के साथ संवाद करते हैं वे हैं छोटी पल्सेज़ बिजली की, जिन्हें स्पाइक्स भी कहते हैं लेकिन उसका सिर्फ़ मतलब है बिजली की पल्सेज़. तो यहाँ एक न्यूरॉन है और यह क्या करता है, यदि यह एक संदेश भेजना चाहता है यह क्या करता है बिजली का एक छोटा पल्स भेजता है. ऐक्सॉन के माध्यम से किसी अन्य न्यूरान को और यहाँ, यह ऐक्सॉन वह है यह खुली तार, जुड़ती है दूसरे न्यूरॉन के डेन्ड्राइट से यहाँ पर, जो तब लेता है यह आने वाला संदेश, करता है कुछ गणना. और वे, निर्णय लेते है कि भेजना है यह संदेश इस ऐक्सॉन पर अन्य न्यूरॉन्स को, और यह प्रक्रिया है जिसके द्वारा मानव की सोच होती है. यह ये न्यूरॉन्स हैं गणना करते हुए और भेजते हुए संदेश अन्य न्यूरॉन्स, जो इन्पुट्स उन्हें मिली हैं उसके परिणाम स्वरूप. और, वैसे, ऐसे ही हमारी इंद्रियाँ और हमारी मांसपेशियों भी काम करते हैं. यदि आप अपनी मांसपेशियों को हिलाना चाहते हैं जिस ढंग से वह होता है कि आपका न्यूरॉन शायद भेजे यह बिजली आपकी मांसपेशियों को और वह सिकोड़े आपकी मांसपेशियों को और आपकी आँखों को, कुछ इंद्रियाँ जैसे आँखे अवश्य भेजती हैं एक संदेश आपके मस्तिष्क को तब यह क्या करती है कि यह भेजती है बिजली का पल्स एक न्यूरान को आपके मस्तिष्क में इस तरह. एक न्यूरल नेटवर्क में, या यूँ कहें, एक कृत्रिम न्यूरल नेटवर्क में जो हमने इम्प्लमेंट किया है कम्प्यूटर पर, हम इस्तेमाल करेंगे एक बहुत सरल मॉडल जो एक न्यूरॉन करता है हम मॉडल करेंगे एक न्यूरॉन को सिर्फ़ एक लॉजिस्टिक यूनिट की तरह. तो जब मैं बनाता हूँ एक पीला वृत्त उस तरह, आप सोचें उसे एक करते हुए एक भूमिका, जो है बॉडी एक नयूरोन की, और हम तब देते हैं न्यूरॉन को कुछ इन्पुट्स विभिन्न डेंड्रायट्स पर या इनपुट तारों पर. और न्यूरॉन करता है कुछ गणना. और आउट्पुट करता है कुछ वैल्यू इस आउट्पुट तार पर, या जैविक न्यूरॉन में, यह एक ऐक्सॉन है. और जब भी मैं एक चित्र खींचता हूँ इस तरह से, इसका मतलब क्या है कि यह दर्शाता है एक कॉम्प्यूटेशन h ऑफ़ x बराबर है एक बटा एक जमा e की पॉवर नेगेटिव थीटा ट्रान्स्पोज़ x. जहाँ हमेशा की तरह, x और थीटा हैं हमारे पेरामिटर वेक्टर्स, इस तरह. तो यह एक बहुत ही सरल, शायद एक बेहद सरलीकृत मॉडल है, कॉम्प्यूटेशन्स का जो न्यूरॉन करता है, जहां इसे मिलती हैं कुछ इन्पुट्स, x1, x2, x3 और यह आउट्पुट करता है कुछ वैल्यू जो कम्प्यूट की जाती है इस तरह. जब मैं बनाता हूँ एक न्यूरल नेटवर्क, अक्सर मैं सिर्फ़ बनाता हूँ केवल इनपुट नोड्स x1, x2, x3. कभी कभी जब ऐसा करना उपयोगी है, मैं बनाऊँगा एक अतिरिक्त नोड x0 के लिए. यह x0 अब उसे कभी कभी कहते हैं बाइयस यूनिट या बाइयस न्यूरान, लेकिन क्योंकि पहले से ही x0 है बराबर 1, कभी मैं यह बनाता हूँ, कभी नहीं निर्भर करते हुए जो भी ज़्यादा सुविधा जनक है नोटेशन के हिसाब से उस उदाहरण के लिए. अंत में, एक आख़िरी जानकारी टर्मिनॉलॉजी की जब हम बात करते हैं न्यूरल नेटवर्क्स की, कभी कभी हम कहेंगे कि यह है एक न्यूरॉन या एक कृत्रिम न्यूरॉन एक सिग्मोईड लॉजिस्टिक ऐक्टिवेशन फ़ंक्शन के साथ. तो यह ऐक्टिवेशन फ़ंक्शन न्यूरल नेटवर्क टर्मिनॉलॉजी में. यह है सिर्फ़ एक अन्य टर्म उस फ़ंक्शन के लिए उस नॉन-लिनीअर g(z)= 1 ओवर 1+e की पॉवर -z के लिए. और जबकि अभी तक मैं कहता रहा हूँ थीटा को पेरमिटर्स मॉडल के मैं ज्यादातर जारी रखूँगा प्रयोग करना उस टर्मिनॉलॉजी का. यहाँ, यह है एक कॉपी पेरमिटर्स की, लेकिन न्यूरल नेटवर्क्स में, न्यूरल नेटवर्क के साहित्य में कभी कभी आप सुनेगें लोगों को बात करते हुए वेटस की एक मॉडल के और वेटस का सिर्फ़ मतलब है वही जो मॉडल के पेरमिटर्स का है. लेकिन मैं ज्यादातर जारी रखूँगा प्रयोग करना पेरामिटर टर्मिनॉलॉजी का इन वीडीयोज़ में, लेकिन कभी कभी, आप सुन सकते हैं दूसरों को वेटस टर्मिनॉलॉजी का उपयोग करते हुए. तो, यह छोटा चित्र दर्शाता है एक अकेला न्यूरॉन. क्या है एक न्यूरल नेटवर्क, है सिर्फ़ एक समूह इन विभिन्न न्यूरॉन्स का जोड़े हुए एक साथ. पूरी तरह से, यहाँ हमारे पास हैं इनपुट यूनिट्स x1, x2, x3 और एक बार फिर, कभी कभी आप इस अतिरिक्त नोड x0 को बना सकते हैं और कभी-कभी नहीं, बस इसे यहाँ से बना दें. और यहाँ हमारे पास हैं तीन न्यूरॉन्स जिन्हें मैंने लिखा है b1, b2, b3. मैं बात करूँगा उन इंडिसीज़ की बाद में. और एक बार फिर हम जोड़ सकते हैं यदि हम चाहते हैं a0 और जोड़ दें मिश्रित बाइयस यूनिट वहाँ. जिसकी वैल्यू है हमेशा 1. और फिर अंत में हमारे पास है यह तीसरा नोड और अंतिम लेयर, और यहाँ है यह तीसरा नोड जो आउट्पुट करता है वैल्यू जो हायपॉथिसस h(x) कम्प्यूट करती है. थोड़ी और जानकारी देने के लिए टर्मिनॉलॉजी की, एक न्यूरल नेटवर्क में, पहली लेयर, इसे इनपुट लेयर भी कहते हैं क्योंकि यह है जहाँ हम इनपुट करते हैं हमारे फ़ीचर्ज़ x1, x2, x3. अंतिम लेयर को आउट्पुट लेयर भी कहते हैं क्योंकि उस लेयर में है एक न्यूरॉन, यह यहाँ, जो आउट्पुट करता हैं अंतिम वैल्यू हायपॉथिसस द्वारा कम्प्यूट की हुई. और फिर, बीच में लेयर 2, इसे हिडन लेयर कहा जाता है. टर्म हिडन लेयर एक बहुत बढ़िया टर्मिनॉलॉजी नहीं है, लेकिन विचार है कि, आप जानते हैं, आपने सूपर्वायज़ किया पहले, जहाँ आप देख सकते हैं इन्पुट्स, आपको दिखती है सही आउट्पुट्स, जहाँ इस हिडन लेयर की वैल्यूज़ आप नहीं देख पाते हैं ट्रेनिंग सेट अप में. यह नहीं है x, और यह नहीं है y, इसलिए हम इसे हिडन कहते हैं. और वे प्रयास करते हैं देखने का न्यूरल नेट्स को एक से अधिक लेयर के साथ लेकिन इस उदाहरण में, हमारे पास है एक इनपुट लेयर, लेयर 1, एक हिडन लेयर, लेयर 2, एक आउट्पुट लेयर, लेयर 3. लेकिन असल में, जो कुछ भी नहीं है एक इनपुट लेयर और नहीं है एक आउट्पुट लेयर कहलाता है एक हिडन लेयर. तो मैं काफ़ी स्पष्ट होना चाहता हूँ कि यह न्यूरल नेटवर्क क्या कर रहा है. चलो करते हैं कॉम्प्यूटेशनल सटेप्स जो है और दर्शाए गए हैं इस चित्र में. इन विशिष्ट कॉम्प्यूटेशन्स को समझाने के लिए जो दर्शाई गई हैं एक न्यूरल नेटवर्क से, यहाँ है थोड़ी और नोटेशन. मैं इस्तेमाल करूँगा एक सूपरस्क्रिप्ट j सबस्क्रिप्ट i का डिनोट करने के लिए ऐक्टिवेशन को न्यूरॉन i का या यूनिट i का लेयर जे में. तो पूरी तरह से यह देता है सूपरस्क्रिप्ट एक सब ग्रूप एक को, वह है ऐक्टिवेशन पहली यूनिट का लेयर दो में, हमारी हिडन लेयर में. और ऐक्टिवेशन से मेरा सिर्फ़ मतलब है वैल्यू जो कम्प्यूट कि जाती है और आउट्पुट की जाती है एक विशेष यूनिट से. इसके अलावा, न्यूरल नेटवर्क को पेरामिटर दिए गए हैं इन मेट्रिसीज़ से, थीटा सूपरस्क्रिप्ट j, जहाँ थीटा j होगा एक मेट्रिक्स वेट्स की जो नियंत्रित करता है फ़ंक्शन मैपिंग एक लेयर से, मान लो पहली लेयर से दूसरी लेयर तक, या दूसरी लेयर से तीसरी लेयर तक. तो यहाँ हैं कॉम्प्यूटेशन्स जो दर्शाई गई इस चित्र के द्वारा. इस पहली हिडन यूनिट की वैल्यू कम्प्यूट की जाती है निम्न तरह से, यहाँ है एक a 21 जो बराबर है सिग्मोईड फ़ंक्शन के, सिग्मोईड ऐक्टिवेशन फ़ंक्शन के, जिसे लॉजिस्टिक ऐक्टिवेशन फ़ंक्शन भी कहते हैं, अप्लाई किया हुआ इस तरह के लिनीअर संयोजन को इन इन्पुट्स के. और फिर इस दूसरी हिडन यूनिट का है यह ऐक्टिवेशन वैल्यू कम्प्यूट की गई है इसके सिग्मोईड की तरह. और इसी तरह इस तीसरी हिडन यूनिट कम्प्यूट की जाती है उस फ़ॉर्म्युला से. तो यहाँ हमारे पास है 3 थीटा 1 जो है एक मेट्रिक्स पेरमिटर्स की संचालित करते हुए हमारी मैपिंग हमारी तीन विभिन्न यूनिट्स से, हमारी हिडन यूनिट्स तक. थीटा 1 होगी एक 3. थीटा 1 होगी एक 3x4-डिमेन्शनल मेट्रिक्स. और अधिक सामान्य रूप में, यदि एक नेटवर्क में हैं sj यूनिट्स लेयर j में s(j + 1) यूनिट्स लेयर j + 1 में, तब मेट्रिक्स थीटा j जो संचालित करती हैं फ़ंक्शन मैपिंग लेयर j से j +1 तक. जो मुझे बताना पड़ेगा sj + 1, sj +1 से मैं सिर्फ़ स्पष्ट करूँगा यह नोटेशन सही करने के लिए. यह है सबस्क्रिप्ट j + 1 और वह है सबस्क्रिप्ट j, और फिर यह पूरी चीज़, प्लस 1, यह पूरी चीज़ (sj +1), ठीक है? तो वह है सबस्क्रिप्ट j + 1, तो वह है सबस्क्रिप्ट j + 1, sj +1 के साथ जहाँ यह प्लस नहीं है हिस्सा सबस्क्रिप्ट का. ठीक है, तो हमने बात की कि ये तीन हिडन यूनिट्स क्या करती हैं कम्प्यूट करने के लिए उनकी वैल्यूज़. अंत में, मैपिंग है इस अंतिम लेयर को और उसके बाद हमारे पास है एक और यूनिट जो कम्प्यूट करती हैं h ऑफ़ x और वह है बराबर लिखी जा सकती है a(3)1 जैसे भी और वह है बराबर इसके. और आप ध्यान दें कि मैंने लिखी है सूपरस्क्रिप्ट दो यहाँ, क्योंक थीटा सूपरस्क्रिप्ट दो का है मेट्रिक्स पेरमिटर्स की, या मेट्रिक्स वेट्स की जो नियंत्रित करती है फ़ंक्शन जो मैप करता है हिडन यूनिट्स से, जो है लेयर दो की यूनिट्स से लेयर तीन की एक यूनिट को, जो है आउट्पुट यूनिट. सारांश में, हमने क्या किया है कि दिखाया है कैसे एक चित्र इस तरह का यहाँ परिभाषित करता हैं एक कृत्रिम न्यूरल नेटवर्क को जो परिभाषित करता है एक फ़ंक्शन h मैप करता है x की इनपुट वैल्यूज़ उस स्पेस जो देती है y. और ये हायपॉथिसस पेरामिटर की गई हैं पेरमिटर्स से जो डिनोट किए गए है एक कैपिटल थीटा से ताकि जैसे हम बदलाव करते हैं थीटा में, हमें मिलती हैं विभिन्न हायपॉथिसस और हमें मिलते हैं विभिन्न हायपॉथिसस फ़ंक्शंज़. मैप करते हुए मान लो x से y तक. तो यह देता है हमें गणितीय परिभाषा कि कैसे दर्शाते हैं हायपॉथिसस न्यूरल नेटवर्क में. अगले कुछ वीडियो में, मैं आप को एक बेहतर अनुभव देने की कोशिश करूँगा क्या ये ह्यपोथेसीस रेप्रेज़ेंटेशन करती हैं, तथा करेंगे कुछ उदाहरण और बात करेंगे कैसे कम्प्यूट करना है उन्हें कुशलता से.