1
00:00:00,280 --> 00:00:01,330
पिछले विडीओ में, हमने दी

2
00:00:01,570 --> 00:00:03,540
एक गणितीय परिभाषा कि कैसे

3
00:00:03,700 --> 00:00:04,990
रेप्रेज़ेंट करते हैं या कैसे

4
00:00:05,090 --> 00:00:07,160
कम्प्यूट करते हैं हायपाथिसस न्यूरल नेटवर्क की.

5
00:00:08,420 --> 00:00:09,620
इस विडीओ में, मैं चाहता हूँ

6
00:00:09,730 --> 00:00:11,280
दिखाना आपको कि कैसे वास्तव में

7
00:00:11,450 --> 00:00:14,040
करते हैं कम्प्यूट कुशलता से, और

8
00:00:14,710 --> 00:00:16,050
बताना आपको कि कैसे लिखते हैं एक वेक्टराइज्ड इम्प्लमेंटेशन,

9
00:00:17,660 --> 00:00:18,930
और दूसरा, और अधिक महत्वपूर्ण बात, मैं चाहता हूँ

10
00:00:19,100 --> 00:00:21,110
देना शुरू करना आपको अनुभव

11
00:00:21,390 --> 00:00:22,590
कि क्यों ये न्यूरल नेटवर्क रेप्रेज़ेंटेशन्स

12
00:00:23,360 --> 00:00:24,640
एक अच्छा विचार हो सकता है और कैसे

13
00:00:25,010 --> 00:00:27,290
वे हमारी मदद कर सकते हैं लर्न करने में जटिल नॉन-लिनीअर हायपॉथिसस.

14
00:00:28,970 --> 00:00:29,880
लें ये न्यूरल नेटवर्क.

15
00:00:30,520 --> 00:00:31,720
इससे पहले हमने कहा था कि

16
00:00:32,010 --> 00:00:33,070
क्रम सटेप्स का जो हमें

17
00:00:33,170 --> 00:00:34,090
चाहिए करने के लिए कम्प्यूट

18
00:00:34,650 --> 00:00:35,850
एक हायपॉथिसस की आउट्पुट

19
00:00:36,320 --> 00:00:37,780
हैं ये इक्वेज़न दी हुईं

20
00:00:37,950 --> 00:00:38,770
बाईं तरफ़ जहाँ हम कम्प्यूट करते हैं

21
00:00:39,540 --> 00:00:41,330
ऐक्टिवेशन वैल्यूज़

22
00:00:41,450 --> 00:00:43,220
तीन हिडन नोड्ज़ की और फिर

23
00:00:43,420 --> 00:00:44,580
हम इस्तेमाल करते हैं उन्हें कम्प्यूट करने के लिए

24
00:00:44,650 --> 00:00:45,710
आउट्पुट हमारी हायपॉथिसस

25
00:00:46,680 --> 00:00:48,410
h ऑफ़ x की. अब मैं करूँगा

26
00:00:48,480 --> 00:00:50,200
परिभाषित कुछ अतिरिक्त टर्म्ज़.

27
00:00:50,570 --> 00:00:52,210
तो, यह टर्म यहाँ जिसे मैं

28
00:00:52,410 --> 00:00:54,090
रेखांकित कर रहा हूँ, मैं करूँगा

29
00:00:54,180 --> 00:00:55,560
परिभाषित उसे

30
00:00:56,230 --> 00:00:58,410
z सूपरस्क्रिप्ट 2 सबस्क्रिप्ट 1.

31
00:00:58,790 --> 00:00:59,830
ताकि हमारे पास है वह

32
00:01:00,650 --> 00:01:02,310
a(2)1, जो है यह

33
00:01:02,470 --> 00:01:03,930
टर्म है बराबर

34
00:01:04,170 --> 00:01:06,020
g ऑफ़ z की पॉवर 1.

35
00:01:06,130 --> 00:01:08,100
और

36
00:01:08,180 --> 00:01:09,750
वैसे तो, ये सूपरस्क्रिप्ट 2, आप

37
00:01:10,570 --> 00:01:11,580
जानते हैं, उसका क्या मतलब है कि

38
00:01:11,870 --> 00:01:12,960
z2 और यह a2

39
00:01:13,080 --> 00:01:14,140
भी, सूपरस्क्रिप्ट

40
00:01:14,840 --> 00:01:16,450
2 कोष्ठकों में का मतलब है कि ये

41
00:01:16,740 --> 00:01:18,330
हैं वैल्यूज़ संलग्न लेयर

42
00:01:18,570 --> 00:01:19,810
2 से, जो है हिडन

43
00:01:20,100 --> 00:01:21,390
लेयर न्यूरल नेटवर्क में.

44
00:01:22,820 --> 00:01:25,200
अब यह टर्म यहाँ

45
00:01:25,990 --> 00:01:27,640
मैं इसी प्रकार परिभाषित करूँगा

46
00:01:29,530 --> 00:01:30,140
z(2)2.

47
00:01:30,490 --> 00:01:31,860
और अंत में, यह आख़िरी

48
00:01:32,170 --> 00:01:33,100
टर्म जो मैं रेखांकित कर रहा हूँ,

49
00:01:34,160 --> 00:01:37,040
मैं उसे परिभाषित करता हूँ z(2)3 की तरह.

50
00:01:37,090 --> 00:01:38,710
तो इसी तरह से हमारे पास है a(2)3

51
00:01:38,850 --> 00:01:43,200
बराबर g ऑफ़

52
00:01:44,990 --> 00:01:45,360
z(2)3.

53
00:01:45,480 --> 00:01:46,760
तो ये z वैल्यूज़ हैं सिर्फ़

54
00:01:47,290 --> 00:01:48,940
एक लिनीअर संयोजन, एक वेटेड

55
00:01:49,360 --> 00:01:51,200
एक लिनीअर संयोजन,

56
00:01:51,490 --> 00:01:52,800
इनपुट वैल्यूज़ x0, x1,

57
00:01:53,060 --> 00:01:55,350
x2, x3 का, जो जाती हैं एक विशेष न्यूरॉन में.

58
00:01:57,090 --> 00:01:58,260
अब, अगर आप देखें

59
00:01:58,900 --> 00:02:00,470
नम्बर्ज़ के इस ब्लॉक को,

60
00:02:01,990 --> 00:02:03,310
आप शायद ध्यान करेंगे कि वह ब्लॉक

61
00:02:03,490 --> 00:02:05,880
नम्बर्ज़ का कॉरेस्पॉंड करता है समान रूप से

62
00:02:06,950 --> 00:02:08,330
मेट्रिक्स वेक्टर

63
00:02:08,800 --> 00:02:10,260
ऑपरेशन से, मेट्रिक्स वेक्टर गुणन से

64
00:02:11,070 --> 00:02:12,710
जो है x1 गुणा

65
00:02:12,790 --> 00:02:14,840
वेक्टर x. इस को इस्तेमाल करते हुए इस बात का

66
00:02:15,580 --> 00:02:18,730
हम कर पाएँगे वेक्टराइज़ इस कॉम्प्यूटेशन को

67
00:02:19,700 --> 00:02:20,280
न्यूरल नेटवर्क की.

68
00:02:21,470 --> 00:02:23,510
वास्तव में चलो करते हैं परिभाषित

69
00:02:23,680 --> 00:02:24,810
फ़ीचर वेक्टर x हमेशा की तरह

70
00:02:25,290 --> 00:02:27,020
वेक्टर x0, x1,

71
00:02:27,260 --> 00:02:28,550
x2, x3 का जहाँ x0 है

72
00:02:29,010 --> 00:02:30,280
हमेशा की तरह हमेशा बराबर है

73
00:02:30,610 --> 00:02:31,860
1 और वह परिभाषित करता है

74
00:02:32,390 --> 00:02:33,420
z2 को वेक्टर

75
00:02:34,360 --> 00:02:37,250
इन z वैल्यूज़ का, आप जानते हैं z(2)1, z(2)2, z(2)3 ka.

76
00:02:38,560 --> 00:02:40,210
और ध्यान दें कि, वहाँ z2, यह

77
00:02:40,440 --> 00:02:42,500
एक तीन-डिमेन्शनल वेक्टर.

78
00:02:43,910 --> 00:02:47,200
अब हम कर सकते हैं वेक्टराइज़ इस कॉम्प्यूटेशन को

79
00:02:48,270 --> 00:02:48,860
a(2)1, a(2)2, a(2)3 निम्न तरह से.

80
00:02:49,490 --> 00:02:50,690
हम लिख सकते हैं इसे सिर्फ़ दो सटेप्स में.

81
00:02:51,500 --> 00:02:53,400
हम कर सकते हैं कम्प्यूट z2 को थीटा

82
00:02:53,950 --> 00:02:55,490
1 गुणा x की तरह जो

83
00:02:55,790 --> 00:02:57,020
देगा हमें यह वेक्टर z2;

84
00:02:57,400 --> 00:02:59,360
और फिर a2 है

85
00:02:59,860 --> 00:03:02,180
g z2 का और सिर्फ़

86
00:03:02,440 --> 00:03:03,860
स्पष्ट करने के लिए z2 यहाँ, यह

87
00:03:04,200 --> 00:03:05,880
एक तीन-डिमेन्शनल वेक्टर और

88
00:03:06,060 --> 00:03:08,150
a2 भी है एक तीन-डिमेन्शनल

89
00:03:08,810 --> 00:03:10,410
वेक्टर और इसलिए यह

90
00:03:10,690 --> 00:03:12,680
ऐक्टिवेशन g. यह अप्लाई करता है

91
00:03:12,950 --> 00:03:15,290
सिग्मोईड फ़ंक्शन एलिमेंट-वाइज़ प्रत्येक

92
00:03:15,550 --> 00:03:18,290
z2 के एलिमेंट्स को. और

93
00:03:18,380 --> 00:03:19,270
वैसे तो, बनाने के हमारी नोटेशन

94
00:03:19,950 --> 00:03:21,260
थोड़ी और समान उससे

95
00:03:21,440 --> 00:03:23,330
जो हम बाद में करेंगे, इस

96
00:03:23,590 --> 00:03:24,600
इनपुट लेयर में हमारे पास हैं

97
00:03:24,670 --> 00:03:25,840
इन्पुट्स x, लेकिन हम

98
00:03:25,960 --> 00:03:26,950
सोच सकते हैं उसे

99
00:03:27,300 --> 00:03:29,270
ऐक्टिवेशन पहली लेयर में की तरह भी.

100
00:03:29,680 --> 00:03:30,430
तो, यदि मैं परिभाषित करता हूँ a1 को

101
00:03:30,470 --> 00:03:32,510
बराबर x के. तो,

102
00:03:32,660 --> 00:03:34,270
a1 है वेक्टर, मैं

103
00:03:34,500 --> 00:03:35,520
अब ले सकता हूँ यह x यहाँ

104
00:03:36,230 --> 00:03:38,850
और इसके स्थान पर रख सकता हूँ z2 बराबर थीटा1

105
00:03:39,570 --> 00:03:40,680
गुणा a1 सिर्फ़ परिभाषित करके

106
00:03:41,410 --> 00:03:43,350
a1 को ऐक्टिवेशन मेरी इनपुट लेयर में.

107
00:03:44,990 --> 00:03:46,000
अब, मैंने जो लिखा है

108
00:03:46,280 --> 00:03:47,500
अभी तक मुझे

109
00:03:47,900 --> 00:03:49,940
मिली हैं वैल्यूज़ a1,

110
00:03:50,820 --> 00:03:52,690
a2, a3 और वास्तव मैं

111
00:03:52,780 --> 00:03:53,980
मुझे लगाना चाहिए

112
00:03:54,290 --> 00:03:55,600
सूपरस्क्रिप्ट वहाँ भी.

113
00:03:56,430 --> 00:03:57,530
लेकिन मुझे चाहिए एक और

114
00:03:57,940 --> 00:03:59,810
वैल्यू, जो है कि मुझे चाहिए यह a(0)2 भी.

115
00:04:00,050 --> 00:04:02,050
और वह कॉरेस्पॉंड करता है

116
00:04:02,250 --> 00:04:04,350
एक बाइयस यूनिट को

117
00:04:04,550 --> 00:04:06,420
हिडन लेयर में जो जाता है आउट्पुट में वहाँ.

118
00:04:06,990 --> 00:04:07,780
ज़ाहिर है, था एक

119
00:04:07,810 --> 00:04:08,850
बाइयस यूनिट यहाँ भी जो,

120
00:04:09,000 --> 00:04:10,060
आप जानते हैं, मैंने केवल बनाया नहीं था

121
00:04:10,270 --> 00:04:11,820
यहाँ पर लेकिन

122
00:04:11,970 --> 00:04:13,100
ध्यान रखनाए के लिए इस अतिरिक्त बाइयस यूनिट का,

123
00:04:13,870 --> 00:04:15,650
हम क्या करंगे कि जोड़ेंगे

124
00:04:16,320 --> 00:04:18,720
एक अतिरिक्त a0 सूपरस्क्रिप्ट 2,

125
00:04:18,890 --> 00:04:20,870
जो है बराबर एक, और बाद में

126
00:04:21,010 --> 00:04:21,990
इस सटेप के हमारे पास अब है

127
00:04:22,290 --> 00:04:23,860
वह a2 होगा

128
00:04:24,010 --> 00:04:25,390
एक चार डिमेन्शनल / आयामों वाला फ़ीचर

129
00:04:25,690 --> 00:04:26,820
वेक्टर क्योंकि हमने अभी जोड़ा है

130
00:04:27,300 --> 00:04:28,490
यह अतिरिक्त, आप जानते हैं,

131
00:04:28,620 --> 00:04:30,260
a0 जो है बराबर

132
00:04:30,500 --> 00:04:31,700
1 कॉरेस्पॉंड करता है बाइयस यूनिट को

133
00:04:32,080 --> 00:04:33,550
हिडन लेयर में. और अंत में,

134
00:04:35,080 --> 00:04:37,620
कम्प्यूट करने के लिए वास्तविक

135
00:04:38,070 --> 00:04:40,100
वैल्यू आउट्पुट हमारी हायपॉथिसस की, हमें

136
00:04:40,250 --> 00:04:41,190
तब बस ज़रूरत है कम्प्यूट करने की

137
00:04:42,470 --> 00:04:44,980
z3. तो z3 है

138
00:04:45,350 --> 00:04:47,940
बराबर इस टर्म के यहाँ जो मैं रेखांकित कर रहा हूँ,

139
00:04:48,800 --> 00:04:51,450
यह टर्म यहाँ है z3.

140
00:04:53,980 --> 00:04:55,160
और z3 को कहा गया है

141
00:04:55,500 --> 00:04:57,120
2 गुणा a2 और अंत में

142
00:04:57,810 --> 00:04:59,560
मेरी हायपॉथिसस आउट्पुट h ऑफ़ x जो

143
00:04:59,750 --> 00:05:01,210
है a3 मतलब

144
00:05:01,360 --> 00:05:03,910
ऐक्टिवेशन मेरी

145
00:05:04,750 --> 00:05:06,040
एक और सिर्फ़ एक यूनिट का

146
00:05:06,290 --> 00:05:09,500
आउट्पुट लेयर में. तो, वह है केवल एक रियल नम्बर. आप लिख सकते हैं इसे a3 की तरह

147
00:05:10,050 --> 00:05:12,390
यह a(3)1 और वह है g z3 का.

148
00:05:13,240 --> 00:05:15,020
यह प्रक्रिया कम्प्यूट करने की h ऑफ़ x

149
00:05:15,940 --> 00:05:18,110
फ़ॉर्वर्ड प्रॉपगेशन भी कहलाती है

150
00:05:19,130 --> 00:05:20,440
और इसे वह कहते हैं क्योंकि हम

151
00:05:20,550 --> 00:05:21,310
शुरू करते हैं ऐक्टिवेशन्स से

152
00:05:22,010 --> 00:05:24,400
इनपुट यूनिट्स के और फिर

153
00:05:24,940 --> 00:05:26,770
एक तरह से फ़ॉर्वर्ड प्रापगेट करते हैं उसे

154
00:05:26,860 --> 00:05:29,390
हिडन लेयर तक और कम्प्यूट करते हैं ऐक्टिवेशन्स

155
00:05:29,580 --> 00:05:30,400
हिडन लेयर के और फिर हम

156
00:05:30,540 --> 00:05:32,040
एक तरह से फ़ॉर्वर्ड प्रापगेट करते हैं उसे

157
00:05:32,760 --> 00:05:36,270
और कम्प्यूट करते हैं ऐक्टिवेशन्स

158
00:05:37,480 --> 00:05:39,170
आउट्पुट लेयर के, लेकिन यह प्रक्रिया कम्प्यूट करने की ऐक्टिवेशन्स इनपुट से फिर

159
00:05:39,290 --> 00:05:40,400
हिडन फिर आउट्पुट लेयर,

160
00:05:40,940 --> 00:05:42,030
और वह भी फ़ॉर्वर्ड प्रॉपगेशन भी कहलाती है

161
00:05:43,320 --> 00:05:44,150
और हमने जो अभी किया है

162
00:05:44,310 --> 00:05:45,370
हमने अभी बनाया है एक वेक्टर

163
00:05:45,740 --> 00:05:47,140
वाइज़ इम्प्लमेंटेशन इस

164
00:05:47,280 --> 00:05:48,890
प्रक्रिया का. तो, यदि आप

165
00:05:48,970 --> 00:05:50,260
इम्प्लमेंट करते हैं इसे इस्तेमाल करके इन इक्वेज़ंज़ को

166
00:05:50,800 --> 00:05:51,740
जो हमारे पास हैं दाईं तरफ़, ये

167
00:05:51,850 --> 00:05:53,280
देंगी आपको एक कुशल ढंग

168
00:05:53,460 --> 00:05:54,980
या दोनो एक कुशल ढंग

169
00:05:55,120 --> 00:05:56,130
कम्प्यूट करने का h ऑफ़ x.

170
00:05:58,250 --> 00:05:59,860
यह फ़ॉर्वर्ड प्रॉपगेशन दृष्टि कोण

171
00:06:00,860 --> 00:06:02,270
सहायता करता है हमें समझने में कि क्या

172
00:06:02,550 --> 00:06:03,640
न्यूरल नेटवर्क कर रहा हो सकता हैं

173
00:06:04,110 --> 00:06:05,290
और क्यों वे हमारी मदद कर सकते हैं

174
00:06:05,510 --> 00:06:07,170
लर्न करने में दिलचस्प नॉन-लिनीअर हायपॉथिसस.

175
00:06:08,670 --> 00:06:09,760
लें ये निम्न न्यूरल नेटवर्क

176
00:06:10,500 --> 00:06:11,820
और मान लो ढक देता हूँ

177
00:06:12,040 --> 00:06:13,810
बाईं तरफ़ का हिस्सा इस चित्र का अभी के लिए.

178
00:06:14,650 --> 00:06:16,170
यदि आप देखते हैं क्या बचा है इस चित्र में.

179
00:06:17,030 --> 00:06:18,020
और यह दिखता है बहुत कुछ जैसे

180
00:06:18,260 --> 00:06:19,520
लॉजिस्टिक रिग्रेशन जहाँ क्या

181
00:06:19,660 --> 00:06:20,570
कर रहे हैं हम कि हम इस्तेमाल कर रहे हैं

182
00:06:20,990 --> 00:06:22,000
वह नोड, वह है केवल

183
00:06:22,130 --> 00:06:23,770
लॉजिस्टिक रिग्रेशन यूनिट और हम कर रहे हैं

184
00:06:24,120 --> 00:06:26,060
इस्तेमाल उसका करने के लिए एक

185
00:06:26,380 --> 00:06:28,290
प्रिडिक्शन h ऑफ़ x. और वस्तुत:,

186
00:06:28,440 --> 00:06:30,340
हायपॉथिसस क्या आउट्पुट कर रही है

187
00:06:30,710 --> 00:06:31,830
कि h ऑफ़ x होगा

188
00:06:31,890 --> 00:06:33,760
बराबर g को जो

189
00:06:33,980 --> 00:06:38,110
है मेरा सिग्मोईड ऐक्टिवेशन फ़ंक्शन गुणा थीटा 0

190
00:06:38,560 --> 00:06:40,450
गुणा a0 है बराबर

191
00:06:41,270 --> 00:06:43,380
1 जमा थीटा 1

192
00:06:45,220 --> 00:06:49,080
जमा थीटा 2

193
00:06:49,260 --> 00:06:52,090
गुणा a2 जमा थीटा

194
00:06:52,830 --> 00:06:55,180
3 गुणा a3 जहाँ

195
00:06:55,370 --> 00:06:56,910
वैल्यूज़ a1, a2, a3

196
00:06:57,050 --> 00:06:59,860
हैं वे जो दी गई हैं इन तीन दी हुई यूनिट्स से.

197
00:07:01,060 --> 00:07:02,790
अब, वास्तव में समान करने के लिए

198
00:07:03,490 --> 00:07:05,000
हमारी पहले की नोटेशन से. असल में हमें

199
00:07:05,170 --> 00:07:06,360
चाहिए, आप जानते हैं, भरनी

200
00:07:06,470 --> 00:07:10,700
ये सूपरस्क्रिप्ट्स 2 यहाँ हर जगह

201
00:07:12,260 --> 00:07:13,920
और मेरे पास हैं ये

202
00:07:14,160 --> 00:07:16,800
इंडिसीज़ 1 भी वहाँ क्योंकि मेरे

203
00:07:16,930 --> 00:07:20,610
पास है केवल एक आउट्पुट यूनिट, लेकिन यदि आप ध्यान करें नीले हिस्सों पर नोटेशन के.

204
00:07:20,930 --> 00:07:21,900
यह है, आप जानते हैं, यह दिखता है

205
00:07:22,150 --> 00:07:23,680
काफ़ी कुछ जैसे स्टैंडर्ड लॉजिस्टिक

206
00:07:23,870 --> 00:07:25,530
रेग्रेशन मॉडल है, सिवाय कि

207
00:07:25,600 --> 00:07:28,060
अब मेरे पास है एक कैपिटल थीटा बजाय लोअर केस थीटा के.

208
00:07:29,170 --> 00:07:30,690
और यह क्या

209
00:07:30,850 --> 00:07:32,520
कर रहा है सिर्फ़ लॉजिस्टिक रिग्रेशन.

210
00:07:33,660 --> 00:07:35,240
लेकिन जहाँ फ़ीचर्ज़ फ़ीड किए जाते हैं

211
00:07:35,590 --> 00:07:37,250
लॉजिस्टिक रिग्रेशन में हैं ये

212
00:07:38,200 --> 00:07:40,170
वैल्यूज़ कम्प्यूट की गई हिडन लेयर द्वारा.

213
00:07:41,340 --> 00:07:42,690
सिर्फ़ फिर से बताने के लिएउसे फिर से, क्या

214
00:07:42,910 --> 00:07:44,420
न्यूरल नेटवर्क कर रहा है कि

215
00:07:45,130 --> 00:07:47,050
लॉजिस्टिक रिग्रेशन के समान, सिवाय

216
00:07:47,440 --> 00:07:48,900
कि बजाय इस्तेमाल करने के

217
00:07:49,110 --> 00:07:50,770
प्रारम्भिक फ़ीचर्ज़ x1, x2, x3,

218
00:07:52,400 --> 00:07:54,260
यह इस्तेमाल कर रहा है नए फ़ीचर्ज़ a1, a2, a3.

219
00:07:54,440 --> 00:07:56,810
फिर से, हम डालेंगे सूपरस्क्रिप्ट्स

220
00:07:58,130 --> 00:08:00,380
वहाँ, आप जानते हैं, नोटेशन के हिसाब से.

221
00:08:02,820 --> 00:08:04,610
और अच्छी बात इस बारे में,

222
00:08:05,040 --> 00:08:06,220
है कि फ़ीचर्ज़ a1, a2,

223
00:08:06,720 --> 00:08:08,310
a3, वे ख़ुद भी लर्न किए हुए हैं

224
00:08:08,760 --> 00:08:09,930
इनपुट के फ़ंक्शन से.

225
00:08:10,960 --> 00:08:12,640
वास्तव में, फ़ंक्शन मैपिंग

226
00:08:13,320 --> 00:08:14,540
लेयर 1 से लेयर 2 तक,

227
00:08:14,810 --> 00:08:16,390
वह निर्धारित की जाती है किसी

228
00:08:16,750 --> 00:08:18,550
सेट से पेरमिटर्स थीटा 1 के.

229
00:08:19,380 --> 00:08:20,210
तो, यह है जैसे कि

230
00:08:20,270 --> 00:08:22,030
न्यूरल नेटवर्क, बजाय होने के

231
00:08:22,240 --> 00:08:24,050
विवश फ़ीड करने के लिए

232
00:08:24,120 --> 00:08:25,760
फ़ीचर्ज़ x1, x2, x3 लॉजिस्टिक रेग्रेशन को.

233
00:08:26,210 --> 00:08:27,440
यह कर पाता है

234
00:08:27,720 --> 00:08:29,320
लर्न इसके अपने फ़ीचर्ज़, a1,

235
00:08:29,810 --> 00:08:32,010
a2, a3 फ़ीड करने के लिए

236
00:08:32,130 --> 00:08:33,950
लॉजिस्टिक रिग्रेशन में और जैसे कि

237
00:08:34,650 --> 00:08:36,270
आप कल्पना कर सकते हैं निर्भर करते हुए

238
00:08:36,360 --> 00:08:37,690
क्या पेरमिटर्स यह लेता है

239
00:08:37,900 --> 00:08:39,880
थीटा 1 के लिए. आप लर्न कर सकते हैं कुछ बहुत दिलचस्प

240
00:08:40,390 --> 00:08:42,460
जटिल फ़ीचर्ज़ और इसलिए

241
00:08:43,780 --> 00:08:44,830
आपको मिल सकती है एक

242
00:08:45,050 --> 00:08:46,650
बेहतर हायपॉथिसस तुलना में यदि

243
00:08:46,840 --> 00:08:47,870
आप मजबूर होते इस्तेमाल करने के लिए

244
00:08:48,020 --> 00:08:50,520
मूल फ़ीचर्ज़ x1, x2 या x3 या यदि

245
00:08:50,640 --> 00:08:52,530
आप मजबूर होते चुनने के लिए

246
00:08:52,620 --> 00:08:53,730
पालिनोमीयल टर्म्ज़, आप जानते हैं,

247
00:08:53,920 --> 00:08:55,550
x1, x2, x3 और इसी प्रकार आगे.

248
00:08:55,790 --> 00:08:57,250
लेकिन इसके बजाय, इस अल्गोरिद्म में है

249
00:08:57,530 --> 00:08:59,130
सुविधा प्रयास करने की

250
00:08:59,420 --> 00:09:01,990
लर्न करने के लिए जो भी फ़ीचर्ज़ एक बार में, इस्तेमाल करके

251
00:09:02,680 --> 00:09:03,990
ये a1, a2, a3

252
00:09:04,110 --> 00:09:05,190
फ़ीड करने के लिए इस

253
00:09:05,510 --> 00:09:07,830
अंतिम यूनिट में जो है अनिवार्यत:

254
00:09:09,240 --> 00:09:11,920
लॉजिस्टिक रिग्रेशन यहाँ. मुझे समझ में आया

255
00:09:12,550 --> 00:09:13,970
कि यह उदाहरण यहाँ वर्णित किया है

256
00:09:14,060 --> 00:09:15,500
एक कुछ ऊँचे स्तर पर और इसलिए

257
00:09:15,750 --> 00:09:16,520
मुझे निश्चित नहीं है यदि यह अनुभव

258
00:09:17,440 --> 00:09:18,870
न्यूरल नेटवर्क का, आप जानते हैं, होना

259
00:09:19,720 --> 00:09:21,420
अधिक जटिल फ़ीचर्ज़ का कुछ

260
00:09:21,630 --> 00:09:23,120
अभी समझ आया होगा, लेकिन यदि

261
00:09:23,210 --> 00:09:24,440
अभी नहीं आया है अगले

262
00:09:24,810 --> 00:09:25,860
दो वीडियो में मैं करूँगा

263
00:09:25,970 --> 00:09:27,300
विस्तार से एक विशेष उदाहरण

264
00:09:28,250 --> 00:09:29,590
कि कैसे एक न्यूरल नेटवर्क हो सकता है

265
00:09:29,830 --> 00:09:30,860
इस्तेमाल इस हिडन लेयर का वहाँ कम्प्यूट करने के लिए

266
00:09:31,250 --> 00:09:32,880
अधिक जटिल फ़ीचर्ज़ फ़ीड करने के लिए

267
00:09:33,130 --> 00:09:34,520
इस अंतिम आउट्पुट लेयर में

268
00:09:35,060 --> 00:09:37,100
और कैसे वह लर्न कर सकता है अधिक जटिल हायपॉथिसस.

269
00:09:37,920 --> 00:09:39,120
तो, यदि जो मैं

270
00:09:39,180 --> 00:09:40,090
कह रहा हूँ यहाँ नहीं कुछ

271
00:09:40,230 --> 00:09:41,650
समझ आ रहा, बने रहें मेरे साथ

272
00:09:41,810 --> 00:09:42,960
अगले दो वीडियो तक और

273
00:09:43,190 --> 00:09:44,370
उम्मीद है वहाँ कर लेने से

274
00:09:44,580 --> 00:09:46,690
वे उदाहरण यह विवरण

275
00:09:47,030 --> 00:09:48,640
थोड़ा और समझ आएगा.

276
00:09:49,020 --> 00:09:49,740
लेकिन सिर्फ़ इशारा करने के लिए, आपको

277
00:09:49,820 --> 00:09:51,120
मिल सकते हैं न्यूरल नेटवर्क्स

278
00:09:51,470 --> 00:09:52,990
दूसरे तरह के चित्रों से भी,

279
00:09:53,080 --> 00:09:54,270
और जिस तरह से

280
00:09:54,450 --> 00:09:58,000
न्यूरल नेटवर्क जोड़े जाते हैं, उसे कहते हैं आर्किटेक्चर.

281
00:09:58,390 --> 00:10:00,150
तो टर्म आर्किटेक्चर बताती है

282
00:10:00,490 --> 00:10:02,380
कि कैसे विभिन्न न्यूरांस एक-दूसरे से जोड़े जाते हैं.

283
00:10:03,220 --> 00:10:04,180
यह है एक उदाहरण

284
00:10:04,840 --> 00:10:06,300
एक अलग न्यूरल नेटवर्क आर्किटेक्चर का

285
00:10:07,480 --> 00:10:08,750
और एक बार फिर आपको

286
00:10:09,260 --> 00:10:10,770
शायद मिल सकता है यह अनुभव

287
00:10:10,940 --> 00:10:12,180
कि कैसे दूसरी लेयर,

288
00:10:12,900 --> 00:10:14,120
यहाँ हमारे पास है तीन हिडन यूनिट्स

289
00:10:14,910 --> 00:10:16,200
जो कम्प्यूट कर रही हैं कुछ जटिल

290
00:10:16,660 --> 00:10:17,900
फ़ंक्शन शायद

291
00:10:17,990 --> 00:10:19,530
इनपुट लेयर का और फ़िर

292
00:10:19,730 --> 00:10:20,750
तीसरी लेयर ले सकती है

293
00:10:20,840 --> 00:10:22,260
दूसरी लेयर के फ़ीचर्ज़ और कम्प्यूट कर सकती है

294
00:10:22,550 --> 00:10:24,070
और अधिक जटिल फ़ीचर्ज़ लेयर तीन में

295
00:10:24,980 --> 00:10:25,880
ताकि जब तक हम पहुँचते हैं

296
00:10:25,960 --> 00:10:27,160
आउट्पुट लेयर तक, लेयर चार,

297
00:10:27,900 --> 00:10:29,130
आप के पास हैं और भी अधिक

298
00:10:29,370 --> 00:10:30,690
जटिल फ़ीचर्ज़ जो

299
00:10:30,860 --> 00:10:32,040
कम्प्यूट कर सकते हैं

300
00:10:32,280 --> 00:10:34,710
लेयर तीन में और पा सकते हैं बहुत दिलचस्प नॉन-लिनीअर हायपॉथिसस.

301
00:10:36,730 --> 00:10:37,580
वैसे तो, एक नेटवर्क में

302
00:10:37,810 --> 00:10:38,980
इस तरह के, लेयर एक, इसे

303
00:10:39,130 --> 00:10:40,670
कहते हैं इनपुट लेयर, लेयर चार

304
00:10:41,360 --> 00:10:43,170
अभी भी है आउट्पुट लेयर, और

305
00:10:43,340 --> 00:10:45,040
इस नेटवर्क में हैं दो हिडन लेयर्स.

306
00:10:46,000 --> 00:10:47,440
तो वह सब कुछ जो नहीं है एक

307
00:10:48,000 --> 00:10:49,020
इनपुट लेयर या एक आउट्पुट

308
00:10:49,340 --> 00:10:50,590
लेयर कहलाता है एक हिडन लेयर.

309
00:10:53,390 --> 00:10:54,470
तो, उम्मीद है इस वीडियो से

310
00:10:54,760 --> 00:10:55,840
आपको समझ आया होगा

311
00:10:56,140 --> 00:10:58,360
कि कैसे फ़ीड फ़ॉर्वर्ड प्रॉपगेशन स्टेप

312
00:10:58,830 --> 00:11:00,230
एक न्यूरल नेटवर्क में काम करता है आप

313
00:11:00,390 --> 00:11:01,670
शुरू करते हैं ऐक्टिवेशन्स से

314
00:11:01,720 --> 00:11:03,150
इन्पुट लेयर के और फ़ॉर्वर्ड

315
00:11:03,450 --> 00:11:04,480
प्रापगेट करते हैं उसे

316
00:11:04,570 --> 00:11:05,560
पहली हिडन लेयर को, और फिर दूसरी

317
00:11:06,070 --> 00:11:08,200
हिडन लेयर को, और फिर अंत में आउट्पुट लेयर को.

318
00:11:08,990 --> 00:11:10,250
और आपने देखा कैसे

319
00:11:10,560 --> 00:11:12,010
हम कर सकते हैं वेक्टराइज़ उस कॉम्प्यूटेशन को.

320
00:11:13,660 --> 00:11:14,830
अगले में, मैंने महसूस किया

321
00:11:15,240 --> 00:11:16,680
कि कुछ अनुभव इस

322
00:11:16,850 --> 00:11:19,220
वीडियो में कैसे, आप जानते हैं, अन्य कुछ

323
00:11:19,550 --> 00:11:22,570
लेयर्स कम्प्यूट कर रही हैं जटिल फ़ीचर्ज़ पिछली लेयर्स के.

324
00:11:22,910 --> 00:11:23,540
मुझे लगता है कि कुछ हिस्सा उस अनुभव का

325
00:11:24,190 --> 00:11:26,660
शायद अभी भी थोड़ा काल्पनिक और ऊँचे स्तर का हो सकता है.

326
00:11:27,450 --> 00:11:28,240
और इसलिए मैं क्या चाहता हूँ

327
00:11:28,350 --> 00:11:29,460
करना दो वीडियो में

328
00:11:30,210 --> 00:11:31,540
कि हल करूँ विस्तार से एक उदाहरण

329
00:11:32,510 --> 00:11:33,810
कि कैसे एक न्यूरल नेटवर्क हो सकता है

330
00:11:33,960 --> 00:11:35,740
इस्तेमाल कम्प्यूट करने के लिए नॉन-लिनीअर

331
00:11:36,710 --> 00:11:38,030
फ़ंक्शन इनपुट का और

332
00:11:38,330 --> 00:11:39,450
मैं आशा करता हूँ कि वह देगा आपको एक

333
00:11:39,540 --> 00:11:40,860
बेहतर समझ इस तरह के

334
00:11:41,010 --> 00:11:44,630
जटिल नॉनलिनीअर हायपाथिसस की जो हमें मिल सकती है न्यूरल नेटवर्क से.