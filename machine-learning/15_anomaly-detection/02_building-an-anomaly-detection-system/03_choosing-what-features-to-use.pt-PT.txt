Até agora, você já deve ter visto o algoritmo de detecção de anomalias e falamos também de como avaliar um algortimo de detecção de anomalias. E o resultado é que quando se aplica a detecção de anomalias uma das coisas que tem um efeito enorme em quão bem ela funciona são os atributos que se utiliza, e quais atributos se escolhe, para fornecer ao algoritmo. Assim, nesse vídeo, gostaria de dizer algumas palavras, dar algumas sugestões e diretrizes sobre como seguir no desenho ou seleção dos atributos fornecidos a um algoritmo de detecção de anomalias. No nosso algoritmo de deteção de anomalias, uma das coisas que fizemos foi modelar os atributos utilizando este tipo de distribuição gaussiana. Com xi para mu i, sigma ao quadrado i. Então, uma coisa que costumo fazer é traçar os dados ou o histograma dos dados para certificar-me de que os dados pareçam vagamente gaussianos antes de fornecê-los a meu algoritmo de detecção de anomalias. E, normalmente funcionará bem, mesmo se seus dados não sejam gaussianos, mas isso é um bom controle sanitário para se executar. Aliás, no caso de seus dados não parecerem gaussianos, os algoritmos normalmente funcionarão bem. Mas, se eu concretamente traçar no gráfico dados como esses e se parecer um histograma como esse e a forma de criar um histograma é utilizar o HIST ou o o comando HIST em Octave, mas se parece com isso, vagamente Gaussiano, portanto se minhas variáveis parecem dessa forma, Eu estaria tranquilo em utilizar em meu algoritmo. Mas se eu fosse fazer um histograma dos meus dados, e fosse para parecer dessa forma, bem, isso não parece de forma alguma uma curva de sino bem formada, trata-se de uma distribuição muito assimétrica, com um pico muito para um dos lados. Se é assim que meus dados parecem, o que eu normalmente faria é brincar com diferentes transformações para fazê-los parecer mais Gaussianos. E o algoritmo vai funcionar, mesmo se você não as fizer. Mas se você usar essas transformações para tornar seus dados mais gaussianos, deve funcionar um pouco melhor. Assim, dado o conjunto de dados que se parece com isso, o que eu devo fazer é tomar uma transformação logarítmica dos dados e se eu fizer isso e plotar novamente o histograma, o que vou obter com este exemplo particular, é um histograma que se parece com isso. E isso parece muito mais Gaussiano, certo? Isso parece muito mais com a clássica curva em forma de sino, que podemos ajustar a um valor médio e a uma variância "sigma". Então, o que quero dizer com tomar uma transformação logarítmica, é realmente que se eu tiver uma característica x1 e então o histograma de x1 se parecer com isso, então eu deveria pegar a minha característica x1 e substituí-la pelo log de x1 e esse é meu novo x1, que vou plotar no histograma à direita, e isso parece muito mais Gaussiano. Em vez de uma simples transformação logarítmica, há algumas outras coisas você pode fazer, pode ser, digamos que eu tenha uma característica diferente x2, talvez eu a substitua por log x + 1 ou, mais genericamente, com log x com x2 e alguma constante c e essa constante pode ser algo com o qual eu brinque, para tentar fazê-la parecer o mais Gaussiano possível. Ou por um parâmetro diferente "x3", e talvez substituí-lo pela raiz quadrada de "x3", por exemplo. A raiz quadrada é apenas x3 elevado a meio, certo? E esse meio é outro exemplo de parâmetro com o qual posso brincar. Assim, eu poderia ter x4 e talvez poderia, em vez disso, substituí-la por x4 elevado a alguma outra potência, talvez a potência 1/3 E estas, todas estas, esta aqui, este parâmetro do expoente, ou o parâmetro C, todos estes são exemplos de parâmetros com os quais você pode brincar para fazer seus dados parecerem um pouco mais Gaussianos Então, deixe-me fazer uma demonstração ao vivo do que eu realmente faço quando trabalho meus dados para fazê-los parecer mais Gaussianos. Eu já carreguei aqui pra dentro do Octave um conjunto de características x. Eu tenho milhares de exemplos carregados lá. Vamos levantar o histograma dos meus dados. Use o comando hist x. Aí está o meu histograma. Por padrão, acho que ele usa 10 intervalos de histograma, mas eu quero ver um histograma mais fino. Então usamos "hist(x, 50)", para plotar com 50 intervalos diferentes. Assim está melhor. Mas isso não parece muito gaussiano, parece? Vamos começar a brincar um pouco com os dados. Vamos tentar um histograma de "x" elevado a 0,5. Então pegamos a raiz quadrada dos dados e plotamos o histograma. E, bom, parece um pouco mais gaussiano, mas ainda não chegou lá, vamos mexer com o parâmetro 0,5. Vejamos, Usando 0,2. Parece um pouco mais gaussiano. Vamos reduzir um pouco mais: 0,1. Bem, isso parece bom. Eu poderia usar 0,1. Bom, vamos tentar 0,05. Bom... Agora está bem gaussiano, já posso definir um novo parâmetro que é "xNew" igual a "x" elevado a 0,05. Agora meu novo parâmetro "xNew" se parece muito mais gaussiano que o meu anterior. Eu poderia usar, então, esse novo parâmetro para alimentar diretamente o algoritmo de detecção de anomalias. E, claro, há mais de uma forma de se fazer isso. Você poderia usar o histograma do logaritmo de "x". Esse é outro exemplo de transformação que pode ser usada. E, quer saber, também me parece bem gaussiano. Então, posso definir "xNew = log(x)" Essa seria uma outra boa escolha de parâmetros para usar. Resumindo, se você plotar o histograma dos dados e achar que está bastante não-gaussiano, vale a pena mexer um pouco com diferentes transformações como essas para ver se você consegue fazer seus dados ficarem um pouco mais gaussianos antes de colocá-los no algoritmo de aprendizagem. Apesar disso, mesmo se você não o fizer, pode funcionar bem. Mas geralmente eu faço essa etapa. Agora, a segunda coisa que eu gostaria de falar é como chegar aos parâmetros para um algoritmo de detecção de anomalias. Como eu geralmente faço é por meio de um processo de análise de erros. O que eu quero dizer com isso é que é um processo muito similar à analise de erros que usamos para o aprendizado supervisionado, nele, treinaríamos algoritmo completo e o rodaríamos em um conjunto de validação cruzada, olhando para os exemplares em que ele erra e vendo se encontramos parâmetros adicionais para ajudar o algoritmo a ter um melhor desempenho no exemplares errados do conjunto de validação cruzada. Então, vamos tentar exemplificar esse processo, Na detecção de anomalias, esperamos que "p(x)" seja grande para exemplares normais e pequeno para exemplares anômalos. Assim, um problema bem comum seria ter valores comparáveis de "p(x)", talvez valores grandes tanto para exemplares normais como para os anômalos. Vamos ver um exemplo específico disso. Digamos que esses são meus dados Aqui, temos apenas um parâmetro, "x1", então, vou ajustar uma gaussiana a ele. A gaussiana ajustada aos dados pode ser algo assim. Agora, digamos que tenho um exemplar anômalo e que esse exemplar anômalo tem "x" com um valor de 2,5. Assim, ploto meu exemplar anômalo. E, veja, ele está um pouco "enterrado" no meio de vários exemplares normais, então, apenas esse exemplar anômalo, que eu desenhei em verde, tem uma grande probabilidade, que é a altura da curva azul, e o algoritmo não consegue marcar esse exemplar anômalo. Agora, se isso fosse, talvez, uma manufatura de motores de avião ou algo assim, o que eu faria seria olhar meus exemplares de treino e ver o que deu errado com aquele motor em particular e ver se, ao olhar o exemplar, consigo propor um novo parâmetro "x2" que me ajude a distinguir entre esse mau exemplar quando comparado ao resto dos exemplares vermelhos comparados aos motores de avião normais. Se eu conseguir fazer isso, espera-se que, se eu criar um novo parâmetro "x2", quando eu replotar meus dados, Tomando todos os exemplares normais de conjunto de treinamento com sorte, conseguirei ver todos meus exemplares de treino, as cruzes vermelhas aqui. E, com sorte, para o exemplar anômalo, o parâmetro "x2" terá um valor incomum. Assim, meu exemplar verde, essa anomalia aqui, ainda tem "x1" valendo 2,5. Mas talvez, com sorte, "x2" terá um valor muito grande, como 3,5, ou um valor muito pequeno. Mas agora, se eu modelar meus dados, e perceber que meu algoritmo de detecção de anomalias resulta em alta probabilidade para dados nas regiões centrais, um pouco menor aqui e um pouco menor aqui. Um exemplar que está lá fora receberá do meu algoritmo uma probabilidade bem baixa. Resumindo, esse processo é prestar bastante atenção aos erros que são cometidos. Veja a anomalia que o algoritmo não está conseguindo identificar e veja se você consegue propor um novo parâmetro que indique algo incomum nesse motor de avião e use isso para criar um novo parâmetro que torne mais fácil distinguir as anomalias dos bons exemplares. Portanto, esse é o processo de análise de erro use-o para criar novos parâmetros para detecção de anomalias. Finalmente, vou mostrá-lo meu pensamento de como eu geralmente escolho os parâmetros para detecção de anomalias. Então, geralmente o que considero para criar parâmetros é que eu que parâmetros que terão valores ou muito, muito grandes ou muito, muito pequenos para exemplares que imagino que possam se vir a ser anomalias. Vamos voltar ao nosso exemplo de monitoramento de computadores em um centro de processamento de dados. Nele, você terá muitas máquinas, talvez milhares, ou dezenas de milhares de máquinas em um centro de processamento de dados. Queremos saber se um dos computadores está agindo mal ou de forma estranha. Aqui vão alguns exemplos de parâmetros que você pode escolher uso de memória, número de acessos ao disco, carga do CPU, tráfego na rede. Agora, digamos que eu suspeito que um dos casos de falha, por exemplo, nos meu conjunto de dados imagino que o uso do CPU e o tráfego de rede tendam a crescer linearmente um ao outro. Se eu estiver rodando vários servidores de rede e um dos meus servidores está servindo muitos usuários, terei uma alta carga no CPU e um alto uso da rede. Digamos que, eu suspeite que um dos casos de falha é se um dos meus computadores tiver um processo que trava em algum tipo de loop infinito. Imagino que um dos casos de falha, é uma máquina, um dos servidores, tiver um código que está travado em algum loop infinito, fazendo o uso de CPU crescer mas sem aumentar o uso da rede porque ele simplesmente está patinando com o CPU trabalhando muito preso em algum loop infinito. Nesse caso, para detectar esse tipo de anomalia, eu poderia criar um novo parâmetro "x5" que é a carga de CPU dividida pelo tráfego de rede. Com isso, "x5" terá um valor excepcionalmente grande se uma das máquinas tiver uma carga muito grande no CPU mas nem tanto tráfego de rede assim. Esse será um parâmetro que ajudará seu detector de anomalias a capturar um certo tipo de anomalia. Você também pode usar a criatividade e propor outros parâmetros. Por exemplo, um parâmetro "x6" igual à carga do CPU ao quadrado dividida pelo tráfego de rede. Esse seria uma variação de um parâmetro como "x5" para tentar capturar anomalias nas quais uma das máquinas está com uma carga muito grande no CPU mas não tem um tráfego de rede igualmente grande. Ao criar parâmetros como esses, você pode começar a capturar anomalias correspondentes a combinações incomuns dos valores dos parâmetros. Neste vídeo falamos sobre como pegar um parâmetro e talvez transformá-lo um pouco para que ele fique um pouco mais gaussiano antes de colocá-lo em um algoritmo de detecção de anomalias. Também falamos da análise de erros no processo de criação de parâmetros para tentar capturar diferentes tipos de anomalias. Estes são alguns guias que podem ajudá-lo a escolher bons parâmetros para seu algoritmo de detecção de anomalias, ajudando-o a capturar todo tipo de anomalias.