1
00:00:00,200 --> 00:00:01,770
ここまでで我々は

2
00:00:02,250 --> 00:00:03,540
アノマリー検出のアルゴリズムを見てきた。

3
00:00:03,740 --> 00:00:05,240
また、アノマリー検出のアルゴリズムを

4
00:00:05,570 --> 00:00:06,870
どう評価するのかも見てきた。

5
00:00:07,330 --> 00:00:08,880
実は、実際に

6
00:00:09,530 --> 00:00:10,800
アノマリー検出を適用してみると、

7
00:00:11,170 --> 00:00:12,400
それがどれだけ

8
00:00:12,460 --> 00:00:13,290
うまく機能するかに

9
00:00:13,720 --> 00:00:14,860
巨大な影響を与えているのは

10
00:00:14,940 --> 00:00:16,440
なんのフィーチャーを使うのか、

11
00:00:16,520 --> 00:00:17,720
何のフィーチャーを選んで

12
00:00:18,530 --> 00:00:19,910
アノマリー検出のアルゴリズムに与えるか、という部分だ。

13
00:00:20,830 --> 00:00:22,170
だからこのビデオでは、

14
00:00:22,280 --> 00:00:23,390
アノマリー検出のアルゴリズムに

15
00:00:23,480 --> 00:00:24,890
食わせるフィーチャーを

16
00:00:25,000 --> 00:00:26,250
どうデザインするか、どう選ぶかについて

17
00:00:26,370 --> 00:00:27,920
二、三の助言、

18
00:00:28,470 --> 00:00:30,950
提案をしたいと思う。

19
00:00:33,920 --> 00:00:35,310
我らのアノマリー検出のアルゴリズムにおいては

20
00:00:36,120 --> 00:00:37,270
こんな種類のガウス分布を用いて

21
00:00:37,510 --> 00:00:40,330
フィーチャー達をモデリングするという過程があります。

22
00:00:41,180 --> 00:00:42,810
xiを、ミューiと

23
00:00:43,120 --> 00:00:46,050
シグマ二乗iで。

24
00:00:46,550 --> 00:00:47,890
そうであるから、私が良く

25
00:00:47,950 --> 00:00:49,620
やる事としては、

26
00:00:50,670 --> 00:00:52,260
私のアノマリー検出のアルゴリズムに

27
00:00:52,330 --> 00:00:53,490
データを食わせる前に

28
00:00:53,940 --> 00:00:55,210
このデータのヒストグラムをプロットしてみて

29
00:00:55,540 --> 00:00:57,320
なんとなくガウス分布っぽいかを

30
00:00:57,470 --> 00:00:58,830
見てみる、という事があります。

31
00:00:59,810 --> 00:01:01,040
あなたのデータがガウス分布でなくても

32
00:01:01,610 --> 00:01:02,820
普通はオーケーです。

33
00:01:03,400 --> 00:01:05,700
だけどこれは、実行してみるに値する、良いサニティチェックです。

34
00:01:05,970 --> 00:01:06,860
ところで、あなたのデータが非ガウス分布をとっていても、

35
00:01:07,400 --> 00:01:09,540
アルゴリズムは普通に正しく機能する事が多い。

36
00:01:10,410 --> 00:01:12,070
具体的に見ると

37
00:01:12,430 --> 00:01:13,510
データをこんな風にプロットしてみて、

38
00:01:13,850 --> 00:01:15,280
ヒストグラムがこんな感じに見えたら

39
00:01:15,370 --> 00:01:16,480
ところでヒストグラムの

40
00:01:16,630 --> 00:01:17,800
プロットの仕方は

41
00:01:17,950 --> 00:01:19,910
hist関数を

42
00:01:20,130 --> 00:01:21,820
Octaveでは使いますが

43
00:01:21,910 --> 00:01:22,800
そこでこんな見た目なら、

44
00:01:23,010 --> 00:01:24,770
これはだいたいガウス分布っぽい。

45
00:01:24,940 --> 00:01:26,200
つまりフィーチャーがこんな感じなら

46
00:01:26,480 --> 00:01:29,970
アルゴリズムに、とても幸せな気持ちで食わせられる。

47
00:01:30,180 --> 00:01:31,830
だが、もしもデータのヒストグラムをプロットしてみたら

48
00:01:31,950 --> 00:01:33,070
それがもしもこんな感じなら、

49
00:01:33,210 --> 00:01:34,800
うーん、

50
00:01:35,060 --> 00:01:36,090
こいつはベル型のカーブには

51
00:01:36,220 --> 00:01:38,430
まったく見えないなぁ。
これはとても非対称な分布だ。

52
00:01:39,410 --> 00:01:40,660
これはピークが片側に偏り過ぎている。

53
00:01:41,750 --> 00:01:42,660
もしこんな風に私のデータが見えたら

54
00:01:42,800 --> 00:01:43,960
私が良くやる手段は

55
00:01:44,190 --> 00:01:45,370
様々なデータ変換を試して

56
00:01:45,730 --> 00:01:46,920
もっとガウス分布っぽく

57
00:01:47,010 --> 00:01:48,850
見えるようにする。

58
00:01:49,480 --> 00:01:51,940
繰り返しになるが、別にそんな事しなくても、だいたいはアルゴリズムはちゃんと機能する。

59
00:01:52,590 --> 00:01:53,660
でももしこれらの変換でデータをより

60
00:01:54,630 --> 00:01:56,590
ガウス分布っぽく見えるように出来たら、そっちの方がアルゴリズムはちょっとだけ改善される。

61
00:01:58,030 --> 00:01:59,780
だからこんな見た目の

62
00:02:00,140 --> 00:02:01,340
データセットが与えられた時、

63
00:02:01,430 --> 00:02:02,810
私が試すだろう事は

64
00:02:03,010 --> 00:02:04,520
logをとってデータを変換し

65
00:02:04,660 --> 00:02:05,930
その後に

66
00:02:06,060 --> 00:02:07,810
データをヒストグラムとして再プロットして

67
00:02:08,150 --> 00:02:09,110
この例の場合は例えば

68
00:02:09,330 --> 00:02:10,500
結果としてこんな

69
00:02:11,130 --> 00:02:12,400
ヒストグラムを得る。

70
00:02:12,540 --> 00:02:14,470
こっちの方がガウス分布っぽいでしょう？

71
00:02:14,650 --> 00:02:15,720
こっちの方がより古典的な

72
00:02:16,690 --> 00:02:18,020
ベル型のカーブに見える。

73
00:02:18,710 --> 00:02:21,000
それはある平均と分散のパラメータでフィッティング出来る。

74
00:02:22,180 --> 00:02:22,940
ログ変換を取る、と言っているのは

75
00:02:23,230 --> 00:02:24,610
具体的には

76
00:02:24,860 --> 00:02:26,140
あるフィーチャーx1があったとして、

77
00:02:26,860 --> 00:02:28,260
そのx1のヒストグラムがこんな見た目だとすると

78
00:02:28,720 --> 00:02:30,500
フィーチャーx1を

79
00:02:31,070 --> 00:02:32,210
log x1で

80
00:02:32,410 --> 00:02:33,890
置き換える。

81
00:02:34,800 --> 00:02:36,730
そしてこれを

82
00:02:36,860 --> 00:02:37,880
新しいx1とみなし、

83
00:02:38,170 --> 00:02:40,000
それのヒストグラムを右にプロットすると、

84
00:02:40,430 --> 00:02:42,350
よりガウス分布っぽくなっている。

85
00:02:44,000 --> 00:02:44,730
log変換の他に、選択肢として考えられる物は

86
00:02:44,920 --> 00:02:46,020
異なるフィーチャー

87
00:02:46,110 --> 00:02:47,720
x2があったとして、

88
00:02:48,690 --> 00:02:49,840
それをlog(x+1)で

89
00:02:50,120 --> 00:02:52,560
置き換える、

90
00:02:52,630 --> 00:02:54,720
またはより一般に

91
00:02:56,360 --> 00:02:57,690
log xのxをx2とある定数c で

92
00:02:58,430 --> 00:03:00,350
置き換えた物で置き換える、というのが考えられる。

93
00:03:00,520 --> 00:03:01,540
この定数cはいろいろ調整して

94
00:03:01,890 --> 00:03:04,390
なるべくガウス分布っぽく見えるようにする。

95
00:03:05,610 --> 00:03:06,820
他には別のフィーチャーx3に対し

96
00:03:07,200 --> 00:03:08,610
x3をルートを取った物で

97
00:03:09,730 --> 00:03:11,250
置き換えても良いかもしれない。

98
00:03:11,610 --> 00:03:14,180
ルートってのはx3の、単なる1/2乗に過ぎない、でしょ？

99
00:03:15,260 --> 00:03:16,660
そしてこの1/2というのも

100
00:03:17,130 --> 00:03:19,220
いろいろ調整する事が出来るパラメータとなる。

101
00:03:19,640 --> 00:03:21,600
x4があったとして、

102
00:03:22,450 --> 00:03:23,820
そのx4を代わりに

103
00:03:24,410 --> 00:03:25,370
x4の違う指数乗、例えば

104
00:03:25,730 --> 00:03:26,790
1/3乗とかで

105
00:03:26,890 --> 00:03:28,460
置き換えても良い。

106
00:03:28,940 --> 00:03:30,830
そしてこれら全て、

107
00:03:30,900 --> 00:03:32,320
これ、この指数乗の

108
00:03:32,540 --> 00:03:33,670
パラメータ、または

109
00:03:33,810 --> 00:03:35,110
パラメータCも、

110
00:03:35,380 --> 00:03:36,880
これら全てがあなたのデータを

111
00:03:36,960 --> 00:03:38,110
ちょっとでもガウス分布っぽく見せる為に

112
00:03:38,460 --> 00:03:40,420
いじれるパラメータの例となる。

113
00:03:45,180 --> 00:03:46,210
ではここで、私のデータを

114
00:03:46,740 --> 00:03:48,720
実際にいろいろいじって

115
00:03:49,150 --> 00:03:50,690
よりガウス分布っぽくする生のデモをお見せしよう。

116
00:03:51,650 --> 00:03:52,370
その為、ここに既に

117
00:03:52,750 --> 00:03:54,730
Octaveにロードしておいた、

118
00:03:54,860 --> 00:03:56,170
幾つかのフィーチャーxを。千のサンプルをここでは

119
00:03:57,150 --> 00:03:57,870
ロードしておいた。

120
00:03:58,580 --> 00:04:00,100
では私のデータのヒストグラムを出しておこう、

121
00:04:01,560 --> 00:04:02,570
このhist xのコマンドで。

122
00:04:03,190 --> 00:04:04,100
これが私のヒストグラムだ。

123
00:04:05,660 --> 00:04:06,580
デフォルトだと確か

124
00:04:06,680 --> 00:04:08,250
この10個のビンをヒストグラムは使うと思うが

125
00:04:08,610 --> 00:04:10,400
私はもっと粒度の細かいグリッドのヒストグラムを見たい。

126
00:04:11,330 --> 00:04:12,950
だからhistに x, 50と渡す

127
00:04:13,050 --> 00:04:14,970
これは50個のことなるビンでプロットする。

128
00:04:15,310 --> 00:04:15,660
オーケー。良くなった。

129
00:04:16,180 --> 00:04:18,570
現在のところ、これはそんなにガウス分布っぽくは無い。でしょ？

130
00:04:18,930 --> 00:04:20,720
だからちょっとデータをいじってみよう。

131
00:04:20,900 --> 00:04:22,310
まずhistの

132
00:04:22,610 --> 00:04:24,810
xの0.5乗を試してみよう。

133
00:04:25,090 --> 00:04:26,590
つまりデータのルートを取って

134
00:04:26,870 --> 00:04:28,820
そのヒストグラムをプロットする。

135
00:04:30,670 --> 00:04:31,680
オーケー。ちょっとガウスっぽく

136
00:04:31,800 --> 00:04:32,870
なってきた。だがまだまだだね。

137
00:04:32,960 --> 00:04:34,550
ではこの0.5というパラメータをいじってみよう。

138
00:04:34,790 --> 00:04:35,330
どうなるか？

139
00:04:36,520 --> 00:04:38,110
これを0.2にセットする。

140
00:04:38,280 --> 00:04:39,780
もうちょっとガウス分布っぽくなった。

141
00:04:40,930 --> 00:04:43,150
もうちょっと減らして0.1にしてみよう。

142
00:04:44,450 --> 00:04:45,220
いえーい！凄い良くなった！

143
00:04:45,500 --> 00:04:48,440
これは実際だったら0.1で良い気がするね。

144
00:04:48,880 --> 00:04:50,190
さらに減らして0.05にしてみよう。

145
00:04:50,520 --> 00:04:50,910
ご想像の通り、、、

146
00:04:51,740 --> 00:04:52,750
よし、これはいい感じにガウス分布だ。

147
00:04:53,230 --> 00:04:54,090
だから新しいフィーチャーとして

148
00:04:54,190 --> 00:04:55,510
xミュー イコール xの0.05乗

149
00:04:56,110 --> 00:04:58,940
と定義する。

150
00:04:59,620 --> 00:05:01,380
するとこの新しいフィーチャー

151
00:05:01,610 --> 00:05:03,050
xミューは、以前のよりも

152
00:05:03,250 --> 00:05:04,490
よりガウス分布っぽくなって、

153
00:05:04,510 --> 00:05:05,560
これを代わりに

154
00:05:05,850 --> 00:05:07,070
アノマリー検出のアルゴリズムに

155
00:05:07,380 --> 00:05:09,390
食わせても良い。

156
00:05:10,150 --> 00:05:12,100
もちろん、これを行う方法は一つだけでは無い。

157
00:05:12,410 --> 00:05:14,530
histのlog xというのも試しても良い。

158
00:05:14,710 --> 00:05:17,320
それはもう一つの試してみる価値のある変換の例だ。

159
00:05:18,270 --> 00:05:20,410
そしてこれも、見ての通りなかなかガウスっぽい。

160
00:05:20,870 --> 00:05:22,040
だからxミューを

161
00:05:22,230 --> 00:05:23,760
log xと定義しても良い。

162
00:05:24,220 --> 00:05:25,120
これもまたなかなか良い

163
00:05:25,300 --> 00:05:26,890
フィーチャーのチョイスといえる。

164
00:05:28,040 --> 00:05:29,400
まとめると、データのヒストグラムを

165
00:05:29,520 --> 00:05:30,580
プロットしてみて、

166
00:05:31,000 --> 00:05:31,690
それがだいぶガウス分布っぽくなかったら

167
00:05:31,940 --> 00:05:33,460
今回試したような変換で

168
00:05:33,740 --> 00:05:35,110
ちょっとデータをつついてみるのは

169
00:05:35,280 --> 00:05:37,120
試してみる価値がある。

170
00:05:37,290 --> 00:05:38,190
もうちょっとガウス分布っぽく

171
00:05:38,300 --> 00:05:39,410
ならないかなぁ、と

172
00:05:39,570 --> 00:05:40,520
学習アルゴリズムに食わしてみる前に。

173
00:05:40,770 --> 00:05:41,970
やらなかったとしても、

174
00:05:42,050 --> 00:05:43,550
たぶんうまく機能するけどね。

175
00:05:43,850 --> 00:05:45,070
でも普段、私はこのステップを踏む。

176
00:05:45,850 --> 00:05:46,880
ここで二番目に話したい事として、

177
00:05:46,970 --> 00:05:48,280
アノマリー検出に使うフィーチャーを

178
00:05:48,400 --> 00:05:51,540
どう見つけるか、というのがある。

179
00:05:52,650 --> 00:05:53,780
私が良くやるのは

180
00:05:53,990 --> 00:05:56,490
誤差分析の手順だ。

181
00:05:57,630 --> 00:05:58,590
それの意味する所は

182
00:05:58,970 --> 00:05:59,960
教師有り学習での

183
00:06:00,320 --> 00:06:02,320
誤差分析の手順と

184
00:06:02,450 --> 00:06:04,600
本当に似た物で、

185
00:06:04,860 --> 00:06:06,810
そこでは完全にアルゴリズムを

186
00:06:06,860 --> 00:06:08,220
学習させて、

187
00:06:08,350 --> 00:06:09,980
それをクロスバリデーションセットにかける、

188
00:06:10,840 --> 00:06:11,870
そして間違いのサンプルを見る、

189
00:06:12,230 --> 00:06:13,500
そしてフィーチャーを追加して

190
00:06:13,580 --> 00:06:14,800
それがクロスバリデーションセットで

191
00:06:15,370 --> 00:06:16,440
誤りだった物を

192
00:06:16,580 --> 00:06:17,870
正しく扱う助けとなるかを

193
00:06:18,280 --> 00:06:19,850
見てみる。

194
00:06:21,060 --> 00:06:23,380
ではこのプロセスを

195
00:06:24,040 --> 00:06:25,960
例を通して見てみよう。

196
00:06:26,950 --> 00:06:28,680
アノマリー検出のアルゴリズムにおいては

197
00:06:28,880 --> 00:06:29,690
通常のサンプルについてはpのxが大きく、

198
00:06:29,840 --> 00:06:30,910
アノマリーなサンプルでは小さくなる事を

199
00:06:31,760 --> 00:06:33,180
期待している。

200
00:06:34,400 --> 00:06:35,370
だから、良くある問題としては

201
00:06:35,950 --> 00:06:37,780
pのxが同じような値という場合、

202
00:06:38,480 --> 00:06:41,540
例えば普通の物とアノマリーな物が両方とも大きい場合などだ。

203
00:06:42,940 --> 00:06:44,380
その具体例を見てみよう。

204
00:06:45,150 --> 00:06:46,760
これが私のラベル無しデータとする。

205
00:06:47,120 --> 00:06:47,970
ここではたった一つのフィーチャーx1しか無いので

206
00:06:48,210 --> 00:06:51,130
これをガウス分布でフィッティングする。

207
00:06:52,160 --> 00:06:55,990
そしてフィッティングしたガウス曲線がこんな感じだったとしよう。

208
00:06:57,300 --> 00:06:59,130
そしてアノマラスなサンプルがあったとしよう。

209
00:06:59,670 --> 00:07:00,480
そしてそのアノマラスなサンプルはxの値

210
00:07:01,080 --> 00:07:02,850
2.5を取るとする。

211
00:07:03,020 --> 00:07:06,420
このアノマラスなサンプルをプロットしてみた。

212
00:07:07,200 --> 00:07:08,120
すると見ての通り、

213
00:07:08,650 --> 00:07:09,730
それはたくさんの普通のサンプルの中に

214
00:07:09,880 --> 00:07:11,690
埋もれてしまっている。

215
00:07:13,450 --> 00:07:14,850
つまりこのアノマラスなサンプルは

216
00:07:15,460 --> 00:07:16,780
緑で描いた物だが、それは

217
00:07:16,820 --> 00:07:18,550
とても高い確率となる。それは青い曲線の

218
00:07:18,730 --> 00:07:20,000
高さで表される訳だ。

219
00:07:20,960 --> 00:07:22,280
そしてアルゴリズムはこれを

220
00:07:22,390 --> 00:07:23,840
アノマラスなサンプルだとフラグづけする事に失敗してしまう。

221
00:07:25,320 --> 00:07:26,600
ここで、これは航空機エンジンの

222
00:07:27,000 --> 00:07:29,540
製造とかだとしよう。

223
00:07:29,680 --> 00:07:30,490
ここで実際に取れる対策としては

224
00:07:30,860 --> 00:07:32,370
トレーニングサンプルを実際に見て、

225
00:07:32,840 --> 00:07:34,500
うまく行っていない特定の不良エンジンについて

226
00:07:34,730 --> 00:07:36,920
どこが悪くなっているかを調べる。

227
00:07:37,030 --> 00:07:38,360
そしてもしそのエンジンを調べていて

228
00:07:38,720 --> 00:07:40,720
それにインスパイアされて

229
00:07:40,860 --> 00:07:41,800
新たなフィーチャーx2を思いついたとする。

230
00:07:42,290 --> 00:07:43,890
それがこの不良エンジンを

231
00:07:44,650 --> 00:07:46,530
識別するには有用な訳だ。

232
00:07:46,900 --> 00:07:47,850
残りの赤いサンプル、

233
00:07:48,530 --> 00:07:49,850
私の全ての正常な航空機エンジンと

234
00:07:50,980 --> 00:07:51,600
比較して。

235
00:07:52,790 --> 00:07:53,840
そしてなんとかそこまで行ったら

236
00:07:54,000 --> 00:07:54,910
以下のような事を期待する訳だ:

237
00:07:55,150 --> 00:07:56,540
新しいフィーチャーx2を作って、

238
00:07:56,610 --> 00:07:59,360
私のデータを再プロットしたら

239
00:07:59,610 --> 00:08:01,490
トレーニングセットの正常なサンプルは

240
00:08:01,580 --> 00:08:02,530
プロットしてみたら

241
00:08:02,770 --> 00:08:04,420
正常なサンプルは

242
00:08:04,750 --> 00:08:05,560
赤いバツのサンプルは

243
00:08:05,710 --> 00:08:07,380
こんな感じで見えたとして、

244
00:08:08,210 --> 00:08:09,580
アノマラスなサンプルは

245
00:08:09,860 --> 00:08:11,390
フィーチャーx2が

246
00:08:11,480 --> 00:08:13,490
異常な値を取るという風に出来る事を期待する訳だ。

247
00:08:14,470 --> 00:08:15,820
例えば私のこの緑のサンプル

248
00:08:16,290 --> 00:08:18,670
このアノマリーは

249
00:08:18,940 --> 00:08:20,800
x1の値は2.5のままだけど、

250
00:08:21,260 --> 00:08:22,900
x2の値は例えば、

251
00:08:23,290 --> 00:08:24,530
とても大きな値とか、

252
00:08:24,840 --> 00:08:26,710
こっちの3.5とかそういう値か、

253
00:08:27,940 --> 00:08:28,450
またらとても小さな値を期待する訳だ。

254
00:08:29,450 --> 00:08:30,530
ここでこのデータをモデリングすると、

255
00:08:30,970 --> 00:08:32,480
アノマリー検出のアルゴリズムは

256
00:08:33,050 --> 00:08:34,660
まんなかのあたりの領域のデータに

257
00:08:35,240 --> 00:08:36,830
高い確率を与え、

258
00:08:37,190 --> 00:08:39,160
そのちょっと低い確率がこの辺に、

259
00:08:39,200 --> 00:08:42,470
それよりさらにちょっと低い確率がこの辺に、となる。

260
00:08:42,660 --> 00:08:43,960
そしてこの遥か遠くのサンプルに対しては

261
00:08:44,070 --> 00:08:45,450
私のアルゴリズムは

262
00:08:45,630 --> 00:08:46,720
ここではとても低い

263
00:08:48,360 --> 00:08:48,360
確率を与えるだろう。

264
00:08:48,510 --> 00:08:49,170
つまりこのプロセスは

265
00:08:49,230 --> 00:08:50,320
実際に間違いだった物、

266
00:08:51,430 --> 00:08:52,570
アルゴリズムがフラグ付けに失敗した

267
00:08:52,830 --> 00:08:54,370
アノマリーを直接調べて、

268
00:08:54,580 --> 00:08:56,020
それが新しいフィーチャーを作るよう

269
00:08:56,320 --> 00:08:59,100
インスパイアしてくれるかどうかを見てみる。

270
00:08:59,590 --> 00:09:01,180
その航空機エンジンの

271
00:09:01,470 --> 00:09:02,590
何か普通で無い所を探して

272
00:09:02,800 --> 00:09:03,640
それを用いて新しいフィーチャーを作る。

273
00:09:04,530 --> 00:09:05,780
この新しいフィーチャーで

274
00:09:05,900 --> 00:09:07,140
正常なサンプルとアノマリー達を

275
00:09:07,400 --> 00:09:09,250
より簡単に区別出来るようになるように。

276
00:09:09,880 --> 00:09:11,170
以上が誤差解析の

277
00:09:11,280 --> 00:09:12,600
手順であり、

278
00:09:14,020 --> 00:09:15,360
それをアノマリー検出に使う

279
00:09:15,750 --> 00:09:17,100
新しいフィーチャーを作るのに使うやり方だ。

280
00:09:17,770 --> 00:09:18,980
最後に、私が普段

281
00:09:19,090 --> 00:09:20,440
アノマリー検出のフィーチャーを選ぶのに

282
00:09:20,630 --> 00:09:23,190
どうやってるのかについて、私の考えを共有しておきたい。

283
00:09:24,350 --> 00:09:27,700
普段私がフィーチャーの選択についてどう考えているかといえば、

284
00:09:27,960 --> 00:09:29,160
アノマリーのサンプルだと思う時には

285
00:09:29,270 --> 00:09:30,610
なるべく凄く凄く小さくなるか

286
00:09:30,860 --> 00:09:32,000
凄く凄く大きくなるような

287
00:09:32,110 --> 00:09:33,890
フィーチャーを

288
00:09:34,750 --> 00:09:36,420
探したい、と考えている。

289
00:09:37,850 --> 00:09:38,710
ここでも再びコンピューターのデータセンターの

290
00:09:39,060 --> 00:09:41,820
モニタリングの例を考えてみよう。

291
00:09:42,250 --> 00:09:43,560
たくさんのマシンがあって

292
00:09:43,630 --> 00:09:44,930
たとえば何千とか何万とかのマシンが

293
00:09:45,170 --> 00:09:47,830
データセンターにあるかもしれない。

294
00:09:48,310 --> 00:09:49,410
そしてマシンの一つが

295
00:09:49,580 --> 00:09:50,640
コンピュータの一つが

296
00:09:50,710 --> 00:09:53,320
いかれているか、つまり何か妙な事をしているかを知りたい。

297
00:09:54,180 --> 00:09:56,050
そこでこんなフィーチャーを選ぶかもしれない。

298
00:09:57,020 --> 00:09:59,630
メモリー使用量とかディスクアクセスの回数とかCPUロードとかネットワークトラフィックとか。

299
00:10:01,040 --> 00:10:01,960
だがここで、失敗してるケースの一つに、

300
00:10:02,220 --> 00:10:03,040
私のデータセットの失敗してるケースの一つが、

301
00:10:03,470 --> 00:10:04,580
CPUロードとネットワークトラフィックが

302
00:10:05,230 --> 00:10:06,970
共にリニアに増えていくと

303
00:10:07,150 --> 00:10:08,460
疑っていると

304
00:10:08,990 --> 00:10:10,820
しよう。

305
00:10:11,110 --> 00:10:12,120
例えばたくさんのwebサーバを走らせていて

306
00:10:12,220 --> 00:10:13,370
そのサービスの一つが

307
00:10:13,750 --> 00:10:15,050
たくさんのユーザに対して

308
00:10:15,310 --> 00:10:16,530
サービスを提供していたら

309
00:10:16,850 --> 00:10:19,050
とても高いCPUロードと高いネットワークトラフィックを得るだろう。

310
00:10:20,230 --> 00:10:21,360
だが例えば、

311
00:10:21,840 --> 00:10:23,280
失敗のケースの一つは

312
00:10:23,390 --> 00:10:24,890
もしコンピュータの一つが

313
00:10:25,180 --> 00:10:26,240
無限ループで固まってるジョブを持っていると

314
00:10:26,530 --> 00:10:29,590
疑ってるとしよう。

315
00:10:29,670 --> 00:10:30,750
つまり私は

316
00:10:30,800 --> 00:10:32,240
ある失敗のケースは

317
00:10:32,420 --> 00:10:33,470
あるマシンの

318
00:10:34,380 --> 00:10:36,020
あるweb server、もといサーバーのcodeが

319
00:10:36,680 --> 00:10:37,990
無限ループで詰まってる、と思ってるとすると、

320
00:10:38,230 --> 00:10:39,550
その時はCPUロードは上がるだろうが

321
00:10:40,380 --> 00:10:41,490
ネットワークトラフィックは上昇しないだろう。

322
00:10:41,560 --> 00:10:42,790
何故ならそれは単に糸車がくるくると回っていて

323
00:10:42,940 --> 00:10:44,570
たくさんのCPUの仕事をしている、つまり

324
00:10:44,870 --> 00:10:46,000
無限ループに詰まってる。

325
00:10:46,930 --> 00:10:47,850
その場合、その種のアノマリーを

326
00:10:48,240 --> 00:10:49,610
検出する為には、

327
00:10:49,780 --> 00:10:52,440
新たなフィーチャーX5として、

328
00:10:53,170 --> 00:10:55,130
CPUロードをネットワークトラフィックで割ったような新たなフィーチャーを

329
00:10:56,600 --> 00:11:00,120
作るかもしれない。

330
00:11:01,230 --> 00:11:02,810
するとx5は、もしあるマシンが

331
00:11:03,180 --> 00:11:04,860
とても大きなCPUロードでありながら

332
00:11:05,700 --> 00:11:06,410
そんなに大きくないネットワークトラフィックの時には

333
00:11:06,790 --> 00:11:08,190
異常に大きな値を

334
00:11:08,470 --> 00:11:09,980
とるだろう。

335
00:11:10,250 --> 00:11:11,030
だからこのフィーチャーは

336
00:11:11,160 --> 00:11:12,390
あなたのアノマリー検出が

337
00:11:12,490 --> 00:11:14,180
ある種のアノマリーを検出するのを助ける事になる。

338
00:11:15,000 --> 00:11:16,700
こんな風にさらに別の

339
00:11:16,840 --> 00:11:19,060
フィーチャーも思いつくかもしれない。

340
00:11:19,230 --> 00:11:20,090
例えばx6として

341
00:11:20,570 --> 00:11:22,050
CPUロードを二乗した物を

342
00:11:22,880 --> 00:11:25,540
ネットワークトラフィックで割った物を使うかもしれない。

343
00:11:27,030 --> 00:11:28,280
これはx5の変種の一つと

344
00:11:28,950 --> 00:11:29,910
考えられる。それはマシンの一つが

345
00:11:30,020 --> 00:11:32,120
とても高いCPUロードにありながら

346
00:11:32,280 --> 00:11:33,650
それに見合うネットワークトラフィックが無い

347
00:11:33,800 --> 00:11:35,030
物を見分けようと

348
00:11:35,290 --> 00:11:37,100
しているフィーチャーだ。

349
00:11:38,540 --> 00:11:40,080
これらのようなフィーチャーを作る事で

350
00:11:40,290 --> 00:11:41,560
フィーチャーの異常な

351
00:11:42,770 --> 00:11:44,550
組み合わせを

352
00:11:45,690 --> 00:11:48,270
捉えていく事が出来る。

353
00:11:50,990 --> 00:11:52,090
このビデオでは

354
00:11:52,260 --> 00:11:53,550
どうフィーチャーを選び

355
00:11:53,690 --> 00:11:54,670
必要ならアルゴリズムに

356
00:11:55,120 --> 00:11:56,680
食わせる前に

357
00:11:56,830 --> 00:11:57,910
ちょっと変換して

358
00:11:58,260 --> 00:12:00,480
よりガウス分布っぽくするかを議論した。

359
00:12:00,950 --> 00:12:02,110
また、新しいフィーチャーを作って

360
00:12:02,740 --> 00:12:04,220
異なる種類のアノマリーを捕捉する為の

361
00:12:04,870 --> 00:12:06,710
エラー分析の手順も議論した。

362
00:12:07,550 --> 00:12:10,300
これらのガイドラインが

363
00:12:10,850 --> 00:12:12,180
あなたが良いフィーチャーを選び

364
00:12:12,460 --> 00:12:14,310
すべてのアノマリーをあなたの検出アルゴリズムが

365
00:12:14,430 --> 00:12:15,920
捕捉出来る一助にならんことを！