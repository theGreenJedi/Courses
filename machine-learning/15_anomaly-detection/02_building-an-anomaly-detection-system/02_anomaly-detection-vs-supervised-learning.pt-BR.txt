No vídeo anterior, nós falamos sobre o processo para avaliar um algoritmo de detecção de anomalias. E então começamos a usar alguns dados etiquetados com exemplos que nós sabíamos serem anômalos ou não anômalos com Y igual a um, ou Y igual a 0. E então, a questão surge, e se temos os dados etiquetados, que nós temos alguns exemplos e conhecemos as anomalias, e que alguns deles não serão anômalos. Por que não apenas usar um supervisor para metade deles? Então por que não usamos regressão logística, ou uma rede neural para tentar aprender diretamente a partir dos nossos dados etiquetados para prever se Y é igual a 1 ou Y é igual a 0. Neste vídeo, tentarei compartilhar com você alguns pensamentos e diretrizes sobre quando provavelmente usaria o algoritmo de detecção de anomalia, e se ele seria mais útil ao invés de usar um supervisor no algoritmo. Este slide mostra que há situações nass quais você poderia usar detecção de anomalia versus quando aprendizagem supervisionada daria mais resultado. Se você tem um problema com um número muito pequeno de exemplos positivos, e lembre-se de que exemplos de y iguais a um são exemplos de anomalia. Então, você deveria considerar o uso de um algoritmo de detecção de anomalia. Então, tendo entre 0 e 20, talvez até 50 exemplos positivos, seria bem típico. E geralmente temos pequenos positivos assim, conjunto de exemplos positivos, vamos guardar os exemplos positivos apenas para o conjunto de validação cruzada do conjunto de teste. E em contraste, numa típica configuração normal de detecção de anomalia, teremos frequentemente um número relativamente grande de exemplos negativos de exemplos normais de motores de aeronaves normais. E podemos então usar este  número bem grande de exemplos negativos com os quais ajustamos o modelo p(x). E então existe a ideia que em muitos aplicativos de detecção de anomalia, você tem poucos exemplos positivos e muitos exemplos negativos. E quando estamos realizando o processo de estimar p(x), afetando todos aqueles parâmetros de Gauss, precisamos apenas de exemplos negativos para fazer isso. Então, se você tem muitos dados negativos, nós podemos ainda ajustar p(x) muito bem. Em contrapartida, para aprendizagem supervisionada, mais tipicamente nós teríamos um número razoavelmente grande de exemplos de ambos positivos e negativos. E então isso é uma forma de olhar para o problema e decidir se deveria usar o algoritmo de detecção de anomalia ou um supervisionado. Aqui está outro modo de pensar das pessoas sobre algoritmos de detecção de anomalias. Em aplicativos de detecção de anomalias, frequentemente há muitos tipos distintos de anomalias. Então, pense em muitas formas distintas de dar errado. Há muitas coisas que poderiam dar errado e pifar o motor de uma aeronave. E sendo assim, e se você tiver um conjunto muito pequeno de exemplos positivos, então isso pode ser difícil para o algoritmo, difícil para o algoritmo aprender a partir deste conjunto pequeno de exemplos positivos de como se parecem as anomalias. Em particular, você sabe que anomalias futuras podem não parecer em nada com as que você já viu até então. Logo, pode ser que no seu conjunto de exemplos positivos, você pode ter visto 5 ou 10 ou 20 formas distintas que podem fazer um motor de aeronave funcionar de modo errado. Mas talvez amanhã, você precise detectar um conjunto totalmente novo, um tipo totalmente novo de anomalia. Um modo totalmente novo de pifar um motor de aeronave, que você simplesmente nunca viu antes. Se este for o caso, poderia ser mais promissor simplesmente modelar os exemplos negativos com este tipo de modelo de Gauss, p de x, ao invés de tentar modelar os exemplos positivos. Porque as anomalias futuras podem não parecer em nada com as que você já viu até então. Em contraste, em alguns outros problemas, você tem exemplos positivos suficientes para um algoritmo ter noção de como os exemplos positivos se parecem. Em especial, se você pensar que exemplos positivos futuros tendem a ser similares aos do conjunto treinado, então, nesta configuração, poderia ser mais razoável ter um supervisor no algoritmo que verifica todos os exemplos positivos, verifica todos os exemplos negativos, e usa isso para tentar distinguir entre os positivos e os negativos. Espero que isso lhe dê uma noção se você tiver um problema específico, de pensar em usar um algoritmo de detecção de anomalia, ou em usar um algoritmo de aprendizagem supervisionado. E uma diferença importante é realmente que na detecção de anomalia, sempre nós temos aquele pequeno número de exemplos positivos que não possibilitam a um algoritmo de aprendizagem aprender muito sobre estes exemplos positivos. E então, o que fazemos ao invés disso é pegar uma grande amostra de exemplos negativos e tendo aprendido muito, aprendido p(x) apenas dos exemplos negativos. Do motor normal da aeronave, digamos, e tendo reservado um pequeno número de exemplos positivos para avaliar nossos algoritmos para usar ou na validação cruzada do conjunto, ou do conjunto de testes. E só um comentário à parte sobre estes vários tipos distintos de anomalias. Em alguns vídeos anteriores falamos sobre exemplos de e-mail spam. Naqueles exemplos, na verdade há vários tipos distintos de e-mail spam, certo? Há e-mail spam que tenta vender coisas. E-mail spam tentando roubar senhas, este é chamado de e-mail phishing e muitos tipos distintos de e-mails de spam. Mas para o problema do spam geralmente temos exemplos de spam suficientes para ver a maioria destes tipos distintos de e-mail spam porque nos temos um grande conjunto de exemplos de spam. E esta é a razão de geralmente pensarmos em spam como uma configuração de aprendizagem supervisionada mesmo que hajam muitos tipos distintos deles. Se olharmos para alguns aplicativos de detecção de anomalias versus aprendizagem supervisionada encontraremos detecção de fraude. Se você tem muitos tipos distintos dos modos que as pessoas cometem fraudes e um número relativamente pequeno de usuários fraudulentos em seu website, então eu usaria um algoritmo de detecção de anomalia. Devo dizer que, se você tem, se você é um grande revendedor online e se você de fato tem muitas pessoas cometendo fraude em seu website, então você na verdade tem muitos exemplos de y=1, então algumas vezes a detecção de fraude poderia na verdade mudar para a coluna de aprendizagem supervisionada. Mas, se você não tem visto muitos exemplos de usuários fazendo coisas estranhas em seu website, então a detecção de fraude mais frequentemente deve ser tratada como um algoritmo de detecção de anomalia ao invés de um algoritmo de aprendizagem supervisionada. Outros exemplos, nós já falamos sobre fabricação. Felizmente, mais e mais vemos exemplos que não são muitas anomalias, mas se de novo, para alguns processos de fabricação, se você produz em volumes muito grandes e você vê muitos exemplos defeituosos, pode ser que sua produção mude também para a coluna de aprendizagem supervisionada. Mas se você não tem encontrado muitos exemplos com defeito então a detecção de anomalias nas máquinas de monitoramento no datacenter podem resolver o problema aplicando argumentos semelhantes. Ao passo que, você deve ter classificação, previsão do tempo, e classificação de cânceres. Se você tem um número igual de exemplos positivos e negativos. Seus exemplos positivos e negativos, então tendemos a tratá-los todos como problemas de supervisor. Espero que isso lhe dê uma noção de uma das propriedades do problema de aprendizagem que o levaria a tratá-lo como um problema de detecção de anomalia versus um problema de aprendizagem supervisionada. E para muitos outros problemas que você se deparar em diversas empresas de tecnologia e assim por diante, nós, na verdade, estamos estabelecendo onde temos muito poucos ou algumas vezes nenhum exemplo treinado zero positivo. Simplesmente há tantas formas distintas de anomalias que nós nunca vimos antes. E para tais tipos de problemas, frequentemente o algoritmo que usamos é o de detecção de anomalia.