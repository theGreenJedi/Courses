1
00:00:00,120 --> 00:00:01,220
前回のビデオでは

2
00:00:01,850 --> 00:00:03,200
アノマリー検出のアルゴリズムを開発した。

3
00:00:04,150 --> 00:00:05,240
このビデオでは、具体的な問題に対して

4
00:00:05,300 --> 00:00:06,870
どのようにアノマリー検出を

5
00:00:07,090 --> 00:00:08,750
適用するか、

6
00:00:09,060 --> 00:00:10,790
そのプロセスを

7
00:00:11,410 --> 00:00:12,810
議論していく。特に、

8
00:00:13,470 --> 00:00:14,500
今回はアノマリー検出アルゴリズムの評価を

9
00:00:15,090 --> 00:00:18,700
どう行うかについてフォーカスしていきたい。

10
00:00:18,880 --> 00:00:20,490
前回のビデオでは、実数による評価の

11
00:00:20,800 --> 00:00:22,380
重要性について話してきた。

12
00:00:22,570 --> 00:00:24,770
これは、特定の応用に関する

13
00:00:25,170 --> 00:00:26,810
学習アルゴリズムを

14
00:00:27,270 --> 00:00:28,460
開発しようとしている時に、

15
00:00:28,690 --> 00:00:30,300
通常たくさんの選択を

16
00:00:30,560 --> 00:00:31,540
行う必要がある、たとえばどのフィーチャーを使うか、

17
00:00:31,710 --> 00:00:34,410
などを選択する必要がある、という発想を捉えている。

18
00:00:35,010 --> 00:00:36,800
これらの選択の全てについて、

19
00:00:36,880 --> 00:00:38,540
決断を下すには、

20
00:00:38,780 --> 00:00:39,890
あなたの学習アルゴリズムを評価する

21
00:00:40,040 --> 00:00:41,330
数字が得られる方が、

22
00:00:41,410 --> 00:00:43,190
より簡単になる事がしばしばある。

23
00:00:44,200 --> 00:00:44,950
たとえば、もう一つ追加の

24
00:00:45,980 --> 00:00:47,130
フィーチャーを加えるかについて、

25
00:00:47,220 --> 00:00:49,730
何か追加のフィーチャーについて心当たりがある時、

26
00:00:50,560 --> 00:00:51,560
もしそのフィーチャーを加えて

27
00:00:51,760 --> 00:00:52,830
アルゴリズムを走らせて、

28
00:00:52,960 --> 00:00:54,420
さらにフィーチャー無しでアルゴリズムを走らせて

29
00:00:54,570 --> 00:00:55,960
そこから数字を得たら、

30
00:00:56,100 --> 00:00:57,350
それがこのフィーチャーを加えた事で

31
00:00:57,460 --> 00:01:00,070
パフォーマンスが改善したか悪化したかを教えてくれる。

32
00:01:00,670 --> 00:01:01,480
それはつまり、そのフィーチャーを

33
00:01:01,670 --> 00:01:04,370
含めるべきかどうかを決定する為の

34
00:01:04,590 --> 00:01:06,110
より良い、よりシンプルな方法を提供してくれる。

35
00:01:07,570 --> 00:01:09,010
だから、アノマリー検出の

36
00:01:09,200 --> 00:01:10,850
システムを手早く

37
00:01:11,410 --> 00:01:13,880
開発する為には、

38
00:01:14,080 --> 00:01:14,960
そのアノマリー検出のシステムを

39
00:01:15,150 --> 00:01:17,820
評価する方法がある事は、とても有用だ。

40
00:01:19,260 --> 00:01:20,420
これを行う為に、

41
00:01:20,790 --> 00:01:22,380
アノマリー検出のシステムを

42
00:01:22,730 --> 00:01:24,080
評価する為に、

43
00:01:24,310 --> 00:01:26,380
実際にはあるラベル付けされたデータを仮定する。

44
00:01:27,270 --> 00:01:28,270
ここまでの所、アノマリー検出を

45
00:01:28,420 --> 00:01:29,870
教師なし学習として

46
00:01:30,310 --> 00:01:31,770
扱ってきた、ラベル付けされていない

47
00:01:32,210 --> 00:01:33,560
データを扱って。

48
00:01:34,010 --> 00:01:35,190
でも、もしどれがアノマリーのサンプルかを

49
00:01:35,560 --> 00:01:37,390
示すラベルのついたデータが

50
00:01:37,700 --> 00:01:39,570
あれば、そしてどれが

51
00:01:39,670 --> 00:01:42,030
非アノマリーのサンプルかを示すデータがあれば、

52
00:01:42,470 --> 00:01:43,350
これは普通の、アノマリー検出のアルゴリズムを

53
00:01:43,630 --> 00:01:45,670
評価する方法と考える事が出来る。

54
00:01:45,820 --> 00:01:49,020
航空機野エンジンの例を

55
00:01:49,300 --> 00:01:50,580
ふたたび考えよう。

56
00:01:51,010 --> 00:01:52,680
ラベル付けされたデータで、

57
00:01:53,070 --> 00:01:55,840
そのうちのちょっとだけが

58
00:01:56,330 --> 00:01:57,890
アノマリーの航空機エンジンの

59
00:01:58,400 --> 00:02:00,780
サンプル、つまり過去に製造されていてアノマリーだと、

60
00:02:01,520 --> 00:02:02,360
欠陥品か、とにかく何らかの意味で異常な物だと判明しているとする。

61
00:02:02,400 --> 00:02:04,130
また、非アノマリーの

62
00:02:04,360 --> 00:02:05,750
完璧にオーケーな

63
00:02:06,100 --> 00:02:07,810
サンプルも幾つか

64
00:02:08,050 --> 00:02:10,200
あるとしよう。

65
00:02:10,940 --> 00:02:12,050
y=0をノーマル、

66
00:02:12,110 --> 00:02:13,600
または非アノマリーのサンプルを

67
00:02:13,790 --> 00:02:15,470
表すのに使い、

68
00:02:15,530 --> 00:02:21,450
そしてy=1を、アノマリーのサンプルを表すのに使う。

69
00:02:22,450 --> 00:02:24,670
アノマリー検出のアルゴリズムを開発し、

70
00:02:25,130 --> 00:02:26,450
評価していくプロセスは以下のようになる。

71
00:02:27,500 --> 00:02:28,300
まずはトレーニングセットについて、

72
00:02:28,560 --> 00:02:29,830
ところでクロスバリデーションセットと

73
00:02:30,000 --> 00:02:31,310
テストセットについては後で話すが、

74
00:02:31,440 --> 00:02:32,580
まずはトレーニングセットについて。

75
00:02:33,280 --> 00:02:34,000
これは普通、ラベルづけされてない

76
00:02:35,040 --> 00:02:36,180
トレーニングセットと考える。

77
00:02:36,510 --> 00:02:37,250
これは普通の、

78
00:02:37,560 --> 00:02:39,580
アノマリーで無いデータが

79
00:02:40,190 --> 00:02:41,130
大量に集まっている、と考える。

80
00:02:42,400 --> 00:02:43,530
普通はこれを非アノマリーと

81
00:02:43,690 --> 00:02:44,750
考えるが、

82
00:02:45,010 --> 00:02:46,490
だが実際はちょっとアノマリーなのが

83
00:02:46,740 --> 00:02:48,660
紛れ込むくらいはオーケーだ。

84
00:02:48,660 --> 00:02:51,240
それがラベル無しトレーニングセットに入っちゃってても。

85
00:02:51,420 --> 00:02:52,100
次に、クロスバリデーションセットと

86
00:02:52,310 --> 00:02:53,830
テストセットを

87
00:02:54,100 --> 00:02:55,510
定義する。

88
00:02:55,750 --> 00:02:58,360
それで個々のアノマリー検出アルゴリズムの評価を行う。

89
00:02:59,230 --> 00:03:00,850
つまり、具体的には、クロスバリデーションと

90
00:03:01,000 --> 00:03:01,960
テストセットではどちらも、

91
00:03:02,080 --> 00:03:03,590
アノマリーだと分かっている

92
00:03:03,800 --> 00:03:05,030
サンプルが含まれているという

93
00:03:05,670 --> 00:03:06,720
前提だ。

94
00:03:06,900 --> 00:03:08,150
クロスバリデーションにも

95
00:03:08,910 --> 00:03:09,660
テストセットにも。

96
00:03:10,200 --> 00:03:11,410
つまりテストセットには

97
00:03:11,950 --> 00:03:13,270
y=1となるサンプルが

98
00:03:13,340 --> 00:03:14,770
幾つか含まれている。

99
00:03:15,040 --> 00:03:17,470
それはアノマリーな航空機エンジンに対応している。

100
00:03:18,640 --> 00:03:19,800
具体的にはこうだ。

101
00:03:20,930 --> 00:03:23,120
これらを合わせて、我らの持ってる

102
00:03:23,280 --> 00:03:24,990
データだとしよう。

103
00:03:25,260 --> 00:03:27,410
1万機の、分かってる範囲では

104
00:03:28,130 --> 00:03:29,140
完全に正常な

105
00:03:29,450 --> 00:03:30,740
航空機エンジンを製造したとしよう。

106
00:03:31,220 --> 00:03:33,110
完全に良い航空機エンジン。

107
00:03:34,060 --> 00:03:35,240
そしてここでも、ちょっとの

108
00:03:35,560 --> 00:03:37,310
欠陥品がこの1万の中に

109
00:03:37,740 --> 00:03:39,400
紛れ込んでたとしても、

110
00:03:39,550 --> 00:03:40,860
実際はオーケーだ。

111
00:03:40,970 --> 00:03:41,970
だがこれらの中の大多数は

112
00:03:42,410 --> 00:03:44,300
良い、普通の、アノマリーでない

113
00:03:44,500 --> 00:03:47,660
エンジンである、と仮定する。

114
00:03:48,480 --> 00:03:50,940
そしてこれまでに

115
00:03:51,200 --> 00:03:52,120
長い期間工場を運営してきて、

116
00:03:52,650 --> 00:03:54,130
フィーチャーを計測していて

117
00:03:54,480 --> 00:03:55,930
だいたい20機の

118
00:03:56,440 --> 00:03:57,970
欠陥エンジン、

119
00:03:58,240 --> 00:04:00,180
アノマリーのエンジンを得ているとする。

120
00:04:01,120 --> 00:04:03,030
ところでアノマリー検出の

121
00:04:03,310 --> 00:04:05,490
きわめて典型的な適用ケースでは、

122
00:04:06,740 --> 00:04:08,090
アノマリーのサンプルの数は、つまりy=1となるサンプルの数は

123
00:04:08,760 --> 00:04:10,650
だいたい20から50ってあたりだ。

124
00:04:10,820 --> 00:04:12,920
この辺が

125
00:04:13,360 --> 00:04:14,570
典型的なy=1となる

126
00:04:14,830 --> 00:04:16,710
数の範囲。

127
00:04:16,910 --> 00:04:17,730
そして通常は、もっとずっと多くの

128
00:04:17,860 --> 00:04:20,000
正常なサンプルがある。

129
00:04:21,810 --> 00:04:23,150
だからデータセットが与えられた時の

130
00:04:24,180 --> 00:04:25,410
極めて標準的な

131
00:04:25,850 --> 00:04:27,150
トレーニングセット、クロスバリデーションセット、

132
00:04:27,430 --> 00:04:29,210
テストセットの分割方法は以下のようになる。

133
00:04:30,390 --> 00:04:31,880
1万の良品の航空機エンジンから

134
00:04:32,360 --> 00:04:34,060
6000をラベル無しの

135
00:04:34,260 --> 00:04:37,100
トレーニングセットとして取り分ける。

136
00:04:37,620 --> 00:04:38,800
これをラベル無しと言ったが、

137
00:04:39,130 --> 00:04:40,050
これらは全てy=0に対応した

138
00:04:40,640 --> 00:04:42,510
サンプルだ、

139
00:04:42,810 --> 00:04:44,380
我らの知る限りは。

140
00:04:45,300 --> 00:04:46,350
そしてこれをp(x)をフィットするのに

141
00:04:46,520 --> 00:04:48,840
使う。

142
00:04:49,150 --> 00:04:49,850
つまり我らはこれら6000のエンジンを

143
00:04:50,350 --> 00:04:51,180
p(x)をフィットするのに使う、

144
00:04:51,360 --> 00:04:52,190
ここでp(x1)は

145
00:04:52,420 --> 00:04:53,930
ミュー1とシグマ二乗1で

146
00:04:54,330 --> 00:04:56,380
パラメトライズされていて、

147
00:04:56,540 --> 00:04:57,700
これはp(xn)が

148
00:04:58,370 --> 00:04:59,570
ミューnとシグマ二乗nでパラメトライズされている所まで続く。

149
00:05:00,790 --> 00:05:02,300
つまりこれら6000の手本を使って

150
00:05:02,500 --> 00:05:03,930
パラメータの

151
00:05:04,110 --> 00:05:05,370
ミュー1、シグマ二乗1から

152
00:05:05,590 --> 00:05:06,760
ミューn、シグマ二乗nまでを

153
00:05:07,140 --> 00:05:08,960
推計する。

154
00:05:09,200 --> 00:05:10,280
以上が我らのトレーニングセットで

155
00:05:10,500 --> 00:05:11,960
それらは全て正常な、

156
00:05:12,150 --> 00:05:13,980
または少なくとも大部分が正常なサンプルだ。

157
00:05:15,430 --> 00:05:16,950
次に、正常な

158
00:05:17,140 --> 00:05:18,380
航空機エンジンの中から

159
00:05:18,660 --> 00:05:19,470
いくらかをクロスバリデーションセットに、

160
00:05:19,580 --> 00:05:21,320
さらにまた幾らかをテストセットに

161
00:05:21,570 --> 00:05:22,970
入れます。

162
00:05:23,280 --> 00:05:24,300
例えば6000+2000+2000。

163
00:05:24,480 --> 00:05:25,470
こんな風に1万機の

164
00:05:25,740 --> 00:05:28,820
正常な航空機エンジンを分割します。

165
00:05:29,260 --> 00:05:31,460
次に、20機の不良エンジンが

166
00:05:31,930 --> 00:05:33,380
あるとして、

167
00:05:33,490 --> 00:05:34,890
それを、例えば

168
00:05:35,160 --> 00:05:36,100
10個ずつに分けて、

169
00:05:36,200 --> 00:05:37,230
クロスバリデーションセットと

170
00:05:37,370 --> 00:05:39,560
テストセットにそれぞれ入れます。

171
00:05:39,850 --> 00:05:41,320
そして次のスライドで

172
00:05:41,660 --> 00:05:42,460
これらを実際に、どのように使って

173
00:05:42,750 --> 00:05:43,800
アノマリー検出のアルゴリズムを評価するかを

174
00:05:44,520 --> 00:05:46,330
議論していく。

175
00:05:48,130 --> 00:05:49,140
ここまでで私が

176
00:05:49,220 --> 00:05:50,610
書いてきた事は、

177
00:05:50,790 --> 00:05:52,300
ラベル付けされたデータとラベル付けされていないデータの

178
00:05:52,440 --> 00:05:55,290
分割する望ましい方法だ。

179
00:05:55,820 --> 00:05:57,970
航空機エンジンのうち、良品と欠陥品の。

180
00:05:58,480 --> 00:06:00,380
我らは良品に関しては

181
00:06:00,730 --> 00:06:01,650
60、20，20%に

182
00:06:01,800 --> 00:06:03,350
それぞれ分割し、

183
00:06:03,570 --> 00:06:04,780
欠陥品に関しては

184
00:06:04,910 --> 00:06:05,750
クロスバリデーションセットと

185
00:06:05,870 --> 00:06:06,940
テストセットだけに入れた。

186
00:06:07,030 --> 00:06:09,200
次のスライドでどうしてそうしたかが分かる。

187
00:06:10,370 --> 00:06:12,080
補足になるが、たまに世の中の人々が

188
00:06:12,360 --> 00:06:13,360
アノマリー検出のアルゴリズムを適用するやり方として、

189
00:06:13,750 --> 00:06:15,400
たまにデータを異なったやり方で

190
00:06:15,510 --> 00:06:16,980
分割してるのを見かける事もあるかもしれない。

191
00:06:17,460 --> 00:06:19,400
これはあまりオススメしない代替案だが

192
00:06:19,660 --> 00:06:21,290
代替案としては、

193
00:06:21,470 --> 00:06:23,650
ある人々は1万個の良品を

194
00:06:23,790 --> 00:06:24,770
6000個をトレーニングセットに、

195
00:06:24,820 --> 00:06:26,020
残りの4000をクロスバリデーションセットと

196
00:06:26,320 --> 00:06:27,130
テストセットの両方に

197
00:06:27,650 --> 00:06:28,800
入れる、という事を

198
00:06:30,380 --> 00:06:31,020
やるかもしれない。

199
00:06:31,170 --> 00:06:32,030
でもご存知の通り、クロスバリデーションセットと

200
00:06:32,360 --> 00:06:33,340
テストセットを

201
00:06:33,400 --> 00:06:34,620
完全に異なるデータと

202
00:06:35,280 --> 00:06:36,370
我々は思いたいのだった。

203
00:06:37,690 --> 00:06:39,030
だがアノマリー検出では、

204
00:06:39,230 --> 00:06:40,360
たまにテストセットと

205
00:06:40,600 --> 00:06:41,760
クロスバリデーションセットの

206
00:06:42,070 --> 00:06:42,970
両方に同じ良品のエンジンを

207
00:06:43,370 --> 00:06:44,640
使うのを見かける場合があり、

208
00:06:44,710 --> 00:06:46,150
時には欠陥品の方のエンジンまで

209
00:06:46,250 --> 00:06:48,070
全く同じセットを

210
00:06:48,180 --> 00:06:49,800
クロスバリデーションセットと

211
00:06:50,880 --> 00:06:54,190
テストセットに使ってるのを見る事すらある。

212
00:06:54,590 --> 00:06:55,970
これらは皆、より悪いやり方だと

213
00:06:56,850 --> 00:06:59,030
みなす事が出来るので、決してオススメしない。

214
00:07:00,250 --> 00:07:01,360
確実に、クロスバリデーションセットと

215
00:07:01,650 --> 00:07:02,530
テストセットで

216
00:07:03,200 --> 00:07:04,220
同じデータを使うのは

217
00:07:04,510 --> 00:07:06,400
機械学習における良い習慣では無い。

218
00:07:07,180 --> 00:07:08,780
でもたまにこれをやってる人を見かけるだろう。

219
00:07:09,790 --> 00:07:11,330
さて、トレーニング、クロスバリデーション、そしてテストセットが

220
00:07:11,550 --> 00:07:12,780
与えられたとして、

221
00:07:13,260 --> 00:07:15,220
これが評価方法、、、いや、

222
00:07:15,370 --> 00:07:16,920
これがアルゴリズムの開発方法と評価方法だ。

223
00:07:18,490 --> 00:07:19,510
まず、トレーニングセットに対し、

224
00:07:19,910 --> 00:07:20,750
モデルp(x)をフィッティングする。

225
00:07:20,840 --> 00:07:21,860
これら全てをガウス分布に

226
00:07:22,210 --> 00:07:24,600
フィッティングする。

227
00:07:25,060 --> 00:07:26,690
m個のラベル無し航空機エンジンのサンプルを。

228
00:07:27,090 --> 00:07:28,140
ところでこれらをラベル無しサンプルと

229
00:07:28,270 --> 00:07:29,560
呼んだが、実のところこれらは、

230
00:07:29,660 --> 00:07:31,370
良品、正常な航空機エンジンであると

231
00:07:31,790 --> 00:07:33,390
想定している。

232
00:07:34,580 --> 00:07:36,510
そして次に、アノマリー検出のアルゴリズムが

233
00:07:36,650 --> 00:07:38,590
実際に予測をしているのを想像してみよう。

234
00:07:39,030 --> 00:07:40,070
つまりクロスバリデーションとテストのセットに対し、

235
00:07:40,630 --> 00:07:42,280
サンプルxを検定する。

236
00:07:42,610 --> 00:07:44,660
p(x)がエプシロンより

237
00:07:44,840 --> 00:07:46,490
小さければ、

238
00:07:46,730 --> 00:07:48,090
アルゴリズムはy=1を

239
00:07:48,230 --> 00:07:49,320
予測したと考え、

240
00:07:50,040 --> 00:07:51,740
もしp(x)が

241
00:07:52,280 --> 00:07:54,760
エプシロン以上なら

242
00:07:54,950 --> 00:07:57,340
y =0に違いない、と考える。

243
00:07:58,390 --> 00:07:59,280
つまりxが与えられた時に、ラベルがどちらかを

244
00:07:59,340 --> 00:08:00,270
予測しようとする。y=1は

245
00:08:00,500 --> 00:08:01,470
アノマリーに対応し、

246
00:08:01,630 --> 00:08:06,380
y=0は通常のサンプルに対応する。

247
00:08:07,290 --> 00:08:09,480
ではトレーニング、クロスバリデーション、テストセットがそれぞれ与えられたとして、

248
00:08:09,940 --> 00:08:11,080
どうアルゴリズムを開発していくか？

249
00:08:11,480 --> 00:08:12,920
より詳細に言うと、

250
00:08:13,010 --> 00:08:15,450
アノマリー検出のアルゴリズムをどうやって評価するか？

251
00:08:15,790 --> 00:08:17,470
これらを元に、

252
00:08:17,820 --> 00:08:19,410
最初のステップは

253
00:08:19,670 --> 00:08:21,130
ラベル無しのトレーニングセットに対し

254
00:08:21,290 --> 00:08:23,520
モデルp(x)をフィッティングする。

255
00:08:23,990 --> 00:08:25,060
つまりこれを取るのだが、

256
00:08:25,130 --> 00:08:26,620
これはラベル無しトレーニングセットと言っているが、

257
00:08:26,910 --> 00:08:28,390
実際は、それらの大多数は

258
00:08:28,870 --> 00:08:30,290
通常の航空機エンジンだと

259
00:08:30,750 --> 00:08:32,400
想定している物だった。

260
00:08:32,900 --> 00:08:34,020
それらはアノマリーでは無さそうだから

261
00:08:34,150 --> 00:08:35,380
それにモデルp(x)を

262
00:08:35,490 --> 00:08:36,470
フィッティングする訳だ。

263
00:08:36,640 --> 00:08:38,110
このパラメータ全部で、、、

264
00:08:38,240 --> 00:08:40,330
これらガウス分布のデータ全てでフィッティングする。

265
00:08:41,560 --> 00:08:43,190
次にクロスバリデーションとテストセットに対して、

266
00:08:43,300 --> 00:08:44,480
アノマリー検出の

267
00:08:44,600 --> 00:08:45,460
アルゴリズムを、

268
00:08:46,100 --> 00:08:47,530
yの値を予測する物と

269
00:08:47,640 --> 00:08:48,580
みなす。

270
00:08:49,540 --> 00:08:51,670
つまり各テストのサンプルに

271
00:08:52,430 --> 00:08:53,470
対して、

272
00:08:54,140 --> 00:08:56,110
これらxi testと

273
00:08:57,200 --> 00:08:58,720
yi testがある訳だが、

274
00:08:58,870 --> 00:09:00,100
ここでyは、これがアノマリーかどうかに応じて

275
00:09:00,320 --> 00:09:03,230
1か0のどちらかの値を取る。

276
00:09:04,370 --> 00:09:05,510
テストセットから入力xが与えられた時、

277
00:09:05,600 --> 00:09:07,340
このアノマリー検出のアルゴリズムを

278
00:09:07,730 --> 00:09:08,850
p(x)がイプシロンより小さかったら

279
00:09:09,100 --> 00:09:11,880
yが1と予測している、とみなす。

280
00:09:12,240 --> 00:09:15,120
つまりそれがアノマリーと予測するという事は、そんなサンプルとなる確率がとても低いという事だ。

281
00:09:15,960 --> 00:09:17,810
そしてアルゴリズムは、 p(x)がイプシロンより大きいか等しい場合に

282
00:09:17,970 --> 00:09:20,830
y=0を予測しているとみなす。

283
00:09:21,290 --> 00:09:23,600
つまりp(x)が普通の感覚で十分に大きければ

284
00:09:24,200 --> 00:09:26,340
それらを正常なサンプルとみなす。

285
00:09:27,350 --> 00:09:28,510
つまり、これでアノマリー検出のアルゴリズムを

286
00:09:28,720 --> 00:09:29,930
これらのテストセット、クロスバリデーションセットの

287
00:09:30,580 --> 00:09:32,040
yラベルの値を

288
00:09:32,240 --> 00:09:33,490
予測するものと

289
00:09:33,830 --> 00:09:35,080
みなす事が

290
00:09:36,050 --> 00:09:37,000
出来た訳だ。

291
00:09:37,720 --> 00:09:39,140
これはようするに、教師有り学習に

292
00:09:39,670 --> 00:09:41,250
似たようなセッティングになる、でしょ？

293
00:09:41,620 --> 00:09:42,870
そこではラベル付きのテストセットがあって、

294
00:09:43,170 --> 00:09:44,550
我らのアルゴリズムは

295
00:09:44,800 --> 00:09:46,060
これらのラベルに対して予測を行う。

296
00:09:46,190 --> 00:09:48,050
つまりこれらのラベルを

297
00:09:48,480 --> 00:09:50,930
どれだけ当てられるかで、それを評価する訳だ。

298
00:09:52,180 --> 00:09:53,820
もちろんこれらのラベルは

299
00:09:54,540 --> 00:09:56,420
とても歪んだ割合となっている、

300
00:09:56,710 --> 00:09:57,930
何故ならy=0、それは正常なサンプルだが、

301
00:09:58,300 --> 00:10:00,490
このケースの方が通常は

302
00:10:00,780 --> 00:10:01,930
y=1、つまりアノマリーのサンプルとなるよりも

303
00:10:02,310 --> 00:10:03,520
ずっと一般的だからだ。

304
00:10:04,660 --> 00:10:05,610
だがそれも、教師有り学習の

305
00:10:06,040 --> 00:10:06,990
評価で使った評価指標と

306
00:10:07,690 --> 00:10:09,770
似た事情だ。

307
00:10:12,390 --> 00:10:14,500
ではどの評価指標を使うのが良いか？

308
00:10:14,790 --> 00:10:18,530
データはとても歪んでいるのだから

309
00:10:18,840 --> 00:10:20,450
y =0の方がずっと一般的なのだから、

310
00:10:20,880 --> 00:10:22,980
分類の精度はきっと

311
00:10:23,520 --> 00:10:24,950
良い指標では無いだろう。

312
00:10:25,360 --> 00:10:26,760
この件は以前のビデオで議論した。

313
00:10:28,360 --> 00:10:29,130
もしとても歪んだ

314
00:10:29,410 --> 00:10:31,360
データセットに対するなら、

315
00:10:31,740 --> 00:10:32,750
いつもy=0と予測するだけで、

316
00:10:33,430 --> 00:10:34,300
とても高い分類精度が得られてしまう。

317
00:10:35,690 --> 00:10:36,820
その代わりに、以下のような評価指標を使うべきだ:

318
00:10:37,330 --> 00:10:38,920
真陽性（true positive）、偽陽性（false  positive）、

319
00:10:39,530 --> 00:10:41,030
偽陰性（false negative）、真陰性（true nagative）の

320
00:10:41,670 --> 00:10:42,940
比率の計算結果とか、

321
00:10:43,580 --> 00:10:44,830
適合率（precision）と再現率（recall）を

322
00:10:44,890 --> 00:10:46,370
計算するとか、

323
00:10:46,790 --> 00:10:48,370
F1スコアなど、、、これは

324
00:10:48,520 --> 00:10:50,510
適合率と再現率を

325
00:10:50,630 --> 00:10:51,680
一つの実数で要約するような物だったが、

326
00:10:52,600 --> 00:10:53,450
それを計算するなどする。

327
00:10:54,340 --> 00:10:55,090
これらがクロスバリデーションセットとテストセットで

328
00:10:55,750 --> 00:10:56,940
アノマリー検出のアルゴリズムを

329
00:10:57,320 --> 00:10:59,090
評価する方法となる。

330
00:11:01,550 --> 00:11:02,960
最後に、

331
00:11:03,100 --> 00:11:05,050
アノマリー検出のアルゴリズムには

332
00:11:05,200 --> 00:11:06,720
このイプシロン、というバラメータもあった。

333
00:11:07,400 --> 00:11:09,100
イプシロンはある物を

334
00:11:09,920 --> 00:11:11,320
アノマリーとフラグ付けするかを決定する

335
00:11:11,790 --> 00:11:13,630
閾値となる。

336
00:11:14,840 --> 00:11:16,740
だからクロスバリデーションセットが

337
00:11:16,840 --> 00:11:18,380
ある時に、このパラメータ

338
00:11:19,000 --> 00:11:20,320
イプシロンを選ぶ、もう一つの方法は、

339
00:11:20,710 --> 00:11:22,020
たくさんの異なる

340
00:11:22,240 --> 00:11:24,090
イプシロンの値を、

341
00:11:24,340 --> 00:11:26,220
ほんとにたくさん試して、

342
00:11:26,380 --> 00:11:27,520
そして例えばf1スコアを最大化する

343
00:11:27,990 --> 00:11:30,670
イプシロンを選ぶという方法が考えられる。

344
00:11:31,620 --> 00:11:33,940
そうすれば、クロスバリデーションセットでは良い結果が得られるから。

345
00:11:35,340 --> 00:11:36,770
より一般的には、

346
00:11:37,000 --> 00:11:38,230
トレーニング、テスト、そして

347
00:11:38,630 --> 00:11:40,230
クロスバリデーションセットを減らす方法としては、

348
00:11:41,760 --> 00:11:43,020
意思決定をしようとする時には、

349
00:11:43,640 --> 00:11:45,430
例えばどのフィーチャーを含めるべきかとか、

350
00:11:45,570 --> 00:11:46,580
またはパラメータのイプシロンをチューンしたい時には、

351
00:11:47,100 --> 00:11:48,160
クロスバリデーションセットに対して

352
00:11:48,410 --> 00:11:51,010
継続的にアルゴリズムを

353
00:11:51,500 --> 00:11:52,870
評価して、

354
00:11:53,000 --> 00:11:54,120
それらの決定は全て、、、

355
00:11:54,320 --> 00:11:55,700
例えばどのフィーチャーを含めるかとか

356
00:11:55,790 --> 00:11:57,650
イプシロンを幾つに設定するかとか、

357
00:11:58,240 --> 00:11:59,410
そういう時はクロスバリデーションセットに対してアルゴリズムを評価し、

358
00:11:59,880 --> 00:12:00,870
そしてフィーチャーを選んだり、

359
00:12:01,320 --> 00:12:02,770
これでいい！と思うイプシロンの値を

360
00:12:02,910 --> 00:12:03,860
選んだ時には、

361
00:12:04,070 --> 00:12:05,150
その最終的にモデルで、

362
00:12:05,250 --> 00:12:07,030
それをテストセットに対し

363
00:12:07,270 --> 00:12:08,680
アルゴリズムの評価を

364
00:12:08,770 --> 00:12:11,360
行う。

365
00:12:12,680 --> 00:12:13,900
このビデオでは、

366
00:12:14,180 --> 00:12:15,240
アノマリー検出の

367
00:12:15,520 --> 00:12:17,060
アルゴリズムの評価をどうやるか、の

368
00:12:17,520 --> 00:12:18,970
手順を議論した。

369
00:12:19,960 --> 00:12:21,220
ここでも、アルゴリズムを

370
00:12:21,410 --> 00:12:22,540
評価する時には、

371
00:12:22,640 --> 00:12:23,830
単一の実数による評価、

372
00:12:24,730 --> 00:12:25,630
例えばF1スコアみたいな物は、

373
00:12:26,530 --> 00:12:27,660
しばしばあなたの時間を

374
00:12:28,080 --> 00:12:29,710
より効率的に使わせてくれる、

375
00:12:29,960 --> 00:12:31,160
アノマリー検出のシステムを

376
00:12:31,280 --> 00:12:33,250
開発しようとしている時には。

377
00:12:33,800 --> 00:12:34,970
そしてこの種の意思決定、たとえば

378
00:12:35,650 --> 00:12:38,020
イプシロンを選ぶとか、どのフィーチャーを含めるかとか、そういう意思決定をしたい時には。

379
00:12:38,970 --> 00:12:39,920
このビデオでは、アノマリー検出の

380
00:12:40,330 --> 00:12:40,830
アルゴリズムを評価する為に、

381
00:12:41,590 --> 00:12:42,750
ラベル付けされたデータを

382
00:12:43,020 --> 00:12:43,550
少量使う。

383
00:12:43,570 --> 00:12:45,710
これはちょっとだけ

384
00:12:45,890 --> 00:12:48,340
教師有り学習に近くなる。

385
00:12:49,610 --> 00:12:50,810
次のビデオでは、

386
00:12:51,000 --> 00:12:52,780
その事ついてもうすこし説明します。

387
00:12:52,940 --> 00:12:54,240
特に、どういう時はアノマリー検出アルゴリズムを

388
00:12:54,440 --> 00:12:55,860
使うべきで、

389
00:12:56,310 --> 00:12:57,130
どういう時はその代わりに教師有り学習を

390
00:12:57,560 --> 00:13:00,770
採用すべきか、そしてこれら2つの形式化の違いについても扱います。