ここまでで我々は アノマリー検出のアルゴリズムを見てきた。 また、アノマリー検出のアルゴリズムを どう評価するのかも見てきた。 実は、実際に アノマリー検出を適用してみると、 それがどれだけ うまく機能するかに 巨大な影響を与えているのは なんのフィーチャーを使うのか、 何のフィーチャーを選んで アノマリー検出のアルゴリズムに与えるか、という部分だ。 だからこのビデオでは、 アノマリー検出のアルゴリズムに 食わせるフィーチャーを どうデザインするか、どう選ぶかについて 二、三の助言、 提案をしたいと思う。 我らのアノマリー検出のアルゴリズムにおいては こんな種類のガウス分布を用いて フィーチャー達をモデリングするという過程があります。 xiを、ミューiと シグマ二乗iで。 そうであるから、私が良く やる事としては、 私のアノマリー検出のアルゴリズムに データを食わせる前に このデータのヒストグラムをプロットしてみて なんとなくガウス分布っぽいかを 見てみる、という事があります。 あなたのデータがガウス分布でなくても 普通はオーケーです。 だけどこれは、実行してみるに値する、良いサニティチェックです。 ところで、あなたのデータが非ガウス分布をとっていても、 アルゴリズムは普通に正しく機能する事が多い。 具体的に見ると データをこんな風にプロットしてみて、 ヒストグラムがこんな感じに見えたら ところでヒストグラムの プロットの仕方は hist関数を Octaveでは使いますが そこでこんな見た目なら、 これはだいたいガウス分布っぽい。 つまりフィーチャーがこんな感じなら アルゴリズムに、とても幸せな気持ちで食わせられる。 だが、もしもデータのヒストグラムをプロットしてみたら それがもしもこんな感じなら、 うーん、 こいつはベル型のカーブには まったく見えないなぁ。
これはとても非対称な分布だ。 これはピークが片側に偏り過ぎている。 もしこんな風に私のデータが見えたら 私が良くやる手段は 様々なデータ変換を試して もっとガウス分布っぽく 見えるようにする。 繰り返しになるが、別にそんな事しなくても、だいたいはアルゴリズムはちゃんと機能する。 でももしこれらの変換でデータをより ガウス分布っぽく見えるように出来たら、そっちの方がアルゴリズムはちょっとだけ改善される。 だからこんな見た目の データセットが与えられた時、 私が試すだろう事は logをとってデータを変換し その後に データをヒストグラムとして再プロットして この例の場合は例えば 結果としてこんな ヒストグラムを得る。 こっちの方がガウス分布っぽいでしょう？ こっちの方がより古典的な ベル型のカーブに見える。 それはある平均と分散のパラメータでフィッティング出来る。 ログ変換を取る、と言っているのは 具体的には あるフィーチャーx1があったとして、 そのx1のヒストグラムがこんな見た目だとすると フィーチャーx1を log x1で 置き換える。 そしてこれを 新しいx1とみなし、 それのヒストグラムを右にプロットすると、 よりガウス分布っぽくなっている。 log変換の他に、選択肢として考えられる物は 異なるフィーチャー x2があったとして、 それをlog(x+1)で 置き換える、 またはより一般に log xのxをx2とある定数c で 置き換えた物で置き換える、というのが考えられる。 この定数cはいろいろ調整して なるべくガウス分布っぽく見えるようにする。 他には別のフィーチャーx3に対し x3をルートを取った物で 置き換えても良いかもしれない。 ルートってのはx3の、単なる1/2乗に過ぎない、でしょ？ そしてこの1/2というのも いろいろ調整する事が出来るパラメータとなる。 x4があったとして、 そのx4を代わりに x4の違う指数乗、例えば 1/3乗とかで 置き換えても良い。 そしてこれら全て、 これ、この指数乗の パラメータ、または パラメータCも、 これら全てがあなたのデータを ちょっとでもガウス分布っぽく見せる為に いじれるパラメータの例となる。 ではここで、私のデータを 実際にいろいろいじって よりガウス分布っぽくする生のデモをお見せしよう。 その為、ここに既に Octaveにロードしておいた、 幾つかのフィーチャーxを。千のサンプルをここでは ロードしておいた。 では私のデータのヒストグラムを出しておこう、 このhist xのコマンドで。 これが私のヒストグラムだ。 デフォルトだと確か この10個のビンをヒストグラムは使うと思うが 私はもっと粒度の細かいグリッドのヒストグラムを見たい。 だからhistに x, 50と渡す これは50個のことなるビンでプロットする。 オーケー。良くなった。 現在のところ、これはそんなにガウス分布っぽくは無い。でしょ？ だからちょっとデータをいじってみよう。 まずhistの xの0.5乗を試してみよう。 つまりデータのルートを取って そのヒストグラムをプロットする。 オーケー。ちょっとガウスっぽく なってきた。だがまだまだだね。 ではこの0.5というパラメータをいじってみよう。 どうなるか？ これを0.2にセットする。 もうちょっとガウス分布っぽくなった。 もうちょっと減らして0.1にしてみよう。 いえーい！凄い良くなった！ これは実際だったら0.1で良い気がするね。 さらに減らして0.05にしてみよう。 ご想像の通り、、、 よし、これはいい感じにガウス分布だ。 だから新しいフィーチャーとして xミュー イコール xの0.05乗 と定義する。 するとこの新しいフィーチャー xミューは、以前のよりも よりガウス分布っぽくなって、 これを代わりに アノマリー検出のアルゴリズムに 食わせても良い。 もちろん、これを行う方法は一つだけでは無い。 histのlog xというのも試しても良い。 それはもう一つの試してみる価値のある変換の例だ。 そしてこれも、見ての通りなかなかガウスっぽい。 だからxミューを log xと定義しても良い。 これもまたなかなか良い フィーチャーのチョイスといえる。 まとめると、データのヒストグラムを プロットしてみて、 それがだいぶガウス分布っぽくなかったら 今回試したような変換で ちょっとデータをつついてみるのは 試してみる価値がある。 もうちょっとガウス分布っぽく ならないかなぁ、と 学習アルゴリズムに食わしてみる前に。 やらなかったとしても、 たぶんうまく機能するけどね。 でも普段、私はこのステップを踏む。 ここで二番目に話したい事として、 アノマリー検出に使うフィーチャーを どう見つけるか、というのがある。 私が良くやるのは 誤差分析の手順だ。 それの意味する所は 教師有り学習での 誤差分析の手順と 本当に似た物で、 そこでは完全にアルゴリズムを 学習させて、 それをクロスバリデーションセットにかける、 そして間違いのサンプルを見る、 そしてフィーチャーを追加して それがクロスバリデーションセットで 誤りだった物を 正しく扱う助けとなるかを 見てみる。 ではこのプロセスを 例を通して見てみよう。 アノマリー検出のアルゴリズムにおいては 通常のサンプルについてはpのxが大きく、 アノマリーなサンプルでは小さくなる事を 期待している。 だから、良くある問題としては pのxが同じような値という場合、 例えば普通の物とアノマリーな物が両方とも大きい場合などだ。 その具体例を見てみよう。 これが私のラベル無しデータとする。 ここではたった一つのフィーチャーx1しか無いので これをガウス分布でフィッティングする。 そしてフィッティングしたガウス曲線がこんな感じだったとしよう。 そしてアノマラスなサンプルがあったとしよう。 そしてそのアノマラスなサンプルはxの値 2.5を取るとする。 このアノマラスなサンプルをプロットしてみた。 すると見ての通り、 それはたくさんの普通のサンプルの中に 埋もれてしまっている。 つまりこのアノマラスなサンプルは 緑で描いた物だが、それは とても高い確率となる。それは青い曲線の 高さで表される訳だ。 そしてアルゴリズムはこれを アノマラスなサンプルだとフラグづけする事に失敗してしまう。 ここで、これは航空機エンジンの 製造とかだとしよう。 ここで実際に取れる対策としては トレーニングサンプルを実際に見て、 うまく行っていない特定の不良エンジンについて どこが悪くなっているかを調べる。 そしてもしそのエンジンを調べていて それにインスパイアされて 新たなフィーチャーx2を思いついたとする。 それがこの不良エンジンを 識別するには有用な訳だ。 残りの赤いサンプル、 私の全ての正常な航空機エンジンと 比較して。 そしてなんとかそこまで行ったら 以下のような事を期待する訳だ: 新しいフィーチャーx2を作って、 私のデータを再プロットしたら トレーニングセットの正常なサンプルは プロットしてみたら 正常なサンプルは 赤いバツのサンプルは こんな感じで見えたとして、 アノマラスなサンプルは フィーチャーx2が 異常な値を取るという風に出来る事を期待する訳だ。 例えば私のこの緑のサンプル このアノマリーは x1の値は2.5のままだけど、 x2の値は例えば、 とても大きな値とか、 こっちの3.5とかそういう値か、 またらとても小さな値を期待する訳だ。 ここでこのデータをモデリングすると、 アノマリー検出のアルゴリズムは まんなかのあたりの領域のデータに 高い確率を与え、 そのちょっと低い確率がこの辺に、 それよりさらにちょっと低い確率がこの辺に、となる。 そしてこの遥か遠くのサンプルに対しては 私のアルゴリズムは ここではとても低い 確率を与えるだろう。 つまりこのプロセスは 実際に間違いだった物、 アルゴリズムがフラグ付けに失敗した アノマリーを直接調べて、 それが新しいフィーチャーを作るよう インスパイアしてくれるかどうかを見てみる。 その航空機エンジンの 何か普通で無い所を探して それを用いて新しいフィーチャーを作る。 この新しいフィーチャーで 正常なサンプルとアノマリー達を より簡単に区別出来るようになるように。 以上が誤差解析の 手順であり、 それをアノマリー検出に使う 新しいフィーチャーを作るのに使うやり方だ。 最後に、私が普段 アノマリー検出のフィーチャーを選ぶのに どうやってるのかについて、私の考えを共有しておきたい。 普段私がフィーチャーの選択についてどう考えているかといえば、 アノマリーのサンプルだと思う時には なるべく凄く凄く小さくなるか 凄く凄く大きくなるような フィーチャーを 探したい、と考えている。 ここでも再びコンピューターのデータセンターの モニタリングの例を考えてみよう。 たくさんのマシンがあって たとえば何千とか何万とかのマシンが データセンターにあるかもしれない。 そしてマシンの一つが コンピュータの一つが いかれているか、つまり何か妙な事をしているかを知りたい。 そこでこんなフィーチャーを選ぶかもしれない。 メモリー使用量とかディスクアクセスの回数とかCPUロードとかネットワークトラフィックとか。 だがここで、失敗してるケースの一つに、 私のデータセットの失敗してるケースの一つが、 CPUロードとネットワークトラフィックが 共にリニアに増えていくと 疑っていると しよう。 例えばたくさんのwebサーバを走らせていて そのサービスの一つが たくさんのユーザに対して サービスを提供していたら とても高いCPUロードと高いネットワークトラフィックを得るだろう。 だが例えば、 失敗のケースの一つは もしコンピュータの一つが 無限ループで固まってるジョブを持っていると 疑ってるとしよう。 つまり私は ある失敗のケースは あるマシンの あるweb server、もといサーバーのcodeが 無限ループで詰まってる、と思ってるとすると、 その時はCPUロードは上がるだろうが ネットワークトラフィックは上昇しないだろう。 何故ならそれは単に糸車がくるくると回っていて たくさんのCPUの仕事をしている、つまり 無限ループに詰まってる。 その場合、その種のアノマリーを 検出する為には、 新たなフィーチャーX5として、 CPUロードをネットワークトラフィックで割ったような新たなフィーチャーを 作るかもしれない。 するとx5は、もしあるマシンが とても大きなCPUロードでありながら そんなに大きくないネットワークトラフィックの時には 異常に大きな値を とるだろう。 だからこのフィーチャーは あなたのアノマリー検出が ある種のアノマリーを検出するのを助ける事になる。 こんな風にさらに別の フィーチャーも思いつくかもしれない。 例えばx6として CPUロードを二乗した物を ネットワークトラフィックで割った物を使うかもしれない。 これはx5の変種の一つと 考えられる。それはマシンの一つが とても高いCPUロードにありながら それに見合うネットワークトラフィックが無い 物を見分けようと しているフィーチャーだ。 これらのようなフィーチャーを作る事で フィーチャーの異常な 組み合わせを 捉えていく事が出来る。 このビデオでは どうフィーチャーを選び 必要ならアルゴリズムに 食わせる前に ちょっと変換して よりガウス分布っぽくするかを議論した。 また、新しいフィーチャーを作って 異なる種類のアノマリーを捕捉する為の エラー分析の手順も議論した。 これらのガイドラインが あなたが良いフィーチャーを選び すべてのアノマリーをあなたの検出アルゴリズムが 捕捉出来る一助にならんことを！