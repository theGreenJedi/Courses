1
00:00:00,200 --> 00:00:03,950
No vídeo anterior, nós falamos sobre o processo para avaliar

2
00:00:03,950 --> 00:00:05,750
um algoritmo de detecção de anomalias.

3
00:00:05,750 --> 00:00:09,660
E então começamos a usar alguns dados etiquetados com exemplos que nós sabíamos

4
00:00:09,660 --> 00:00:14,570
serem anômalos ou não anômalos com Y igual a um, ou Y igual a 0.

5
00:00:14,570 --> 00:00:18,670
E então, a questão surge, e se temos os dados etiquetados, que nós temos

6
00:00:18,670 --> 00:00:23,070
alguns exemplos e conhecemos as anomalias, e que alguns deles não serão anômalos.

7
00:00:23,070 --> 00:00:25,690
Por que não apenas usar um supervisor para metade deles?

8
00:00:25,690 --> 00:00:28,280
Então por que não usamos regressão logística, ou

9
00:00:28,280 --> 00:00:32,310
uma rede neural para tentar aprender diretamente a partir dos nossos dados etiquetados

10
00:00:32,310 --> 00:00:34,940
para prever se Y é igual a 1 ou Y é igual a 0.

11
00:00:34,940 --> 00:00:38,970
Neste vídeo, tentarei compartilhar com você alguns pensamentos e diretrizes

12
00:00:38,970 --> 00:00:42,200
sobre quando provavelmente usaria o algoritmo de detecção de anomalia, e

13
00:00:42,200 --> 00:00:45,549
se ele seria mais útil ao invés de usar um supervisor no algoritmo.

14
00:00:47,170 --> 00:00:51,540
Este slide mostra que há situações nass quais você poderia usar

15
00:00:51,540 --> 00:00:55,830
detecção de anomalia versus quando aprendizagem supervisionada daria mais resultado.

16
00:00:55,830 --> 00:01:00,210
Se você tem um problema com um número muito pequeno de exemplos positivos, e

17
00:01:00,210 --> 00:01:05,420
lembre-se de que exemplos de y iguais a um são exemplos de anomalia.

18
00:01:05,420 --> 00:01:09,308
Então, você deveria considerar o uso de um algoritmo de detecção de anomalia.

19
00:01:09,308 --> 00:01:13,470
Então, tendo entre 0 e 20, talvez até 50 exemplos positivos,

20
00:01:13,470 --> 00:01:14,910
seria bem típico.

21
00:01:14,910 --> 00:01:19,710
E geralmente temos pequenos positivos assim, conjunto de exemplos positivos, vamos 

22
00:01:19,710 --> 00:01:24,270
guardar os exemplos positivos apenas para o conjunto de validação cruzada do conjunto de teste.

23
00:01:24,270 --> 00:01:29,320
E em contraste, numa típica configuração normal de detecção de anomalia,

24
00:01:29,320 --> 00:01:33,180
teremos frequentemente um número relativamente grande de exemplos negativos

25
00:01:33,180 --> 00:01:37,730
de exemplos normais de motores de aeronaves normais.

26
00:01:37,730 --> 00:01:41,480
E podemos então usar este  número bem grande de exemplos negativos com

27
00:01:41,480 --> 00:01:43,280
os quais ajustamos o modelo p(x).

28
00:01:43,280 --> 00:01:47,700
E então existe a ideia que em muitos aplicativos de detecção de anomalia,

29
00:01:47,700 --> 00:01:51,900
você tem poucos exemplos positivos e muitos exemplos negativos.

30
00:01:51,900 --> 00:01:56,290
E quando estamos realizando o processo de estimar p(x),

31
00:01:56,290 --> 00:02:00,640
afetando todos aqueles parâmetros de Gauss, precisamos apenas de exemplos negativos para fazer isso.

32
00:02:00,640 --> 00:02:05,380
Então, se você tem muitos dados negativos, nós podemos ainda ajustar p(x) muito bem.

33
00:02:05,380 --> 00:02:10,010
Em contrapartida, para aprendizagem supervisionada, mais tipicamente nós teríamos um número

34
00:02:10,010 --> 00:02:13,890
razoavelmente grande de exemplos de ambos positivos e negativos.

35
00:02:13,890 --> 00:02:16,770
E então isso é uma forma de olhar para o problema e

36
00:02:16,770 --> 00:02:22,170
decidir se deveria usar o algoritmo de detecção de anomalia ou um supervisionado.

37
00:02:22,170 --> 00:02:25,540
Aqui está outro modo de pensar das pessoas sobre algoritmos de detecção de anomalias.

38
00:02:25,540 --> 00:02:27,950
Em aplicativos de detecção de anomalias,

39
00:02:27,950 --> 00:02:30,580
frequentemente há muitos tipos distintos de anomalias.

40
00:02:30,580 --> 00:02:34,280
Então, pense em muitas formas distintas de dar errado.

41
00:02:34,280 --> 00:02:38,800
Há muitas coisas que poderiam dar errado e pifar o motor de uma aeronave.

42
00:02:38,800 --> 00:02:44,430
E sendo assim, e se você tiver um conjunto muito pequeno de exemplos positivos,

43
00:02:44,430 --> 00:02:47,550
então isso pode ser difícil para o algoritmo, difícil para o algoritmo

44
00:02:47,550 --> 00:02:51,670
aprender a partir deste conjunto pequeno de exemplos positivos de como se parecem as anomalias.

45
00:02:51,670 --> 00:02:52,430
Em particular,

46
00:02:52,430 --> 00:02:56,060
você sabe que anomalias futuras podem não parecer em nada com as que você já viu até então.

47
00:02:56,060 --> 00:02:59,770
Logo, pode ser que no seu conjunto de exemplos positivos, você pode ter visto 5 ou 10 ou

48
00:02:59,770 --> 00:03:03,810
20 formas distintas que podem fazer um motor de aeronave funcionar de modo errado.

49
00:03:03,810 --> 00:03:08,090
Mas talvez amanhã, você precise detectar um conjunto totalmente novo,

50
00:03:08,090 --> 00:03:10,450
um tipo totalmente novo de anomalia.

51
00:03:10,450 --> 00:03:12,000
Um modo totalmente novo de

52
00:03:12,000 --> 00:03:16,050
pifar um motor de aeronave, que você simplesmente nunca viu antes.

53
00:03:16,050 --> 00:03:17,610
Se este for o caso,

54
00:03:17,610 --> 00:03:23,160
poderia ser mais promissor simplesmente modelar os exemplos negativos com este tipo de

55
00:03:23,160 --> 00:03:27,310
modelo de Gauss, p de x, ao invés de tentar modelar os exemplos positivos.

56
00:03:27,310 --> 00:03:30,990
Porque as anomalias futuras podem não parecer em nada com as que você já viu até então.

57
00:03:32,310 --> 00:03:37,820
Em contraste, em alguns outros problemas, você tem exemplos positivos suficientes para

58
00:03:37,820 --> 00:03:41,250
um algoritmo ter noção de como os exemplos positivos se parecem.

59
00:03:41,250 --> 00:03:46,150
Em especial, se você pensar que exemplos positivos futuros tendem a ser similares

60
00:03:46,150 --> 00:03:48,830
aos do conjunto treinado, então, nesta configuração,

61
00:03:48,830 --> 00:03:53,210
poderia ser mais razoável ter um supervisor no algoritmo que verifica

62
00:03:53,210 --> 00:03:56,710
todos os exemplos positivos, verifica todos os exemplos negativos, e

63
00:03:56,710 --> 00:03:59,910
usa isso para tentar distinguir entre os positivos e os negativos.

64
00:04:01,710 --> 00:04:05,410
Espero que isso lhe dê uma noção se você tiver um problema específico,

65
00:04:05,410 --> 00:04:09,130
de pensar em usar um algoritmo de detecção de anomalia, ou

66
00:04:09,130 --> 00:04:10,039
em usar um algoritmo de aprendizagem supervisionado.

67
00:04:11,080 --> 00:04:14,560
E uma diferença importante é realmente que na detecção de anomalia, sempre nós

68
00:04:14,560 --> 00:04:18,830
temos aquele pequeno número de exemplos positivos que não possibilitam a um

69
00:04:18,830 --> 00:04:22,450
algoritmo de aprendizagem aprender muito sobre estes exemplos positivos.

70
00:04:22,450 --> 00:04:26,160
E então, o que fazemos ao invés disso é pegar uma grande amostra de exemplos negativos e

71
00:04:26,160 --> 00:04:30,080
tendo aprendido muito, aprendido p(x) apenas dos exemplos negativos.

72
00:04:30,080 --> 00:04:32,590
Do motor normal da aeronave, digamos, e

73
00:04:32,590 --> 00:04:36,600
tendo reservado um pequeno número de exemplos positivos para avaliar

74
00:04:36,600 --> 00:04:40,150
nossos algoritmos para usar ou na validação cruzada do conjunto, ou do conjunto de testes.

75
00:04:41,190 --> 00:04:45,710
E só um comentário à parte sobre estes vários tipos distintos de anomalias.

76
00:04:45,710 --> 00:04:50,060
Em alguns vídeos anteriores falamos sobre exemplos de e-mail spam.

77
00:04:50,060 --> 00:04:53,940
Naqueles exemplos, na verdade há vários tipos distintos de e-mail spam, certo?

78
00:04:53,940 --> 00:04:55,850
Há e-mail spam que tenta vender coisas.

79
00:04:55,850 --> 00:04:59,950
E-mail spam tentando roubar senhas, este é chamado de e-mail phishing e

80
00:04:59,950 --> 00:05:01,310
muitos tipos distintos de e-mails de spam.

81
00:05:01,310 --> 00:05:05,950
Mas para o problema do spam geralmente temos exemplos de spam suficientes

82
00:05:05,950 --> 00:05:09,640
para ver a maioria destes tipos distintos de e-mail spam

83
00:05:09,640 --> 00:05:12,390
porque nos temos um grande conjunto de exemplos de spam.

84
00:05:12,390 --> 00:05:16,540
E esta é a razão de geralmente pensarmos em spam como uma configuração de aprendizagem supervisionada

85
00:05:16,540 --> 00:05:18,107
mesmo que hajam muitos tipos distintos deles.

86
00:05:22,318 --> 00:05:27,017
Se olharmos para alguns aplicativos de detecção de anomalias versus aprendizagem supervisionada

87
00:05:27,017 --> 00:05:29,320
encontraremos detecção de fraude.

88
00:05:29,320 --> 00:05:34,390
Se você tem muitos tipos distintos dos modos que as pessoas cometem fraudes e

89
00:05:34,390 --> 00:05:38,580
um número relativamente pequeno de usuários fraudulentos em seu website,

90
00:05:38,580 --> 00:05:40,690
então eu usaria um algoritmo de detecção de anomalia.

91
00:05:40,690 --> 00:05:46,960
Devo dizer que, se você tem, se você é um grande revendedor online e

92
00:05:46,960 --> 00:05:50,500
se você de fato tem muitas pessoas cometendo fraude em seu website, então

93
00:05:50,500 --> 00:05:53,780
você na verdade tem muitos exemplos de y=1, então algumas vezes

94
00:05:53,780 --> 00:05:58,880
a detecção de fraude poderia na verdade mudar para a coluna de aprendizagem supervisionada.

95
00:05:58,880 --> 00:06:05,300
Mas, se você não tem visto muitos exemplos de usuários fazendo coisas estranhas

96
00:06:05,300 --> 00:06:09,890
em seu website, então a detecção de fraude mais frequentemente deve ser tratada como

97
00:06:09,890 --> 00:06:13,040
um algoritmo de detecção de anomalia ao invés de um algoritmo de aprendizagem supervisionada.

98
00:06:14,150 --> 00:06:16,266
Outros exemplos, nós já falamos sobre fabricação.

99
00:06:16,266 --> 00:06:20,732
Felizmente, mais e mais vemos exemplos que não são muitas anomalias, mas

100
00:06:20,732 --> 00:06:23,470
se de novo, para alguns processos de fabricação,

101
00:06:23,470 --> 00:06:27,935
se você produz em volumes muito grandes e você vê muitos exemplos defeituosos,

102
00:06:27,935 --> 00:06:32,493
pode ser que sua produção mude também para a coluna de aprendizagem supervisionada.

103
00:06:32,493 --> 00:06:38,645
Mas se você não tem encontrado muitos exemplos com defeito então a detecção de anomalias

104
00:06:38,645 --> 00:06:45,300
nas máquinas de monitoramento no datacenter podem resolver o problema aplicando argumentos semelhantes.

105
00:06:45,300 --> 00:06:47,400
Ao passo que, você deve ter classificação,

106
00:06:47,400 --> 00:06:50,310
previsão do tempo, e classificação de cânceres.

107
00:06:50,310 --> 00:06:54,600
Se você tem um número igual de exemplos positivos e negativos.

108
00:06:55,600 --> 00:06:57,290
Seus exemplos positivos e negativos,

109
00:06:57,290 --> 00:07:00,900
então tendemos a tratá-los todos como problemas de supervisor.

110
00:07:00,900 --> 00:07:05,390
Espero que isso lhe dê uma noção

111
00:07:05,390 --> 00:07:09,090
de uma das propriedades do problema de aprendizagem que o levaria

112
00:07:09,090 --> 00:07:14,320
a tratá-lo como um problema de detecção de anomalia versus um problema de aprendizagem supervisionada.

113
00:07:14,320 --> 00:07:18,500
E para muitos outros problemas que você se deparar em diversas empresas de tecnologia e assim

114
00:07:18,500 --> 00:07:22,380
por diante, nós, na verdade, estamos estabelecendo onde temos muito poucos ou

115
00:07:22,380 --> 00:07:25,440
algumas vezes nenhum exemplo treinado zero positivo.

116
00:07:25,440 --> 00:07:26,830
Simplesmente há 

117
00:07:26,830 --> 00:07:29,490
tantas formas distintas de anomalias que nós nunca vimos antes.

118
00:07:29,490 --> 00:07:31,650
E para tais tipos de problemas,

119
00:07:31,650 --> 00:07:35,490
frequentemente o algoritmo que usamos é o de detecção de anomalia.