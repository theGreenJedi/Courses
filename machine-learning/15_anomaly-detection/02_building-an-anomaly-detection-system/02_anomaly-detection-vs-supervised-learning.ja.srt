1
00:00:00,180 --> 00:00:01,210
前回のビデオでは

2
00:00:01,580 --> 00:00:02,950
アノマリー検出のアルゴリズムを

3
00:00:03,790 --> 00:00:05,780
評価する手順について話した。

4
00:00:05,910 --> 00:00:06,980
そこではラベル付きのデータを

5
00:00:07,210 --> 00:00:08,810
アノマリーかそうでないか分かっているサンプルに対して、

6
00:00:08,880 --> 00:00:10,150
y=1か0かで対応させる事で

7
00:00:11,010 --> 00:00:13,170
ラベル付けしたデータを用いた。

8
00:00:14,690 --> 00:00:15,380
そこで浮かぶ疑問としては、

9
00:00:15,690 --> 00:00:17,700
このラベル付きデータがあるなら

10
00:00:18,130 --> 00:00:19,620
どれがアノマリーで

11
00:00:19,750 --> 00:00:20,840
どれがアノマリーじゃない、という事が

12
00:00:21,020 --> 00:00:21,850
分かっているデータがあるのなら、

13
00:00:22,090 --> 00:00:23,540
何故単純に

14
00:00:23,640 --> 00:00:25,580
教師有り学習アルゴリズムを使わないのか？

15
00:00:25,720 --> 00:00:26,790
つまりなんでただロジスティック回帰や

16
00:00:27,110 --> 00:00:28,360
ニューラルネットワークを使って

17
00:00:28,680 --> 00:00:29,770
ラベル付けされたデータから

18
00:00:30,020 --> 00:00:31,260
直接学習してしまわないのか？

19
00:00:31,550 --> 00:00:34,120
そうしてyが1か0かを予測してしまえばいいのでは？

20
00:00:34,900 --> 00:00:35,900
このビデオでは、どういう時に

21
00:00:36,160 --> 00:00:37,170
アノマリー検出アルゴリズムを使い

22
00:00:37,350 --> 00:00:38,820
どういう時には

23
00:00:39,130 --> 00:00:40,610
教師有り学習アルゴリズムの使用を検討したほうが

24
00:00:40,720 --> 00:00:42,160
実りが多いのかについて、

25
00:00:42,440 --> 00:00:43,500
いくつかの考え方とガイドラインを

26
00:00:43,920 --> 00:00:45,380
お話したい。

27
00:00:47,160 --> 00:00:48,950
このスライドでは、

28
00:00:49,010 --> 00:00:50,130
どういう状況ではアノマリー検出を使った方が良くて

29
00:00:50,900 --> 00:00:52,370
どういう時は教師有り学習の方が実りが多いのかを

30
00:00:52,930 --> 00:00:54,590
示している。

31
00:00:56,030 --> 00:00:57,440
もし陽性のサンプルの数が

32
00:00:57,560 --> 00:00:58,820
とても少い場合は、

33
00:00:59,720 --> 00:01:01,780
ここでy=1がアノマリーの

34
00:01:01,890 --> 00:01:03,000
サンプルだったかだが、

35
00:01:03,650 --> 00:01:05,520
その場合は

36
00:01:06,170 --> 00:01:08,160
アノマリー検出のアルゴリズムの使用を検討すべきだ。

37
00:01:09,260 --> 00:01:10,430
つまり0から20個とか、

38
00:01:10,600 --> 00:01:12,740
まぁ50個くらいまでの陽性のサンプルは

39
00:01:13,450 --> 00:01:15,190
とても典型的な範囲で、通常は

40
00:01:15,680 --> 00:01:16,810
そんなに陽性のサンプル数が

41
00:01:17,130 --> 00:01:18,340
少ない時は、

42
00:01:19,270 --> 00:01:20,170
それらの陽性のサンプルを

43
00:01:20,510 --> 00:01:21,530
クロスバリデーションセットと

44
00:01:21,840 --> 00:01:24,440
テストセットの為に取っておくのが良かろう。

45
00:01:24,850 --> 00:01:26,130
逆に、典型的な

46
00:01:26,510 --> 00:01:28,560
アノマリー検出の状況としては、

47
00:01:29,340 --> 00:01:30,630
相対的にとても大量の

48
00:01:31,010 --> 00:01:32,340
陰性のサンプルがある。

49
00:01:33,110 --> 00:01:34,300
これら正常なサンプル、

50
00:01:34,910 --> 00:01:36,710
これら正常は航空機エンジンなど。

51
00:01:37,720 --> 00:01:38,900
そしてこれらのとても大量の

52
00:01:39,200 --> 00:01:40,240
サンプルを使って

53
00:01:41,470 --> 00:01:42,510
モデルp(x)のフィッティングを行う事が出来る。

54
00:01:43,000 --> 00:01:44,090
つまり、だいたい

55
00:01:44,190 --> 00:01:45,930
アノマリー検出の適用のケースでは

56
00:01:46,320 --> 00:01:48,510
陽性のサンプルが

57
00:01:48,760 --> 00:01:50,220
ほんのちょっとしか無くて

58
00:01:50,320 --> 00:01:52,540
陰性のサンプルは大量にある場合だ。

59
00:01:52,810 --> 00:01:54,960
そしてp(x)を推計している時、

60
00:01:55,220 --> 00:01:57,520
ガウス分布のパラメータをフィッティングしている時は

61
00:01:58,650 --> 00:02:00,690
陰性のサンプルしか必要としない。

62
00:02:00,850 --> 00:02:01,680
だからたくさんの陰性のデータがあれば、

63
00:02:02,140 --> 00:02:04,310
p(x)をフィッティングするのは極めてうまくやれる。

64
00:02:05,340 --> 00:02:07,090
逆に教師有り学習の時は、

65
00:02:07,760 --> 00:02:08,790
十分にたくさんの、

66
00:02:09,180 --> 00:02:10,810
陽性と陰性のサンプル両方が

67
00:02:11,050 --> 00:02:12,370
あるのがより典型的だ。

68
00:02:13,920 --> 00:02:14,970
これがあなたの問題に対して

69
00:02:15,070 --> 00:02:16,240
アノマリー検出アルゴリズムを使うべきか

70
00:02:16,770 --> 00:02:17,860
教師有り学習のアルゴリズムを使うべきかを決めるのに

71
00:02:18,240 --> 00:02:20,180
着目すべきポイントの一つだ。

72
00:02:21,750 --> 00:02:24,750
さて、アノマリー検出のアルゴリズムについて皆が良く思う、もう一つの考え方はこうだ。

73
00:02:25,530 --> 00:02:26,890
アノマリー検出の適用時は、

74
00:02:27,900 --> 00:02:28,890
しばしばたくさんの異なる種類の

75
00:02:29,040 --> 00:02:30,600
アノマリーがあるものだ。

76
00:02:31,280 --> 00:02:31,770
航空機エンジンについて考えてみてくれ。

77
00:02:32,040 --> 00:02:34,680
お分かりのように、航空機のエンジンが不良品となるには、実に様々なパターンが考えられる。

78
00:02:34,880 --> 00:02:36,980
様々な物が不良品となり得て、それぞれが航空機エンジンの故障の原因たりえる。

79
00:02:38,830 --> 00:02:40,080
そしてさらに、もし陽性のサンプルが

80
00:02:40,120 --> 00:02:40,940
とても少ししか

81
00:02:41,140 --> 00:02:43,560
得られていなければ

82
00:02:44,430 --> 00:02:46,760
そのちょっとの陽性のサンプルから

83
00:02:47,580 --> 00:02:48,380
アノマリーとはどんな物かをそこから

84
00:02:48,740 --> 00:02:50,130
学習するのは、難しいかもしれない。

85
00:02:50,180 --> 00:02:51,880
そしてさらに、

86
00:02:52,800 --> 00:02:54,050
将来起こりうるアノマリーが

87
00:02:54,220 --> 00:02:55,750
ここまで見た物と全く似てないかもしれない。

88
00:02:56,050 --> 00:02:57,540
つまりあなたの集めた

89
00:02:57,790 --> 00:02:59,030
陽性のサンプルは、

90
00:02:59,190 --> 00:02:59,740
5とか10とか20種類の相異なる

91
00:02:59,950 --> 00:03:02,960
航空機のエンジンが、どう壊れるかのパターンを示しているかもしれないが、

92
00:03:03,780 --> 00:03:05,600
だが明日にはひょっとすると、

93
00:03:05,780 --> 00:03:07,110
全く新しい、

94
00:03:07,440 --> 00:03:08,870
新種のアノマリーを、

95
00:03:09,250 --> 00:03:10,620
全く新しい航空機エンジンの

96
00:03:10,820 --> 00:03:12,170
故障の仕方で、

97
00:03:12,570 --> 00:03:13,870
まったく見たこと無いような物を

98
00:03:14,090 --> 00:03:15,660
検出する必要がある。

99
00:03:15,950 --> 00:03:17,010
その場合は

100
00:03:17,550 --> 00:03:18,460
単純に陰性のサンプルを

101
00:03:18,650 --> 00:03:20,020
モデリングする方が、

102
00:03:20,480 --> 00:03:21,770
ガウス分布のモデルp(x)で

103
00:03:21,970 --> 00:03:23,620
モデリングする方が、より筋が良いだろう。

104
00:03:23,970 --> 00:03:24,950
陽性のサンプルを

105
00:03:25,290 --> 00:03:26,250
必死にモデリングするよりも。

106
00:03:26,640 --> 00:03:27,850
何故なら明日の

107
00:03:28,040 --> 00:03:29,310
アノマリーはここまで見た物とは

108
00:03:29,420 --> 00:03:32,680
まったく似てないかも知れないのだから。

109
00:03:33,140 --> 00:03:34,640
逆に、他の問題で、

110
00:03:34,790 --> 00:03:36,170
十分な陽性のサンプルを

111
00:03:36,600 --> 00:03:37,790
持っていて、アルゴリズムに

112
00:03:38,730 --> 00:03:40,850
陽性のサンプルとはどんな感じか、という感じが掴めそうなら

113
00:03:40,980 --> 00:03:42,860
そしてとりわけ、

114
00:03:42,960 --> 00:03:44,270
もし将来現れるであろう陽性のサンプルが

115
00:03:44,870 --> 00:03:45,690
トレーニングセットにある物と

116
00:03:46,130 --> 00:03:46,980
似たような物だろうと思われるなら、

117
00:03:47,670 --> 00:03:49,090
その場合には教師有り学習の

118
00:03:49,230 --> 00:03:51,720
アルゴリズムを用いる方がより合理的かもしれない。

119
00:03:52,550 --> 00:03:53,390
それはたくさんの陽性のサンプルを見て

120
00:03:53,520 --> 00:03:54,760
たくさんの陰性のサンプルを見て、

121
00:03:54,930 --> 00:03:56,530
そしてそれらを用いて

122
00:03:56,650 --> 00:03:58,980
陽性と陰性を見分けようとする物だ。

123
00:04:01,620 --> 00:04:02,780
以上で、もし特定の問題が

124
00:04:02,870 --> 00:04:04,180
目の前にあった時に

125
00:04:04,520 --> 00:04:05,690
アノマリー検出のアルゴリズムの使用を

126
00:04:05,950 --> 00:04:07,800
検討すべきか

127
00:04:08,110 --> 00:04:09,450
または教師有り学習のアルゴリズムを検討すべきか、だいたいの感じはつかめたかな。

128
00:04:11,110 --> 00:04:12,340
キーとなる重要な違いは

129
00:04:12,520 --> 00:04:13,870
アノマリー検出では、

130
00:04:14,020 --> 00:04:15,040
陽性のサンプルが

131
00:04:15,330 --> 00:04:17,200
ちょっとしか無いから

132
00:04:17,240 --> 00:04:18,640
そんなちょっとの物から学習アルゴリズムが

133
00:04:19,330 --> 00:04:21,810
多くを学ぶなんてそもそも不可能なのだ。

134
00:04:22,430 --> 00:04:23,440
だから代わりにやる事としては、

135
00:04:23,890 --> 00:04:25,050
たくさんの陰性のサンプルを

136
00:04:25,230 --> 00:04:26,420
とってきて、それについてたくさん学習し、

137
00:04:27,050 --> 00:04:28,070
p(x)を陰性のサンプルだけから、

138
00:04:28,230 --> 00:04:29,300
例えば正常な航空機エンジンだけから

139
00:04:29,500 --> 00:04:31,730
学習する。

140
00:04:32,190 --> 00:04:33,480
そして少ししかない陽性のサンプルを

141
00:04:33,640 --> 00:04:36,740
我らのアルゴリズムを評価する為に

142
00:04:37,350 --> 00:04:39,680
クロスバリデーションセットかテストセットにとっておく。

143
00:04:41,210 --> 00:04:42,380
これらたくさんの異なるアノマリーについて

144
00:04:42,620 --> 00:04:43,970
補足しておくと、

145
00:04:44,090 --> 00:04:45,490
以前のビデオでは

146
00:04:45,790 --> 00:04:46,910
eメールのスパムについて

147
00:04:47,050 --> 00:04:49,060
議論した。

148
00:04:50,020 --> 00:04:51,510
それらの例でも、

149
00:04:51,910 --> 00:04:53,450
たくさんの異なる種類のスパムメールが実際にある。

150
00:04:53,930 --> 00:04:54,750
スパムメールは物をあなたに

151
00:04:55,030 --> 00:04:57,650
売りつけようとする物もあるし、スパムメールはあなたのパスワードを盗もうとする場合もある。

152
00:04:58,470 --> 00:05:01,060
これはフィッシングメールと呼ばれる。
他にも様々なスパムメールがある。

153
00:05:01,820 --> 00:05:03,490
だがスパムの問題では、

154
00:05:03,930 --> 00:05:05,660
普通は調べる事が出来る十分な数の

155
00:05:06,000 --> 00:05:07,400
スパムが手に入る。

156
00:05:07,490 --> 00:05:08,650
これら異なる種類のほとんどのスパムメールを

157
00:05:08,890 --> 00:05:10,200
入手出来る。何故なら我らは

158
00:05:10,410 --> 00:05:11,650
大量のスパムメールを持ってるからだ。

159
00:05:11,860 --> 00:05:13,050
そしてだからこそ

160
00:05:13,330 --> 00:05:14,800
普通スパムの問題を

161
00:05:14,980 --> 00:05:16,510
教師有り学習の問題とみなすのだ。

162
00:05:16,710 --> 00:05:17,390
たくさんの種類の

163
00:05:17,530 --> 00:05:19,230
スパムがあるにも関わらず。

164
00:05:21,890 --> 00:05:23,170
つまり、実際の応用において

165
00:05:23,310 --> 00:05:24,940
アノマリー検出と教師有り学習を

166
00:05:25,600 --> 00:05:27,290
比較してみると、

167
00:05:27,480 --> 00:05:29,280
欠陥の検出において、

168
00:05:29,410 --> 00:05:31,040
もし様々な種類の

169
00:05:31,450 --> 00:05:32,510
欠陥とみなしたい物が

170
00:05:32,680 --> 00:05:34,120
ありそうなら、

171
00:05:34,170 --> 00:05:35,730
そして相対的に少しのトレーニングセットしか、

172
00:05:35,880 --> 00:05:37,500
詐欺行為をしているユーザーがあなたのwebサイトにはちょっとしかいなければ

173
00:05:37,920 --> 00:05:40,300
その時は私はアノマリー検出のアルゴリズムを使うだろう。

174
00:05:41,310 --> 00:05:42,520
つまりこんな時、たとえば

175
00:05:42,650 --> 00:05:44,560
あなたがとても大きな

176
00:05:44,700 --> 00:05:46,810
オンラインの小売商だったとして、

177
00:05:46,930 --> 00:05:48,170
実際にたくさんの人が

178
00:05:48,330 --> 00:05:49,230
詐欺行為を働こうと

179
00:05:49,390 --> 00:05:50,420
しているとする。

180
00:05:50,480 --> 00:05:51,340
つまり実際たくさんの

181
00:05:51,410 --> 00:05:53,760
y=1となるサンプルがあるとすると、

182
00:05:53,970 --> 00:05:55,410
そういう場合など、時には詐欺の検出は

183
00:05:55,700 --> 00:05:58,030
現実には教師有り学習へと変化する場合がありうる。

184
00:05:58,850 --> 00:06:01,000
だがもしあなたが

185
00:06:01,210 --> 00:06:02,440
あなたのwebサイトにおいて

186
00:06:02,940 --> 00:06:04,480
奇妙な行動に出るユーザーのサンプルが

187
00:06:04,690 --> 00:06:05,720
そんなには見られないのなら、

188
00:06:05,920 --> 00:06:07,970
こちらの方がありがちだが、この場合は詐欺検出は

189
00:06:08,510 --> 00:06:09,730
アノマリー検出として扱う事になる、

190
00:06:09,990 --> 00:06:12,060
教師有り学習では無く。

191
00:06:14,140 --> 00:06:15,160
他の例でも、製造業については

192
00:06:15,310 --> 00:06:16,810
既に話したが、望ましいのは

193
00:06:16,950 --> 00:06:18,230
たくさんの正常なサンプルと

194
00:06:19,110 --> 00:06:19,840
そんなに多くないアノマリーを見る、という状態だが、

195
00:06:20,520 --> 00:06:21,560
ある製造工程では

196
00:06:22,180 --> 00:06:23,900
もし大量の製造を

197
00:06:23,990 --> 00:06:25,690
行なっていて、

198
00:06:25,860 --> 00:06:26,780
既にたくさんの不良品のサンプルが

199
00:06:27,230 --> 00:06:29,220
見られているなら、その製造も

200
00:06:29,790 --> 00:06:31,690
教師有り学習アルゴリズムに変化しうる。

201
00:06:32,630 --> 00:06:33,680
でも過去の製造結果に

202
00:06:33,950 --> 00:06:35,640
そんなにたくさんの不良品のサンプルが

203
00:06:35,830 --> 00:06:38,140
見られていないなら、私だったらこれをアノマリー検出で扱うね。

204
00:06:39,180 --> 00:06:40,290
データセンターでのマシーンのモニタリングでも

205
00:06:40,400 --> 00:06:42,450
同種の議論が

206
00:06:42,880 --> 00:06:44,050
適用出来る。

207
00:06:45,280 --> 00:06:46,650
一方eメールのスパム分類、

208
00:06:47,070 --> 00:06:48,950
天気予報、ガンの分類などでは、

209
00:06:49,510 --> 00:06:50,580
だいたい同等の数の

210
00:06:51,200 --> 00:06:52,850
陽性と陰性のサンプルがあるなら、

211
00:06:52,870 --> 00:06:53,920
陽性と陰性のサンプルを

212
00:06:54,010 --> 00:06:55,550
たくさん

213
00:06:55,670 --> 00:06:56,780
得ているなら

214
00:06:57,030 --> 00:06:57,870
これら全てを教師有り学習の問題と

215
00:06:58,080 --> 00:07:00,630
みなす傾向にある。

216
00:07:03,400 --> 00:07:04,500
以上で問題の

217
00:07:04,580 --> 00:07:05,600
どんな性質が

218
00:07:05,770 --> 00:07:07,050
それをあなたが

219
00:07:07,350 --> 00:07:08,980
アノマリー検出の問題と扱うか、

220
00:07:09,420 --> 00:07:10,410
または教師有り学習の問題と扱うかを

221
00:07:10,810 --> 00:07:12,660
決めているかについて、

222
00:07:14,250 --> 00:07:14,250
感じがつかめただろうか。

223
00:07:14,690 --> 00:07:16,020
様々な技術の会社において、

224
00:07:16,260 --> 00:07:17,820
直面する問題の多くでは、

225
00:07:18,200 --> 00:07:19,780
本当にちょっとの

226
00:07:19,860 --> 00:07:20,900
陽性のサンプルしか無かったり、

227
00:07:21,510 --> 00:07:23,320
時にはゼロ個の

228
00:07:24,060 --> 00:07:25,090
陽性のサンプルしかなかったり、

229
00:07:25,400 --> 00:07:26,830
あまりにもたくさんの種類の

230
00:07:26,980 --> 00:07:28,410
まだ見ぬアノマリーが存在したりする。

231
00:07:28,530 --> 00:07:29,810
そういう種類の問題では

232
00:07:29,960 --> 00:07:31,900
とてもしばしば

233
00:07:32,440 --> 00:07:33,580
用いられる学習アルゴリズムは

234
00:07:33,790 --> 00:07:35,170
アノマリー検出のアルゴリズムだ。