1
00:00:00,090 --> 00:00:01,240
在上节课的视频中

2
00:00:01,560 --> 00:00:03,660
我们谈到了高斯分布

3
00:00:03,810 --> 00:00:05,350
在本节视频中

4
00:00:05,440 --> 00:00:07,300
我将应用高斯分布开发异常检测算法

5
00:00:10,360 --> 00:00:11,690
假如说我们有一个无标签的训练集

6
00:00:11,840 --> 00:00:13,390
共有 m 个训练样本

7
00:00:13,650 --> 00:00:15,410
并且

8
00:00:15,470 --> 00:00:16,730
这里的训练集里的每一个样本

9
00:00:16,760 --> 00:00:18,350
都是 n 维的特征

10
00:00:18,440 --> 00:00:19,420
因此你的训练集应该是

11
00:00:20,540 --> 00:00:21,860
m 个 n 维的特征构成的样本矩阵

12
00:00:22,730 --> 00:00:24,150
比如 m 个飞机引擎产品的样本

13
00:00:24,960 --> 00:00:26,730
或者是

14
00:00:27,070 --> 00:00:28,290
来自 m 个用户或者其它的什么东西

15
00:00:29,320 --> 00:00:30,460
现在

16
00:00:30,840 --> 00:00:32,310
我们解决异常检测的方法是

17
00:00:32,350 --> 00:00:33,480
我们要从数据中

18
00:00:33,860 --> 00:00:35,640
建立一个 p(x) 概率模型

19
00:00:36,240 --> 00:00:38,530
我们要尝试计算出这些哪些特征出现的概率比较高

20
00:00:38,860 --> 00:00:40,620
哪些特征的概率较低

21
00:00:41,350 --> 00:00:42,810
因此

22
00:00:43,090 --> 00:00:44,900
x 是一个向量

23
00:00:45,320 --> 00:00:46,580
我们要做的事情是

24
00:00:47,020 --> 00:00:48,870
建立一个 p(x) 的模型 表示 x1 的概率

25
00:00:49,440 --> 00:00:50,390
这是 x 的第一个组成部分

26
00:00:50,950 --> 00:00:53,180
并用它乘以 x2 的概率

27
00:00:53,990 --> 00:00:54,960
这是第二个特征的概率

28
00:00:55,510 --> 00:00:57,350
然后再乘以

29
00:00:57,450 --> 00:00:58,860
第三个特征的概率

30
00:00:59,090 --> 00:01:01,230
一直这样下去

31
00:01:01,410 --> 00:01:03,290
直到最后一个特征  xn

32
00:01:03,760 --> 00:01:03,930
直到最后一个特征  xn

33
00:01:04,200 --> 00:01:06,320
这里我先空着 最后再来填满

34
00:01:08,780 --> 00:01:09,720
那么

35
00:01:09,830 --> 00:01:10,960
我们如何为这些项进行建模呢？

36
00:01:11,460 --> 00:01:13,020
p(x1) p(x2) 等等

37
00:01:14,080 --> 00:01:15,380
我们下面要做的

38
00:01:15,680 --> 00:01:16,860
是假定特征 x1

39
00:01:17,480 --> 00:01:19,830
其分布

40
00:01:20,340 --> 00:01:22,950
服从高斯正态分布

41
00:01:23,160 --> 00:01:25,140
你也可以

42
00:01:25,340 --> 00:01:25,850
写出期望 μ1

43
00:01:25,920 --> 00:01:26,900
以及方差

44
00:01:26,990 --> 00:01:28,560
我用 σ1 的平方表示

45
00:01:29,890 --> 00:01:30,690
这样

46
00:01:30,820 --> 00:01:32,020
p(x1) 就可以写成

47
00:01:32,350 --> 00:01:34,410
这样一个高斯分布

48
00:01:34,610 --> 00:01:37,580
其期望为 μ1 方差为 (σ1)^2

49
00:01:38,230 --> 00:01:39,660
同样地

50
00:01:39,720 --> 00:01:40,570
我假设 x2

51
00:01:40,760 --> 00:01:42,220
也服从高斯分布

52
00:01:42,870 --> 00:01:44,620
这里的小波浪线读作"服从" 

53
00:01:44,800 --> 00:01:47,220
表示它服从高斯分布

54
00:01:47,740 --> 00:01:49,490
其期望为 μ2

55
00:01:49,830 --> 00:01:51,780
方差为 (σ2)^2

56
00:01:52,170 --> 00:01:54,230
所以它服从的高斯分布与刚刚那个不同

57
00:01:54,460 --> 00:01:58,010
它的期望和方差都不一样

58
00:01:58,120 --> 00:02:00,160
与此类似

59
00:02:00,360 --> 00:02:04,020
x3 服从另外一个高斯分布

60
00:02:04,480 --> 00:02:06,590
因此

61
00:02:06,780 --> 00:02:09,100
x3 也会有一个不同的期望

62
00:02:09,300 --> 00:02:11,630
以及一个与其它特征不同的标准差

63
00:02:11,830 --> 00:02:15,370
直到 xn 都是如此

64
00:02:17,000 --> 00:02:17,740
这就是我要说的模型

65
00:02:19,010 --> 00:02:20,230
顺便说一下

66
00:02:20,370 --> 00:02:21,490
对那些擅长统计的同学来说

67
00:02:21,890 --> 00:02:22,770
实际上

68
00:02:22,990 --> 00:02:23,850
我刚刚写的式子

69
00:02:24,250 --> 00:02:25,590
写出来实际上就对应于

70
00:02:25,750 --> 00:02:27,490
一个从 x1 到 xn 上的独立的假设

71
00:02:28,060 --> 00:02:29,550
一个从 x1 到 xn 上的独立的假设

72
00:02:30,290 --> 00:02:31,520
但实际中 结果是

73
00:02:32,040 --> 00:02:34,010
这些算法的效果都还不错

74
00:02:34,410 --> 00:02:36,330
无论这些特征

75
00:02:36,610 --> 00:02:37,780
是否独立

76
00:02:38,280 --> 00:02:39,810
即使这个独立的假设不成立

77
00:02:40,240 --> 00:02:41,830
这个算法的效果也还不错

78
00:02:42,650 --> 00:02:45,870
如果你不知道

79
00:02:45,970 --> 00:02:47,380
我刚刚提到的独立事件和其它相关内容

80
00:02:47,830 --> 00:02:48,460
也不要担心

81
00:02:49,170 --> 00:02:50,840
你将会慢慢有能力去理解

82
00:02:51,360 --> 00:02:52,690
并且能很好地实现这些算法

83
00:02:53,250 --> 00:02:55,310
刚才插入的那些内容也不重要

84
00:02:57,790 --> 00:02:58,880
最后

85
00:02:59,210 --> 00:03:00,320
做一个总结

86
00:03:00,590 --> 00:03:04,680
让我把这些式子写得紧凑点

87
00:03:05,120 --> 00:03:06,200
我可以把这个式子

88
00:03:06,310 --> 00:03:07,500
写成一个乘积式

89
00:03:07,740 --> 00:03:09,520
从 j=1 到 j=n

90
00:03:10,230 --> 00:03:11,840
从 j=1 到 j=n

91
00:03:12,140 --> 00:03:15,350
乘积项是 p(xj; μj,  (σj)^2)

92
00:03:16,020 --> 00:03:17,930
也就是 n 个概率的乘积

93
00:03:19,500 --> 00:03:21,500
在这里

94
00:03:21,790 --> 00:03:23,330
出现了一个有趣的符号

95
00:03:23,780 --> 00:03:25,220
希腊字母 Π

96
00:03:25,490 --> 00:03:27,600
这个有趣的字母表示的是

97
00:03:28,190 --> 00:03:29,980
一系列数值的乘积

98
00:03:30,590 --> 00:03:32,290
同时

99
00:03:32,400 --> 00:03:33,930
你应该对求和符号比较熟悉

100
00:03:34,520 --> 00:03:36,460
从 i=1 到 n 求和

101
00:03:36,930 --> 00:03:39,070
也就是

102
00:03:39,960 --> 00:03:41,820
1+2+3+...

103
00:03:42,230 --> 00:03:43,730
直到加到 n

104
00:03:43,910 --> 00:03:45,350
因此刚才的符号 Π

105
00:03:45,660 --> 00:03:46,910
正如这个求和符号 ∑ 一样

106
00:03:47,390 --> 00:03:48,630
只是表示从 i 等于1

107
00:03:48,840 --> 00:03:50,310
到 n 进行连乘

108
00:03:50,620 --> 00:03:52,210
那么

109
00:03:52,520 --> 00:03:54,530
这里的 Π 用法一样 只不过表示连乘而不是连加

110
00:03:55,200 --> 00:03:56,680
这就变成了

111
00:03:56,880 --> 00:03:58,700
1×2×3 一直乘到 n

112
00:03:59,910 --> 00:04:01,330
所以这里用的就是

113
00:04:01,860 --> 00:04:03,430
这里连乘的符号

114
00:04:03,570 --> 00:04:05,880
这个表达式表示从等于 j=1 开始一直乘到 j=n

115
00:04:06,620 --> 00:04:08,440
这样写看起来更紧凑

116
00:04:08,820 --> 00:04:09,960
这样写只是避免了

117
00:04:10,330 --> 00:04:12,810
把这个乘积表达式

118
00:04:13,120 --> 00:04:14,400
的所有项都写出来而已

119
00:04:15,200 --> 00:04:16,200
因为我们需要把

120
00:04:16,430 --> 00:04:17,510
所有的 p(xj; μj,  (σj)^2) 项

121
00:04:17,730 --> 00:04:18,740
全部乘起来

122
00:04:19,130 --> 00:04:20,290
同时

123
00:04:21,540 --> 00:04:22,830
顺便要说的是

124
00:04:23,250 --> 00:04:25,370
估计 p(x) 的分布问题

125
00:04:25,990 --> 00:04:27,130
这种问题通常被称为

126
00:04:28,280 --> 00:04:29,540
密度估计问题

127
00:04:30,420 --> 00:04:31,270
正如幻灯片的标题上写的

128
00:04:33,800 --> 00:04:35,310
把所有的结合起来

129
00:04:35,500 --> 00:04:36,920
下面便是我们的异常检测算法

130
00:04:38,120 --> 00:04:40,290
第一步便是选择特征

131
00:04:40,650 --> 00:04:41,600
或者是找出一些

132
00:04:41,700 --> 00:04:42,740
我们认为的具有比较反常样本

133
00:04:43,040 --> 00:04:45,340
的特征 xi

134
00:04:46,050 --> 00:04:47,020
我的意思是

135
00:04:47,240 --> 00:04:48,490
我们可以尝试

136
00:04:48,680 --> 00:04:49,990
找出一些特征

137
00:04:50,280 --> 00:04:51,630
这些特征能看出比如

138
00:04:52,190 --> 00:04:53,000
在你的系统里有一些不同寻常的用户

139
00:04:53,190 --> 00:04:54,790
可能可以看出他们的反常或欺诈行为

140
00:04:55,020 --> 00:04:56,670
或者是那个飞机引擎的例子

141
00:04:56,760 --> 00:04:59,500
在飞机的众多引擎里有一个奇怪的引擎

142
00:05:00,280 --> 00:05:01,230
选出这种特征 xi

143
00:05:02,000 --> 00:05:03,330
这个特征可能会

144
00:05:04,410 --> 00:05:05,860
呈现一个特别大的数值

145
00:05:06,020 --> 00:05:08,750
或者特别小的数值

146
00:05:08,880 --> 00:05:10,160
因为这个看起来本身就有些异常

147
00:05:10,910 --> 00:05:12,440
但更为普遍的是

148
00:05:12,690 --> 00:05:14,340
尽可能尝试选择能够

149
00:05:16,160 --> 00:05:19,380
描述数据相关的属性的特征

150
00:05:20,030 --> 00:05:21,360
接下来 给出一组 

151
00:05:22,020 --> 00:05:23,980
m 个无标签数据构成的训练集

152
00:05:25,000 --> 00:05:26,980
从 x(1) 到 x(m)

153
00:05:27,170 --> 00:05:28,580
我们要拟合出

154
00:05:29,090 --> 00:05:30,170
期望 μ1 到 μn

155
00:05:30,340 --> 00:05:31,480
以及方差值 (σ1)^2 到 (σn)^2

156
00:05:31,690 --> 00:05:33,460
同时

157
00:05:33,840 --> 00:05:34,810
这些公式

158
00:05:34,840 --> 00:05:36,420
和之前视频里的

159
00:05:36,680 --> 00:05:37,610
公式是类似的

160
00:05:37,740 --> 00:05:39,180
因此 我们便可以

161
00:05:39,310 --> 00:05:41,120
估计这些参数的值

162
00:05:42,030 --> 00:05:43,670
我们再说得详细一点

163
00:05:44,060 --> 00:05:47,830
μj 是特征 j 的平均值

164
00:05:48,720 --> 00:05:51,580
因此 μj 对应的模型

165
00:05:52,440 --> 00:05:53,870
就是 p(xj; μj,  (σj)^2)

166
00:05:54,220 --> 00:05:55,590
就是 p(xj; μj,  (σj)^2)

167
00:05:55,920 --> 00:05:57,890
因此

168
00:05:58,360 --> 00:05:59,620
μj 就相当于

169
00:05:59,700 --> 00:06:00,720
对特征 j 的

170
00:06:01,070 --> 00:06:02,930
所有训练集数据取平均值

171
00:06:03,860 --> 00:06:05,100
同时 

172
00:06:05,220 --> 00:06:07,410
正如我刚才所讲

173
00:06:07,620 --> 00:06:08,830
你需要对 j 从1到n

174
00:06:09,420 --> 00:06:10,360
计算这些概率值

175
00:06:10,700 --> 00:06:11,960
也就是说用这些公式来估计 μ1

176
00:06:12,230 --> 00:06:14,020
再估计 μ2

177
00:06:14,070 --> 00:06:15,620
直到 μn

178
00:06:16,170 --> 00:06:17,460
同样地 对于 σ^2 也一样

179
00:06:17,770 --> 00:06:19,060
同时

180
00:06:19,390 --> 00:06:21,530
用向量化的方法也可以写出来

181
00:06:21,830 --> 00:06:22,900
所以 你可以把

182
00:06:23,000 --> 00:06:25,220
你把 μ 假想成一个向量

183
00:06:25,920 --> 00:06:27,430
那么向量 μ 就有

184
00:06:27,760 --> 00:06:29,230
μ1 μ2 直到 μn

185
00:06:29,570 --> 00:06:31,180
那么

186
00:06:31,660 --> 00:06:33,510
这个公式的向量表示形式

187
00:06:33,910 --> 00:06:35,530
就能被写出来

188
00:06:36,440 --> 00:06:37,830
μ 的值等于 x(i) 的值

189
00:06:37,880 --> 00:06:39,610
从 i = 1 到 n 求和 再乘以 1/m

190
00:06:40,290 --> 00:06:41,290
因此我刚刚写出的公式

191
00:06:41,410 --> 00:06:43,530
还是用来估计 μ 的值

192
00:06:43,990 --> 00:06:45,160
其中 x(i) 是一系列特征组成的向量

193
00:06:45,660 --> 00:06:48,140
同时包含了所有 n 个值

194
00:06:49,140 --> 00:06:50,070
同样地 我们也可以

195
00:06:50,430 --> 00:06:52,130
写出估计 (σj^2) 的

196
00:06:52,290 --> 00:06:55,110
向量化的公式

197
00:06:56,500 --> 00:06:57,890
最后 当给出一个新样本时

198
00:06:58,100 --> 00:06:59,270
比如当有一个新的飞机引擎时

199
00:06:59,740 --> 00:07:01,420
你想要知道这个飞机引擎是否出现异常

200
00:07:02,470 --> 00:07:03,430
我们要做的就是

201
00:07:03,570 --> 00:07:05,610
计算出 p(x) 的值来 那么这个案例中的概率是多少呢

202
00:07:06,790 --> 00:07:07,670
我们知道 p(x) 的值

203
00:07:07,990 --> 00:07:09,990
等于这个乘积式

204
00:07:10,100 --> 00:07:11,140
你现在

205
00:07:11,750 --> 00:07:14,040
需要用这个公式计算

206
00:07:15,000 --> 00:07:16,610
而这一项

207
00:07:16,840 --> 00:07:17,900
就是乘积项

208
00:07:18,260 --> 00:07:19,250
就是在计算高斯概率

209
00:07:19,800 --> 00:07:21,000
所以你需要计算出这一项

210
00:07:21,240 --> 00:07:22,880
然后看看

211
00:07:22,940 --> 00:07:24,420
如果这个概率值很小

212
00:07:24,860 --> 00:07:26,370
那么你就将这一项标注为异常

213
00:07:27,570 --> 00:07:29,380
这就是我们应用这种方法的一个案例

214
00:07:30,870 --> 00:07:31,860
假如说我们有一系列数据

215
00:07:32,210 --> 00:07:35,430
就是在幻灯片左上角绘制的数据集

216
00:07:36,670 --> 00:07:38,860
让我们看这个特征 x1

217
00:07:39,610 --> 00:07:40,640
如果你看到这个数据集

218
00:07:40,750 --> 00:07:42,600
你会发现它看起来比较平均

219
00:07:42,950 --> 00:07:44,330
x1 这个特征的均值大约是5

220
00:07:45,540 --> 00:07:47,420
并且也有一个标准差

221
00:07:47,590 --> 00:07:48,660
如果你只看

222
00:07:49,010 --> 00:07:50,030
数据集中 x1 的值

223
00:07:50,310 --> 00:07:51,720
其标准差可能为2

224
00:07:52,370 --> 00:07:55,110
所以这一段就是 σ1

225
00:07:55,460 --> 00:07:57,380
然后你再来看第二个特征

226
00:07:57,670 --> 00:07:59,070
从纵轴测量的

227
00:07:59,250 --> 00:08:00,370
特征 x2

228
00:08:00,840 --> 00:08:01,730
看起来其平均值

229
00:08:02,010 --> 00:08:03,110
可能是3

230
00:08:03,380 --> 00:08:05,750
且其标准差值大约为1

231
00:08:05,880 --> 00:08:06,940
如果你使用这个数据集

232
00:08:07,010 --> 00:08:08,690
且如果你估计出 μ1 μ2 σ1 σ2

233
00:08:09,030 --> 00:08:11,410
你就会得到这样的结果

234
00:08:11,610 --> 00:08:12,930
再次说明一下 我在这里写的 σ

235
00:08:13,140 --> 00:08:14,620
表示的是标准差

236
00:08:15,100 --> 00:08:16,240
但先前的公式里给出的

237
00:08:16,280 --> 00:08:17,640
实际上可以将这些项的平方(也就是方差)

238
00:08:18,120 --> 00:08:20,670
也即得到的是σ1的平方 σ2的平方

239
00:08:20,940 --> 00:08:21,920
所以你要仔细一点

240
00:08:22,090 --> 00:08:23,260
注意一下到底在使用σ1 σ2

241
00:08:23,380 --> 00:08:25,490
还是 σ1 σ2 的平方

242
00:08:25,960 --> 00:08:26,700
所以

243
00:08:26,820 --> 00:08:28,500
σ1的平方的值当然等于4

244
00:08:31,130 --> 00:08:32,260
就是 2的平方

245
00:08:32,310 --> 00:08:34,010
在图上

246
00:08:34,180 --> 00:08:35,550
以 μ1 σ1^2 

247
00:08:35,660 --> 00:08:36,830
为参数的 p(x1; μ1,σ1^2)

248
00:08:37,120 --> 00:08:38,130
和以 μ2 σ2 为参数的

249
00:08:38,230 --> 00:08:39,050
为参数的 p(x2; μ2,σ2^2)

250
00:08:39,190 --> 00:08:41,360
呈现出像这样的两个分布

251
00:08:42,650 --> 00:08:44,280
实际上

252
00:08:44,480 --> 00:08:45,960
如果绘制 p(x) 的图像

253
00:08:46,210 --> 00:08:47,540
也就是

254
00:08:47,710 --> 00:08:49,000
这两个概率值的乘积

255
00:08:49,210 --> 00:08:50,450
事实上

256
00:08:50,800 --> 00:08:52,770
你会得到一个这样的立体图像

257
00:08:53,360 --> 00:08:54,370
这就是

258
00:08:54,640 --> 00:08:55,920
p(x) 值的图像

259
00:08:56,390 --> 00:08:57,730
我们可以得出

260
00:08:57,830 --> 00:08:58,950
具体的某一点

261
00:08:58,990 --> 00:09:01,360
对应的高度值

262
00:09:01,470 --> 00:09:03,670
给出一个具体的 x1 和 x2 的值

263
00:09:03,930 --> 00:09:05,640
假如 x1 等于2 

264
00:09:05,800 --> 00:09:07,830
x2 也等于2 那么就是这个点

265
00:09:08,510 --> 00:09:09,450
在3-D表面图上的高度

266
00:09:09,710 --> 00:09:11,280
就表示 p(x) 值

267
00:09:13,020 --> 00:09:14,420
所以 p(x) 就是这个图的高度

268
00:09:14,710 --> 00:09:16,220
完整地写出来

269
00:09:16,340 --> 00:09:17,520
这个 p(x) 的值等于 

270
00:09:18,640 --> 00:09:20,010
p(x1; μ1,σ1^2) 

271
00:09:20,290 --> 00:09:22,540
乘以

272
00:09:23,200 --> 00:09:25,050
p(x2; μ2,σ2^2)

273
00:09:25,120 --> 00:09:27,530
p(x2; μ2,σ2^2)

274
00:09:27,720 --> 00:09:29,180
现在

275
00:09:29,320 --> 00:09:31,400
我们就知道了如何从数据拟合参数

276
00:09:31,930 --> 00:09:32,950
让我们看看一些新的样本

277
00:09:33,530 --> 00:09:35,090
假如在这里我们有了一个新样本

278
00:09:36,700 --> 00:09:38,340
我要知道这个样本是否异常

279
00:09:38,550 --> 00:09:39,220
或许我还有另一个样本

280
00:09:39,570 --> 00:09:41,860
比如我在这里有第二个新样本

281
00:09:42,140 --> 00:09:43,400
这个样本又是否异常呢?

282
00:09:44,360 --> 00:09:47,050
要回答这个问题

283
00:09:47,190 --> 00:09:48,470
我们可以先给计算机设某个无穷小的数值

284
00:09:48,620 --> 00:09:49,490
假如我设置的

285
00:09:50,020 --> 00:09:51,220
无穷小量数值为0.02

286
00:09:51,980 --> 00:09:54,110
我会在后面讲到如何选取 ε 的值

287
00:09:55,180 --> 00:09:56,110
不过 我们先看第一个样本

288
00:09:56,540 --> 00:09:57,360
我们把这个称为

289
00:09:57,500 --> 00:09:59,500
x(1)test

290
00:10:00,200 --> 00:10:01,010
同时

291
00:10:02,800 --> 00:10:03,900
称第二个样本为 x(2)test

292
00:10:04,780 --> 00:10:05,670
我们现在要做的

293
00:10:05,820 --> 00:10:07,380
是计算 p(x(1)test)

294
00:10:07,540 --> 00:10:08,740
我们用上面这个公式

295
00:10:08,990 --> 00:10:10,400
就能计算出来

296
00:10:11,140 --> 00:10:12,760
不难发现这是一个相当大的数

297
00:10:13,250 --> 00:10:15,560
具体地 这个值可能大于

298
00:10:15,920 --> 00:10:18,480
或者大于等于 ε 值

299
00:10:18,670 --> 00:10:19,670
相较于计算机的无穷小量 ε

300
00:10:19,810 --> 00:10:21,290
这个数值是比较大的

301
00:10:21,490 --> 00:10:22,510
所以我们说

302
00:10:22,970 --> 00:10:24,490
x1 检测的结果是 不是异常

303
00:10:25,650 --> 00:10:27,370
然而 如果你计算 p(x(2)test)

304
00:10:27,440 --> 00:10:29,810
会是一个更加小的数

305
00:10:30,170 --> 00:10:31,340
比 ε 还要小很多

306
00:10:31,490 --> 00:10:32,490
那么我们会说

307
00:10:32,720 --> 00:10:34,400
x2 确实是一个异常数值

308
00:10:34,860 --> 00:10:37,350
因为那已经远远小于了先前我们定义的 ε 值

309
00:10:38,450 --> 00:10:39,950
但事实上 我们也可以对这个方法进行改进

310
00:10:40,460 --> 00:10:43,340
看这个三维表面图

311
00:10:44,660 --> 00:10:46,270
从图上不难发现

312
00:10:46,350 --> 00:10:47,940
在这个图的中间部分的x1 x2

313
00:10:48,210 --> 00:10:50,570
通常都对应于

314
00:10:50,810 --> 00:10:52,770
一个比较高的表面值

315
00:10:52,910 --> 00:10:55,160
预示着非异常样本 或者正常样本

316
00:10:55,970 --> 00:10:57,450
而在周围边缘的点

317
00:10:57,640 --> 00:10:58,940
这些桃红色的区域

318
00:10:59,150 --> 00:11:00,460
所有这些区域

319
00:11:00,580 --> 00:11:01,740
对应的概率值

320
00:11:01,910 --> 00:11:02,940
都是非常小的

321
00:11:03,020 --> 00:11:04,310
因此我们会标记这些点

322
00:11:04,620 --> 00:11:06,350
为异常样本区域

323
00:11:06,760 --> 00:11:07,790
所以 我们也许可以

324
00:11:08,000 --> 00:11:09,480
定义某个区域

325
00:11:09,810 --> 00:11:12,160
像这样 在这个外面的

326
00:11:12,380 --> 00:11:12,580
标记为异常区域

327
00:11:14,940 --> 00:11:16,260
而在这个里面的

328
00:11:16,770 --> 00:11:18,340
可以标记为非异常区

329
00:11:18,570 --> 00:11:21,320
表示无异常的样本

330
00:11:22,110 --> 00:11:24,040
所以这个测试样本

331
00:11:24,250 --> 00:11:26,260
x(2)test 处于无异常区之外

332
00:11:26,650 --> 00:11:27,510
也就是说

333
00:11:27,620 --> 00:11:30,280
它所对应的概率值很小 因此认为它是一个异常样本

334
00:11:31,400 --> 00:11:32,990
在这段视频中

335
00:11:33,460 --> 00:11:35,440
我们介绍了如何拟合 p(x)

336
00:11:35,590 --> 00:11:36,840
也就是 x 的概率值

337
00:11:36,930 --> 00:11:38,740
以开发出一种异常检测算法

338
00:11:39,880 --> 00:11:40,890
同时 在这节课中

339
00:11:41,260 --> 00:11:42,970
我们也给出了

340
00:11:43,830 --> 00:11:45,090
通过给出的数据集

341
00:11:45,340 --> 00:11:47,740
拟合参数 进行参数估计

342
00:11:48,370 --> 00:11:50,570
得到参数 μ 和 σ

343
00:11:50,700 --> 00:11:52,180
然后检测新的样本

344
00:11:52,740 --> 00:11:54,110
确定新样本是否是异常 这一系列完整的过程

345
00:11:55,490 --> 00:11:56,800
在接下来的课程中

346
00:11:56,880 --> 00:11:58,580
我们将深入研究这一算法

347
00:11:58,980 --> 00:11:59,930
同时更深入地介绍

348
00:12:00,230 --> 00:12:02,310
怎样让算法工作地更加有效 【教育无边界字幕组】翻译：Yuens 校对/审核：所罗门捷列夫