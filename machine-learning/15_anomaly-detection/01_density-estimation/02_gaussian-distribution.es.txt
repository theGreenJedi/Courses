En este video, me gustaría hablar acerca de la distribución Gaussiana, también conocida como distribución normal. En caso de que ya esté muy familiarizado con la distribución Gaussiana, está bien si se salta este video. Pero si no está seguro o si ha pasado un tiempo desde que trabajó con una distribución Gaussiana o distribución normal, entonces por favor vea este video hasta el final. En el siguiente video, empezaremos a aplicar la distribución Gaussiana para desarrollar un algoritmo de detección de anomalías. Digamos que "x" es un variable aleatoria de valor real, "x" es un número real. Si la distribución de probabilidad de "x" es Gaussiana, esto significaría «Mu» y la variante «sigma» cuadrada, entonces escribiremos esto como x, la variable aleatoria tilde, que es este pequeño tilde que significa "distribuido como" y para denotar la distribución Gaussiana, a veces va a escribir "N", paréntesis, «Mu», «sigma» al cuadrado. Entonces, esta letra "N" significa que es normal ya que la distribución Gaussiana y normal hacen referencia a lo mismo, así que son sinónimos y una distribución Gaussiana se parametriza mediante 2 parámetros, por un parámetro que denotamos «Mu» y un parámetro de variación que denota por «sigma» cuadrado. Si graficamos la distribución Gaussiana o densidad de probabilidad Gaussiana, se verá como la curva en forma de campana, que quizá ya haya visto antes. Esta curva en forma de campana es parametrizada por esos 2 parámetros «Mu» y «sigma» y la ubicación del centro de esta curva en forma de campana es la «Mu» media y el ancho de esta curva en forma de campana, que es más o menos, digamos, este parámetro «sigma» también llamado desviación estándar. Y así, esto especifica la probabilidad de "x" tomando diferentes valores, entonces "x" asume valores, como sabe, en el centro, se trata de valores muy altos, ya que la densidad Gaussiana aquí es bastante alta, mientras que si "x" toma valores más y más alejados, va estar disminuyendo en probabilidad. Por último, para completar, déjeme escribir la fórmula para la distribución Gaussiana, entonces tenemos la propiedad de"x", y a veces escribiré esto en vez de p(x), voy a escribir esto como p(x); «Mu», «sigma» al cuadrado. Esto denota que la probabilidad de "x" es parametrizada por los dos parámetros «Mu» y «sigma» al cuadrado. La fórmula para la densidad Gaussiana es esta: 1 sobre 2 «pi», «sigma», a la "x" negativa menos «Mu» al cuadrado sobre 2 «sigma» cuadrado. Así que no hay necesidad de memorizar esta fórmula, ya sabes, esto es simplemente la fórmula para la curva en forma de campana aquí a la izquierda. Así que no hay necesidad de memorizarla, si alguna vez necesita usarla, siempre puede buscarla y. la figura a la izquierda es lo que obtiene si toma un valor fijo de «Mu» y un valor fijo de «sigma» y traza p(x). Así que esta curva de aquí, es realmente p(x) trazada como una función de x, ya sabe, para un valor fijo de «Mu» y el cuadrado de «sigma», «sigma» al cuadrado, que llamamos varianza. A veces es más fácil pensar en términos de «sigma», «sigma» es llamada la desviación estándar, por lo que especifica el ancho de esta densidad de probabilidad Gaussiana mientras que el cuadrado de «sigma», «sigma» al cuadrado, es conocida como la varianza. Veamos algunos ejemplos de cómo luce la distribución Gaussiana. Si «Mu» es igual a cero, «sigma» es igual a 1, luego tenemos una distribución Gaussiana, que se centra alrededor de cero, porque eso es «Mu» y el ancho de esta Gaussiana, es la desviación de estándar, es «sigma» en aquel lado. Veamos algunos ejemplos de Gaussianas. Si «Mu» es igual a cero o  igual a 1, entonces corresponde a una distribución de Gauss, que se centra en cero, ya que «Mu» es cero y el ancho de esta Gaussiana, es controlada de este modo por por «sigma», por ese parámetro de varianza. Aquí hay otro ejemplo. Digamos que «Mu» es igual a cero y «sigma» es igual a la mitad, y la desviación estándar es 0.5 y la varianza «sigma» al cuadrado por lo tanto sería el cuadrado de 0.5, sería entonces, 0.25. El cuadrado de 0.5 sería 0.25 y en ese caso, la distribución Gaussiana, o la densidad de probabilidad Gaussiana se ve así, también se centra en cero pero ahora, el ancho de esto es mucho menor debido a la menor varianza, el ancho de esta densidad Gaussiana, es aproximadamente la mitad de amplio. Pero como esta es una distribución de probabilidad, el área bajo la curva, que es el área sombreada de allá, esa área debe integrarse a 1. Esta es una propiedad de las distribuciones de probabilidad. Porque, como sabes, esto es una densidad Gaussiana mucho más alta porque es la mitad de ancho, con la mitad de la desviación de estándar, pero es dos veces más alta. Otro ejemplo, si «sigma» es igual a 2, obtenemos una densidad Gaussiana más robusta, o mucho más amplia. Entonces, aquí el parámetro «sigma» controla que esta densidad Gaussiana tenga un ancho mayor. Y una vez más, el área bajo la curva, que es el área sombreada siempre se integra a 1. Esa es una propiedad de las distribuciones de probabilidad y debido a que es más amplia, también es la mitad de alta, con el fin de simplemente integrarse a la misma cosa. Finalmente, un último ejemplo sería, si ahora cambiamos los parámetros «Mu» también, entonces en vez de centrarse en cero, ahora tenemos una distribución Gaussiana centrada en tres, porque se desplaza sobre toda la distribución Gaussiana. A continuación, hablemos sobre el problema de estimación de parámetros. ¿Qué es el problema de estimación parámetro? Supongamos que tenemos un conjunto de datos de ejemplos "m", entonces x1 a través de x(m) y digamos que cada uno de estos ejemplos es un número real. Aquí en la figura, he trazado un ejemplo de un conjunto de datos, donde el eje horizontal es el eje "x" y, como sabe, tengo un rango de ejemplos de "x" y los acabo de trazar en esta figura aquí. Y el problema de estimación de parámetros es, digamos que tengo la sospecha de que estos ejemplos de una distribución Gaussiana, entonces tengo la sospecha de que cada uno de mis ejemplos x(i) fue distribuido. Eso es lo que significa esta tilde. Por lo tanto, tengo la sospecha de que cada uno de estos ejemplos se distribuyó según una distribución normal o una distribución Gaussiana, con cierto parámetro «Mu» y algún parámetro «sigma» cuadrado pero no sé cuáles son los valores de estos parámetros. El problema con la estimación de parámetros es: dado mi conjunto de datos que quiero encontrar, quiero estimar, cuáles son los valores de «Mu» y «sigma» cuadrada. Así que si tiene un conjunto de datos como este, parece que tal vez, si estimo de qué distribución Gaussiana vinieron los datos, tal vez eso puede ser más o menos la distribución Gaussiana de donde provinieron, con «Mu» siendo el centro de la distribución y «sigma», la desviación estándar que controla la anchura de esta distribución Gausiana. Parece un ajuste razonable de los datos, porque, ya sabe, parece que los datos tienen una muy alta probabilidad de estar en la región central, baja probabilidad de estar lejos, baja probabilidad de estar más lejos y así sucesivamente. Quizá esta sea una estimación razonable de «Mu» y de «sigma» al cuadrado, que si corresponde a una distribución Gaussiana, entonces luego tendrá esta apariencia. Entonces, lo que haré es escribir las fórmulas, la fórmulas estándar para para estimar los parámetros de «Mu» y «sigma» cuadrada. La forma en que vamos a estimar «Mu» será sólo el promedio de mi ejemplo. Entonces «Mu» es el parámetro medio, voy a tomar mi conjunto de entrenamiento, tomo mis ejemplos "m" y los promedio. Esto sólo me da el centro de esta distribución pero ¿que hay de «sigma» al cuadrado? Bueno, la varianza, sólo voy a escribir la fórmula estándar de nuevo, voy a estimarla como la suma de 1 a través de m(xi), menos «Mu» al cuadrado, y esta letra «Mu» aquí, es en realidad la letra «Mu» que puedo calcular aquí usando esta fórmula, y lo que es la varianza o una interpretación de la varianza, es que si se fija en este término, es la diferencia al cuadrado entre el valor que obtuve en mi ejemplo, menos la media, menos el centro, menos la media de distribución. Como sabe, la varianza, la voy a estimar como sólo el promedio de las diferencias al cuadrado, entre mis ejemplos, menos de la media. Sólo como un comentario adicional, sólo para aquellos que son expertos en las estadísticas, si es un experto en estadística y si ha escuchado de la estimación máxima de probabilidad, entonces, estas estimaciones son en realidad la estimación de la probabilidad máxima de los parámetros «Mu» y «sigma» cuadrada. Pero si no ha oído sobre eso antes, no se preocupe, todo lo que necesita saber es que estas son las dos fórmulas estándar para tratar de averiguar lo que «Mu» y «sigma» cuadrada valen, dado el conjunto de datos. Finalmente, una última observación: de nuevo, sólo para aquellos que tal vez han tomado una clase de estadísticas antes. Si usted ha tomado una clase de estadística antes, algunos de ustedes puede que hayan visto la fórmula aquí, donde, ya sabe, esta es "m" menos 1, en vez de "m". De modo que este primer término se convierte en 1 sobre m-1, en lugar de 1 sobre m. En el aprendizaje automático, las personas tienden a usar esta fórmula de 1 sobre m pero en la práctica, el hecho de que sea 1 sobre m o 1 sobre m-1, no hace ninguna diferencia esencial, suponiendo que, m es razonablemente grande, es un conjunto de entrenamiento de gran tamaño. Así que, sólo en caso de que haya visto esta otra versión antes, en cualquier versión funciona igualmente bien pero en el aprendizaje automático, la mayoría de las personas tiende a usar 1 sobre m en esta fórmula. Las dos versiones tienen propiedades teóricas ligeramente diferentes, propiedades matemáticas un poco distintas pero en la práctica, realmente hace muy poca diferencia, si la hay. Pues bien, espero que ahora tengan una buena idea de cómo luce la distribución Gaussiana y cómo estimar los parámetros «Mu» y «sigma» al cuadrado de la distribución de Gaussiana y si le dan un conjunto de entrenamiento, esto es, si tiene un conjunto de datos que sospecha que proviene de una distribución Gaussiana con parámetros desconocidos utilizando «sigma» al cuadrado. En el siguiente video empezaremos a retomar esto y a aplicarlo para desarrollar un algoritmo de detección de anomalías.