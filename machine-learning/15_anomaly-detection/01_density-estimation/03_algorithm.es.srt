1
00:00:00,090 --> 00:00:01,240
En el último vídeo hablamos

2
00:00:01,560 --> 00:00:03,660
acerca de la distribución Gaussiana. En

3
00:00:03,810 --> 00:00:05,350
este video aplicaremos eso para

4
00:00:05,440 --> 00:00:07,300
desarrollar un algoritmo de detección de anomalías,

5
00:00:10,360 --> 00:00:11,690
digamos que tenemos

6
00:00:11,840 --> 00:00:13,390
su conjunto de entrenamiento sin valor asignado de

7
00:00:13,650 --> 00:00:15,410
"m" ejemplos y cada uno de esos ejemplos

8
00:00:15,470 --> 00:00:16,730
será una variable

9
00:00:16,760 --> 00:00:18,350
en Rn, de modo que su

10
00:00:18,440 --> 00:00:19,420
conjunto de entrenamiento podrían ser

11
00:00:20,540 --> 00:00:21,860
vectores de dirección de los últimos

12
00:00:22,730 --> 00:00:24,150
motores de aviones "m" fabricados o

13
00:00:24,960 --> 00:00:26,730
podrían ser funciones de usuarios "m"

14
00:00:27,070 --> 00:00:28,290
o algo más.

15
00:00:29,320 --> 00:00:30,460
La forma en que vamos a tratar la

16
00:00:30,840 --> 00:00:32,310
detección de anomalías es que vamos a

17
00:00:32,350 --> 00:00:33,480
modelar p(x)

18
00:00:33,860 --> 00:00:35,640
del conjuntos de datos.

19
00:00:36,240 --> 00:00:38,530
Vamos a tratar de averiguar cuáles son las variables alta probabilidad, cuáles son

20
00:00:38,860 --> 00:00:40,620
tipos de variables de menor probabilidad.

21
00:00:41,350 --> 00:00:42,810
Entonces, "x" es un

22
00:00:43,090 --> 00:00:44,900
vector y lo que vamos a hacer

23
00:00:45,320 --> 00:00:46,580
es modelar p(x),

24
00:00:47,020 --> 00:00:48,870
como probabilidad de x1,

25
00:00:49,440 --> 00:00:50,390
que es del primer componente de "x",

26
00:00:50,950 --> 00:00:53,180
por la probabilidad de x2

27
00:00:53,990 --> 00:00:54,960
que es la probabilidad

28
00:00:55,510 --> 00:00:57,350
de la segunda función por

29
00:00:57,450 --> 00:00:58,860
la probabilidad de la tercera

30
00:00:59,090 --> 00:01:01,230
variable, y así sucesivamente hasta

31
00:01:01,410 --> 00:01:03,290
la probabilidad de la función final

32
00:01:03,760 --> 00:01:03,930
de xn.

33
00:01:04,200 --> 00:01:06,320
Ahora voy a dejar espacio aquí porque voy a escribir algo en un minuto.

34
00:01:08,780 --> 00:01:09,720
Entonces, ¿cómo

35
00:01:09,830 --> 00:01:10,960
modelamos cada uno de estos términos, p(x1),

36
00:01:11,460 --> 00:01:13,020
p(x2) y así sucesivamente?

37
00:01:14,080 --> 00:01:15,380
Lo que haremos será

38
00:01:15,680 --> 00:01:16,860
asumir que la función,

39
00:01:17,480 --> 00:01:19,830
x1, se distribuye según

40
00:01:20,340 --> 00:01:22,950
una distribución Gaussiana, con

41
00:01:23,160 --> 00:01:25,140
cierta media, que usted

42
00:01:25,340 --> 00:01:25,850
quiere escribir como la letra griega «Mu» 1 y

43
00:01:25,920 --> 00:01:26,900
cierta varianza, que escribiré

44
00:01:26,990 --> 00:01:28,560
como «sigma» cuadrada 1,

45
00:01:29,890 --> 00:01:30,690
entonces p(x1) va

46
00:01:30,820 --> 00:01:32,020
a ser una distribución de

47
00:01:32,350 --> 00:01:34,410
probabilidad Gaussiana,

48
00:01:34,610 --> 00:01:37,580
con "mi 1" media y varianza «sigma» al cuadrado 1.

49
00:01:38,230 --> 00:01:39,660
De manera similar, voy a

50
00:01:39,720 --> 00:01:40,570
asumir que, x2

51
00:01:40,760 --> 00:01:42,220
es distribuida según el modelo Gaussiano,

52
00:01:42,870 --> 00:01:44,620
eso es lo que representa esta pequeña tilde,

53
00:01:44,800 --> 00:01:47,220
significa distribución según el modelo Gaussiano

54
00:01:47,740 --> 00:01:49,490
con media «Mu» 2 y ««sigma»»

55
00:01:49,830 --> 00:01:51,780
al cuadrado, así que se distribuye de acuerdo con una

56
00:01:52,170 --> 00:01:54,230
Gaussiana diferente, que tiene

57
00:01:54,460 --> 00:01:58,010
un conjunto diferente de parámetros, «Mu» 2, «sigma» al cuadrado2.

58
00:01:58,120 --> 00:02:00,160
Y, del mismo modo, ya sabe,

59
00:02:00,360 --> 00:02:04,020
x3 es todavía otra

60
00:02:04,480 --> 00:02:06,590
Gaussiana, así que esto

61
00:02:06,780 --> 00:02:09,100
puede tener una media diferente y

62
00:02:09,300 --> 00:02:11,630
una desviación estándar diferente a las

63
00:02:11,830 --> 00:02:15,370
otras variables y así sucesivamente, hasta xn.

64
00:02:17,000 --> 00:02:17,740
Y ese es mi modelo.

65
00:02:19,010 --> 00:02:20,230
Sólo como un comentario para

66
00:02:20,370 --> 00:02:21,490
aquellos que son expertos

67
00:02:21,890 --> 00:02:22,770
en estadísticas, resulta que

68
00:02:22,990 --> 00:02:23,850
esta ecuación que acabo de

69
00:02:24,250 --> 00:02:25,590
escribir, en realidad corresponde a una

70
00:02:25,750 --> 00:02:27,490
suposición de independencia en los

71
00:02:28,060 --> 00:02:29,550
valores de las variables de x 1 a xn.

72
00:02:30,290 --> 00:02:31,520
Pero en la práctica resulta

73
00:02:32,040 --> 00:02:34,010
que el algoritmo de este fragmento, funciona bien,

74
00:02:34,410 --> 00:02:36,330
ya sea que estas variables estén o no

75
00:02:36,610 --> 00:02:37,780
en cualquier lugar cerca de la independencia y

76
00:02:38,280 --> 00:02:39,810
aunque la suposición de independencia

77
00:02:40,240 --> 00:02:41,830
no se mantenga, este algoritmo funciona muy bien.

78
00:02:42,650 --> 00:02:45,870
En caso de que no conozca

79
00:02:45,970 --> 00:02:47,380
esos términos, sólo usé supuestos de independencia y así sucesivamente,

80
00:02:47,830 --> 00:02:48,460
no se preocupe por eso.

81
00:02:49,170 --> 00:02:50,840
Usted será capaz de entender

82
00:02:51,360 --> 00:02:52,690
e implementar este algoritmo de manera correcta

83
00:02:53,250 --> 00:02:55,310
y ese comentario realmente era sólo para los expertos en estadística.

84
00:02:57,790 --> 00:02:58,880
Finalmente, con el fin de

85
00:02:59,210 --> 00:03:00,320
terminar, permítame

86
00:03:00,590 --> 00:03:04,680
tomar esta expresión y escribirla de forma un poco más reducida.

87
00:03:05,120 --> 00:03:06,200
Entonces, vamos a

88
00:03:06,310 --> 00:03:07,500
escribir que este producto

89
00:03:07,740 --> 00:03:09,520
de j=1

90
00:03:10,230 --> 00:03:11,840
a través de "n" de

91
00:03:12,140 --> 00:03:15,350
p(xj) parametrizada por

92
00:03:16,020 --> 00:03:17,930
"mi j", «sigma» cuadrada

93
00:03:19,500 --> 00:03:21,500
"j". Este gracioso

94
00:03:21,790 --> 00:03:23,330
símbolo aquí, es la

95
00:03:23,780 --> 00:03:25,220
«pi» mayúscula del alfabeto griego,

96
00:03:25,490 --> 00:03:27,600
ese símbolo raro allí corresponde a

97
00:03:28,190 --> 00:03:29,980
tomar el producto de un conjunto de valores.

98
00:03:30,590 --> 00:03:32,290
Y así, se familiariza con

99
00:03:32,400 --> 00:03:33,930
la notación sumatoria, así que la

100
00:03:34,520 --> 00:03:36,460
suma de "i" igual a 1 a

101
00:03:36,930 --> 00:03:39,070
través de n, de "i". Esto

102
00:03:39,960 --> 00:03:41,820
significa 1 + 2 + 3 más

103
00:03:42,230 --> 00:03:43,730
punto, punto, punto, hasta

104
00:03:43,910 --> 00:03:45,350
"n". Donde este símbolo raro

105
00:03:45,660 --> 00:03:46,910
aquí, este símbolo de producto,

106
00:03:47,390 --> 00:03:48,630
el producto de i=1

107
00:03:48,840 --> 00:03:50,310
a través de "n"

108
00:03:50,620 --> 00:03:52,210
de "i".  Entonces esto

109
00:03:52,520 --> 00:03:54,530
significa que, es igual a la suma excepto que ahora estamos multiplicando.

110
00:03:55,200 --> 00:03:56,680
Esto se convierte en 1 x 2

111
00:03:56,880 --> 00:03:58,700
x3 hasta

112
00:03:59,910 --> 00:04:01,330
"n" y al usar

113
00:04:01,860 --> 00:04:03,430
esta notación de producto, este

114
00:04:03,570 --> 00:04:05,880
producto de j= 1 a trav´´es de "n" de esta expresión es más

115
00:04:06,620 --> 00:04:08,440
compacto, esta es

116
00:04:08,820 --> 00:04:09,960
una manera más corta de escribir

117
00:04:10,330 --> 00:04:12,810
este producto de

118
00:04:13,120 --> 00:04:14,400
todos esos términos allá arriba.

119
00:04:15,200 --> 00:04:16,200
Puesto que estamos  tomando esta

120
00:04:16,430 --> 00:04:17,510
p(xj), dados los términos "mi j",

121
00:04:17,730 --> 00:04:18,740
«sigma» cuadrada "j"

122
00:04:19,130 --> 00:04:20,290
y los multiplicamos juntos,

123
00:04:21,540 --> 00:04:22,830
por cierto, el problema de

124
00:04:23,250 --> 00:04:25,370
la estimación de esta distribución

125
00:04:25,990 --> 00:04:27,130
p(x), a veces se conoce como

126
00:04:28,280 --> 00:04:29,540
el problema de la estimación de la densidad.

127
00:04:30,420 --> 00:04:31,270
Por lo tanto, ese es el título de la diapositiva,

128
00:04:33,800 --> 00:04:35,310
al reunir todo esto, se forma

129
00:04:35,500 --> 00:04:36,920
un algoritmo de detección de anomalías.

130
00:04:38,120 --> 00:04:40,290
El primer paso es elegir

131
00:04:40,650 --> 00:04:41,600
variables o encontrar

132
00:04:41,700 --> 00:04:42,740
variables "xi"que pensamos

133
00:04:43,040 --> 00:04:45,340
que pueden ser indicativas de ejemplos anómalos.

134
00:04:46,050 --> 00:04:47,020
A lo que me refiero con eso

135
00:04:47,240 --> 00:04:48,490
es, tratar de encontrar

136
00:04:48,680 --> 00:04:49,990
variables, de modo que cuando haya

137
00:04:50,280 --> 00:04:51,630
un usuario inusual en su

138
00:04:52,190 --> 00:04:53,000
sistema que puede estar haciendo

139
00:04:53,190 --> 00:04:54,790
cosas fraudulentas, o cuando en el

140
00:04:55,020 --> 00:04:56,670
ejemplo del motor de avión, ya sabe,

141
00:04:56,760 --> 00:04:59,500
hay algo curioso, algo extraño en uno de los motores de avión,

142
00:05:00,280 --> 00:05:01,230
elija variables xi, que

143
00:05:02,000 --> 00:05:03,330
crea que podrían tomar inusualmente

144
00:05:04,410 --> 00:05:05,860
grandes valores, o inusualmente

145
00:05:06,020 --> 00:05:08,750
valores pequeños, que den la

146
00:05:08,880 --> 00:05:10,160
apariencia de un ejemplo anómalo.

147
00:05:10,910 --> 00:05:12,440
De manera más general, sólo trate de

148
00:05:12,690 --> 00:05:14,340
elegir las variables que describen las

149
00:05:16,160 --> 00:05:19,380
propiedades generales de las cosas sobre las que está recolectando datos.

150
00:05:20,030 --> 00:05:21,360
A continuación, dado un sistema de entrenamiento de "m",

151
00:05:22,020 --> 00:05:23,980
ejemplos con valores no asignados,

152
00:05:25,000 --> 00:05:26,980
x1 a xm, luego

153
00:05:27,170 --> 00:05:28,580
ajuste los parámetros,

154
00:05:29,090 --> 00:05:30,170
«Mu» 1 a «Mu» n y

155
00:05:30,340 --> 00:05:31,480
«sigma» cuadrada 1 a «sigma»

156
00:05:31,690 --> 00:05:33,460
cuadrada "n",

157
00:05:33,840 --> 00:05:34,810
así que estas fórmulas fueron similares

158
00:05:34,840 --> 00:05:36,420
a las fórmulas que teníamos

159
00:05:36,680 --> 00:05:37,610
en el video anterior, que íbamos

160
00:05:37,740 --> 00:05:39,180
a usar para estimar

161
00:05:39,310 --> 00:05:41,120
cada uno de estos parámetros y para dar

162
00:05:42,030 --> 00:05:43,670
una interpretación,«Mu» "j"

163
00:05:44,060 --> 00:05:47,830
que es mi valor promedio de la variable "j",

164
00:05:48,720 --> 00:05:51,580
«Mu» "j" entra en este término p(xj),

165
00:05:52,440 --> 00:05:53,870
parametrizado por «Mu» "j"

166
00:05:54,220 --> 00:05:55,590
y «sigma» cuadrada "j".

167
00:05:55,920 --> 00:05:57,890
Esto indica que

168
00:05:58,360 --> 00:05:59,620
"mi j" sólo toma

169
00:05:59,700 --> 00:06:00,720
la media sobre mi conjunto de

170
00:06:01,070 --> 00:06:02,930
valores de entrenamiento de la variable "j".

171
00:06:03,860 --> 00:06:05,100
Y, sólo por mencionar, que

172
00:06:05,220 --> 00:06:07,410
hace esto, usted calcula estas

173
00:06:07,620 --> 00:06:08,830
fórmulas para

174
00:06:09,420 --> 00:06:10,360
j=1 hasta "n". Así que use

175
00:06:10,700 --> 00:06:11,960
estas fórmulas para estimar «Mu» 1,

176
00:06:12,230 --> 00:06:14,020
para estimar «Mu» 2

177
00:06:14,070 --> 00:06:15,620
y así sucesivamente hasta

178
00:06:16,170 --> 00:06:17,460
«Mu» n y de forma similar para  «sigma»

179
00:06:17,770 --> 00:06:19,060
cuadrada, y también es

180
00:06:19,390 --> 00:06:21,530
es posible inventar versiones vectorizadas de éstos.

181
00:06:21,830 --> 00:06:22,900
Así es que si piensa en

182
00:06:23,000 --> 00:06:25,220
«Mu» como un vector, entonces, si «Mu»

183
00:06:25,920 --> 00:06:27,430
es un vector, tenemos «Mu» 1,

184
00:06:27,760 --> 00:06:29,230
«Mu» 2, hasta "mi n"

185
00:06:29,570 --> 00:06:31,180
después se puede escribir una

186
00:06:31,660 --> 00:06:33,510
versión vectorizada de ese conjunto

187
00:06:33,910 --> 00:06:35,530
de parámetros,

188
00:06:36,440 --> 00:06:37,830
de este modo, la suma de

189
00:06:37,880 --> 00:06:39,610
i=1 por medio de n, x(i).

190
00:06:40,290 --> 00:06:41,290
Esta fórmula que acabo

191
00:06:41,410 --> 00:06:43,530
de escribir estima esta "xi"

192
00:06:43,990 --> 00:06:45,160
como los vectores de dirección

193
00:06:45,660 --> 00:06:48,140
que estiman «Mu» para todos los valores de "n" de forma simultánea.

194
00:06:49,140 --> 00:06:50,070
También es posible encontrar

195
00:06:50,430 --> 00:06:52,130
una fórmula vectorizada para

196
00:06:52,290 --> 00:06:55,110
estimar «sigma» cuadrada "j". Por último,

197
00:06:56,500 --> 00:06:57,890
cuando le den un nuevo ejemplo,

198
00:06:58,100 --> 00:06:59,270
cuando tenga un nuevo motor de avión

199
00:06:59,740 --> 00:07:01,420
y quiera saber si el motor de este avión es anómalo,

200
00:07:02,470 --> 00:07:03,430
lo que tenemos que hacer es

201
00:07:03,570 --> 00:07:05,610
calcular p(x), que es la probabilidad de este nuevo ejemplo.

202
00:07:06,790 --> 00:07:07,670
Entonces, p(x) es igual

203
00:07:07,990 --> 00:07:09,990
a este producto y

204
00:07:10,100 --> 00:07:11,140
lo que usted implementa, lo que calcula

205
00:07:11,750 --> 00:07:14,040
es esta fórmula y

206
00:07:15,000 --> 00:07:16,610
donde, esto de aquí

207
00:07:16,840 --> 00:07:17,900
es sólo la

208
00:07:18,260 --> 00:07:19,250
fórmula para la probabilidad Gaussiana,

209
00:07:19,800 --> 00:07:21,000
así usted calcular

210
00:07:21,240 --> 00:07:22,880
esto y finalmente si

211
00:07:22,940 --> 00:07:24,420
esta probabilidad es muy pequeña,

212
00:07:24,860 --> 00:07:26,370
entonces marca esto como una anomalía.

213
00:07:27,570 --> 00:07:29,380
Aquí hay un ejemplo de una aplicación de este método.

214
00:07:30,870 --> 00:07:31,860
Digamos que tenemos este conjunto

215
00:07:32,210 --> 00:07:35,430
de datos trazado en la parte superior izquierda de esta diapositiva,

216
00:07:36,670 --> 00:07:38,860
si se fija, bueno, vamos a ver la función de x1.

217
00:07:39,610 --> 00:07:40,640
si observa este grupo de datos, parece

218
00:07:40,750 --> 00:07:42,600
que en promedio, las variables

219
00:07:42,950 --> 00:07:44,330
x1 tienen una media de aproximadamente 5

220
00:07:45,540 --> 00:07:47,420
y la desviación estándar,

221
00:07:47,590 --> 00:07:48,660
si sólo mira los valores de x1

222
00:07:49,010 --> 00:07:50,030
de este conjunto de datos

223
00:07:50,310 --> 00:07:51,720
tiene una desviación estándar de quizá 2.

224
00:07:52,370 --> 00:07:55,110
Así que esa es «sigma» 1,

225
00:07:55,460 --> 00:07:57,380
parece que x2, ya sabe, los valores de las

226
00:07:57,670 --> 00:07:59,070
las variables, tal como se miden

227
00:07:59,250 --> 00:08:00,370
en el eje vertical,

228
00:08:00,840 --> 00:08:01,730
pareciera que tiene un valor promedio

229
00:08:02,010 --> 00:08:03,110
de aproximadamente 3, y

230
00:08:03,380 --> 00:08:05,750
una desviación estándar de aproximadamente 1. Si

231
00:08:05,880 --> 00:08:06,940
toma este conjunto de datos y si

232
00:08:07,010 --> 00:08:08,690
estima "mi 1", mi 2", «sigma» 1, «sigma» 2

233
00:08:09,030 --> 00:08:11,410
esto es lo que obtiene.

234
00:08:11,610 --> 00:08:12,930
Y otra vez, estoy escribiendo «sigma» aquí,

235
00:08:13,140 --> 00:08:14,620
estoy pensando en desviaciones estándar, pero

236
00:08:15,100 --> 00:08:16,240
la fórmula de la diapositiva anterior,

237
00:08:16,280 --> 00:08:17,640
en realidad dio las estimaciones de los cuadrados

238
00:08:18,120 --> 00:08:20,670
de las cosas: «sigma» cuadrada 1 y «sigma» cuadrada 2.

239
00:08:20,940 --> 00:08:21,920
Sólo tenga cuidado si

240
00:08:22,090 --> 00:08:23,260
está usando «sigma» 1, «sigma» 2,

241
00:08:23,380 --> 00:08:25,490
«sigma» cuadrada 1 o «sigma» cuadrada 2.

242
00:08:25,960 --> 00:08:26,700
Entonces, «sigma» cuadrada 1, por supuesto,

243
00:08:26,820 --> 00:08:28,500
sería igual a 4, por ejemplo,

244
00:08:31,130 --> 00:08:32,260
como el cuadrado de 2.

245
00:08:32,310 --> 00:08:34,010
En imágenes se muestra que p(x1)

246
00:08:34,180 --> 00:08:35,550
parametrizada por «Mu» 1  y «sigma» al cuadrado 1,

247
00:08:35,660 --> 00:08:36,830
y p(x2)

248
00:08:37,120 --> 00:08:38,130
parametrizada por «Mu» 2

249
00:08:38,230 --> 00:08:39,050
y «sigma» cuadrada 2,

250
00:08:39,190 --> 00:08:41,360
luciría como estas dos distribuciones aquí.

251
00:08:42,650 --> 00:08:44,280
Resulta que

252
00:08:44,480 --> 00:08:45,960
si tuviéramos que trazar

253
00:08:46,210 --> 00:08:47,540
p(x), ¿no?, que

254
00:08:47,710 --> 00:08:49,000
es el producto de estas dos cosas,

255
00:08:49,210 --> 00:08:50,450
en realidad puede obtener

256
00:08:50,800 --> 00:08:52,770
un gráfico de superficie que tiene este aspecto.

257
00:08:53,360 --> 00:08:54,370
Este es un trazo de p(x)

258
00:08:54,640 --> 00:08:55,920
donde la altura

259
00:08:56,390 --> 00:08:57,730
por encima de este, donde la

260
00:08:57,830 --> 00:08:58,950
altura de esta superficie en un

261
00:08:58,990 --> 00:09:01,360
punto particular, dados los valores

262
00:09:01,470 --> 00:09:03,670
en particular de x1, x2

263
00:09:03,930 --> 00:09:05,640
de x2, si

264
00:09:05,800 --> 00:09:07,830
x1 es igual a 2, x igual a 2, ese es este punto y

265
00:09:08,510 --> 00:09:09,450
la altura de esta superficie 3D

266
00:09:09,710 --> 00:09:11,280
esa es

267
00:09:13,020 --> 00:09:14,420
p(x). Así que p(x), que es la altura

268
00:09:14,710 --> 00:09:16,220
de este diagrama, es literalmente

269
00:09:16,340 --> 00:09:17,520
p(x1)

270
00:09:18,640 --> 00:09:20,010
parametrizada por «Mu»12, «sigma» al cuadrado 1,

271
00:09:20,290 --> 00:09:22,540
por p(x2)

272
00:09:23,200 --> 00:09:25,050
parametrizada por «Mu» 2

273
00:09:25,120 --> 00:09:27,530
«sigma» cuadrada 2.

274
00:09:27,720 --> 00:09:29,180
Ahora, así es como

275
00:09:29,320 --> 00:09:31,400
ajustamos los parámetros a estos datos.

276
00:09:31,930 --> 00:09:32,950
Vamos a ver si tenemos un par de ejemplos nuevos,

277
00:09:33,530 --> 00:09:35,090
tal vez tengo un nuevo ejemplo aquí, ¿se tratará

278
00:09:36,700 --> 00:09:38,340
de una anomalía o no?

279
00:09:38,550 --> 00:09:39,220
o, tal vez tenga un ejemplo distinto,

280
00:09:39,570 --> 00:09:41,860
quizá tenga un segundo ejemplo diferente allí.

281
00:09:42,140 --> 00:09:43,400
Entonces, ¿es una anomalía o no?

282
00:09:44,360 --> 00:09:47,050
La forma en que hacemos esto, es que

283
00:09:47,190 --> 00:09:48,470
estableceríamos un valor para

284
00:09:48,620 --> 00:09:49,490
«épsilon», vamos decir que he elegido

285
00:09:50,020 --> 00:09:51,220
«épsilon»= 0.02.

286
00:09:51,980 --> 00:09:54,110
Diré más adelante cómo elegimos «épsilon» pero

287
00:09:55,180 --> 00:09:56,110
vamos a tomar este primer ejemplo,

288
00:09:56,540 --> 00:09:57,360
déjeme nombrar esto como

289
00:09:57,500 --> 00:09:59,500
ejemplo "x1 prueba"

290
00:10:00,200 --> 00:10:01,010
y nombraré al segundo ejemplo como

291
00:10:02,800 --> 00:10:03,900
"x2 prueba"

292
00:10:04,780 --> 00:10:05,670
Lo que hacemos es

293
00:10:05,820 --> 00:10:07,380
calcular p(x1)

294
00:10:07,540 --> 00:10:08,740
de "x1 prueba", así que utilizamos

295
00:10:08,990 --> 00:10:10,400
esta fórmula para calcularlo y

296
00:10:11,140 --> 00:10:12,760
esto parece un valor muy grande.

297
00:10:13,250 --> 00:10:15,560
En particular, esto es mayor

298
00:10:15,920 --> 00:10:18,480
o igual a «épsilon» y

299
00:10:18,670 --> 00:10:19,670
entonces esta es una

300
00:10:19,810 --> 00:10:21,290
muy alta probabilidad, al menos

301
00:10:21,490 --> 00:10:22,510
más grande que «épsilon», entonces diremos

302
00:10:22,970 --> 00:10:24,490
"x1 prueba" no es una anomalía.

303
00:10:25,650 --> 00:10:27,370
Considerando que, si usted calcula p(x2 prueba)

304
00:10:27,440 --> 00:10:29,810
bueno, es sólo un valor mucho menor.

305
00:10:30,170 --> 00:10:31,340
Entonces si esto es menor a épsilon,

306
00:10:31,490 --> 00:10:32,490
diremos que

307
00:10:32,720 --> 00:10:34,400
de hecho si es una anomalía porque

308
00:10:34,860 --> 00:10:37,350
es mucho menor a «épsilon» que elegimos.

309
00:10:38,450 --> 00:10:39,950
Y de hecho, podría mejorarlo aquí,

310
00:10:40,460 --> 00:10:43,340
lo que realmente muestra esto es que, si se fija en el diagrama de superficie 3D,

311
00:10:44,660 --> 00:10:46,270
está indicando que

312
00:10:46,350 --> 00:10:47,940
todos los valores de x1 y x2

313
00:10:48,210 --> 00:10:50,570
que tienen una gran altura

314
00:10:50,810 --> 00:10:52,770
por encima de la superficie, corresponden a

315
00:10:52,910 --> 00:10:55,160
un ejemplo no anómalo, a un ejemplo correcto o normal.

316
00:10:55,970 --> 00:10:57,450
Mientras que todos los puntos lejos

317
00:10:57,640 --> 00:10:58,940
de aquí, todos los puntos fuera

318
00:10:59,150 --> 00:11:00,460
tienen

319
00:11:00,580 --> 00:11:01,740
una probabilidad muy baja,

320
00:11:01,910 --> 00:11:02,940
entonces vamos a

321
00:11:03,020 --> 00:11:04,310
marcar esos puntos

322
00:11:04,620 --> 00:11:06,350
como anómalos, y así se va a definir

323
00:11:06,760 --> 00:11:07,790
alguna region, que tal vez

324
00:11:08,000 --> 00:11:09,480
se vea así, de modo que todo lo que está

325
00:11:09,810 --> 00:11:12,160
fuera de esto, lo marca

326
00:11:12,380 --> 00:11:12,580
como anómalo,

327
00:11:14,940 --> 00:11:16,260
mientras que las cosas dentro de esta

328
00:11:16,770 --> 00:11:18,340
elipse que acabo de dibujar, se consideran

329
00:11:18,570 --> 00:11:21,320
ejemplos normales, no anómalos o no anormales.

330
00:11:22,110 --> 00:11:24,040
Entonces este ejemplo de "x2 prueba"

331
00:11:24,250 --> 00:11:26,260
está fuera de

332
00:11:26,650 --> 00:11:27,510
esa región, por lo que

333
00:11:27,620 --> 00:11:30,280
tiene una probabilidad muy pequeña, entonces lo consideramos un ejemplo anómalo.

334
00:11:31,400 --> 00:11:32,990
En este vídeo hablamos acerca

335
00:11:33,460 --> 00:11:35,440
de cómo estimar p(x), la probabilidad de x,

336
00:11:35,590 --> 00:11:36,840
con el propósito de

337
00:11:36,930 --> 00:11:38,740
desarrollar un algoritmo de detección de anomalías.

338
00:11:39,880 --> 00:11:40,890
En este vídeo también nos adentramos

339
00:11:41,260 --> 00:11:42,970
en un proceso completo

340
00:11:43,830 --> 00:11:45,090
para obtener conjuntos de datos, estuvimos

341
00:11:45,340 --> 00:11:47,740
ajustando los parámetros, haciendo cálculos de parámetros.

342
00:11:48,370 --> 00:11:50,570
Obtuvimos los parámetros «Mu» y «sigma», y

343
00:11:50,700 --> 00:11:52,180
tomamos nuevos ejemplos para decidir

344
00:11:52,740 --> 00:11:54,110
si los nuevos ejemplos eran anómalos o no.

345
00:11:55,490 --> 00:11:56,800
En los próximos videos seguiremos

346
00:11:56,880 --> 00:11:58,580
profundizando en este algoritmo

347
00:11:58,980 --> 00:11:59,930
y hablaré un poco más

348
00:12:00,230 --> 00:12:02,310
acerca de cómo hacer que en realidad funcione bien.