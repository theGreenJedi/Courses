1
00:00:00,090 --> 00:00:01,240
No último vídeo, falamos

2
00:00:01,560 --> 00:00:03,660
sobre a distribuição gaussiana. Neste

3
00:00:03,810 --> 00:00:05,350
vídeo vamos aplicar isso

4
00:00:05,440 --> 00:00:07,300
para criar um algoritmo de detecção de anomalias.

5
00:00:10,360 --> 00:00:11,690
Digamos que temos um conjunto

6
00:00:11,840 --> 00:00:13,390
não etiquetado com "m" exemplos de treino,

7
00:00:13,650 --> 00:00:15,410
e cada um

8
00:00:15,470 --> 00:00:16,730
desses exemplos vai ser

9
00:00:16,760 --> 00:00:18,350
um escalar em "ℝⁿ".

10
00:00:18,440 --> 00:00:19,420
Assim, ele poderia ser

11
00:00:20,540 --> 00:00:21,860
vetores de características dos últimos

12
00:00:22,730 --> 00:00:24,150
"m" motores de avião fabricados,

13
00:00:24,960 --> 00:00:26,730
ou características de "m"

14
00:00:27,070 --> 00:00:28,290
usuários, ou outra coisa.

15
00:00:29,320 --> 00:00:30,460
Vamos tratar a

16
00:00:30,840 --> 00:00:32,310
detecção de anomalias

17
00:00:32,350 --> 00:00:33,480
modelando "p(x)"

18
00:00:33,860 --> 00:00:35,640
a partir do conjunto de dados.

19
00:00:36,240 --> 00:00:38,530
Tentaremos descobrir quais as características de alta probabilidade

20
00:00:38,860 --> 00:00:40,620
e quais são as de baixa probabilidade.

21
00:00:41,350 --> 00:00:42,810
Portanto, "x" é

22
00:00:43,090 --> 00:00:44,900
um vetor, e nós

23
00:00:45,320 --> 00:00:46,580
vamos modelar "p(x)"

24
00:00:47,020 --> 00:00:48,870
como a probabilidade de "x₁",

25
00:00:49,440 --> 00:00:50,390
ou seja, do primeiro componente

26
00:00:50,950 --> 00:00:53,180
de "x", vezes a probabilidade

27
00:00:53,990 --> 00:00:54,960
de "x₂", a probabilidade da

28
00:00:55,510 --> 00:00:57,350
segunda caracterísitica, vezes

29
00:00:57,450 --> 00:00:58,860
a probabilidade da terceira

30
00:00:59,090 --> 00:01:01,230
característica, e por aí adiante

31
00:01:01,410 --> 00:01:03,290
até a probabilidade da última característica "xₙ".

32
00:01:03,760 --> 00:01:03,930
de Xn.

33
00:01:04,200 --> 00:01:06,320
Deixei um espaço aqui porque vou completar tudo num minuto.

34
00:01:08,780 --> 00:01:09,720
Como é que nós

35
00:01:09,830 --> 00:01:10,960
modelamos cada um destes termos,

36
00:01:11,460 --> 00:01:13,020
"p(x₁)", "p(x₂)", e em diante?

37
00:01:14,080 --> 00:01:15,380
O que vamos fazer é

38
00:01:15,680 --> 00:01:16,860
assumir que essa característica,

39
00:01:17,480 --> 00:01:19,830
"x₁", está distribuída de acordo

40
00:01:20,340 --> 00:01:22,950
com uma distribuição gaussiana, com

41
00:01:23,160 --> 00:01:25,140
uma média "μ₁"

42
00:01:25,340 --> 00:01:25,850
e

43
00:01:25,920 --> 00:01:26,900
uma variância,

44
00:01:26,990 --> 00:01:28,560
"σ₁²".

45
00:01:29,890 --> 00:01:30,690
Assim, "p(x₁)"

46
00:01:30,820 --> 00:01:32,020
será uma distribuição de probabilidade

47
00:01:32,350 --> 00:01:34,410
gaussiana com média

48
00:01:34,610 --> 00:01:37,580
"μ₁" e variância "σ₁²".

49
00:01:38,230 --> 00:01:39,660
Similarmente, vou

50
00:01:39,720 --> 00:01:40,570
assumir que "x₂"

51
00:01:40,760 --> 00:01:42,220
é uma distribuição gaussiana,

52
00:01:42,870 --> 00:01:44,620
indicada por este pequeno til,

53
00:01:44,800 --> 00:01:47,220
isso significa distribuído de forma gaussiana

54
00:01:47,740 --> 00:01:49,490
com média "μ₂" e variância

55
00:01:49,830 --> 00:01:51,780
"σ₂²", portanto distribuída de acordo com

56
00:01:52,170 --> 00:01:54,230
uma gaussiana diferente que tem

57
00:01:54,460 --> 00:01:58,010
outro conjunto de parâmetros, "μ₂" e "σ₂²".

58
00:01:58,120 --> 00:02:00,160
Similarmente,

59
00:02:00,360 --> 00:02:04,020
"x₃" é ainda outra

60
00:02:04,480 --> 00:02:06,590
gaussiana, portanto

61
00:02:06,780 --> 00:02:09,100
pode ter uma média e

62
00:02:09,300 --> 00:02:11,630
um desvio padrão diferente das outras

63
00:02:11,830 --> 00:02:15,370
características, e assim por diante, até "xₙ".

64
00:02:17,000 --> 00:02:17,740
Esse é o meu modelo.

65
00:02:19,010 --> 00:02:20,230
Apenas um comentário à parte para

66
00:02:20,370 --> 00:02:21,490
aqueles que são experientes em

67
00:02:21,890 --> 00:02:22,770
estatística,

68
00:02:22,990 --> 00:02:23,850
esta equação que eu acabei

69
00:02:24,250 --> 00:02:25,590
de escrever na verdade corresponde a

70
00:02:25,750 --> 00:02:27,490
assumir que os valores das

71
00:02:28,060 --> 00:02:29,550
características "x₁" a "xₙ" são

72
00:02:30,290 --> 00:02:31,520
independentes.

73
00:02:32,040 --> 00:02:34,010
Apesar disso, o algoritmo funciona muito bem,

74
00:02:34,410 --> 00:02:36,330
quer estes elas sejam próximas

75
00:02:36,610 --> 00:02:37,780
de independentes ou não.

76
00:02:38,280 --> 00:02:39,810
Mesmo que elas não sejam realmente

77
00:02:40,240 --> 00:02:41,830
indepententes, este algoritmo funciona bem.

78
00:02:42,650 --> 00:02:45,870
Mas caso você não conheça esses termos, como

79
00:02:45,970 --> 00:02:47,380
assumir independência, não se preocupe.

80
00:02:47,830 --> 00:02:48,460
não se preocupe com isso.

81
00:02:49,170 --> 00:02:50,840
Você vai ser capaz de compreender

82
00:02:51,360 --> 00:02:52,690
e implementar este algoritmo corretamete

83
00:02:53,250 --> 00:02:55,310
o comentário é para as pessoas mais experientes em estatística.

84
00:02:57,790 --> 00:02:58,880
Finalmente, para podermos

85
00:02:59,210 --> 00:03:00,320
terminar isto, deixem-me

86
00:03:00,590 --> 00:03:04,680
tornar esta expressão um pouco mais compacta.

87
00:03:05,120 --> 00:03:06,200
Então, escrevemos

88
00:03:06,310 --> 00:03:07,500
isto como um produto

89
00:03:07,740 --> 00:03:09,520
de "j = 1"

90
00:03:10,230 --> 00:03:11,840
até "n", de "p(xⱼ)"

91
00:03:12,140 --> 00:03:15,350
parametrizado por

92
00:03:16,020 --> 00:03:17,930
"μⱼ" e "σⱼ²".

93
00:03:19,500 --> 00:03:21,500
Este símbolo

94
00:03:21,790 --> 00:03:23,330
estranho aqui é

95
00:03:23,780 --> 00:03:25,220
a letra grega "π" maiúscula,

96
00:03:25,490 --> 00:03:27,600
esse símbolo corresponde a tomar

97
00:03:28,190 --> 00:03:29,980
o produto de um conjunto de valores.

98
00:03:30,590 --> 00:03:32,290
Você está familiarizado com

99
00:03:32,400 --> 00:03:33,930
a notação de somatório, ou seja

100
00:03:34,520 --> 00:03:36,460
a soma de "i = 1" até

101
00:03:36,930 --> 00:03:39,070
"n" de "i".

102
00:03:39,960 --> 00:03:41,820
Isso é "1 + 2 + 3 + ..."

103
00:03:42,230 --> 00:03:43,730
até "n".

104
00:03:43,910 --> 00:03:45,350
Já esta outra expressão,

105
00:03:45,660 --> 00:03:46,910
com esse símbolo de produtório,

106
00:03:47,390 --> 00:03:48,630
representa o produto de "i = 1"

107
00:03:48,840 --> 00:03:50,310
até "n", de "i"

108
00:03:50,620 --> 00:03:52,210
É como no somatório,

109
00:03:52,520 --> 00:03:54,530
só que agora estamos multiplicando.

110
00:03:55,200 --> 00:03:56,680
Isso fica

111
00:03:56,880 --> 00:03:58,700
"1 · 2 · 3 · ..." até "n"

112
00:03:59,910 --> 00:04:01,330
Assim, usando

113
00:04:01,860 --> 00:04:03,430
essa notação de produto, essa

114
00:04:03,570 --> 00:04:05,880
expressão do produto de "j = 1" até "n"

115
00:04:06,620 --> 00:04:08,440
fica mais compacta, é um modo

116
00:04:08,820 --> 00:04:09,960
mais curto de escrever

117
00:04:10,330 --> 00:04:12,810
o produto de

118
00:04:13,120 --> 00:04:14,400
todos esses termos aí em cima.

119
00:04:15,200 --> 00:04:16,200
Tomamos esses termos,

120
00:04:16,430 --> 00:04:17,510
"p(xⱼ; μⱼ; σⱼ²)",

121
00:04:17,730 --> 00:04:18,740
"p(xⱼ; μⱼ; σⱼ²)",

122
00:04:19,130 --> 00:04:20,290
e os multiplicamos.

123
00:04:21,540 --> 00:04:22,830
Aliás, o problema

124
00:04:23,250 --> 00:04:25,370
de estimar esta distribuição

125
00:04:25,990 --> 00:04:27,130
"p(x)" às vezes é chamado

126
00:04:28,280 --> 00:04:29,540
"problema da estimativa da densidade",

127
00:04:30,420 --> 00:04:31,270
Daí o título do slide.

128
00:04:33,800 --> 00:04:35,310
Assim, juntando tudo, aqui

129
00:04:35,500 --> 00:04:36,920
está nosso algoritmo de detecção de anomalias.

130
00:04:38,120 --> 00:04:40,290
O primeiro passo é escolher características,

131
00:04:40,650 --> 00:04:41,600
definir características

132
00:04:41,700 --> 00:04:42,740
"xᵢ" que achamos

133
00:04:43,040 --> 00:04:45,340
que podem indicar exemplos anômalos.

134
00:04:46,050 --> 00:04:47,020
Quero dizer que

135
00:04:47,240 --> 00:04:48,490
é tentar encontrar

136
00:04:48,680 --> 00:04:49,990
características que indiquem

137
00:04:50,280 --> 00:04:51,630
quando há um usuário estranho

138
00:04:52,190 --> 00:04:53,000
sistema que possa estar fazendo

139
00:04:53,190 --> 00:04:54,790
coisas fraudulentas, ou, nos exemplos

140
00:04:55,020 --> 00:04:56,670
de motores de avião, se você sabe que

141
00:04:56,760 --> 00:04:59,500
há algo de errado com um dos motores, escolha

142
00:05:00,280 --> 00:05:01,230
características "xᵢ"

143
00:05:02,000 --> 00:05:03,330
que você pense que, nesses casos,

144
00:05:04,410 --> 00:05:05,860
tomarão valores anormalmente

145
00:05:06,020 --> 00:05:08,750
grandes ou pequenos, quando

146
00:05:08,880 --> 00:05:10,160
o exemplo é anômalo.

147
00:05:10,910 --> 00:05:12,440
Mas, em geral, tente

148
00:05:12,690 --> 00:05:14,340
escolher características que descrevam

149
00:05:16,160 --> 00:05:19,380
propriedades gerais daquilo sobre o qual você está recolhendo dados.

150
00:05:20,030 --> 00:05:21,360
Em seguida, dado um conjunto de treino

151
00:05:22,020 --> 00:05:23,980
de "m" exemplos não etiquetados

152
00:05:25,000 --> 00:05:26,980
"x₁" a "xₘ", nós

153
00:05:27,170 --> 00:05:28,580
vamos ajustar os parâmetros

154
00:05:29,090 --> 00:05:30,170
"μ₁" a "μₙ" e

155
00:05:30,340 --> 00:05:31,480
"σ₁²"

156
00:05:31,690 --> 00:05:33,460
a "σₙ²".

157
00:05:33,840 --> 00:05:34,810
As fórmulas são

158
00:05:34,840 --> 00:05:36,420
parecidas com as do vídeo anterior,

159
00:05:36,680 --> 00:05:37,610
que usamos

160
00:05:37,740 --> 00:05:39,180
para estimar

161
00:05:39,310 --> 00:05:41,120
de cada um desses parâmetros.

162
00:05:42,030 --> 00:05:43,670
Dando uma interpretação, "μⱼ"

163
00:05:44,060 --> 00:05:47,830
é o valor médio da característica "j".

164
00:05:48,720 --> 00:05:51,580
"μⱼ" aparece neste termo "p(xⱼ)"

165
00:05:52,440 --> 00:05:53,870
que é parametrizado por "μⱼ"

166
00:05:54,220 --> 00:05:55,590
"σⱼ²".

167
00:05:55,920 --> 00:05:57,890
Isso quer dizer que,

168
00:05:58,360 --> 00:05:59,620
para "μⱼ", basta tomar

169
00:05:59,700 --> 00:06:00,720
a média dos valores

170
00:06:01,070 --> 00:06:02,930
da característica "j" nos exemplos de treino.

171
00:06:03,860 --> 00:06:05,100
Vale à pena mencionar que

172
00:06:05,220 --> 00:06:07,410
você calcula estas fórmulas

173
00:06:07,620 --> 00:06:08,830
com "j = 1" a "n".

174
00:06:09,420 --> 00:06:10,360
Portanto,

175
00:06:10,700 --> 00:06:11,960
usamos as fórmulas para

176
00:06:12,230 --> 00:06:14,020
estimar "μ₁", "μ₂",

177
00:06:14,070 --> 00:06:15,620
e assim por diante até "μₙ",

178
00:06:16,170 --> 00:06:17,460
e da mesma forma para "σ²".

179
00:06:17,770 --> 00:06:19,060
Também é possível

180
00:06:19,390 --> 00:06:21,530
escrever uma versão vetorizada dessas fórmulas.

181
00:06:21,830 --> 00:06:22,900
Assim, se pensarmos

182
00:06:23,000 --> 00:06:25,220
em "μ" como um vetor,

183
00:06:25,920 --> 00:06:27,430
com componentes "μ₁",

184
00:06:27,760 --> 00:06:29,230
"μ₂"  até "μₙ",

185
00:06:29,570 --> 00:06:31,180
uma versão vetorizada

186
00:06:31,660 --> 00:06:33,510
desse conjunto de parâmetros

187
00:06:33,910 --> 00:06:35,530
pode ser escrita

188
00:06:36,440 --> 00:06:37,830
como uma soma dos "xᵢ"

189
00:06:37,880 --> 00:06:39,610
de "i = 1" até "n", dividida por "m".

190
00:06:40,290 --> 00:06:41,290
Por isso, essa fórmula

191
00:06:41,410 --> 00:06:43,530
que eu escrevi estima "μ" para todos os

192
00:06:43,990 --> 00:06:45,160
valores de "m"

193
00:06:45,660 --> 00:06:48,140
simultaneamente, onde os "xᵢ" são os vetores de características.

194
00:06:49,140 --> 00:06:50,070
Também é possível

195
00:06:50,430 --> 00:06:52,130
encontrar uma fórmula vetorizada

196
00:06:52,290 --> 00:06:55,110
para estimar "σⱼ²".

197
00:06:56,500 --> 00:06:57,890
Quando você recebe um novo exemplo,

198
00:06:58,100 --> 00:06:59,270
por exemplo, um novo motor

199
00:06:59,740 --> 00:07:01,420
de avião que não sabe se é anômalo,

200
00:07:02,470 --> 00:07:03,430
precisamos

201
00:07:03,570 --> 00:07:05,610
calcular "p(x)".
Qual é a probabilidade desse novo exemplo?

202
00:07:06,790 --> 00:07:07,670
"p(x)" é igual

203
00:07:07,990 --> 00:07:09,990
a esse produto, e o que você

204
00:07:10,100 --> 00:07:11,140
implementa, ou calcula,

205
00:07:11,750 --> 00:07:14,040
é essa fórmula, onde

206
00:07:15,000 --> 00:07:16,610
isto aqui é apenas

207
00:07:16,840 --> 00:07:17,900
a fórmula para a

208
00:07:18,260 --> 00:07:19,250
distribuição gaussiana

209
00:07:19,800 --> 00:07:21,000
de probabilidade.

210
00:07:21,240 --> 00:07:22,880
Finalmente, se essa

211
00:07:22,940 --> 00:07:24,420
probabilidade é muito pequena, você

212
00:07:24,860 --> 00:07:26,370
marca este exemplo como uma anomalia.

213
00:07:27,570 --> 00:07:29,380
Aqui está um exemplo de aplicação desse método.

214
00:07:30,870 --> 00:07:31,860
Digamos que nós temos

215
00:07:32,210 --> 00:07:35,430
este conjunto de dados no canto superior esquerdo do slide.

216
00:07:36,670 --> 00:07:38,860
Vamos olhar para a característica "x₁".

217
00:07:39,610 --> 00:07:40,640
Olhando bem para esses

218
00:07:40,750 --> 00:07:42,600
dados, parece que os valores de "x₁"

219
00:07:42,950 --> 00:07:44,330
têm média em torno de 5,

220
00:07:45,540 --> 00:07:47,420
e o desvio padrão, olhando

221
00:07:47,590 --> 00:07:48,660
apenas para os valores "x₁"

222
00:07:49,010 --> 00:07:50,030
do conjunto de dados,

223
00:07:50,310 --> 00:07:51,720
talvez seja igual a 2,

224
00:07:52,370 --> 00:07:55,110
isso é "σ₁".

225
00:07:55,460 --> 00:07:57,380
Parece, também, que

226
00:07:57,670 --> 00:07:59,070
os valores de "x₂",

227
00:07:59,250 --> 00:08:00,370
medidos no eixo vertical,

228
00:08:00,840 --> 00:08:01,730
têm

229
00:08:02,010 --> 00:08:03,110
média em torno de 3,

230
00:08:03,380 --> 00:08:05,750
e um desvio padrão em torno de 1.

231
00:08:05,880 --> 00:08:06,940
Assim, tomando esse

232
00:08:07,010 --> 00:08:08,690
conjunto de dados e estimando

233
00:08:09,030 --> 00:08:11,410
"μ₁" , "μ₂", "σ₁" e "σ₂", isso é o que você obtém.

234
00:08:11,610 --> 00:08:12,930
De novo, quando eu escrevo "σ"

235
00:08:13,140 --> 00:08:14,620
estou pensando em desvio padrão,

236
00:08:15,100 --> 00:08:16,240
mas a fórmula no slide anterior

237
00:08:16,280 --> 00:08:17,640
na verdade estima os quadrados

238
00:08:18,120 --> 00:08:20,670
dessas quantidades ("σ₁²" e "σ₂²").

239
00:08:20,940 --> 00:08:21,920
Por isso, preste atenção

240
00:08:22,090 --> 00:08:23,260
se está usando "σ₁" e "σ₂"

241
00:08:23,380 --> 00:08:25,490
ou "σ₁²" e "σ₂²".

242
00:08:25,960 --> 00:08:26,700
Assim, "σ₁²" quadrado seria

243
00:08:26,820 --> 00:08:28,500
claramente 4, por exemplo,

244
00:08:31,130 --> 00:08:32,260
pois é o quadrado de 2.

245
00:08:32,310 --> 00:08:34,010
Em desenhos, "p(x₁)",

246
00:08:34,180 --> 00:08:35,550
parametrizada por "μ₁" e

247
00:08:35,660 --> 00:08:36,830
"σ₁²" quadrado, e "p(x₂)",

248
00:08:37,120 --> 00:08:38,130
parametrizada por "μ₂" e

249
00:08:38,230 --> 00:08:39,050
"σ₂²",

250
00:08:39,190 --> 00:08:41,360
parecem-se com essas duas distribuições aqui.

251
00:08:42,650 --> 00:08:44,280
Acontece que, se

252
00:08:44,480 --> 00:08:45,960
se tentássemos traçar "p(x)",

253
00:08:46,210 --> 00:08:47,540
que é o produto

254
00:08:47,710 --> 00:08:49,000
daquelas duas quantidades,

255
00:08:49,210 --> 00:08:50,450
você obtém um

256
00:08:50,800 --> 00:08:52,770
gráfico de superfície que parece com isso.

257
00:08:53,360 --> 00:08:54,370
Isso é uma representação de "p(x)",

258
00:08:54,640 --> 00:08:55,920
onde a altura

259
00:08:56,390 --> 00:08:57,730
da superfície

260
00:08:57,830 --> 00:08:58,950
em um ponto

261
00:08:58,990 --> 00:09:01,360
em particular, por exemplo,

262
00:09:01,470 --> 00:09:03,670
dados valores "x₁" e "x₂",

263
00:09:03,930 --> 00:09:05,640
se "x₁ = 2" e

264
00:09:05,800 --> 00:09:07,830
"x₂ = 2", temos esse ponto.

265
00:09:08,510 --> 00:09:09,450
A altura dessa superfície

266
00:09:09,710 --> 00:09:11,280
3D aqui é "p(x)".

267
00:09:13,020 --> 00:09:14,420
Portanto "p(x)", é a altura

268
00:09:14,710 --> 00:09:16,220
desse gráfico, é

269
00:09:16,340 --> 00:09:17,520
literalmente apenas

270
00:09:18,640 --> 00:09:20,010
"p(x₁; μ₁; σ₁²)"

271
00:09:20,290 --> 00:09:22,540
multiplicada por

272
00:09:23,200 --> 00:09:25,050
"p(x₂; μ₂; σ₂²)".

273
00:09:25,120 --> 00:09:27,530
"p(x₂; μ₂; σ₂²)".

274
00:09:27,720 --> 00:09:29,180
Ajustamos os parâmetros

275
00:09:29,320 --> 00:09:31,400
aos dados da seguinte maneira.

276
00:09:31,930 --> 00:09:32,950
Digamos que temos um grupo de novos exemplos.

277
00:09:33,530 --> 00:09:35,090
Talvez eu tenha um novo exemplo aqui.

278
00:09:36,700 --> 00:09:38,340
Ele é uma anomalia ou não?

279
00:09:38,550 --> 00:09:39,220
Talvez

280
00:09:39,570 --> 00:09:41,860
eu tenha um segundo exemplo diferente aqui.

281
00:09:42,140 --> 00:09:43,400
Aquilo é uma anomalia ou não?

282
00:09:44,360 --> 00:09:47,050
Fazemos isso

283
00:09:47,190 --> 00:09:48,470
definindo um valor para

284
00:09:48,620 --> 00:09:49,490
"ε",

285
00:09:50,020 --> 00:09:51,220
digamos, "ε = 0,02".

286
00:09:51,980 --> 00:09:54,110
Mais tarde digo como escolhemos "ε".

287
00:09:55,180 --> 00:09:56,110
Mas primeiro

288
00:09:56,540 --> 00:09:57,360
vamos

289
00:09:57,500 --> 00:09:59,500
pegar esse primeiro exemplo, "x⁽¹⁾ₜₑₛₜ",

290
00:10:00,200 --> 00:10:01,010
e também

291
00:10:02,800 --> 00:10:03,900
o segundo, "x⁽²⁾ₜₑₛₜ".

292
00:10:04,780 --> 00:10:05,670
Agora

293
00:10:05,820 --> 00:10:07,380
calculamos "p(x⁽¹⁾ₜₑₛₜ)",

294
00:10:07,540 --> 00:10:08,740
usamos esta

295
00:10:08,990 --> 00:10:10,400
fórmula para calcular, e

296
00:10:11,140 --> 00:10:12,760
este parece um valor muito grande.

297
00:10:13,250 --> 00:10:15,560
Em particular, ele é

298
00:10:15,920 --> 00:10:18,480
maior ou igual que "ε".

299
00:10:18,670 --> 00:10:19,670
Essa é uma

300
00:10:19,810 --> 00:10:21,290
probabilidade bem alta, pelo menos

301
00:10:21,490 --> 00:10:22,510
maior que "ε", portanto

302
00:10:22,970 --> 00:10:24,490
dizemos que "x⁽¹⁾ₜₑₛₜ" não é uma anomalia.

303
00:10:25,650 --> 00:10:27,370
Já se você calcular

304
00:10:27,440 --> 00:10:29,810
"p(x⁽²⁾ₜₑₛₜ)", o resultado é um valor muito menor.

305
00:10:30,170 --> 00:10:31,340
É menor que

306
00:10:31,490 --> 00:10:32,490
"ε", e, assim, dizemos

307
00:10:32,720 --> 00:10:34,400
que é realmente uma anomalia,

308
00:10:34,860 --> 00:10:37,350
porque é muito menor que o "ε" que tínhamos escolhido.

309
00:10:38,450 --> 00:10:39,950
Dizendo melhor, o que isso

310
00:10:40,460 --> 00:10:43,340
quer dizer é que se você olhar para o gráfico da superfície 3D,

311
00:10:44,660 --> 00:10:46,270
todos os valores

312
00:10:46,350 --> 00:10:47,940
de "x₁" e "x₂"

313
00:10:48,210 --> 00:10:50,570
que têm uma grande altura

314
00:10:50,810 --> 00:10:52,770
na superfície correspondem a

315
00:10:52,910 --> 00:10:55,160
exemplos não anômalos, normais.

316
00:10:55,970 --> 00:10:57,450
Já todos os pontos mais distantes,

317
00:10:57,640 --> 00:10:58,940
todos os pontos aqui fora

318
00:10:59,150 --> 00:11:00,460
têm uma baixa

319
00:11:00,580 --> 00:11:01,740
probabilidade,

320
00:11:01,910 --> 00:11:02,940
portanto nós

321
00:11:03,020 --> 00:11:04,310
marcamos esses pontos

322
00:11:04,620 --> 00:11:06,350
como anomalias. Isso define

323
00:11:06,760 --> 00:11:07,790
uma região, talvez parecida com

324
00:11:08,000 --> 00:11:09,480
isto, e tudo

325
00:11:09,810 --> 00:11:12,160
fora dela é classificado

326
00:11:12,380 --> 00:11:12,580
como anômalo,

327
00:11:14,940 --> 00:11:16,260
enquanto as coisas dentro desta

328
00:11:16,770 --> 00:11:18,340
elipse que eu acabei de desenhar

329
00:11:18,570 --> 00:11:21,320
são consideradas exemplos não anômalos.

330
00:11:22,110 --> 00:11:24,040
Assim, esse exemplo

331
00:11:24,250 --> 00:11:26,260
"x⁽²⁾ₜₑₛₜ" fica fora

332
00:11:26,650 --> 00:11:27,510
dessa região,

333
00:11:27,620 --> 00:11:30,280
tem probabilidade baixa, nós o consideramos um exemplo anômalo.

334
00:11:31,400 --> 00:11:32,990
Neste vídeo, nós falamos sobre como

335
00:11:33,460 --> 00:11:35,440
estimar "p(x)", a probabilidade de

336
00:11:35,590 --> 00:11:36,840
"x", com o objetivo de

337
00:11:36,930 --> 00:11:38,740
criar um algoritmo de detecção de anomalias.

338
00:11:39,880 --> 00:11:40,890
Neste vídeo, nós também

339
00:11:41,260 --> 00:11:42,970
seguimos o processo

340
00:11:43,830 --> 00:11:45,090
de pegar um conjunto de dados,

341
00:11:45,340 --> 00:11:47,740
ajustar os parâmetros, fazendo estimativa de parâmetros,

342
00:11:48,370 --> 00:11:50,570
Obtivemos os parâmetros "μ" e "σ", e

343
00:11:50,700 --> 00:11:52,180
depois tomamos novos exemplos e decidimos

344
00:11:52,740 --> 00:11:54,110
se eles eram anômalos ou não.

345
00:11:55,490 --> 00:11:56,800
Nos próximos vídeos,

346
00:11:56,880 --> 00:11:58,580
vamos mergulhar mais fundo nesse algoritmo,

347
00:11:58,980 --> 00:11:59,930
e falar um pouco mais

348
00:12:00,230 --> 00:12:02,310
sobre como fazê-lo funcionar bem.