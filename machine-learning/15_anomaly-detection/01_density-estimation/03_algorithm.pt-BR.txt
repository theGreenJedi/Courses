No último vídeo, falamos sobre a distribuição gaussiana. Neste vídeo vamos aplicar isso para criar um algoritmo de detecção de anomalias. Digamos que temos um conjunto não etiquetado com "m" exemplos de treino, e cada um desses exemplos vai ser um escalar em "ℝⁿ". Assim, ele poderia ser vetores de características dos últimos "m" motores de avião fabricados, ou características de "m" usuários, ou outra coisa. Vamos tratar a detecção de anomalias modelando "p(x)" a partir do conjunto de dados. Tentaremos descobrir quais as características de alta probabilidade e quais são as de baixa probabilidade. Portanto, "x" é um vetor, e nós vamos modelar "p(x)" como a probabilidade de "x₁", ou seja, do primeiro componente de "x", vezes a probabilidade de "x₂", a probabilidade da segunda caracterísitica, vezes a probabilidade da terceira característica, e por aí adiante até a probabilidade da última característica "xₙ". de Xn. Deixei um espaço aqui porque vou completar tudo num minuto. Como é que nós modelamos cada um destes termos, "p(x₁)", "p(x₂)", e em diante? O que vamos fazer é assumir que essa característica, "x₁", está distribuída de acordo com uma distribuição gaussiana, com uma média "μ₁" e uma variância, "σ₁²". Assim, "p(x₁)" será uma distribuição de probabilidade gaussiana com média "μ₁" e variância "σ₁²". Similarmente, vou assumir que "x₂" é uma distribuição gaussiana, indicada por este pequeno til, isso significa distribuído de forma gaussiana com média "μ₂" e variância "σ₂²", portanto distribuída de acordo com uma gaussiana diferente que tem outro conjunto de parâmetros, "μ₂" e "σ₂²". Similarmente, "x₃" é ainda outra gaussiana, portanto pode ter uma média e um desvio padrão diferente das outras características, e assim por diante, até "xₙ". Esse é o meu modelo. Apenas um comentário à parte para aqueles que são experientes em estatística, esta equação que eu acabei de escrever na verdade corresponde a assumir que os valores das características "x₁" a "xₙ" são independentes. Apesar disso, o algoritmo funciona muito bem, quer estes elas sejam próximas de independentes ou não. Mesmo que elas não sejam realmente indepententes, este algoritmo funciona bem. Mas caso você não conheça esses termos, como assumir independência, não se preocupe. não se preocupe com isso. Você vai ser capaz de compreender e implementar este algoritmo corretamete o comentário é para as pessoas mais experientes em estatística. Finalmente, para podermos terminar isto, deixem-me tornar esta expressão um pouco mais compacta. Então, escrevemos isto como um produto de "j = 1" até "n", de "p(xⱼ)" parametrizado por "μⱼ" e "σⱼ²". Este símbolo estranho aqui é a letra grega "π" maiúscula, esse símbolo corresponde a tomar o produto de um conjunto de valores. Você está familiarizado com a notação de somatório, ou seja a soma de "i = 1" até "n" de "i". Isso é "1 + 2 + 3 + ..." até "n". Já esta outra expressão, com esse símbolo de produtório, representa o produto de "i = 1" até "n", de "i" É como no somatório, só que agora estamos multiplicando. Isso fica "1 · 2 · 3 · ..." até "n" Assim, usando essa notação de produto, essa expressão do produto de "j = 1" até "n" fica mais compacta, é um modo mais curto de escrever o produto de todos esses termos aí em cima. Tomamos esses termos, "p(xⱼ; μⱼ; σⱼ²)", "p(xⱼ; μⱼ; σⱼ²)", e os multiplicamos. Aliás, o problema de estimar esta distribuição "p(x)" às vezes é chamado "problema da estimativa da densidade", Daí o título do slide. Assim, juntando tudo, aqui está nosso algoritmo de detecção de anomalias. O primeiro passo é escolher características, definir características "xᵢ" que achamos que podem indicar exemplos anômalos. Quero dizer que é tentar encontrar características que indiquem quando há um usuário estranho sistema que possa estar fazendo coisas fraudulentas, ou, nos exemplos de motores de avião, se você sabe que há algo de errado com um dos motores, escolha características "xᵢ" que você pense que, nesses casos, tomarão valores anormalmente grandes ou pequenos, quando o exemplo é anômalo. Mas, em geral, tente escolher características que descrevam propriedades gerais daquilo sobre o qual você está recolhendo dados. Em seguida, dado um conjunto de treino de "m" exemplos não etiquetados "x₁" a "xₘ", nós vamos ajustar os parâmetros "μ₁" a "μₙ" e "σ₁²" a "σₙ²". As fórmulas são parecidas com as do vídeo anterior, que usamos para estimar de cada um desses parâmetros. Dando uma interpretação, "μⱼ" é o valor médio da característica "j". "μⱼ" aparece neste termo "p(xⱼ)" que é parametrizado por "μⱼ" "σⱼ²". Isso quer dizer que, para "μⱼ", basta tomar a média dos valores da característica "j" nos exemplos de treino. Vale à pena mencionar que você calcula estas fórmulas com "j = 1" a "n". Portanto, usamos as fórmulas para estimar "μ₁", "μ₂", e assim por diante até "μₙ", e da mesma forma para "σ²". Também é possível escrever uma versão vetorizada dessas fórmulas. Assim, se pensarmos em "μ" como um vetor, com componentes "μ₁", "μ₂"  até "μₙ", uma versão vetorizada desse conjunto de parâmetros pode ser escrita como uma soma dos "xᵢ" de "i = 1" até "n", dividida por "m". Por isso, essa fórmula que eu escrevi estima "μ" para todos os valores de "m" simultaneamente, onde os "xᵢ" são os vetores de características. Também é possível encontrar uma fórmula vetorizada para estimar "σⱼ²". Quando você recebe um novo exemplo, por exemplo, um novo motor de avião que não sabe se é anômalo, precisamos calcular "p(x)".
Qual é a probabilidade desse novo exemplo? "p(x)" é igual a esse produto, e o que você implementa, ou calcula, é essa fórmula, onde isto aqui é apenas a fórmula para a distribuição gaussiana de probabilidade. Finalmente, se essa probabilidade é muito pequena, você marca este exemplo como uma anomalia. Aqui está um exemplo de aplicação desse método. Digamos que nós temos este conjunto de dados no canto superior esquerdo do slide. Vamos olhar para a característica "x₁". Olhando bem para esses dados, parece que os valores de "x₁" têm média em torno de 5, e o desvio padrão, olhando apenas para os valores "x₁" do conjunto de dados, talvez seja igual a 2, isso é "σ₁". Parece, também, que os valores de "x₂", medidos no eixo vertical, têm média em torno de 3, e um desvio padrão em torno de 1. Assim, tomando esse conjunto de dados e estimando "μ₁" , "μ₂", "σ₁" e "σ₂", isso é o que você obtém. De novo, quando eu escrevo "σ" estou pensando em desvio padrão, mas a fórmula no slide anterior na verdade estima os quadrados dessas quantidades ("σ₁²" e "σ₂²"). Por isso, preste atenção se está usando "σ₁" e "σ₂" ou "σ₁²" e "σ₂²". Assim, "σ₁²" quadrado seria claramente 4, por exemplo, pois é o quadrado de 2. Em desenhos, "p(x₁)", parametrizada por "μ₁" e "σ₁²" quadrado, e "p(x₂)", parametrizada por "μ₂" e "σ₂²", parecem-se com essas duas distribuições aqui. Acontece que, se se tentássemos traçar "p(x)", que é o produto daquelas duas quantidades, você obtém um gráfico de superfície que parece com isso. Isso é uma representação de "p(x)", onde a altura da superfície em um ponto em particular, por exemplo, dados valores "x₁" e "x₂", se "x₁ = 2" e "x₂ = 2", temos esse ponto. A altura dessa superfície 3D aqui é "p(x)". Portanto "p(x)", é a altura desse gráfico, é literalmente apenas "p(x₁; μ₁; σ₁²)" multiplicada por "p(x₂; μ₂; σ₂²)". "p(x₂; μ₂; σ₂²)". Ajustamos os parâmetros aos dados da seguinte maneira. Digamos que temos um grupo de novos exemplos. Talvez eu tenha um novo exemplo aqui. Ele é uma anomalia ou não? Talvez eu tenha um segundo exemplo diferente aqui. Aquilo é uma anomalia ou não? Fazemos isso definindo um valor para "ε", digamos, "ε = 0,02". Mais tarde digo como escolhemos "ε". Mas primeiro vamos pegar esse primeiro exemplo, "x⁽¹⁾ₜₑₛₜ", e também o segundo, "x⁽²⁾ₜₑₛₜ". Agora calculamos "p(x⁽¹⁾ₜₑₛₜ)", usamos esta fórmula para calcular, e este parece um valor muito grande. Em particular, ele é maior ou igual que "ε". Essa é uma probabilidade bem alta, pelo menos maior que "ε", portanto dizemos que "x⁽¹⁾ₜₑₛₜ" não é uma anomalia. Já se você calcular "p(x⁽²⁾ₜₑₛₜ)", o resultado é um valor muito menor. É menor que "ε", e, assim, dizemos que é realmente uma anomalia, porque é muito menor que o "ε" que tínhamos escolhido. Dizendo melhor, o que isso quer dizer é que se você olhar para o gráfico da superfície 3D, todos os valores de "x₁" e "x₂" que têm uma grande altura na superfície correspondem a exemplos não anômalos, normais. Já todos os pontos mais distantes, todos os pontos aqui fora têm uma baixa probabilidade, portanto nós marcamos esses pontos como anomalias. Isso define uma região, talvez parecida com isto, e tudo fora dela é classificado como anômalo, enquanto as coisas dentro desta elipse que eu acabei de desenhar são consideradas exemplos não anômalos. Assim, esse exemplo "x⁽²⁾ₜₑₛₜ" fica fora dessa região, tem probabilidade baixa, nós o consideramos um exemplo anômalo. Neste vídeo, nós falamos sobre como estimar "p(x)", a probabilidade de "x", com o objetivo de criar um algoritmo de detecção de anomalias. Neste vídeo, nós também seguimos o processo de pegar um conjunto de dados, ajustar os parâmetros, fazendo estimativa de parâmetros, Obtivemos os parâmetros "μ" e "σ", e depois tomamos novos exemplos e decidimos se eles eram anômalos ou não. Nos próximos vídeos, vamos mergulhar mais fundo nesse algoritmo, e falar um pouco mais sobre como fazê-lo funcionar bem.