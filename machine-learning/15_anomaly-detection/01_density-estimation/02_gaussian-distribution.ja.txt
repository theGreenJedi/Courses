このビデオでは、 ガウス分布について議論したい、 それは正規分布とも呼ばれる。 もしガウス分布に既に十分に 慣れ親しんでいるのなら、 たぶんこのビデオはスキップしてOKだ。 だがもしあんま自信無かったり ガウス分布または正規分布を 使っていた頃から随分と時間が経っているのなら、 このビデオを終わりまで 見てみてください。 そしてこのビデオの後には、 アノマリー検出のアルゴリズムを 開発する為にガウス分布を用いていきます。 xは実数のランダムな数と します。つまりxは実数です。 もしxの確率分布が ガウス分布で、 平均ミューと分散シグマ二乗である事を こう書ける: ランダム変数x チルダ ここでこの 小さなチルダ記号の意味する所は 分布が等しいという事で、 その後にガウス分布を記述する訳だが、 それには、記号のNにかっこで ミュー、シグマ二乗と書く事になっている。 つまりこの記号NはノーマルのN、 だってガウス分布は正規（ノーマル）分布だから。 それは同じ意味で、 Normalの省略系で ガウス分布は2つのパラメータで パラメトライズされてる、という事を表す。 2つのパラメータとは平均を表すミューと シグマ二乗で示される 分散のパラメータ。 ガウス分布またはガウス確率密度を プロットすると、 ベル型のカーブとなる、 見たことあるかもしれないね。 そしてつまり、このベル型のカーブは 2つのパラメータ、ミューとシグマでパラメトライズされてる。 このベル型のカーブの 中心は平均のミューで、 そしてこのベル型のカーブの 幅がだいたい、 このパラメータ シグマであり、 1標準偏差とも呼ばれている。 これはxが 様々な値を取る 確率を示している、 つまりxがこの 真ん中の値を取ると、極めて高くなる。 なぜならガウス分布のここは とても高い一方で xがこの遥か離れた所の値を取る場合は 確率は減衰するだろう。 最後に、完璧を期するという目的の為だけに、 ガウス分布の式を 書き下しておこう。 xの確率は、、、 ところでたまに、p(x)と 書く代わりに、 これをpのxに セミコロンでミュー、シグマ二乗とつなげて 書くことがある。 これはxの確率は2つのパラメータ ミューとシグマ二乗で パラメトライズされている事を示す。 そしてガウス密度の 式はこれだ。 2パイのシグマ分の一の eのマイナス x引くミュー の二乗 割ることの 2シグマ二乗。 この式を暗記する必要は無い。 これは単に ここの左にある ベル型のカーブの式ってだけに過ぎない。 それを暗記する必要は無いし、 もしこれを使う必要が出てきても、 その時調べれば良い。 以上がこの左にある図で これが ミューとシグマを固定して p(x)をプロットしたら 得る物だ。 このここのカーブ、 これがミューとシグマ二乗、 つまり分散を 固定して p(x)をxの関数として プロットした物だ。 時には（シグマ二乗より）シグマで考えた方が楽な事もある。 シグマは標準偏差と呼ばれる物で それはガウスの確率分布の 幅を 規定するもので、 一方シグマ二乗、 シグマの二乗は 分散と呼ばれる物。 ガウス分布が実際にどんな感じか、例を見てみよう。 ミューが0でシグマが1だとすると、 ゼロを中心に持つ ガウス分布となる、何故ならそれはミューの事で、 ガウス分布の幅は つまり1標準偏差はここのシグマとなる。 ガウス分布の例を見てみよう。 ミューが0で シグマが1の時は ゼロの所を中心とする ガウス分布に対応する、 何故ならミューが0だから。 そしてガウス分布の幅は、、、 ガウス分布では幅は シグマにより、つまり分散のパラメータ、シグマにより制御されている。 もう一つの例はこんな感じ。 ミューが0で シグマが1/2としよう。 つまり標準偏差が1/2で 分散、シグマ二乗は 0.5の二乗、つまり 0.25となる。 その場合、ガウス分布、 ガウス確率密度はこんな感じとなる、 今回もゼロを中心としているが、 だが今回は幅が より狭くなっている、 何故なら分散が小さくなったから。 ガウス密度は だいたい半分の幅となっている。 だがこれは確率分布なのだから、 カーブの下の面積、 つまり影をつけた部分は、 積分すると 必ず1となる。 これは確率分布の性質だ。 また、そうであるから、 これはより背の高いガウス密度となる、だって 標準偏差が半分だから 幅も半分になるので、高さは二倍となる訳だ。 もう一つ例。シグマが2だと より太った、またはより幅の広い ガウス密度となる。 つまりここでは、 パラメータのシグマはガウス密度が どれだけの幅を持つかを制御している。 そして今回も、曲線の下の面積は この影をつけた領域だが、 それはいつでも積分すると1となる。 それは確率分布の性質で 今回はより幅が広くなったのだから、 高さは半分になっている、 積分した結果が同じになるように。 そして最後に、最後の例は、 ミューも同じように変更していった場合、 ゼロを真ん中に分布する代わりに、 ここでは3の回りに 分布するガウス分布を 得る。 何故ならこれはガウス分布全体をシフトさせるから。 次にパラメータの推計の話題にうつろう。 パラメータの推計問題とはなんだろう？ m個の手本データセットが あるとしよう。つまりx1からxmまで。 そしてこれらの手本の個々は 実数だとしよう。 この図で、私は手本の データセットをプロットした。 横軸はx軸で 手本のデータは、 xがある範囲に広がっている。それをここに 単純にプロットしてみた。 そしてパラメータ推計の問題は これらの手本がガウス分布だったと 思っているとして、 つまりこの各手本x(i)が以下のように分布、、、 それがこのチルダの意味だったね。 で、これらの各手本が、 正規分布またの名をガウス分布に 従って分布していると 思ってるとする、 あるパラメータ、ミューとシグマ二乗の。 だが、これらの値が幾つかは知らない。 パラメータ推計の問題とは、 与えられたデータセットに対して、 ミューやシグマ二乗の値が 何になるのかを 推計したい、という事。 もしこんなデータセットを 与えられたら、 どんなガウス分布から このデータが生成されているかを 推計したら、 多分だいたい ミューを中心として シグマ、つまり標準偏差が このガウス分布の幅をコントロールしている。 これはだいたいデータに リーズナブルにフィットしている。何故なら データは見た感じ 中心のあたりにとても高い確率を 持っていて、外に離れれば離れる程 低い確率となっている。 だからこれはたぶん ミューとシグマ二乗の リーズナブルな推計となっている。 つまり、そのデータがガウス分布に 従っているのなら、それはこんな見た目のはずだ。 そこで私は、こうする: 式、つまり正規分布の式を 書き下して、 パラメータのミューとシグマ二乗を 推計する。 ミューを推計する方法は 単に平均をとるだけ、 手本の全体に わたって。 ミューは平均のパラメータだから。 つまりトレーニングセットから、 m個の手本から、 それらの平均をとる。 それは単にこの分布の、中心を与える。 ではシグマ二乗はどうか？ 分散に関しては、また通常の式を 書き下すと、 1からmまでに渡り、x(i)から ミューを引いた物の二乗の和を 計算する。 ここでこのミューは この式を使ってここで 計算したものだ。 そして分散とは何か、というと 一つの解釈としては、 この項を見ると分かるように、 手本の値と平均との 差の二乗と なっている。 つまり中心との差、分布の平均との差の。 そして分散を、 差分、つまり手本と平均との間の差分の 二乗の平均として 推計する訳だ。 ここでちょっと補足しておくと、 あなたが統計のエキスパートだったら 統計のエキスパートだったら 最尤法という物について 聞いたことがあるかもしれない。 そうであるなら、これらの推計は 実際には最尤法によるパラメータ、ミューとシグマ二乗の 推計である。 だがもしそれについて聞いた事が無ければ、気にしないでよろしい。 知らなくてはいけない事の全ては これら2つの公式が 所与のデータセットに対して、 ミューとシグマ二乗を見つけ出す標準的な方法だとという事だけだ。 最後にもう一つおまけ。 これもまた、以前に統計のクラスを 取った事のある人向けの話だ。 以前に統計のクラスを取った事があるなら、 ここにある式を 以前に見た時は mではなくてm-1 だったかもしれない。 つまりの最初の項が、 1/mではなくて、1/(m-1)に なる。機械学習では 1/mの式が使われる事が多い。 だが現実問題としては、 1/mだろうが 1/(m-1)だろうが、 本質的には大差無い、 mが普通に考えられる程度に大きい、つまりトレーニングセットのサイズが普通に大きければ。 ようするに、以前に別のバージョンの方を 見た事があった場合の為に補足しておくと、 どっちのバージョンでもちゃんと機能する。 だが機械学習では多くの人々は この公式の1/mの方を 使う傾向にある。 2つのバージョンは理論的には わずかに異なった特徴があり、 わずかに異なった数学的な特徴があるが、 現実の場面ではほとんど違いは無い。 以上で、ガウス分布が どんな感じか、 感覚的に分かるようになってくれただろうか。 パラメータ、ミューとシグマ二乗の ガウス分布における推計の仕方も 分かってくれただろうか。 トレーニングセットを与えられた時、 ガウス分布に従ったデータだと思われるが そのパラメータ、 ミューとシグマ二乗が 不明な時。 次のビデオでは、 これを用いて、 アノマリー検出のアルゴリズムを開発するのに適用していく。