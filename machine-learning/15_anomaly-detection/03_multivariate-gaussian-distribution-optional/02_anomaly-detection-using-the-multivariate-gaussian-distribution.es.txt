En el último vídeo, hablamos de la distribución Gaussiana multivariada, y vimos algunos ejemplos de los tipos de distribuciones que puede modelar, a medida que varía los parámetros, «Mu» y «sigma». En este video, tomaremos esas ideas y las aplicaremos para desarrollar un algoritmo de detección de anomalías. Para recapitular, la distribución Gaussiana multivariada o distribución normal multivariada, tiene dos parámetros, «Mu» y «sigma», donde «Mu» es un vector dimensional y «sigma», la matriz de covarianza es una matriz nxn. Esta es la fórmula para la probabilidad de "x", como se parametriza por medio de «Mu» y «sigma», a medida que varía «Mu» y «sigma», puede obtener un rango de diferentes distribuciones, como, ya sabe, estos son tres ejemplos de los que vimos en el video anterior. Vamos entonces a hablar del ajuste de parámetros o el problema de la estimación de parámetros. La cuestión, como siempre, es que si tengo conjunto de ejemplos de x1 a xm y aquí cada uno de estos ejemplos es un vector "n"dimensional y creo que mis ejemplos vienen de una distribución Gaussiana multivariada, ¿cómo puedo tratar de estimar los parámetros de «Mu» y «sigma»? Bueno, la fórmulas estándar para su estimación es que usted establece «Mu» para ser el promedio de sus ejemplos de entrenamiento y establece «sigma» para ser igual a esto, esto es en realidad como el «sigma» que habíamos escrito cuando estábamos utilizando el ACP o algoritmo de análisis de componentes principales. Entonces sólo tiene que activar estas dos fórmulas y esto le daría el parámetro estimado «Mu» y su parámetro estimado «sigma». Así que dado un grupo de datos, así es cómo usted estima «Mu» y «sigma». Tomemos este método y apliquémoslo a un algoritmo de detección de anomalías. Entonces, ¿cómo reunimos todo esto para desarrollar un algoritmo de detección de anomalías? Esto es lo que hacemos: Primero tomamos nuestro conjunto de entrenamiento y ajustamos el modelo, ajustamos p(x), al establecer «Mu» y «sigma», como se describió en la diapositiva anterior. Luego, cuando se le da un nuevo ejemplo x, si si se le da un ejemplo de prueba, vamos a tomar un ejemplo anterior para tener un nuevo ejemplo aquí. Ese es mi ejemplo de prueba. Dado el nuevo ejemplo x, lo que haremos será calcular p(x), usando esta fórmula para la distribución Gaussiana multivariada y entonces, si p(x) es muy pequeña, entonces marcamos esto como una anomalía, mientras que, si p(x) es mayor que el parámetro «épsilon», entonces no lo marcamos como anomalía. Así resulta que, si tuviéramos que ajustar una distribución Gaussiana multivarianda para este conjunto de datos, sólo las cruces rojas, no las verdes de ejemplo, termina con una distribución gaussiana que coloca mucha probabilidad en la región central, ligeramente menos probabilidad aquí, ligeramente menos probabilidad aquí, ligeramente menos probabilidad aquí, y muy baja probabilidad en el punto que está afuera. Y si aplica la distribución Gaussiana multivariada a este ejemplo, en realidad marcará correctamente ese ejemplo como una como una anomalía. Por último, vale la pena decir unas pocas palabras acerca de lo que es la relación entre el modelo de distribución Gaussiana multivariada y el modelo original, en el que modelamos p(x) como producto de esta p(x1), p(x2), hasta p(xn). Resulta que usted puede demostrar matemáticamente, no voy a hacer la prueba aquí pero usted puede demostrar matemáticamente esta relación entre el modelo de distribución Gaussiana multivariada y este original. En particular, resulta que el modelo original corresponde a Gaussianas multivariadas, en las que los contornos de las mismas siempre están alineados al eje. Así que estos son tres ejemplos de distribuciones Gaussianas que puede ajustar utilizando el modelo original. Resulta que esto corresponde a Gaussianas multivariadas, en las que como sabe, la elipse aquí, los contornos de esta distribución, tenemos que este modelo realmente corresponde a un caso especial de distribución Gaussiana multivariada y en particular, este caso especial se define al restringir la distribución de p(x), la distribución Gaussiana multivariada de p(x), de modo que que los contornos de la función de densidad de probabilidad, de la función de distribución de probabilidad, están alineados los ejes. Y para que pueda obtener una p(x) con una Gaussiana multivariada que se ve así, o así, o así. Puede darse cuenta que en los 3 ejemplos, estas elipses, o estos óvalos que estoy dibujando, tienen sus ejes alineados con los ejes x1, x2 y lo que no tenemos, es un conjunto de contornos que están en un ángulo, ¿verdad? Y esto corresponde a ejemplos en los que «sigma» es igual a 1 1, 0.8, 0.8, digamos que con elementos distintos a 0 fuera de las diagonales. También resulta que, es posible demostrar matemáticamente que este modelo es en realidad la misma distribución Gaussiana multivariada pero con una restricción. La restricción es que la matriz de covarianza «sigma» debe tener ceros en los elementos fuera de la diagonal. En particular, la matriz de covarianza de «sigma», esto de aquí, podría ser «sigma» cuadrada 1,«sigma» cuadrada 2, hasta «sigma» al cuadrado n y luego todo en las entradas fuera de la diagonal, todos estos elementos por encima y por debajo de la diagonal de la matriz, todos estos van a ser cero. De hecho, si toma estos valores de «sigma», «sigma» cuadrada 1, «sigma» cuadrada 2 hasta «sigma» cuadrada n, y los conecta aquí, ya sabe, conectarlos a esta matriz de covarianza, entonces los dos modelos son en realidad idénticos. Es decir, este nuevo modelo, que usa la distribución Gaussiana multivariada corresponde exactamente al modelo antiguo, si la matriz de covarianza «sigma» sólo tiene elementos 0 fuera de las diagonales y y en las imágenes esto corresponde a tener distribuciones Gaussianas, donde los contornos de esta función de distribución de probabilidad, están alineados a los ejes. Así que no se le permite modelar las correlaciones entre las distintas variables. Así que en ese sentido, el modelo original en realidad es un caso especial de este modelo Gaussiano multivariante. Así que ¿cuando utilizaría cada uno de estos dos modelos? ¿cuándo se usa el modelo original y cuándo se usa el modelo Gaussiano multivariado? El modelo original se usa probablemente un poco más a menudo, mientras que la distribución Gaussiana multivariada se utiliza un poco menos pero tiene la ventaja de ser capaz de capturar las correlaciones entre las variables. De modo que si quiere capturar anomalías donde tiene diferentes variables, digamos que en donde las variables x1, x2 toman combinaciones poco usuales de valores, por lo que en ejemplo anterior, tuvimos ese caso donde la anomalía fue con la carga de CPU y el uso de memoria teniendo combinaciones poco usuales de valores, si desea utilizar el modelo original para captar eso, entonces lo que necesitamos hacer es crear una variable extra, como x3=x1/x2 ya sabe, igualarlo a quizá, la carga de CPU dividida entre la memoria utilizada, o algo así, y necesitará crear variables adicionales si hay combinaciones poco usuales de valores, donde x1 y x2 toman una combinación inusual de valores a pesar de que x1 por sí misma y x2 por sí misma, lucen como si tomaran un valor perfectamente normal pero si usted está dispuesto a invertir el tiempo para crear de forma manual una variable adicional de este tipo, entonces, el modelo original trabajará bien. 
Mientras que por el contrario, el modelo Gaussiano multivariante puede capturar de forma automática las correlaciones entre diferentes variables pero el modelo original tiene algunas otras ventajas más significativas también. Una enorme ventaja del modelo original es que es computacionalmente más barato, otra forma de comprender esto, es que escala mejor a valores muy grandes de "n" y números muy grandes de variables y aún si "n" fuera 10,000, o incluso si "n" fuera igual a 100,000, el modelo original a menudo funcionará bien. Mientras que por el contrario con el modelo Gaussiano multivariante, note aquí, por ejemplo, que necesitamos calcular la inversa de la matriz «sigma», donde «sigma» es una matriz nxn, al calcular «sigma», si «sigma» es una matriz de 100,000x100,000 va a ser muy costoso computacionalmente. Y así, el modelo Gaussiano multivariado escala con menor eficiencia a grandes valores de "n" y finalmente, para el modelo original resulta que funciona bien, incluso si tiene un conjunto de entrenamiento relativamente pequeño, que son estos pequeños ejemplos sin valores asignados que utilizamos para modelar p(x), por supuesto, y esto funciona bien, incluso si «Mu» es, ya sabe, tal vez 50, 100, funcionará bien. Mientras que la distribución Gaussiana multivariada es una clase de propiedad matemática del algoritmo que debe tener m mayor que n, de modo que el número de ejemplos es mayor que el número de variables que tiene. Y hay una propiedad matemática de la forma en que calculamos los parámetros, y si esto no es cierto, si m es menor o igual a n, entonces esta matriz no es invertible, incluso, esta matriz es singular, por lo que ni siquiera se puede utilizar el modelo Gaussiano multivariado, a menos que haga algunos cambios en él. Pero una típica regla general que yo uso es que voy a utilizar el modelo Gaussiano multivariado sólo si m es mucho mayor que n, por lo que esta es una especie de requisito matemático estrecho, sin embargo, en la práctica, usaría el modelo Gaussiano multivariado, sólo si m fuera un poco mayor que n. 
Si m fuera mayor o igual a 10 veces n, digamos que, podría ser una regla razonable general, y si no satisface esto, entonces el modelo Gaussiano multivariante tiene muchos de los parámetros, ¿no?, por lo que este matriz de covarianza «sigma» es una matriz nxn, por lo que tiene, más o menos parámetros al cuadrado n, porque es una matriz simétrica, en realidad está más cerca de n al cuadrado sobre 2 parámetros pero  estos son muchos parámetros, por lo que necesita asegúrarse de que tiene un volumen suficientemente grande para m, asegúrese de que tiene los datos suficientes para ajustar todos estos parámetros. M mayor que 0 o igual a 10n sería una regla razonable general para asegurarse de que puede estimar esta matriz de covarianza «sigma» de forma razonable. Así que en la práctica, el modelo original mostrado a la izquierda es el que se usa con más frecuencia. Si usted sospecha que es necesario capturar las correlaciones entre las variables, lo que la gente suele hacer es diseñar manualmente funciones adicionales como estas para capturar combinaciones específicas poco usuales de valores, no obstante,en problemas en los que tiene un conjunto de entrenamiento muy grande o m es muy grande y "n" no es demasiado grande, entonces vale la pena considerar el modelo Gaussiano multivariante y puede funcionar mejor también además de salvarle de tener que pasar el tiempo creando manualmente variables adicionales en caso de que las anomalías resulten ser capturadas por combinaciones de valores inusuales de las variables. Finalmente, sólo quiero mencionar brevemente una propiedad algo técnica pero si usted está ajustando el modelo Gaussiano multivariado y si se da cuenta de que la matriz de covarianza «sigma» es singular, o si descubre que no es invertible, por lo general hay 2 casos para esto: Uno es que si está fallando al satisfacer esta condición de m mayor que n y el segundo caso es si tiene variables redundantes. Por variables redundantes, me refiero a que si tiene 2 variables que son las mismas, de alguna manera, por accidente ha realizado dos copias de la función, por lo que su x1 es exactamente igual a x2 o si tiene variables redundantes, como por ejemplo, su variable x3 es igual a x4  más la variable x5. ¿De acuerdo?, así que si tiene variables altamente redundantes como estas, donde si x3 es igual a x4 + x5, bueno, x3 no contiene ninguna información extra, ¿verdad? así que sólo tome estas otras 2 variables y agréguelas juntas y si tienes este tipo de variables redundantes, variables duplicadas o esta clase de variables, entonces, «sigma» puede ser no invertible. Existe un conjunto de depuración, esto debe ocurrir con poca frecuencia, por lo que probablemente no se encontrará con esto, es muy poco probable que usted tenga que preocuparse por esto pero en caso de implementar un modelo Gaussiano multivariado, encontrará que «sigma» no es invertible. Lo que quiero hacer es primero asegúrarme de que m es un poco más grande que n, y si es así, lo segundo que haré es simplemente revisar las variables redundantes. Si hay 2 variables que son iguales, sólo las voy a eliminar o si tiene variables redundantes, si x3 es igual a x4 más x5, simplemente hay que deshacerse de la variable redundante y entonces debería funcionar bien de nuevo. Como un apartado para aquellos de ustedes que son expertos en el álgebra lineal, por variables redundantes, me refiero al término formal de que son variables linealmente dependientes. Sin embargo, en la práctica, lo que realmente significa es uno de esos problemas de saturación del algoritmo, si sólo crea variables no redundantes, eso resolvería el problema de que «sigma» no es invertible. Una vez más, las probabilidades de que se encuentre con esto son muy bajas, así que quizá puede sólo aplicar el modelo de distribución Gaussiana multivariada sin tener que preocuparse porque «sigma» no sea invertible, siempre y cuando m sea mayor o igual a n.
De modo que detección de anomalías con la distribución Gaussiana multivariada, si usted aplica este método sería capaz de tener un algoritmo de detección de anomalías, que de forma automática captura las correlaciones negativas y positivas entre sus diferentes variables y marca una anomalía si detecta una combinación inusual de los valores de las variables.