在本视频中，我将介绍一种也许是最常见的机器学习问题。 即监督学习。后面将给出监督学习更正式的定义， 现在最好以示例来说明什么是监督学习。 之后再给出正式的定义。假设你想预测房价（无比需要啊！）， 之前，某学生已经从某地收集了数据集（不是中国的，囧） 其中一个数据集是这样的。 这是横坐标，即不同房子的面积，单位平方脚（^-^） 纵轴上是房价，单位 千美元。 根据给定数据，假设你朋友有栋房子，750平尺（70平米） 想知道这房子能卖多少，好卖掉。 那么，学习算法怎么帮你呢？学习算法可以： 绘出一条直线，让直线尽可能匹配到所有数据。 基于此，看上去，那个房子应该、可能、也许、大概 卖到15万美元（一平米两千刀！）。但这不是唯一的学习算法。 可能还有更好的。比如不用直线了， 可能平方函数会更好， 即二次多项式更符合数据集。如果你这样做， 预测结果就应该是20万刀（一平三千刀，涨价好快）。 后面我们会介绍到如何选择 是选择直线还是平方函数来拟合。 没有明确的选择，就不知哪个能给你的朋友 更好的卖房建议。只是这些每个都是很好的学习算法例子。 也是监督学习的例子。 术语监督学习，意指给出一个算法， 需要部分数据集已经有正确答案。比如给定房价数据集， 对于里面每个数据，算法都知道对应的正确房价， 即这房子实际卖出的价格。算法的结果就是 算出更多的正确价格，比如那个新房子， 你朋友想卖的那个。用更术语的方式来定义， 监督学习又叫回归问题，（应该是回归属于监督中的一种） 意指要预测一个连续值的输出，比如房价。 虽然从技术上，一般把房价记到美分单位。 所以实际还是个离散值，但通常把它看作实际数字， 是一个标量值，一个连续值的数，而术语回归， 意味着要预测这类连续值属性的种类。 另一个监督学习的例子，我和一些朋友 之前研究的领域。让我们来看医学记录， 并预测胸部肿瘤是恶性良性。 如果某人发现有胸部肿瘤，恶性肿瘤有害又危险， 良性肿瘤则是少害。 显然人们很关注这个。让我们看一个收集好的数据集， 假设在数据集中，横轴表示肿瘤的大小， 纵轴我打算圈上0或1，是或否， 即肿瘤是恶性的还是良性的。 所以如图所示，可以看到这个大小的肿瘤块 是良性的，还有这些大小的都是良性的。 不幸地是也看到一些恶性肿瘤，比如这些大小的肿瘤。 所以，有5个良性块，在这一块， 还有5个恶性的，它们纵轴值为1. 现在假设某人杯具地得胸部肿瘤了， 大小大概是这么大。 对应的机器学习问题就是，你能否估算出一个概率， 即肿瘤为恶或为良的概率？ 专业地说，这是个分类问题。 分类是要预测一个离散值输出。 这里是0或1，恶性或良性。事实证明， 在分类问题中，有时会有超过两个的值， 输出的值可能超过两种。举个具体例子， 胸部肿瘤可能有三种类型，所以要预测离散值0，1，2，3 0就是良性肿瘤，没有癌症。 1 表示1号癌症，假设总共有三种癌症。 2 是2号癌症，3 就是3号癌症。 这同样是个分类问题，因为它的输出的离散值集合 分别对应于无癌，1号，2号，3号癌症 我再露一小手，在分类问题中，还有另一种作图方式 来描述数据。我画你猜。要用到些许不同的符号集合 来描绘数据。如果肿瘤大小作为唯一属性， 被用于预测恶性良性，可以把数据作图成这样。 使用不同的符号来表示良性和 恶性，即阴性和阳性。所以，不再统一画叉叉了， 改用圈圈来代表良性肿瘤，就像这样。 仍沿用X（叉叉）代表恶性肿瘤。希望你能明白。 我所做的就是，把在上面的数据， 映射下来。再用不同的符号， 圈和叉来分别代表良性和恶性。 在上例中，只使用了一个特征属性，即肿瘤块大小， 来预测肿瘤是恶性良性。在其它机器学习问题里， 有着不只一个的特征和属性。 例子，现在不只是知道肿瘤大小， 病人年龄和肿瘤大小都知道了。这种情况下， 数据集如表图所示，有些病人，年龄、肿瘤已知， 不同的病人，会有一点不一样， 肿瘤恶性，则用叉来代表。所以，假设 有一朋友得了肿瘤。肿瘤大小和年龄 落在此处。那么依据这个给定的数据集，学习算法 所做的就是画一条直线，分开 恶性肿瘤和良性肿瘤，所以学习算法会 画条直线，像这样，把两类肿瘤分开。 然后你就能判断你朋友的肿瘤是...了 如果它在那边，学习算法就说 你朋友的肿瘤在良性一边，因此更可能 是良性的。好，本例中，总共有两个特征， 即病人年龄和肿瘤大小。在别的ML问题中， 经常会用到更多特征，我朋友研究这个问题时， 通常使用这些特征：比如块的厚度，即胸部肿瘤的厚度 肿瘤细胞大小和形状的一致性， 等等。它表明， 最有趣的学习算法（本课中将学到） 能够处理，无穷多个特征。不是3到5个这么少。 在这张幻灯片中，我已经列举了总共5个不同的特征。 但对于一些学习问题， 真要用到的不只是三五个特征， 要用到无数多个特征，非常多的属性， 所以，你的学习算法要使用很多的属性 或特征、线索来进行预测。那么，你如何处理 无限多特征呢？甚至你如何存储无数的东西 进电脑里，又要避免内存不足？ 事实上，等我们介绍一种叫支持向量机的算法时， 就知道存在一个简洁的数学方法，能让电脑处理无限多的特征。 想像下，我不是这边写两个特征， 右边写三个特征。而是，写一个无限长的特征表， 不停地写特征，似乎是个无限长的特征的表。 但是，我们也有能力设计一个算法来处理这个问题。 所以再从头复述一遍。本课中，我们介绍监督学习。 其基本思想是，监督学习中，对于数据集中的每个数据， 都有相应的正确答案，（训练集） 算法就是基于这些来做出预测。就像那个房价， 或肿瘤的性质。后面介绍了回归问题。 即通过回归来预测一个连续值输出。 我们还谈到了分类问题， 目标是预测离散值输出。下面是个小测验题目： 假设你有家公司，希望研究相应的学习算法去 解决两个问题。第一个问题，你有一堆货物的清单。 假设一些货物有几千件可卖， 你想预测出，你能在未来三个月卖出多少货物。 第二个问题，你有很多用户， 你打算写程序来检查每个用户的帐目。 对每个用户的帐目， 判断这个帐目是否被黑过（hacked or compromised）。 请问，这两个问题是分类问题，还是回归问题？ 当视频暂停时，请用你的鼠标进行选择， 四选一，选择你认为正确的答案。 好，希望你刚才答对了。问题一是个回归问题 因为如果我有几千件货物， 可能只好把它当作一个实际的值，一个连续的值。 也把卖出的数量当作连续值。 第二个问题，则是分类问题，因为可以把 我想预测的一个值设为0，来表示账目没有被hacked 另一个设为1，表示已经被hacked。 就像乳癌例子中，0表示良性，1表示恶性。 所以这个值为0或1，取决于是否被hacked， 有算法能预测出是这两个离散值中的哪个。 因为只有少量的离散值，所以这个就是个分类问题。 这就是监督学习，下个视频将会介绍 无监督学习，学习算法的另一主要类型。