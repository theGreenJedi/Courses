1
00:00:00,380 --> 00:00:01,550
이 번 비디오에서는

2
00:00:01,670 --> 00:00:02,690
기계 학습 문제의 두 번째 주요 타입,

3
00:00:03,010 --> 00:00:05,030
Unsupervised learning에 대해 알아볼 것입니다.

4
00:00:06,300 --> 00:00:08,500
지난 비디오에서 우리는 Supervised learning에 대해 알아보았죠.

5
00:00:09,250 --> 00:00:10,700
거기서는, 이와 같이 data set이 있었고,

6
00:00:11,020 --> 00:00:12,670
거기서는, 이와 같이 data set이 있었고,

7
00:00:12,890 --> 00:00:15,150
각각의 예시들은 각각

8
00:00:15,610 --> 00:00:16,900
O와 X로 표기되었고

9
00:00:17,530 --> 00:00:19,800
각각 양성과 악성을 의미합니다.

10
00:00:20,850 --> 00:00:21,920
Supervised learning의 각 예시들은.

11
00:00:22,410 --> 00:00:24,270
어떤 예시가 맞는 답인지

12
00:00:24,440 --> 00:00:25,760
명시적으로 알려주고,

13
00:00:26,490 --> 00:00:27,580
이것이 곧 양성과 악성을 가리킵니다.

14
00:00:28,550 --> 00:00:30,210
Unsupervised learning에서, 우리는

15
00:00:30,540 --> 00:00:31,720
어떤 라벨도 붙어있지 않거나

16
00:00:31,950 --> 00:00:32,910
모두 같은 라벨을 가지는,

17
00:00:33,190 --> 00:00:34,600
이쪽과 같이, 아마 다른 것 같은 데이터가 주어집니다.

18
00:00:34,720 --> 00:00:35,920
이쪽과 같이, 아마 다른 것 같은 데이터가 주어집니다.

19
00:00:36,130 --> 00:00:37,460
이쪽과 같이, 아마 다른 것 같은 데이터가 주어집니다.

20
00:00:39,680 --> 00:00:40,740
즉, 우리에게 data set이 주어지고

21
00:00:40,980 --> 00:00:42,460
그 data로 무엇을 할 것인지

22
00:00:42,560 --> 00:00:43,290
그 data가 무슨 의미인지

23
00:00:43,640 --> 00:00:44,800
알려주지 않습니다.

24
00:00:45,290 --> 00:00:47,190
그저, data set이 주어질 뿐이죠.

25
00:00:47,870 --> 00:00:49,650
이 data에서 어떤 구조를 찾을 수 있나요?

26
00:00:50,480 --> 00:00:51,670
이 데이터 셋으로,

27
00:00:52,350 --> 00:00:53,940
비지도 학습 알고리즘은 아마도

28
00:00:54,060 --> 00:00:56,090
데이터가 두 집단으로 이루어져 있다고 할 것입니다

29
00:00:56,800 --> 00:00:57,960
그래서 여기에 하나의 집단이 있고,

30
00:00:59,120 --> 00:00:59,910
여기에 다른 집단이 있습니다

31
00:01:01,110 --> 00:01:02,710
그리고, 지도 학습 알고리즘은

32
00:01:03,040 --> 00:01:05,070
두 개의 분리된 집단으로 구분지을 것입니다.

33
00:01:06,410 --> 00:01:08,000
이것을 클러스터링 알고리즘이라고 부릅니다

34
00:01:08,860 --> 00:01:10,310
이것은 많은 곳에서 사용됩니다.

35
00:01:11,930 --> 00:01:13,310
하나의 예로

36
00:01:13,530 --> 00:01:14,860
구글 뉴스에서 사용이 되고

37
00:01:15,060 --> 00:01:16,160
만약 한번도 보지 못했다면

38
00:01:16,360 --> 00:01:17,320
만약 한번도 보지 못했다면

39
00:01:18,210 --> 00:01:19,040
news.google.com 에 들어가서

40
00:01:19,830 --> 00:01:20,460
확인해보세요

41
00:01:21,280 --> 00:01:22,970
구글 뉴스는

42
00:01:23,480 --> 00:01:24,220
매일 만개

43
00:01:24,470 --> 00:01:25,430
혹은 십만 개의

44
00:01:25,720 --> 00:01:26,740
새로운 웹에 있는 이야기를

45
00:01:26,800 --> 00:01:29,410
보고 연관성 있는 뉴스 스토리들로 묶습니다

46
00:01:30,730 --> 00:01:31,690
예를 들어봅시다

47
00:01:33,380 --> 00:01:35,370
여기에 있는 링크는

48
00:01:35,910 --> 00:01:37,260
BP Oil Well에 대한 다른 뉴스들입니다

49
00:01:38,010 --> 00:01:40,110
BP Oil Well에 대한 다른 뉴스들입니다

50
00:01:41,300 --> 00:01:42,160
여기 URL중 하나를 클릭해봅시다.

51
00:01:42,260 --> 00:01:43,090
여기 URL중 하나를 클릭해봅시다.

52
00:01:43,550 --> 00:01:44,780
여기 URL중 하나를 클릭해봅시다.

53
00:01:45,100 --> 00:01:46,970
이와 같은 웹페이지를 볼 수 있습니다.

54
00:01:47,210 --> 00:01:48,390
"BP kills Macondo"란 제목을 가진
월스트리트의 이 기사는

55
00:01:48,590 --> 00:01:50,180
"BP kills Macondo"란 제목을 가진
월스트리트의 이 기사는

56
00:01:51,110 --> 00:01:52,530
BP사 석유시설 폭발로 인한 기름 유출에
 대한 내용을 보여줍니다.

57
00:01:52,920 --> 00:01:54,350
BP사 석유시설 폭발로 인한 기름 유출에
 대한 내용을 보여줍니다.

58
00:01:54,590 --> 00:01:55,700
BP사 석유시설 폭발로 인한 기름 유출에
 대한 내용을 보여줍니다.

59
00:01:55,980 --> 00:01:57,960
또한, 왼쪽 창에서 다른 URL을 클릭하면

60
00:01:58,020 --> 00:01:59,360
또한, 왼쪽 창에서 다른 URL을 클릭하면

61
00:02:00,690 --> 00:02:02,500
다른 기사를 볼 수 있습니다.

62
00:02:02,950 --> 00:02:04,760
이것은 동일한 BP사 기름 유출에 
대해 다룬 CNN의 기사입니다.

63
00:02:04,820 --> 00:02:06,090
이것은 동일한 BP사 기름 유출에 
대해 다룬 CNN의 기사입니다.

64
00:02:07,090 --> 00:02:08,180
이번엔 세 번째 링크를 눌러보면,

65
00:02:08,740 --> 00:02:10,990
다른 이야기에 대한 것을 볼 수 있습니다.

66
00:02:11,440 --> 00:02:13,380
이번 것은 UK Guardian의

67
00:02:13,940 --> 00:02:15,510
BP 기름 유출에 대한 기사입니다.

68
00:02:16,530 --> 00:02:17,790
여기서 구글 뉴스가 한 것은

69
00:02:17,990 --> 00:02:19,440
수만개의 뉴스 기사를 찾고

70
00:02:19,490 --> 00:02:22,170
그것들은 자동으로 
그룹화하여 분류한 것입니다.

71
00:02:23,030 --> 00:02:24,660
그러므로 같은 주제를 가지는 뉴스기사가

72
00:02:25,080 --> 00:02:27,010
함께 보이게 됩니다.

73
00:02:27,210 --> 00:02:29,170
Clustering 과
unsupervised learning은

74
00:02:29,380 --> 00:02:31,020
Clustering 과
unsupervised learning은

75
00:02:31,530 --> 00:02:33,550
다른 많은 문제에도 사용될 수 있습니다.

76
00:02:35,320 --> 00:02:36,690
유전학적 자료 이해에 대한 것입니다.

77
00:02:38,270 --> 00:02:40,510
이것은 DNA 미세배열의 한 예시입니다.

78
00:02:40,990 --> 00:02:42,230
방법은 여러 명으로 부터 유전자 정보를 얻고

79
00:02:42,430 --> 00:02:44,360
방법은 여러 명으로 부터 유전자 정보를 얻고

80
00:02:44,510 --> 00:02:45,590
몇 명의 사람이 특정 유전자를 
가지고 있는지 여부를 확인하는 것입니다.

81
00:02:46,100 --> 00:02:48,580
몇 명의 사람이 특정 유전자를 
가지고 있는지 여부를 확인하는 것입니다.

82
00:02:49,050 --> 00:02:51,640
기술적으로는 특정 유전자들이 
얼마나 발현되었는지 확인합니다.

83
00:02:52,000 --> 00:02:54,190
빨간색, 초록색, 회색과 같은 색깔은
측정군 전체를 대상으로 특정 유전자를

84
00:02:54,930 --> 00:02:56,210
빨간색, 초록색, 회색과 같은 색깔은
측정군 전체를 대상으로 특정 유전자를

85
00:02:56,340 --> 00:02:57,500
보유하는지, 보유하지
않는지에 대한 정도를

86
00:02:57,780 --> 00:02:59,440
보유하는지, 보유하지
않는지에 대한 정도를

87
00:02:59,510 --> 00:03:01,270
보여줍니다.

88
00:03:02,500 --> 00:03:03,400
여기서 할 수 있는 것은

89
00:03:03,610 --> 00:03:05,070
clustering algorithm을 사용하여

90
00:03:05,380 --> 00:03:07,140
개인들을 다른 범주로 분류하거나

91
00:03:07,780 --> 00:03:08,810
개인들을 다른 유형의 사람들로 분류하는 것입니다.

92
00:03:10,230 --> 00:03:11,660
이 방법이 unsupervised learning이라 불리는 것은

93
00:03:11,930 --> 00:03:14,010
우리가 알고리즘에

94
00:03:14,590 --> 00:03:15,690
어떤 사람이 유형 1인지

95
00:03:16,130 --> 00:03:17,420
어떤사람이 유형 2인지

96
00:03:17,560 --> 00:03:18,650
혹은 유형 3인지 말해주지 않고,

97
00:03:19,610 --> 00:03:22,390
단지 많은 data '자체'만 제공하기 때문입니다.

98
00:03:23,110 --> 00:03:24,030
우선적으로 data가 어떤 것인지 모르고

99
00:03:24,750 --> 00:03:25,870
누구의 data이고 어떤 유형인지도 모릅니다.

100
00:03:26,150 --> 00:03:26,940
심지어는 '다른 유형의 사람'이 
어떤 것인지도 모르지만,

101
00:03:27,260 --> 00:03:28,480
심지어는 '다른 유형의 사람'이 
어떤 것인지도 모르지만,

102
00:03:28,610 --> 00:03:30,210
기계적으로 데이터 내에서 
구조를 찾을 수 있고

103
00:03:30,360 --> 00:03:31,260
기계적으로 각 개인을

104
00:03:32,180 --> 00:03:33,620
다른 유형으로 분류할 수 있을까요?

105
00:03:33,870 --> 00:03:35,490
다른 유형으로 분류할 수 있을까요?

106
00:03:35,890 --> 00:03:37,610
우리가 알고리즘에
제공한 데이터와 관련된

107
00:03:38,160 --> 00:03:40,140
문제의 정확한 답을

108
00:03:40,370 --> 00:03:41,270
제공하지 않아서 이 방법은

109
00:03:41,590 --> 00:03:43,090
Unsupervised learning이라 합니다.

110
00:03:44,290 --> 00:03:47,040
Unsupervised learning 혹은 clustering은 
여러 응용에 사용됩니다.

111
00:03:48,340 --> 00:03:50,340
대규모 컴퓨터 클러스터를 
구성할 때 사용됩니다.

112
00:03:51,390 --> 00:03:52,530
제 친구 중 몇몇은 large data centers를 검토합니다.

113
00:03:52,680 --> 00:03:53,970
large data centers는 거대한 
컴퓨터 클러스터를 의미하고,

114
00:03:54,180 --> 00:03:55,970
그 친구들은 어떤 기계가

115
00:03:56,230 --> 00:03:57,470
함께 동작하는 경향이 
있는지 확인합니다.

116
00:03:57,590 --> 00:03:59,130
만약 여러분이

117
00:03:59,200 --> 00:04:00,270
그런 기계들을 함께 동작시킬 수 있다면,

118
00:04:01,100 --> 00:04:03,220
data centers를 더 효율적이게
만들 수 있습니다.

119
00:04:04,810 --> 00:04:06,820
두 번째 응용은 소셜 네트워크 분석입니다.

120
00:04:07,890 --> 00:04:09,230
어떤 친구에게 제일

121
00:04:09,630 --> 00:04:10,840
이메일을 많이 보내는지에 대한 정보나

122
00:04:10,880 --> 00:04:12,150
주어진 페이스북 친구 목록

123
00:04:12,180 --> 00:04:14,150
혹은 구글 플러스 모임으로

124
00:04:14,290 --> 00:04:16,380
우리가 자동으로

125
00:04:16,450 --> 00:04:17,950
어떤 그룹이 친밀한 그룹이고

126
00:04:18,460 --> 00:04:19,420
또, 어떤 그룹이 그룹 내 
전체 사람이 각각을

127
00:04:20,230 --> 00:04:21,010
알고 있는 그룹인지에 대한 
것을 구별할 수 있을까요?

128
00:04:22,540 --> 00:04:22,880
이번은 시장 세분화입니다.

129
00:04:24,680 --> 00:04:26,780
많은 회사는 고객 정보의 
거대한 데이터베이스를 가지고 있습니다.

130
00:04:27,700 --> 00:04:28,410
고객에 대한 데이터 셋을 보고

131
00:04:28,510 --> 00:04:30,000
자동적이고 더 효율적으로

132
00:04:30,740 --> 00:04:32,340
물건을 팔거나
다른 세분 시장에 대해

133
00:04:33,340 --> 00:04:35,290
다른 광고를 보여주는 것, 둘을

134
00:04:35,820 --> 00:04:37,400
동시에 하기 위해서

135
00:04:37,710 --> 00:04:39,490
자동으로 세분 시장을 찾고

136
00:04:39,650 --> 00:04:41,580
자동으로 세분 시장을 찾고 고객들을

137
00:04:41,890 --> 00:04:43,250
다른 여러 세분시장으로 나눌 수 있습니까?

138
00:04:44,260 --> 00:04:45,580
또 말하지만, 모든 고객
 정보를 가지고 있지만

139
00:04:45,820 --> 00:04:46,720
세분시장을 미리 모르고

140
00:04:46,900 --> 00:04:48,340
어떤 고객이 세분 시장 1에 속할지

141
00:04:48,590 --> 00:04:49,710
어떤 고객이 세분 시장 1에 속할지

142
00:04:49,790 --> 00:04:51,270
어떤 고객이 세분 시장 2에 속할지

143
00:04:51,440 --> 00:04:52,570
어떤 고객이 세분 시장 2에 속할지

144
00:04:52,660 --> 00:04:53,590
등등 같은 것을 미리 알 수 없기 때문에

145
00:04:53,690 --> 00:04:54,700
등등 같은 것을 미리 알 수 없기 때문에

146
00:04:54,800 --> 00:04:55,840
이 문제는 unsupervised learning 입니다.

147
00:04:55,940 --> 00:04:57,800
이 문제는 unsupervised learning 입니다.

148
00:04:57,930 --> 00:05:00,630
알고리즘이 data로부터 
모든 것 찾도록 해야합니다.

149
00:05:01,970 --> 00:05:03,140
마지막으로, Unsupervised Learning방법은

150
00:05:03,690 --> 00:05:05,620
놀랍게도 천문학 데이터 분석에서 사용되고 있습니다.

151
00:05:06,090 --> 00:05:08,060
놀랍게도 천문학 데이터 분석에서 사용되고 있습니다.

152
00:05:08,890 --> 00:05:10,390
clustering algorithm은

153
00:05:10,580 --> 00:05:12,440
은하계가 어떻게 탄생하게 되는지에

154
00:05:12,900 --> 00:05:15,610
대한 흥미롭고 유용한 이론은 제공해줍니다.

155
00:05:15,880 --> 00:05:17,620
위에 나와 있는 것들은 clustering에 대한 예제들입니다.

156
00:05:18,400 --> 00:05:20,550
이 예제들은 대표적인 Unsupervised Learning 방법입니다.

157
00:05:21,530 --> 00:05:22,470
이제 다른 예제에 대해 이야기 해보겠습니다.

158
00:05:23,200 --> 00:05:25,020
저는 칵테일 파티 문제에 대한 이야기를 해보겠습니다.

159
00:05:26,310 --> 00:05:28,270
여러분들은 이전에 칵테일 파티에 가본 적이 있나요?

160
00:05:28,440 --> 00:05:30,080
그러면 여러분들은 파티가

161
00:05:30,300 --> 00:05:31,690
진행되고 있다고 상상해봅시다.

162
00:05:31,870 --> 00:05:32,930
방에는 사람들도 가득 차있고,

163
00:05:32,970 --> 00:05:34,390
사람들은 주변에 앉아

164
00:05:34,480 --> 00:05:36,230
있으며 동시에 이야기를 하고 있습니다.

165
00:05:36,590 --> 00:05:37,920
있으며 동시에 이야기를 하고 있습니다.

166
00:05:38,070 --> 00:05:39,730
동시에 이야기를 하고 있어 모든 목소리들은

167
00:05:40,690 --> 00:05:41,970
겹쳐지게 되어서,

168
00:05:42,020 --> 00:05:43,990
당신의 앞에 있는 사람과의 대화에 어려움이 있습니다.

169
00:05:45,690 --> 00:05:46,670
작은 칵테일 파티에서

170
00:05:46,770 --> 00:05:48,090
2명의 사람이

171
00:05:48,740 --> 00:05:49,710
동시에 이야기 합니다.

172
00:05:50,690 --> 00:05:51,630
그리고 우리는

173
00:05:51,890 --> 00:05:53,080
2개의 마이크를

174
00:05:54,060 --> 00:05:55,640
방안에 설치하였습니다.

175
00:05:56,050 --> 00:05:57,430
2개의 마이크를

176
00:05:57,560 --> 00:05:58,900
서로 다른 거리에 설치하였기 때문에,

177
00:05:58,990 --> 00:06:01,250
마이크들은 서로 다른

178
00:06:01,830 --> 00:06:04,720
두 사람의 목소리 조합을 녹음합니다.

179
00:06:05,810 --> 00:06:06,970
아마도 1번화자의 목소리는

180
00:06:07,120 --> 00:06:08,320
1번 마이크에서 조금 더 클 것이고

181
00:06:09,120 --> 00:06:10,680
2번화자의 목소리는

182
00:06:10,800 --> 00:06:12,350
2번 마이크에서 좀 더 클 것입니다.

183
00:06:12,560 --> 00:06:14,040
그 이유는 2개의 마이크가

184
00:06:14,230 --> 00:06:15,950
서로 2명의 화자의 상대적으로

185
00:06:16,400 --> 00:06:19,020
다른 위치에 설치되어 있기 때문입니다.

186
00:06:19,250 --> 00:06:20,390
하지만 각각의 마이크는

187
00:06:20,970 --> 00:06:22,590
두 화자의 목소리 겹친 조합을 만들어 냅니다.

188
00:06:23,960 --> 00:06:25,500
조사자의 의해 녹음된 두명의

189
00:06:26,520 --> 00:06:29,280
여기 실제 녹음 파일이 있습니다.

190
00:06:29,740 --> 00:06:30,950
이제 1번 마이크에

191
00:06:31,060 --> 00:06:32,760
녹음된 내용을 재생하겠습니다.

192
00:06:33,560 --> 00:06:34,800
One (uno), two (dos),

193
00:06:35,070 --> 00:06:36,590
three (tres), four (cuatro), five (cinco),

194
00:06:37,060 --> 00:06:38,550
six (seis), seven (siete),

195
00:06:38,990 --> 00:06:40,610
eight (ocho), nine (nueve), ten (y diez)

196
00:06:41,610 --> 00:06:42,650
아마도 가장 흥미로운

197
00:06:43,000 --> 00:06:44,270
칵테일 파티는 아닐 것입니다.

198
00:06:44,620 --> 00:06:45,670
2명의 화자는 1부터 10까지

199
00:06:46,010 --> 00:06:47,880
2개의 언어로 카운팅을 합니다.

200
00:06:48,870 --> 00:06:49,760
여러분이 들었던 것은

201
00:06:49,820 --> 00:06:52,500
1번 마이크의 녹음파일입니다. 여기 2번 마이크의 녹음 파일입니다.

202
00:06:57,440 --> 00:06:58,040
Uno (one), dos (two), tres (three),

203
00:06:58,060 --> 00:06:58,730
cuatro (four), cinco (five), seis (six),

204
00:06:59,160 --> 00:07:00,900
siete (seven), ocho (eight), nueve (nine) y diez (ten).

205
00:07:01,860 --> 00:07:02,850
우리가 할 수 있는 것은

206
00:07:03,380 --> 00:07:04,660
우선 2개의 녹음 파일을 얻어서

207
00:07:04,980 --> 00:07:06,480
칵테일 파티 algorithm이라고 불리는

208
00:07:07,010 --> 00:07:08,560
Unsupervised Learning algorithm에 입력하는 것입니다.

209
00:07:08,780 --> 00:07:09,910
그러면 이 algorithm은 당신을 위해

210
00:07:10,450 --> 00:07:12,140
이 데이터에서 특정 구조를 찾아 줄 것입니다.

211
00:07:12,250 --> 00:07:14,010
algorithm이 할 일은

212
00:07:14,410 --> 00:07:15,730
2개의 오디오 녹음 파일을

213
00:07:15,980 --> 00:07:17,990
듣고 말하는 것입니다.

214
00:07:18,140 --> 00:07:19,020
2개의 녹음 파일의 소리들은

215
00:07:19,360 --> 00:07:20,950
추가되거나 서로 합쳐지거나,

216
00:07:21,240 --> 00:07:22,450
우리가 가지고 있던

217
00:07:22,670 --> 00:07:25,220
것처럼 하나의 소리도 합쳐집니다.

218
00:07:25,990 --> 00:07:27,330
게다가, 칵테일 파티 algorithm이

219
00:07:27,710 --> 00:07:29,210
게다가, 칵테일 파티 algorithm이

220
00:07:29,570 --> 00:07:30,810
할 일은 합쳐지거나

221
00:07:31,480 --> 00:07:32,700
섞인 녹음 파일에서

222
00:07:33,000 --> 00:07:34,240
2개의 오디오 소스를

223
00:07:34,410 --> 00:07:35,600
분리하는 것이다.

224
00:07:36,200 --> 00:07:38,630
이것이 칵테일파티 algorithm의 첫 번째 결과입니다.

225
00:07:39,790 --> 00:07:41,910
One, two, three, four,

226
00:07:42,590 --> 00:07:46,270
five, six, seven, eight, nine, ten.

227
00:07:47,630 --> 00:07:48,780
그래서 저는 녹음된 파일에서

228
00:07:49,240 --> 00:07:51,220
영어 음성을 분리 했습니다.

229
00:07:52,460 --> 00:07:53,300
이건 2번째 결과입니다.

230
00:07:53,380 --> 00:07:55,280
Uno, dos, tres, quatro,

231
00:07:55,980 --> 00:07:59,830
cinco, seis, siete, ocho, nueve y diez.

232
00:08:00,270 --> 00:08:01,180
나쁘지 않습니다.

233
00:08:03,810 --> 00:08:05,270
한 개 더 예제를 본다면,

234
00:08:05,600 --> 00:08:07,370
여기 비슷한 상황에 다른 녹음파일이 있습니다.

235
00:08:08,060 --> 00:08:09,790
1번 마이크에서는

236
00:08:10,470 --> 00:08:12,430
One, two, three, four, five, six,

237
00:08:13,370 --> 00:08:15,710
seven, eight, nine, ten.

238
00:08:16,980 --> 00:08:17,920
OK, 그러면 이제 남자들은

239
00:08:18,180 --> 00:08:19,350
칵테일파티에서

240
00:08:19,420 --> 00:08:21,880
나온 후 집으로 가고, 그는 지금 방에 앉아있습니다.

241
00:08:23,090 --> 00:08:24,130
이건 2번 마이크에 녹음된 내용입니다.

242
00:08:28,810 --> 00:08:31,800
One, two, three, four, five, six, seven, eight, nine, ten.

243
00:08:33,310 --> 00:08:34,160
여러분이 이 2개의 마이크에

244
00:08:34,610 --> 00:08:35,530
녹음된 파일을 같은 algorithm에게 준다면,

245
00:08:36,360 --> 00:08:37,790
이번 역시 똑같이

246
00:08:38,380 --> 00:08:39,470
2개의 오디오로

247
00:08:39,690 --> 00:08:41,370
분류를 해줍니다.

248
00:08:42,410 --> 00:08:43,820
제가 찾은 음성

249
00:08:44,070 --> 00:08:46,010
소스의 첫 번째 내용입니다.

250
00:08:47,480 --> 00:08:49,300
One, two, three, four,

251
00:08:49,730 --> 00:08:53,430
five, six, seven, eight, nine, ten.

252
00:08:54,650 --> 00:08:56,110
완벽하지는 않지만

253
00:08:56,340 --> 00:08:57,360
약간의 음악소리가

254
00:08:57,570 --> 00:08:59,070
섞인 음성을 얻었습니다.

255
00:08:59,890 --> 00:09:01,360
다음 음성은 algorithm의 2번째 결과입니다.

256
00:09:10,020 --> 00:09:11,310
전체적으로 음성을 제거한 후

257
00:09:11,540 --> 00:09:13,300
나온 2번째 결과물도

258
00:09:13,760 --> 00:09:14,850
나쁘지 않습니다.

259
00:09:15,020 --> 00:09:17,380
음악 소리를 정리하고 카운팅 소리를 제거한 것입니다.

260
00:09:18,840 --> 00:09:20,090
여러분들은 위와 같은

261
00:09:20,180 --> 00:09:21,750
예제를 통해 Unsupervised Learning algorithm을

262
00:09:21,950 --> 00:09:23,050
살펴 볼 수 있습니다.

263
00:09:23,250 --> 00:09:25,110
또한 이 algorithm을 구현이 얼마나 복잡한지도 물어볼 수 있습니다.

264
00:09:25,330 --> 00:09:26,560
이러한 프로그램들을

265
00:09:26,970 --> 00:09:28,870
구현하기 위해,

266
00:09:28,930 --> 00:09:30,550
우선 음성 처리를 하려면

267
00:09:30,670 --> 00:09:31,430
여러분은 자바 라이브러리와

268
00:09:32,240 --> 00:09:33,580
동기화된 수많은 코드를

269
00:09:33,690 --> 00:09:35,380
동기화된 수많은 코드를

270
00:09:35,470 --> 00:09:37,150
작성해야 할

271
00:09:37,240 --> 00:09:38,880
필요가 있습니다.

272
00:09:39,060 --> 00:09:41,040
음성들을 분리 해주는 매우 복잡한 프로그램입니다.

273
00:09:42,460 --> 00:09:43,860
여러분이 방금 들은 것들을

274
00:09:44,070 --> 00:09:45,640
하는 algorithm은 다음에 보여준 것

275
00:09:45,900 --> 00:09:47,280
같은 한 줄의 코드로

276
00:09:47,530 --> 00:09:49,270
작성할 수 있습니다.

277
00:09:50,640 --> 00:09:52,350
이 한 줄을 구현하기 위해

278
00:09:52,610 --> 00:09:54,060
연구자들은 많은 시간을 투자 하였습니다.

279
00:09:54,490 --> 00:09:56,090
이건 절대로 간단한 문제가 아닙니다.

280
00:09:57,080 --> 00:09:57,980
여러분이 이 프로그램

281
00:09:58,180 --> 00:10:00,330
환경을 사용하면, 수많은 학습 algorithm을

282
00:10:00,670 --> 00:10:02,060
간단히 프로그래밍 할 수 있습니다.

283
00:10:03,510 --> 00:10:04,700
우리가 이 수업에서

284
00:10:04,840 --> 00:10:05,890
Octave programming environment을

285
00:10:06,010 --> 00:10:07,430
활용하려는 이유입니다.

286
00:10:08,550 --> 00:10:09,910
Octave는

287
00:10:10,120 --> 00:10:11,620
매트랩 같은

288
00:10:11,670 --> 00:10:13,130
툴이며, 무료로 공개된 SW입니다.

289
00:10:14,000 --> 00:10:15,400
많은 학습 algorithm은

290
00:10:15,690 --> 00:10:17,910
구현하기 위해 몇 줄의 코드만 있으면 됩니다.

291
00:10:18,380 --> 00:10:19,400
이 수업 후반에선

292
00:10:19,620 --> 00:10:20,570
저는 여러분들에게

293
00:10:20,720 --> 00:10:21,920
Octave 사용법은 알려 줄 것입니다.

294
00:10:22,050 --> 00:10:24,590
이후 여러분은 Octave을 이용하여 여러 가지 algorithm을 구현해볼 것 입니다

295
00:10:24,980 --> 00:10:26,050
만약 여러분이 매트랩을 가지고 있으면 매트랩을 이용하셔도 됩니다.

296
00:10:27,120 --> 00:10:28,500
실리콘 벨리에서는,

297
00:10:28,620 --> 00:10:29,470
많은 기계학습 algorithm에 대해서,

298
00:10:30,290 --> 00:10:31,310
우리가 해야 하는 일은

299
00:10:32,040 --> 00:10:33,900
Octave를 활용하여 초기 프로토타입 프로그램을

300
00:10:34,330 --> 00:10:35,250
만드는 것입니다. Octave의 SW를

301
00:10:35,540 --> 00:10:36,920
활용하면 우리는 간단하게 학습 algorithm을 구현할 수 있기 때문입니다.

302
00:10:38,230 --> 00:10:39,110
SVD 함수와 같은

303
00:10:39,720 --> 00:10:41,460
각각의 함수들은

304
00:10:41,680 --> 00:10:42,920
특이값 분해를 의미하는데,

305
00:10:43,240 --> 00:10:44,520
이것들은 선형대수를 이용한

306
00:10:44,640 --> 00:10:45,690
방법이고,

307
00:10:45,820 --> 00:10:48,420
Octave으로 구현 합니다.

308
00:10:49,500 --> 00:10:50,390
만약 여러분들이

309
00:10:50,460 --> 00:10:51,490
이러한 작업을 C++, Java를

310
00:10:51,780 --> 00:10:53,040
통해 하신다면 많은 줄의 코딩과

311
00:10:53,180 --> 00:10:55,680
복잡한 라이브러리를 이용해야만  구현이 가능할 것 입니다.

312
00:10:56,440 --> 00:10:57,490
여러분들은

313
00:10:57,680 --> 00:10:58,690
C++, Java, Python

314
00:10:59,050 --> 00:11:00,090
같은 언어를 통해  이러한 algorithm을 구현할 수 있습니다.

315
00:11:00,290 --> 00:11:02,090
하지만 이러한 언어를 통해 구현하는 것은 일을 훨씬 복잡하게 하는 것입니다.

316
00:11:03,750 --> 00:11:05,060
제가 십년동안 기계학습을

317
00:11:05,300 --> 00:11:06,980
강의 하면서 알게 된 것은여러분들이 Octave같은

318
00:11:07,210 --> 00:11:08,680
프로그래밍 환경을 이용하면

319
00:11:08,890 --> 00:11:10,340
훨씬 빠르게

320
00:11:10,480 --> 00:11:11,700
기계학습을

321
00:11:11,790 --> 00:11:14,070
배운다는 것입니다.

322
00:11:14,250 --> 00:11:15,570
Octave 또는 prototyping

323
00:11:16,260 --> 00:11:17,110
같은 툴을 이용하면

324
00:11:17,240 --> 00:11:18,640
기본적인 빠르게

325
00:11:19,000 --> 00:11:21,280
학습 algorithm을 배우고, 구현하는데 도움이 됩니다.

326
00:11:22,640 --> 00:11:23,850
사실, 실리콘 밸리 회사들은

327
00:11:23,990 --> 00:11:25,390
많은 사람들이

328
00:11:25,730 --> 00:11:27,360
이렇게 작업을 하고 있습니다.

329
00:11:27,560 --> 00:11:29,020
프로트타입 학습 algorithm을

330
00:11:29,370 --> 00:11:31,110
구현하기 위해

331
00:11:31,510 --> 00:11:32,780
Octave같은 algorithm을 이용하고,

332
00:11:32,860 --> 00:11:33,820
작업하고, 사용하기위해

333
00:11:34,390 --> 00:11:35,910
, 이후 C++, 자바

334
00:11:36,890 --> 00:11:37,960
같은 다른 언어로 이식합니다.

335
00:11:38,220 --> 00:11:39,070
이러한 방법을 이용하면

336
00:11:39,400 --> 00:11:40,440
여러분들은 C++을 이용하여  처음부터 코드를

337
00:11:41,300 --> 00:11:43,050
작성하는 것보다 빠르게 구현이 가능할것 입니다.

338
00:11:44,440 --> 00:11:46,010
한명의

339
00:11:46,100 --> 00:11:47,490
교육자로써,

340
00:11:47,570 --> 00:11:48,580
수없이 “한번만 나를 믿어라“

341
00:11:48,730 --> 00:11:49,790
라고 말하고

342
00:11:50,030 --> 00:11:51,420
싶습니다.

343
00:11:51,560 --> 00:11:52,720
이전에 한번도 Octave 같은 프로그램 환경을

344
00:11:53,330 --> 00:11:54,880
사용해 본 적 없는 여러분들을 위한 말입니다.

345
00:11:55,240 --> 00:11:56,070
저는 여러분들에게

346
00:11:56,130 --> 00:11:56,970
지금 이 순간 저를 믿으라고 말할 것 입니다.

347
00:11:57,570 --> 00:11:58,950
여러분들에게 말하고, 또 그렇게 할 것입니다.

348
00:11:59,700 --> 00:12:01,180
저는 여러분들의 시간, 개발 기간이

349
00:12:01,700 --> 00:12:03,100
매우 가치 있는 자원이 될 것이라고 생각합니다.

350
00:12:04,210 --> 00:12:05,570
또 저는 이렇게

351
00:12:05,800 --> 00:12:06,850
공부하는 사람들을 여려명 보았습니다.

352
00:12:07,190 --> 00:12:08,460
그들은 전부 기계학습 연구자

353
00:12:08,850 --> 00:12:09,990
또는 기계학습 개발자 였습니다.

354
00:12:10,830 --> 00:12:12,080
여러분들이 prototype, Octave,

355
00:12:12,220 --> 00:12:13,010
다른 언어를 배우기

356
00:12:13,580 --> 00:12:15,250
시작함으로써능력이 좋아 질것이라 생각됩니다

357
00:12:17,570 --> 00:12:19,790
마지막으로 이 영상을

358
00:12:20,090 --> 00:12:22,890
마무리하기 위해, 저는 여러분들을 위해  하나의 질문을 하겠습니다.

359
00:12:24,400 --> 00:12:26,400
우리는 Unsupervised Learning 방법에 대해 이야기 했습니다.

360
00:12:26,700 --> 00:12:27,670
Unsupervised Learning 방법은

361
00:12:27,760 --> 00:12:28,730
여러분들이 특정 algorithm에게

362
00:12:28,840 --> 00:12:30,120
방대한 데이터를 주고,

363
00:12:30,240 --> 00:12:32,900
특정 데이터 구조를 찾으라는 것을 말합니다.

364
00:12:33,160 --> 00:12:35,170
다음 4가지 예시를 보면,

365
00:12:35,490 --> 00:12:36,410
어떤 경우가

366
00:12:36,870 --> 00:12:37,630
여러분이 생각하기에

367
00:12:37,720 --> 00:12:39,520
Unsupervised Learning algorithm에

368
00:12:40,220 --> 00:12:41,950
해당하는 경우인지

369
00:12:42,730 --> 00:12:43,590
생각해 봅시다.

370
00:12:43,860 --> 00:12:44,850
4개의 체크박스가 왼쪽에 있습니다.

371
00:12:45,640 --> 00:12:46,900
여러분이 자율학습 algorithm에

372
00:12:47,210 --> 00:12:49,400
해당된다고 생각하는 것을

373
00:12:49,700 --> 00:12:51,300
체크하시고

374
00:12:51,440 --> 00:12:53,930
오른쪽 아래 버튼을 클릭 하세요

375
00:12:54,690 --> 00:12:57,030
이제 영상을 잠시 멈추겠습니다.

376
00:12:57,370 --> 00:12:58,750
다음 화면의 문제에 답변을 해보세요.

377
00:13:01,860 --> 00:13:03,950
희망적으로 여러분들은 spam folder problem 기억할 것입니다.

378
00:13:04,710 --> 00:13:06,310
만약 여러분이 스팸, No 스팸이라고

379
00:13:06,450 --> 00:13:07,680
표기된 데이터를

380
00:13:07,800 --> 00:13:10,470
고 있으면 우리는 이것은 Supervised Learning 문제로 처리 할 수 있습니다.

381
00:13:11,620 --> 00:13:13,870
뉴스 예제로 본다면,

382
00:13:14,100 --> 00:13:15,370
우리는 Google News로

383
00:13:15,910 --> 00:13:16,600
예제를 이 영상에서 보았습니다.

384
00:13:17,090 --> 00:13:17,950
우리는 Unsupervised Learning 예제로

385
00:13:18,080 --> 00:13:19,460
기사들을 clustering algorithm을

386
00:13:19,880 --> 00:13:21,980
이용하여 분류하는지 보았습니다.

387
00:13:23,250 --> 00:13:25,440
시장 세분화 분석 예제는

388
00:13:25,510 --> 00:13:27,120
좀 전에 이야기 했습니다.

389
00:13:27,220 --> 00:13:29,110
여러분은 Unsupervised Learning 문제로

390
00:13:29,970 --> 00:13:30,860
이 문제를 다루었고

391
00:13:30,930 --> 00:13:32,340
그 이유는 저는 단지 algorithm에 사용할 데이터를 가지고

392
00:13:32,500 --> 00:13:34,340
있었고 자동적으로 시장 세분화 분석을 요청하였기 때문입니다.

393
00:13:35,610 --> 00:13:37,930
마지막 예제를 보면,

394
00:13:38,070 --> 00:13:39,080
당뇨병에 대한 내용입니다.

395
00:13:39,350 --> 00:13:41,480
이건 이전 영상에 본

396
00:13:42,190 --> 00:13:43,320
유방암 예제와 비슷합니다.

397
00:13:43,600 --> 00:13:45,280
악성 종양인지

398
00:13:45,550 --> 00:13:47,390
양성종양 대신에

399
00:13:47,550 --> 00:13:49,270
단지 당뇨병이

400
00:13:49,330 --> 00:13:50,440
“있다, 없다”로  바꿔 사용한 것입니다.

401
00:13:50,700 --> 00:13:51,830
우리는 지도학습 방법을 이용하여 해결합니다.

402
00:13:52,370 --> 00:13:53,740
우리는 이 문제를

403
00:13:53,870 --> 00:13:54,670
유방암 데이터를 처리한 것 같이

404
00:13:54,730 --> 00:13:56,450
Supervised Learning 문제로 풀 수 있습니다.

405
00:13:58,270 --> 00:13:59,400
그래서 이 영상은 Unsupervised Learning에

406
00:14:00,100 --> 00:14:01,580
대해 다루었습니다.

407
00:14:01,650 --> 00:14:02,940
다음 영상에서는

408
00:14:03,270 --> 00:14:04,600
특정 algorithm에 대해

409
00:14:05,550 --> 00:14:06,590
자세히 공부해보고,

410
00:14:07,220 --> 00:14:08,750
algorithm들이 어떻게 작동하며,

411
00:14:08,920 --> 00:14:11,270
어떻게 구현하는지에 대해 이야기 하겠습니다.