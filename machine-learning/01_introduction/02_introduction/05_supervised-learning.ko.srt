1
00:00:00,000 --> 00:00:04,620
이 비디오에서는 가장 일반적인 기계학습문제인

2
00:00:04,620 --> 00:00:08,910
supervised learning이 무엇인지 알아보도록 하겠습니다.

3
00:00:08,910 --> 00:00:13,255
이에 대한 형식적인 정의는 뒤에 다루고
가장 먼저 설명할 것은

4
00:00:13,255 --> 00:00:17,820
이에 대한 예시입니다. 우선

5
00:00:17,820 --> 00:00:23,072
주택에 대한 가격을 예측해 본다고 가정해 봅시다.
한 학생이 데이터세트를

6
00:00:23,072 --> 00:00:28,745
오래곤주 포트랜드시에서 가져왔습니다. 
그리고 그 데이터세트를 도식화하면 다음과 같이
보이게 됩니다.

7
00:00:28,745 --> 00:00:34,347
가로축은 각각의 주택의 크기를 
평방피트단위로 표시합니다.

8
00:00:34,347 --> 00:00:39,879
세로축은 각각 주택의 가격을 천달라 단위로
표시합니다.

9
00:00:39,879 --> 00:00:45,168
이 데이터를 바탕으로 친구가 750

10
00:00:45,168 --> 00:00:50,708
평방피트의 주택을 소유하고 있고 팔려고 한다면

11
00:00:50,708 --> 00:00:56,116
어느정도의 가격을 받아야할까.에 대해 
학습 알고리즘을 통해 이를 해결할 수 있을까요?

12
00:00:56,116 --> 00:01:01,524
첫째로 학습알고리즘으로 할 수 있는 것은 
데이터를 지나는 직선을 긋고

13
00:01:01,524 --> 00:01:07,111
그 직선을 참고하면, 주택가는

14
00:01:07,111 --> 00:01:13,239
150,000달러정도가 될것이라 보일것입니다.
그렇지만, 학습알고리즘은 이 이상의

15
00:01:13,239 --> 00:01:18,536
것을 할 수 있습니다. 예를 들면, 직선을 데이터에

16
00:01:18,536 --> 00:01:23,620
맞추어 긋는 대신, 이차함수나 
이차 방정식을 적용할 수 있습니다.

17
00:01:23,620 --> 00:01:29,110
이를 적용하게 되면

18
00:01:29,110 --> 00:01:34,667
예상치는 여기가 되고 아마도 우리는 집을

19
00:01:34,667 --> 00:01:39,184
$200,000정도에 팔 수 있을 것 같군요. 우리가 나중에 다룰것중 하나는

20
00:01:39,184 --> 00:01:43,792
데이터에 직선을 그릴지 이차 곡선을 그릴지, 어떻게 선택하고 결정하느냐 입니다.

21
00:01:43,792 --> 00:01:48,631
여기서 여러분의 친구가 집을 더 잘 팔게해줄 정답이란 건 없습니다.

22
00:01:48,631 --> 00:01:53,182
하지만 두가지 방법 모두 학습알고리즘의

23
00:01:53,182 --> 00:01:57,834
좋은 예가 될것입니다.
자 이것이 바로 supervised 학습 알고리즘의 예입니다.

24
00:01:57,834 --> 00:02:03,736
Supervised 학습이라는 용어는 우리가 알고리즘에게

25
00:02:03,736 --> 00:02:09,089
정확한 답을 알고있는 데이터(data set)를 준다는 데서 유래합니다. 
그말은, 우리가 알고리즘에 이 집들에 대한 데이터를 주고선,

26
00:02:09,089 --> 00:02:14,580
그 데이터의 모든 예시들에 대해서, 이게 맞는 가격이고,

27
00:02:14,580 --> 00:02:20,002
그러니까 실제로 집이 팔린 가격이 얼만지도, 다 알려줍니다.

28
00:02:20,002 --> 00:02:25,423
그리고 알고리즘은, 단지 이 올바른 답(right answers)들을
더 만들어내는것이죠.

29
00:02:25,423 --> 00:02:30,579
올바른 답이란건 예컨대 여러분의 친구가 팔고자하는 그 집값이 되겠죠.

30
00:02:30,579 --> 00:02:35,257
좀 더 정확히 용어를 하자면, 이건 regression problem이라고 불립니다.

31
00:02:35,257 --> 00:02:40,467
그러니까 regression problem은 다시 말해 우리가 지금 연속적인 값을 
예측하려는것을 떠올리면 됩니다. 여기서 연속적인 값이란 가격이 되겠죠.

32
00:02:40,467 --> 00:02:44,720
기술적으로 가격은 센트 단위로 절사될 것 같은데요,

33
00:02:44,720 --> 00:02:49,246
그렇게 되면 가격은 이산적인(discrete) 값이 됩니다만,
우리는 보통 집값을

34
00:02:49,246 --> 00:02:53,608
실수로서, 스칼라 값으로서, 연속적인 숫자로서 여깁니다.

35
00:02:53,608 --> 00:02:58,080
regression이라는 용어는 어떤 연속적인 속성 값을
예측하려하는 것을 말합니다.

36
00:02:58,080 --> 00:03:02,060
여기 다른 supervised 학습의 예시를 보겠습니다.

37
00:03:02,060 --> 00:03:06,427
제 동료들과 제가 이전에 실제로 연구했던 사례입니다.
자 봅시다.

38
00:03:06,427 --> 00:03:11,675
여러분은 의료 기록들을 보고 유방암이 악성인지 아닌지를 예측하려 합니다.

39
00:03:11,675 --> 00:03:16,856
만약 유방 종양이나 환자 가슴에 덩어리를 발견했을 때, 악성 종양은

40
00:03:16,856 --> 00:03:22,300
유해하고 위험한 종양이며, 양성 종양은 무해한 종양입니다.

41
00:03:22,300 --> 00:03:27,876
따라서 사람들이 이것에 신경을 꽤나 쓸 것은 분명하네요.
수집된 데이터를 봅시다.

42
00:03:27,876 --> 00:03:33,164
이렇게 가정하겠습니다. 주어진 데이터의 가로축에는 종양의 크기,

43
00:03:33,164 --> 00:03:39,317
세로축에는 1 이나 0, 즉 예/아니요를 놓겠습니다.
악성 종양의 여부를 나타냅니다.

44
00:03:39,317 --> 00:03:45,184
세로축에는 1 이나 0, 즉 예/아니요를 놓겠습니다.
악성 종양의 여부를 나타냅니다.

45
00:03:45,184 --> 00:03:50,392
자 그럼 주어진 데이터가 이렇게 생겼다고 해봅시다.
이 정도 사이즈의 종양이 양성으로 밝혀졌고..

46
00:03:50,392 --> 00:03:56,283
이 정도 크기 하나, 이 정도 크기 하나, 이런식으로요.

47
00:03:56,283 --> 00:04:02,227
그리고 슬프게도 우리는 악성 종양도 몇개 봤습니다.
저 정도 크기 하나, 저 정도 크기 하나..

48
00:04:02,227 --> 00:04:08,572
저 정도 크기 하나.. 등등이요.
그래서 이 예시에서는.. 5개의 양성

49
00:04:08,572 --> 00:04:15,159
종양이 아래에 이렇게 있고, 5개의 악성 종양이 세로축의

50
00:04:15,159 --> 00:04:21,504
값이 1인 채로 이렇게 보입니다.
그리고 슬프게도 가슴에 종양이 있는 친구가 있다고 해봅시다.

51
00:04:21,504 --> 00:04:28,097
그리고 그녀의 가슴 종양의 크기가 한 이정도 쯤 된다고 하죠.

52
00:04:28,097 --> 00:04:32,930
여기서 기계 학습의 질문은 이겁니다.
종양이 악성일지, 양성일지

53
00:04:32,930 --> 00:04:37,819
확률을 예측할 수 있을까요?
용어를 좀 소개하자면

54
00:04:37,819 --> 00:04:42,719
이것은 classification 문제의 예시입니다.

55
00:04:42,719 --> 00:04:47,342
classification이란 용어는 이산적인 결과값을 예측하려하는 것을 의미합니다.

56
00:04:47,342 --> 00:04:52,321
0이나 1, 악성이나 양성 같은 것들이죠.
그리고 classification 문제에서는 때때로

57
00:04:52,321 --> 00:04:58,331
결과값으로서 2개가 가능한 상황에서 2개 보다

58
00:04:58,331 --> 00:05:03,852
많은 값들을 얻기도 합니다.
일례로 유방암이 3가지 타입이 존재할수도 있고

59
00:05:03,852 --> 00:05:09,947
그래서 0을 양성이라할 때, 0, 1, 2, 3의
값들을 예측해야할 수 있습니다.

60
00:05:09,947 --> 00:05:15,138
양성 종양. 암이 아니고.. 그리고 1은..

61
00:05:15,138 --> 00:05:19,836
첫번째 타입의 암을 의미할 수 있겠죠. 
그러니까 세가지 타입의 암이 있었죠. 뭐가 됐건 1은 뭔가를 의미하고..

62
00:05:19,836 --> 00:05:24,654
2는 두번째 타입의 암을 의미할 수 있겠죠.
3은 세번째 타입의 암을 의미하고요.

63
00:05:24,654 --> 00:05:29,111
하지만 이래도 마찬가지로 classification 문제입니다.
왜냐하면

64
00:05:29,111 --> 00:05:33,929
이러한 이산적인 결과값들이 각각 암 없음,

65
00:05:33,929 --> 00:05:39,094
암 타입 1, 암 타입 2, 암타입 3에 대응하기 때문입니다.

66
00:05:39,094 --> 00:05:44,413
classification 문제에서 이 데이터를 나타내는 다른 방식도 존재합니다.
어떤것인지 보여드리겠습니다.

67
00:05:44,413 --> 00:05:49,206
그래프를 그릴때 약간 다른 기호를 사용해볼게요. 
종양의 크기를 통해

68
00:05:49,206 --> 00:05:54,303
그것이 악성인지 양성인지를 예측할 경우에, 
데이터를 이런식으로 그려낼수도있죠.

69
00:05:54,303 --> 00:05:58,975
양성과 악성, 즉 긍정적인 결과와 부정적인 결과를

70
00:05:58,975 --> 00:06:03,707
서로 다른 기호로 나타내보겠습니다.
양성을 X로 표시하지 않고

71
00:06:03,707 --> 00:06:11,595
O로 표시하겠습니다. 그리고

72
00:06:11,595 --> 00:06:18,655
악성 종양은 그대로 X를 쓰겠습니다. 아시겠죠?
이부분이 납득이 가길 바랍니다.

73
00:06:18,655 --> 00:06:23,624
제가 한게 무엇이냐면, 이 상단의 데이터들을 가지고

74
00:06:23,624 --> 00:06:30,894
그냥 아래에 대응시킨겁니다. 이 선 위에 이런식으로요.
그리고 O와 X로

75
00:06:30,894 --> 00:06:35,828
악성과 양성 사례를 나타내는데 다른 기호를 썼습니다.

76
00:06:35,828 --> 00:06:41,091
이제 이 예제에서, 우리는 종양이 악성인지 아닌지를 예측하기 위해

77
00:06:41,091 --> 00:06:46,289
한가지 속성만을 주로 사용했습니다.
다른 기계 학습 문제에서는

78
00:06:46,289 --> 00:06:51,355
한개 이상의 특징, 한개 이상의 속성이 주어지기도 합니다.

79
00:06:51,355 --> 00:06:56,749
예를 들어보죠. 우리가 단지 종양 크기만을 알고 있는 것 대신에

80
00:06:56,749 --> 00:07:02,387
환자들의 나이와 종양 크기 두가지를 안다고 해봅시다.
이 경우 데이터가 이런식으로 생겼겠죠

81
00:07:02,387 --> 00:07:08,562
이 정도 연령과 종양 크기의 환자들이 있을 수 있겠죠.

82
00:07:08,562 --> 00:07:14,980
그리고, 약간 다르게 보이는 환자들의 데이터도 보죠.

83
00:07:15,600 --> 00:07:23,968
악성으로 판명나는 종양을 X로 표시를 했습니다.

84
00:07:23,968 --> 00:07:32,027
자, 종양을 가지고 있는 친구가 있다고 가정해보죠. 아마, 그 종양 크기와 연령

85
00:07:32,027 --> 00:07:37,657
이 정도에 있을 겁니다. 이 처럼 주어진 데이터 셋으로, 러닝 알고리즘은

86
00:07:37,657 --> 00:07:42,462
아마도 양성 종양으로 부터 악성 종양을 구별하기 위해서

87
00:07:42,462 --> 00:07:47,710
이러한 직선을 추출하고, 그래서 이 러닝 알고리즘은

88
00:07:47,710 --> 00:07:53,004
종양의 두 클래스를 구분할 수 있도록 이렇게

89
00:07:53,004 --> 00:07:57,644
이제 당신 친구의 종양에 대해서 결정할 수 있습니다.

90
00:07:57,644 --> 00:08:02,322
친구의 종양이 이렇게 여기에 표시 된다면, 러닝 알고리즘은

91
00:08:02,322 --> 00:08:07,305
친구의 종양이 양성 종양 쪽에 있기 때문에

92
00:08:07,305 --> 00:08:12,044
친구의 종양이 양성 종양 쪽에 있기 때문에

93
00:08:12,044 --> 00:08:17,147
우리는 환자의 나이와, 종양의 크기, 2가지의 feature를 가졌습니다. 다른 머신러닝 문제에서는

94
00:08:17,147 --> 00:08:21,454
우리는 더 많은 feature를 가질 것이고,

95
00:08:21,454 --> 00:08:25,849
그것들은 유방암의 두께 같은 다른 feature를 사용합니다.

96
00:08:25,849 --> 00:08:30,299
종양 세포 크기의 균일함. 종양 세포 모양의 균일함.

97
00:08:30,299 --> 00:08:34,911
등등. 그리고

98
00:08:34,911 --> 00:08:39,907
이번 수업에서 접할 기계학습이

99
00:08:39,907 --> 00:08:45,153
단순히 두서너 혹은 다섯개 정도의 feature만을 다루는 것이 아니라
무한히 많은 feature들을 다룰 수 있다는 것입니다.

100
00:08:45,153 --> 00:08:50,150
이 슬라이드에서, 저는 총 다섯 개의 feature들을 나열했습니다.

101
00:08:50,150 --> 00:08:54,482
두 가지는 축에 표현했고, 세 가지는 오른쪽에 나열했습니다.
어떤 기계학습 문제에 있어서는,

102
00:08:54,482 --> 00:08:58,497
실제로 세 개 또는 다섯 개의 feature로 만족하지 못 할 수 있습니다.

103
00:08:58,497 --> 00:09:02,566
그 대신, 무한히 많은 feature와 속성들을 사용해서,

104
00:09:02,566 --> 00:09:06,211
여러분의 학습 알고리즘이 많은 속성이나

105
00:09:06,211 --> 00:09:10,333
feature 또는 암시 들을 통해 어떤 예측을 하게 할 수도 있습니다.

106
00:09:10,333 --> 00:09:14,439
수 많은 feature들을 다룰 수 있을까요.
어떻게 무한히 많은

107
00:09:14,439 --> 00:09:18,290
것들을 여러분의 컴퓨터의 메모리가 소진되어 가고 있는 상황에서
저장할 수 있을까요.

108
00:09:18,290 --> 00:09:22,188
알고리즘에 대해 이야기할때 Support Vector Machine을 호출하며,

109
00:09:22,188 --> 00:09:26,675
여기에는 잘 정돈된 수학적인 기법을 통해 컴퓨터로 하여금

110
00:09:26,675 --> 00:09:31,214
무한이 많은 feature 들을 다룰 수 있게 합니다.
제가 단순히 두 세개의 feature 들을

111
00:09:31,214 --> 00:09:35,487
여기에 나열하지 않았다고 상상해보세요.
그 대신에, 무한히 긴 목록을 작성하고 있고,

112
00:09:35,487 --> 00:09:39,866
계속해서 더더욱 많은 feature들을 추가하고 있다고 생각해 보세요.
무한히 긴 feature 리스트 같이 말이죠.

113
00:09:39,866 --> 00:09:44,192
우리는 그 것을 다룰 수 있는 알고리즘을 보게 될 것입니다.

114
00:09:44,192 --> 00:09:49,701
요약하자면,
이번 수업에서 우리는 supervised learning에 대해 이야기 할 것입니다.

115
00:09:49,701 --> 00:09:54,167
그리고 앞서 말한 생각들은 우리가 다룰 모든 예제에서

116
00:09:54,167 --> 00:09:58,880
어떤것이 "정답"으로서

117
00:09:58,880 --> 00:10:03,960
이 예제에서 알고리즘이 예측을 하는지 알게 될 것입니다.

118
00:10:03,960 --> 00:10:08,428
종양이 양성인지 음성인지 판별할 수 있게 됩니다.
또한 우리는 회귀 문제에 대해 이야기 할 것입니다.

119
00:10:08,428 --> 00:10:13,202
회귀를 통해서, 우리가 얻고자 하는 것은

120
00:10:13,202 --> 00:10:17,977
연속적인 값을 결과로 얻는 것입니다.
또한 우리는 분류 문제를 다룰 것인데,

121
00:10:17,977 --> 00:10:22,690
이를 통해 우리는 이산적인 값을 얻을 것입니다.
문제로 예를 들어보겠습니다.

122
00:10:22,690 --> 00:10:27,541
여러분이 회사를 운영하고 있으며, 학슴 알고리즘을 통해서

123
00:10:27,541 --> 00:10:32,618
두가지 문제를 구별하고자 합니다.
첫번째 문제는 동일한 제품으로 이뤄진 큰 재고 목록입니다.

124
00:10:32,618 --> 00:10:38,113
즉, 여러분이 수천개의 동일한 제품을

125
00:10:38,113 --> 00:10:43,607
제품들을 판매하고자 하며,
이들중 얼마나 많은 제품들을 석 달 내에 팔 수 있는지 예측하고 싶다고 합시다.

126
00:10:43,607 --> 00:10:49,172
두번째 문제는, 여러분이 수많은 이용자가 있으며

127
00:10:49,172 --> 00:10:54,145
개별적으로 이들을 시험할 수 있는 소프트웨어를 작성하는데

128
00:10:54,145 --> 00:10:59,193
고객의 계정에서, 계정마다

129
00:10:59,193 --> 00:11:04,178
그 계정이 해킹을 당했거나 위험에 노출되어 있는지 판별하려 한다고 합시다.

130
00:11:04,178 --> 00:11:08,914
이러한 문제들은 classification problem 또는

131
00:11:08,914 --> 00:11:14,087
회귀 문제로 다뤄져야 할까요?
비디오가 멈추면 마우스를 이용하여

132
00:11:14,087 --> 00:11:20,884
다음 네가지 보기중 정답을 선택하세요.

133
00:11:20,884 --> 00:11:25,871
정답을 맞추셨기를 바랍니다.
첫번째 보기에서 저는 이것을

134
00:11:25,871 --> 00:11:31,058
회귀 문제로 다룰 것입니다. 왜냐하면, 제가 수천개의 물품이 있다면,
글쎄요, 아마도 저는 실수로 다뤘을 것이기 때문입니다.

135
00:11:31,058 --> 00:11:36,071
실수로 다뤘을 것이기 때문입니다.

136
00:11:36,290 --> 00:11:41,837
그리고, 그렇기 때문에 판매한 제품의 수도 실수로 생각했을 것입니다.

137
00:11:41,837 --> 00:11:47,748
두번째 보기에서, 저는 classification probl

138
00:11:47,748 --> 00:11:53,659
그 이유는 0이란 값을 이용해서 계정이 해킹되지 않았다고 예측하는데 사용할 것이기 때문입니다.

139
00:11:53,659 --> 00:11:58,850
그리고 1을 해킹 되었다고 나타낼 것입니다.

140
00:11:58,850 --> 00:12:03,287
마치 유방암 문제에서 이야기 했던대로 0은 음성, 1은 양성인것 처럼 말이죠.

141
00:12:03,287 --> 00:12:08,150
그러므로 저는 0이나 1을 계정이 해킹이 되었는지 아닌지에 따라 사용할 것이고,

142
00:12:08,150 --> 00:12:13,134
알고리즘은 이 두 이산 값들을 예측할 것입니다.

143
00:12:13,134 --> 00:12:17,693
이 이산 값의 수가 적으므로, 저는 이 문제를 classification problem으로 다루겠다고 한 것입니다.

144
00:12:17,693 --> 00:12:23,075
여기까지가 supervised learning이었습니다. 다음 비디오에서 저는

145
00:12:23,075 --> 00:12:28,325
unsupervised learning에 대해 다룰 것입니다.
이것은 학습 알고리즘의 다른 주요 분야입니다.