1
00:00:00,000 --> 00:00:04,620
У овом видеу ћу дефинисати можда 
најчешћи проблем машинског

2
00:00:04,620 --> 00:00:08,910
учења, а то је надгледано учење. Касније ћу да дефинишем појам надледано учење,

3
00:00:08,910 --> 00:00:13,255
али можда је најбоље да се кроз пример 
објасни шта то представља,

4
00:00:13,255 --> 00:00:17,820
а формалну дефиницију ћемо дати касније. Рецимо да хоћете

5
00:00:17,820 --> 00:00:23,072
да предвидите цене смештаја. Некад давно, студенти су
прикупљали податке од

6
00:00:23,072 --> 00:00:28,745
Портландског Института Орегон. И рецимо да 
нацртате сет података, који изгледа

7
00:00:28,745 --> 00:00:34,347
овако. Хоризонтална оса представља
површину кућа у квадратним стопама,

8
00:00:34,347 --> 00:00:39,879
а вертикална оса представља цену тих кућа у хиљадама долара.

9
00:00:39,879 --> 00:00:45,168
Дакле, имајући у виду овај податак, рецимо да имате 
пријатеља, који поседује кућу од, рецимо

10
00:00:45,168 --> 00:00:50,708
750 квадратних стопа и у нади да је прода,
хоће да сазна колико може

11
00:00:50,708 --> 00:00:56,116
добити за њу.  Дакле, како вам може помоћи учећи алгоритам? Једну ствар коју учећи

12
00:00:56,116 --> 00:01:01,524
алгоритам може да уради је да стави праву линију кроз
податке или да подеси

13
00:01:01,524 --> 00:01:07,111
праву линију на податке, на основу како то изгледа. Можда, 
по овим резултатима кућа

14
00:01:07,111 --> 00:01:13,239
може бити продана за неких 150.000 долара. Али можда ово није једини учећи алгоритам који можете

15
00:01:13,239 --> 00:01:18,536
користити. Можда постоји бољи. На пример, уместо цртања
праве

16
00:01:18,536 --> 00:01:23,620
линије кроз податке, можда је боља одлука да применимо квадратну

17
00:01:23,620 --> 00:01:29,110
функцију или полином другог реда на ове податке. И ако то примените и овде

18
00:01:29,110 --> 00:01:34,667
направите претпоставку, онда изгледа да кућу можемо продати за скоро

19
00:01:34,667 --> 00:01:39,184
200.000 долара. Једна од ствари, о којој ћемо говорити касније је како бирати

20
00:01:39,184 --> 00:01:43,792
и како одлучивати коју ћемо методу користити над подацима

21
00:01:43,792 --> 00:01:48,631
и не постоји правилан одабир неког од метода, помоћу

22
00:01:48,631 --> 00:01:53,182
ког ће ваш пријатељ скупље продати кућу. Али, сваки од ових метода је леп пример

23
00:01:53,182 --> 00:01:57,834
учећег алгоритма. Дакле, ово је један пример надгледаног учећег алгоритма.

24
00:01:57,834 --> 00:02:03,736
А појам надгледано учење се односи на чињеницу да смо алгоритму дали сет података,

25
00:02:03,736 --> 00:02:09,089
у коме су дати 'тачни одговори'. То јест, дали смо сет података

26
00:02:09,089 --> 00:02:14,580
о кућама, у коме смо за сваки пример у сету, рекли која је права цена

27
00:02:14,580 --> 00:02:20,002
на основу стварне цене, за коју је нека кућа продана, а задатак

28
00:02:20,002 --> 00:02:25,423
алгоритма је само да направи још више тих правих одговора, као што је овај

29
00:02:25,423 --> 00:02:30,579
за ову нову кућу, знате, коју ваш пријатељ можда покушава продати. Ово се још зове

30
00:02:30,579 --> 00:02:35,257
регресиони проблем, ако уведемо још више терминологије,

31
00:02:35,257 --> 00:02:40,467
а под регресионим проблемом сматрам да покушавамо предвидети излаз континуалне вредности. То јест, цена.

32
00:02:40,467 --> 00:02:44,720
Дакле, технички гледано, претпостављам да се цене могу заокружити до најближег цента. Можда су

33
00:02:44,720 --> 00:02:49,246
цене дискретне вредности, али уобичајено мислимо о цени куће

34
00:02:49,246 --> 00:02:53,608
као да је реалан број, скаларна вредност, као број континуалне вредности, а појам

35
00:02:53,608 --> 00:02:58,080
регресија се односи на чињеницу да покушавамо предвидети неку врсту  атрибута

36
00:02:58,080 --> 00:03:02,060
континуиране вредности. Овде је још један пример надгледаног учења. Пријатељи

37
00:03:02,060 --> 00:03:06,427
и ја смо радили на овоме раније. Рецимо да хоћете да
погледате

38
00:03:06,427 --> 00:03:11,675
медицинску документацију да предвидите појаву рака дојке као злоћудног или доброћудног. Ако неко

39
00:03:11,675 --> 00:03:16,856
открије тумор на дојци, у виду чвора. Злоћудни тумор

40
00:03:16,856 --> 00:03:22,300
је тумор који је штетан и опасан, а доброћудни је безопасан.

41
00:03:22,300 --> 00:03:27,876
Дакле, очигледно је да људи много брину о  томе. Погледајмо прикупљени сет података и претпоставимо да је у

42
00:03:27,876 --> 00:03:33,164
вашем сету података на хоризонталној оси приказана величина тумора, а на

43
00:03:33,164 --> 00:03:39,317
вертикалној оси ћу да представим помоћу јединице и нуле, да ли је

44
00:03:39,317 --> 00:03:45,184
неки од тумора злоћудан, који је јединица, или нула ако није злоћудан.

45
00:03:45,184 --> 00:03:50,392
Дакле, рецимо, да наш сет података изгледа овако, где се
испоставља да је тумор ове

46
00:03:50,392 --> 00:03:56,283
величине доброћудан. Један ове величине, један
ове и тако даље.

47
00:03:56,283 --> 00:04:02,227
Нажалост видимо и неколико злоћудних тумора, један ове
величине,

48
00:04:02,227 --> 00:04:08,572
један ове, један ове... и тако даље. Дакле, овај пример...
Имамо пет примера доброћудних тумора

49
00:04:08,572 --> 00:04:15,159
приказаних овде доле и пет примера злоћудних тумора са вредношћу један

50
00:04:15,159 --> 00:04:21,504
на вертикалној оси. И рецимо да, имамо пријатељицу, која нажалост има тумор

51
00:04:21,504 --> 00:04:28,097
на дојци, и, рецимо да величина њеног тумора је приближно ова.

52
00:04:28,097 --> 00:04:32,930
Питање машинског учења је, можете ли проценити која је вероватноћа, у колико

53
00:04:32,930 --> 00:04:37,819
случаја је тумор злоћудан, а у колико доброћудан? Да би увели још мало

54
00:04:37,819 --> 00:04:42,719
терминологије, представићемо проблем 
класификације. Појам

55
00:04:42,719 --> 00:04:47,342
класификација се односи на чињеницу коју овде
покушавамо предвидети као излаз

56
00:04:47,342 --> 00:04:52,321
дискретне вредности. Нула или један, злоћудан или доброћудан и испоставља се

57
00:04:52,321 --> 00:04:58,331
да у проблемима класификације можете имати више од две вредности

58
00:04:58,331 --> 00:05:03,852
за две могуће вредности излаза. Као у конкретном примеру, можда постоје

59
00:05:03,852 --> 00:05:09,947
три типа рака дојке, тако да можете покушати да предвидите дискретну вредност нуле,

60
00:05:09,947 --> 00:05:15,138
јединице, двојке или тројке, где нула одговара доброћудном. Значи није рак. Јединица може

61
00:05:15,138 --> 00:05:19,836
значити један тип рака, као, значи имате три врсте рака, било који може

62
00:05:19,836 --> 00:05:24,654
бити јединица. Двојка може бити други тип рака, а тројка може бити трећи тип.

63
00:05:24,654 --> 00:05:29,111
Али ово би могло такође бити проблем класификације, јер овај други

64
00:05:29,111 --> 00:05:33,929
скуп дискретних вредности излаза одговарају, знате, није рак, раку типа један,

65
00:05:33,929 --> 00:05:39,094
или раку типа два или раку типа три. У проблемима класификације постоји

66
00:05:39,094 --> 00:05:44,413
други начин представљања података. Дозволите ми да вам покажем на шта мислим. Дозволићете ми

67
00:05:44,413 --> 00:05:49,206
да користим мало другачији скуп симбола да прикажем ове податке. Дакле, ако ће величина тумора

68
00:05:49,206 --> 00:05:54,303
бити атрибут који ћу користити да предвидим, злоћудне
или доброћудне, своје податке могу и овако

69
00:05:54,303 --> 00:05:58,975
да представим. Користићу друге симболе да означим доброћудне и

70
00:05:58,975 --> 00:06:03,707
злоћудне, или негативне и позитивне примере. Значи,
уместо цртања крстића,

71
00:06:03,707 --> 00:06:11,595
са словом О ћу да представљам доброћудне туморе, овако.
А оставићу крстиће

72
00:06:11,595 --> 00:06:18,655
да означавају злоћудне туморе. У реду? Надам се да ово почиње

73
00:06:18,655 --> 00:06:23,624
да има неки смисао. Све што сам урадио је било да сам узео, знате, овај горњи сет података и

74
00:06:23,624 --> 00:06:30,894
само сам их мапирао доле, на ову доњу линију, овако, и употребио сам различите симболе,

75
00:06:30,894 --> 00:06:35,828
кружиће и крстиће, да означим злоћудне у односу на доброћудне примере. Сада, у овом

76
00:06:35,828 --> 00:06:41,091
примеру, користимо само једну одлику, или атрибут, углавном, величину тумора, како би

77
00:06:41,091 --> 00:06:46,289
предвидели да ли је тумор злоћудан или доброћудан. У другим машинама,

78
00:06:46,289 --> 00:06:51,355
једини проблем је када имамо више од једне одлике, више од једног атрибута.

79
00:06:51,355 --> 00:06:56,749
Ево један пример. Рецимо да поред величине тумора, знамо и

80
00:06:56,749 --> 00:07:02,387
старосну доб пацијента. У том случају, можда ће
ваш сет података изгледати

81
00:07:02,387 --> 00:07:08,562
овако, где могу имати приказе са овим старостима и величинама тумора и

82
00:07:08,562 --> 00:07:14,980
они изгледају овако. И неке друге пацијенте који изгледају мало другачије,

83
00:07:15,600 --> 00:07:23,968
чији тумори се испостављају као злоћудни, као што је означено са крстићима. Дакле, рецимо да ви

84
00:07:23,968 --> 00:07:32,027
имате пријатељицу која нажалост има тумор. И можда величина тумора и старосна доб

85
00:07:32,027 --> 00:07:37,657
припадају овој тачки. Тако на основу датог сета података, оно што учећи алгоритам

86
00:07:37,657 --> 00:07:42,462
може да уради је да исцрта праву линију кроз податке и тиме покуша да одвоји

87
00:07:42,462 --> 00:07:47,710
злоћудне туморе од доброћудних да би учећи алгоритам могао да одлучи.

88
00:07:47,710 --> 00:07:53,004
Дакле, права линија као што је ова одваја две класе тумора.

89
00:07:53,004 --> 00:07:57,644
И, знате, са овим, надајмо се да можете одлучити да је тумор ваше пријатељице

90
00:07:57,644 --> 00:08:02,322
ако се налази овде, да ће, надајмо се, ваш алгоритам

91
00:08:02,322 --> 00:08:07,305
рећи да тумор ваше пријатељице припада на страни доброћудног и да су веће

92
00:08:07,305 --> 00:08:12,044
шансе да је доброћудан него злоћудан. У овом примеру имамо две одлике, односно,

93
00:08:12,044 --> 00:08:17,147
старосна доб пацијента и величина тумора. У другим проблемима машинског учења

94
00:08:17,147 --> 00:08:21,454
чешће ћемо имати више одлика, а моји пријатељи који раде на овом проблему

95
00:08:21,454 --> 00:08:25,849
они заправо користе одлике као ове, које употпуњују тумор на дојци.

96
00:08:25,849 --> 00:08:30,299
Сличност величине ћелија тумора, сличност облика ћелија

97
00:08:30,299 --> 00:08:34,911
тумора, и тако даље, као  и многе друге одлике. Испоставља се да је један од

98
00:08:34,911 --> 00:08:39,907
најинтересантнијих учећих алгоритама који ћемо видети у овом предмету, учећи

99
00:08:39,907 --> 00:08:45,153
алгоритам који може да користи не само две или три или пет одлике, него неограничен

100
00:08:45,153 --> 00:08:50,150
број одлика. На овом слајду, навео сам укупно пет различитих одлика

101
00:08:50,150 --> 00:08:54,482
Десно, две на оси а три овде мало више. Али испоставља се да за неке проблеме

102
00:08:54,482 --> 00:08:58,497
учења, уствари нећете користити три или пет одлика, него

103
00:08:58,497 --> 00:09:02,566
уместо тога, хтећете да користите бесконачан број одлика, бесконачан број

104
00:09:02,566 --> 00:09:06,211
атрибута, тако да ваш учећи алгоритам има много атрибута или

105
00:09:06,211 --> 00:09:10,333
одлика или сигнала. Дакле, како поступате са

106
00:09:10,333 --> 00:09:14,439
бесконачним бројем одлика. Како уопште можете сачувати бесконачан број

107
00:09:14,439 --> 00:09:18,290
ствари у рачунар када ће ваш рачунар остати без меморије.

108
00:09:18,290 --> 00:09:22,188
Испоставиће се да када будемо говорили о алгоритму који се зове машина векторске подршке,

109
00:09:22,188 --> 00:09:26,675
да постоји красан математички тик који ће омогућити рачунару да ради

110
00:09:26,675 --> 00:09:31,214
са бесконачним бројем одлика. Замислите да нисам записао само две одлике

111
00:09:31,214 --> 00:09:35,487
овде и три одлике овде десно. Него замислите да сам записао бесконачно дугу листу,

112
00:09:35,487 --> 00:09:39,866
и да сам наставио да пишем све више и више одлика. Попут бесконачно дуге листе

113
00:09:39,866 --> 00:09:44,192
одлика. Испоставља се да ћемо бити у могућности да нађемо алгоритам који ће моћи да ради са

114
00:09:44,192 --> 00:09:49,701
тим. Дакле, да се подсетимо. На овом часу ћемо да говоримо о надгледаном

115
00:09:49,701 --> 00:09:54,167
учењу. И идеја је та да, у надгледаном учењу, сваки пример у

116
00:09:54,167 --> 00:09:58,880
нашем сету података, о коме смо говорили шта је 'исправан одговор' због кога би нам се

117
00:09:58,880 --> 00:10:03,960
прилично допао алгоритам који је кориштен на том примеру. Као на пример цена

118
00:10:03,960 --> 00:10:08,428
куће, или да ли је тумор злоћудан или доброћудан. Такође смо говорили и о регресионом проблему.

119
00:10:08,428 --> 00:10:13,202
И под регресијом, значи то да је наш циљ да предвидимо

120
00:10:13,202 --> 00:10:17,977
излаз континуалне вредности. Говорили смо и о проблему класификације, где

121
00:10:17,977 --> 00:10:22,690
је циљ да предвидимо излаз дискретне вредности. За крај једно брзо питање.

122
00:10:22,690 --> 00:10:27,541
Претпоставимо да сте покренули компанију и желите да развијете учеће алгоритме

123
00:10:27,541 --> 00:10:32,618
за решавање сваког од два проблема. У првом проблему имамо велики инвентар

124
00:10:32,618 --> 00:10:38,113
идентичних предмета. Замислите да имате хиљаде копија неких идентичних

125
00:10:38,113 --> 00:10:43,607
предмета за продају и желите да предвидите колико ћете тих предмета продати за

126
00:10:43,607 --> 00:10:49,172
следећа три месеца. У другом проблему од вас се тражи, пошто имате много

127
00:10:49,172 --> 00:10:54,145
корисника и хоћете да напишете софтвер да испита сваки појединачно

128
00:10:54,145 --> 00:10:59,193
налог ваших купаца, односно све налоге ваших купаца и да за сваки налог

129
00:10:59,193 --> 00:11:04,178
донесете одлуку да ли је хакован или компромитован. Дакле, да ли сваки од

130
00:11:04,178 --> 00:11:08,914
ових проблема, треба да се третира као проблем класификације или као

131
00:11:08,914 --> 00:11:14,087
регресиони проблем. Када се видео заустави, молим вас да са мишом изаберете које

132
00:11:14,087 --> 00:11:20,884
од ове четири опције лево мислите да су тачан одговор. Дакле, надајмо се

133
00:11:20,884 --> 00:11:25,871
да сте добили ово као одговор. За први проблем, третираћу ово као

134
00:11:25,871 --> 00:11:31,058
регресиони проблем. Јер ако имам, знате, хиљаде предмета, онда бих

135
00:11:31,058 --> 00:11:36,071
вероватно требао то да третирам као реалну вредност. Као реалну вредност, као континуалну вредност.

136
00:11:36,290 --> 00:11:41,837
И потом третирати број проданих предмета као континуалну вредност.

137
00:11:41,837 --> 00:11:47,748
А други проблем бих да се третира као проблем класификације, јер,

138
00:11:47,748 --> 00:11:53,659
могао бих рећи да подесимо вредност коју хоћу да предвидим са нулом, да означим налог који није

139
00:11:53,659 --> 00:11:58,850
хакован. И подесимо вредност један да означимо налог који је хакован. Дакле, исто

140
00:11:58,850 --> 00:12:03,287
као, знате, за рак дојке, нула је доброћудни, а јединица је злоћудни. Дакле,

141
00:12:03,287 --> 00:12:08,150
могао бих подесити да буде нула или јединица у зависности да ли је хакован и да имам

142
00:12:08,150 --> 00:12:13,134
један алгоритам који ће покушати да предвиди сваку од ових дискретних вредности. И зато што постоји

143
00:12:13,134 --> 00:12:17,693
мали број дискретних вредности, стога ћу да овај проблем третирам као проблем

144
00:12:17,693 --> 00:12:23,075
класификације. Дакле, то је све за надгледано учење и у следећем видеу ћу да говорим

145
00:12:23,075 --> 00:12:28,325
о ненадгледаном учењу, који је друга велика категорија учења.