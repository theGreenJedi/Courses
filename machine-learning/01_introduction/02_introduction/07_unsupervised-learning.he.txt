בסרטון הזה, נדבר על הסוג העיקרי השני של למידה חישובית, המכונה למידה בלתי מונחית או לא מושגחת. בסרטון האחרון, דיברנו על למידה מונחית. זוכרים, סטים של נתונים שנראים כמו זה, שבו כל דוגמא סומנה כחיובית או כשלילית, בתלות אם הגידול היה שפיר או ממאיר. עבור כל דוגמה בלמידה מונחית, נאמר לנו במפורש מה היא התשובה הנכונה כביכול, אם הוא שפיר או ממאיר. בלמידה לא מושגחת, נקבל נתונים שנראים שונה מהנתונים שנראים כך, אין שום תוויות או שלכולם יש אותה תווית או שלגמרי אין תוויות. אנו מקבלים סט נתונים ולא אומרים לנו מה לעשות עם זה ולא אומרים לנו מהי כל נקודה בנתונים. במקום זה פשוט אומרים לנו הנה סט נתונים. אתם יכולים למצוא מבנה כלשהו בנתונים? כשיסתכל על מכלול הנתונים הללו אלגוריתם של למידה לא מונחית הוא עשוי להחליט שהנתונים מקובצים בשני אשכולות שונים. כאן יש אשכול אחד וכאן עוד אשכול. אלגוריתם למידה לא מושגחת עשוי לשבור את הנתונים האלה לשני האשכולות הנפרדים האלה. אז זה נקרא אלגוריתם אשכולות. ומתברר שזה שימושי בהרבה מקרים. דוגמא אחת לשימוש באשכולות היא גוגל חדשות, ואם טרם ראית את זה, גלוש ל-news.google.com URL והעף מבט. מה שגוגל חדשות עושה זה הוא כל יום הולך ומסתכל על עשרות אלפי או מאות אלפי סיפורי חדשות באינטרנט ומקבץ אותם לסיפורי חדשות מאוחדים. לדוגמה, בואו נסתכל כאן. הכתובות כאן מוליכות לדפים שונים של כתבות חדשותיות על סיפור דליפת הנפט של BP. אז בואו נלחץ על אחת מהכתובות, לחצנו על הURL הזה. ואני מגיע לדף האינטרנט הזה. זה מאמר בוול סטריט ז'ורנל על דליפת הנפט בשם "BP הרג את מקונדו", מקונדו הוא השם של הקידוח, ואם אתה לוחץ על כתובת אתר שונה בקבוצה אז אתה מגיע לסיפור אחר. הנה סיפור חדשותי של CNN על משחק בשם דליפת הנפט של BP, ואם נלחץ על קישור שלישי, נקבל סיפור אחר. הנה סיפור מהעיתון הבריטי גרדיאן על דליפת הנפט של BP. אז מה שגוגל חדשות עשה זה לחפש עשרות אלפי כתבות חדשותיות ואוטומטית קיבץ אותם לקבוצות. אז כל הכתבות החדשותיות על אותו נושא מוצגות ביחד. מתברר כי אלגוריתמי אשכולות ואלגוריתמים של למידה לא מונחה שימושיים גם בהרבה בעיות אחרות. הנה אחד להבנת גנומיקה. הנה דוגמה של נתוני מיקרו-מערך של DNA. הרעיון הוא לשים קבוצה של אנשים שונים ועבור כל אחד מהם למדוד עד כמה יש להם גן מסוים או לא. טכנית מודדים את רמת הביטוי של גנים מסוימים. אז הצבעים האלה, אדום, ירוק, אפור וכן הלאה, מראים את המידה של הגן המסוים באנשים שונים. ואז מה שאפשר לעשות הוא להריץ אלגוריתם אשכולות שיקבץ את הפרטים לקטגוריות שונות או לסוגים שונים של אנשים. אז זו למידה בלתי מונחית כי אנחנו לא נותנים לאלגוריתם הגדרה מראש שאלה הם אנשים מסוג 1, אלה מסוג 2, אלה מסוג 3 וכן הלאה ובמקום זה אנחנו רק אומרים הנה קבוצת נתונים. אני לא יודע מה יש בנתונים האלה. אני לא יודע של מי ומאיזה סוג. אני אפילו לא יודע מה הסוגים השונים של אנשים שישנם, אבל האם אתה יכול למצוא באופן אוטומטי מבנה מתוך הנתונים? האם אתה יכול אוטומטית לקבץ את האנשים לאשכולות, לסוגים האלה שאני לא יודע מראש? מאחר ואנחנו לא נותנים לאלגוריתם את התשובה הנכונה עבור הדוגמאות בסט הנתונים, זו למידה לא מושגחת. למידה לא מונחית או למידת אשכולות משמשת גם בקבוצה של יישומים אחרים. היא משמשת כדי לארגן אשכולות גדולים של מחשבים. כמה חברים שלי חקרו מרכזי נתונים גדולים, אשכולות מחשבים גדולים בניסיון להבין אילו מכונות נוטות לעבוד יחד, ואם אפשר לשים את המכונות האלה בסמיכות, אפשר לייעל את העבודה של מרכז הנתונים. היישום השני הוא ניתוח הרשת החברתית. בהינתן מידע על לאילו חברים אתה שולח הרבה דוא"ל או החברים שלך בפייסבוק או המעגלים שלך בגוגל פלוס, אנחנו יכולים לזהות באופן אוטומטי אילו מהן הן קבוצות מלוכדות של חברים, קבוצות של אנשים שכולם מכירים זה את זה. פילוח שוק. יש לחברות רבות מאגרי ענק של מידע על לקוחות. האם אפשר להסתכל על מערכת נתוני הלקוחות ולגלות באופן אוטומטי פלחי שוק ולקבץ את קבוצת הלקוחות שלך אוטומטית לתוך פלחי שוק שונים, כך שתוכל אוטומטית וביעילות רבה יותר למכור או לשווק לפלחי השוק השונים שלך? שוב, זו למידה לא מונחית כי יש לנו את כל נתוני הלקוחות האלה, אבל אנחנו לא יודעים מראש מהם פלחי השוק עבור הלקוחות בקבוצת הנתונים שלנו, אנחנו לא יודעים מראש מי נמצא בפלח שוק אחד, מי בשני, וכן הלאה. אלא אנחנו צריכים לתת לאלגוריתם לגלות את כל זה רק מהנתונים. ועוד דוגמא, מסתבר שלמידה לא מונחית משמשת גם לניתוח נתונים אסטרונומיים ואלגוריתמי האשכולות האלה נותנים במפתיע תאוריות שימושיות ומעניינות על היווצרות גלקסיות. כל אלה הם דוגמאות של אלגוריתמי אשכולות, וזה רק סוג אחד של למידה לא מונחית. הרשו לי לספר לכם על עוד אחד. אני הולך לספר לכם על בעיית מסיבת הקוקטייל. האם היית כבר במסיבת קוקטייל בעבר? אז תדמיין שיש מסיבה, בחדר מלא אנשים, כולנו יושבים, כולם מדברים באותו הזמן ויש הרבה קולות חופפים כי כולם מדברים באותו הזמן, וכמעט קשה לשמוע את האדם מולך. אז אולי מסיבת הקוקטייל היא רק עם שני אנשים, שני האנשים מדברים בעת ובעונה אחת, וזו מסיבת קוקטייל קטנה במקצת. ואנחנו שמים שני מיקרופונים בחדר אז יש מיקרופונים, ומפני שהמיקרופונים האלה נמצאים במרחקים שונים משני הדוברים, כל מיקרופון מקליט שילוב שונה של הקולות של שניהם. אולי הדובר הראשון נשמע יותר רם במיקרופון מספר אחת ואולי הדובר השני נשמע קצת יותר חזק במיקרופון שתיים, כי שני המיקרופונים הם בנקודות שונות ביחס לשני הדוברים, אבל כל מיקרופון רושם הקלטה חופפת של שני קולות הדוברים. אז הנה הקלטה בפועל של שני רמקולים כפי שהוקלטו על ידי חוקר. הרשו לי להשמיע את הראשון, מה שהמיקרופון הראשון שמע. אחת (אוּנוֹ), שתיים (דוֹס), שלוש (טְרֶס), אַרְבַּע (קוּוַאטְרוֹ), חמש (סִינְקוֹ), שש (סֵייס), שבע (סְיֶאטֶה), שמונה (אוֹצ'וֹ), תשע (נוּאֶבֶה), עשר (אִי דְיֶאס). טוב, אולי זו לא מסיבת הקוקטייל המעניינת ביותר, שני אנשים סופרים מאחת עד עשר בשתי שפות, אבל אתה יודע, מה ששמעת היה ההקלטה מהמיקרופון הראשון, הנה ההקלטה השנייה. אוּנוֹ (אחד), דוֹס (שתיים), טְרֶס (שלוש), קוּוַאטְרוֹ (ארבע), סִינְקוֹ (חמש), סֵייס (שש), סְיֶאטֶה (שבע), אוֹצ'וֹ (שמונה), נוּאֶבֶה (תשע) אִי דְיֶאס (עשר). מה שאנחנו יכולים לעשות הוא לקחת את ההקלטות האלה ולתת לאלגוריתם למידה לא מונחית הנקרא אלגוריתם מסיבת קוקטייל, ולומר לאלגוריתם - מצא מבנה בנתונים האלה. ומה שהאלגוריתם יעשה הוא להאזין להקלטות האלה ולומר, אתה יודע, זה נשמע כמו שתי הקלטות מעורבבות או שסיכמו שתי הקלטות כדי לייצר את ההקלטות האלה. ויתר על כן, מה שאלגוריתם מסיבת הקוקטייל יעשה הוא יפריד את שני מקורות השמע האלה שהיו מעורבבים כדי ליצור הקלטות שונות, ולמעשה, הנה הפלט הראשון של אלגוריתם מסיבת הקוקטייל. אחד שתיים שלוש ארבע חמש שש שבע שמונה תשע עשר. אז הקול בעברית מופרד לתוך הקלטה אחת. והנה השנייה. אוּנוֹ, דוֹס, טְרֶס, קוּוַאטְרוֹ, סִינְקוֹ, סֵייס, סְיֶאטֶה, אוֹצ'וֹ, נוּאֶבֶה אִי דְיֶאס. לא רע, לתת לכם דוגמה נוספת, הנה עוד הקלטה אחרת במצב דומה, הנה המיקרופון הראשון: אחת, שתיים, שלוש, ארבע, חמש, שש, שבע, שמונה, תשע, עשר. טוב, אז הבחור המסכן הלך הביתה ממסיבת הקוקטייל ועכשיו הוא יושב בחדר לבד ומדבר אל הרדיו שלו. הנה הקלטת המיקרופון השנייה. אחד שתיים שלוש ארבע חמש שש שבע שמונה תשע עשר. כשאתה נותן את שתי ההקלטות האלה לאותו אלגוריתם, מה שהוא עושה, הוא אומר שוב, אתה יודע, זה נשמע כאילו יש שני מקורות אודיו, ויתר על כן, האלגוריתם אומר, הנה המקור הראשון שמצאתי. אחד שתיים שלוש ארבע חמש שש שבע שמונה תשע עשר. אז זה לא היה מושלם, הוא זיהה את הקול, אבל השאיר קצת מהמוסיקה. אז הנה הפלט השני של האלגוריתם. לא רע, כי בפלט השני הוא הצליח להיפטר מהקול לחלוטין. וניקה לגמרי את המוזיקה, נפטר מהמספרים מאחת עד עשר. אז אתה עשוי להסתכל על אלגוריתם למידה לא מונחית כזה ולתהות כמה מסובך ליישם את זה. זה נראה כאילו כדי לבנות את האפליקציה הזו, זה נראה כאילו לעשות את עיבוד הקול הזה אתם צריכים לכתוב המון קוד או אולי להשתמש בספריות ג'אווה סינתיסייזר שמעבדות קול, נראה באמת מסובך, לעשות את האודיו ולהפריד אותו וכך הלאה. מתברר שהאלגוריתם לעשות מה ששמעתם, אפשר לעשות אותו בשורה אחת של קוד שאנו רואים כאן. זה לקח לחוקרים הרבה זמן לכתוב את שורת הקוד. אני לא טוען שזו בעיה קלה, אבל מסתבר שכאשר משתמשים בסביבת תכנות נכונה, אלגוריתמי למידה רבים יכולים להיות תוכניות באמת קצרות. זו גם הסיבה שבקורס זה אנחנו נשתמש בסביבת התכנות אוקטבה. אוקטבה היא תוכנה חופשית וקוד פתוח, ובשימוש בכלים כמו אוקטבה או מאתלאב, אלגוריתמי למידה רבים ייושמו במספר קטן של שורות קוד. בהמשך הקורס הזה, אני אלמד אתכם קצת על אופן השימוש באוקטאבה ואתם תיישמו חלק מהאלגוריתמים האלה באוקטבה. או אם יש לכם מאתלאב, תוכלו גם להשתמש בו. מתברר שבעמק הסיליקון, עבור הרבה אלגוריתמים של למידה חישובית, מה שאנחנו עושים הוא בונים את האבטיפוס הראשון של התוכנה שלנו באוקטבה כי אוקטבה עושה את תהליך הפיתוח של אלגוריתמי למידה אלה מאוד מהיר. כאן כל הפונקציות הללו כמו למשל פונקציית SVD - ראשי תבות של פירוק ערך יחיד; אבל שהוא פונקציית אלגברה ליניארית שבנויה בתוך שפת אוקטבה. אם היית מנסה לעשות את זה ב-++C או בג'אווה, זה יהיה המון שורות קוד ושימוש בספריות מורכבות של השפות. אז אתה יכול ליישם את הדברים האלה ב++C או בג'אווה או בפייתון, אבל זה פשוט הרבה יותר מסובך לעשות זאת בשפות האלו. מה שהבנתי לאחר שלימדתי למידה חישובית במשך כמעט עשור עכשיו, הוא שאתה לומד הרבה יותר מהר אם אתה משתמש באוקטבה כסביבת התכנות שלך, ואם אתה משתמש באוקטבה ככלי למידה ובניית אבטיפוסים , תוכל ללמוד ולבנות אבטיפוסים של אלגוריתמי למידה הרבה יותר מהר. ואכן מה שאנשים רבים עושים למעשה בחברות בעמק הסיליקון הגדולות, הוא שימוש בסביבה כדוגמת אוקטבה כדי לבנות את האבטיפוס הראשון של אלגוריתם הלמידה, ורק אחרי שהוא עובד, להעביר אותו ל ++ C או ג'אווה או מה שלא יהיה. מתברר כי על ידי עשיית דברים בדרך זו, לעתים קרובות אתה יכול לגרום לאלגוריתם שלך לעבוד הרבה יותר מהר מאשר לו התחלת ב++C. אז אני יודע שכמדריך מותר לי להגיד "תאמינו לי בקשר לזה" רק מספר מוגבל של פעמים, אבל בשביל אלה מכם שמעולם לא השתמשו בסביבות פיתוח מסוג אוקטבה קודם, אני מבקש מכם לסמוך עליי בעניין הזה, ולומר שהזמן שלך, זמן הפיתוח שלך הוא אחד המשאבים היקרים ביותר. ואחרי שראיתי הרבה מאד אנשים שעוברים את התהליך, אני חושב שכחוקר או מפתח של למידה חישובית הזמן שלך ינוצל הרבה יותר ביעילות אם תלמד להתחיל באבטיפוס, להתחיל באוקטבה, מאשר בשפה אחרת. לסיום, כדי לסכם את הסרטון, יש לי שאלת חזרה קצרה אחת. דברנו על למידה לא מודרכת, שהיא למידה שבה אתה נותן לאלגוריתם המון נתונים ופשוט מבקש ממנו למצוא איזה שהוא מבנה בנתונים. מבין ארבע הדוגמאות הבאות, אילו מביניהן לדעתך יהיו אלגוריתמים של למידה לא מונחית בניגוד לבעיות של לימוד מונחה. עבור כל אחת מארבע תיבות הסימון משמאל, סמנו את אלה שעבורם אתה חושב שיתאים אלגוריתם למידה לא מונחית ואז לחץ על הכפתור בצד ימין למטה כדי לבדוק את תשובתכם. אז כשהווידאו ייעצר, ענו בבקשה על השאלה בשקופית. אז אני מקווה שזכרתם את בעיית תיקיית הספאם - דואר זבל. אם יש לכם נתונים שהם כבר עם תוויות, כן דואר זבל ולא דואר זבל, אנחנו מתייחסים לזה כאל בעיית לימוד מונחה. הדוגמא של סיפורי החדשות, זו בדיוק הדוגמא של גוגל חדשות שראינו בסרטון הזה, ראינו איך אפשר להשתמש באלגוריתם אשכולות כדי לקבץ מאמרים כאלה ולכן זו למידה לא מונחה. על הדוגמא של פילוח שוק דברתי קצת קודם, זו בעיית למידה לא מונחה כי אנחנו פשוט נותנים את הנתונים לאלגוריתם ומבקשים ממנו לגלות פלחי שוק באופן אוטומטי. והדוגמא האחרונה, סוכרת, טוב, זה בעצם כמו סרטן השד שלנו מהסרטון האחרון. רק שבמקום גידולים סרטניים ממאירים ושפירים יש לנו כן סוכרת או לא סוכרת ולכן נשתמש ונפתור את זה כבעיית למידה מונחה בדיוק כמו שעשינו עבור נתוני הגידולים בשד. טוב, אז זה הכל בקשר ללמידה לא מונחה, ובסרטון הבא נצלול עמוק יותר לתוך אלגוריתמי למידה ספציפיים ונתחיל לדבר על איך עובדים האלגוריתמים האלה ואיך אנחנו יכולים ליישם אותם.