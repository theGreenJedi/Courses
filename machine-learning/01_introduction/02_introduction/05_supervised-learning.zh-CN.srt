1
00:00:00,000 --> 00:00:04,620
在本视频中，我将介绍一种也许是最常见的机器学习问题。

2
00:00:04,620 --> 00:00:08,910
即监督学习。后面将给出监督学习更正式的定义，

3
00:00:08,910 --> 00:00:13,255
现在最好以示例来说明什么是监督学习。

4
00:00:13,255 --> 00:00:17,820
之后再给出正式的定义。假设你想预测房价（无比需要啊！），

5
00:00:17,820 --> 00:00:23,072
之前，某学生已经从某地收集了数据集（不是中国的，囧）

6
00:00:23,072 --> 00:00:28,745
其中一个数据集是这样的。

7
00:00:28,745 --> 00:00:34,347
这是横坐标，即不同房子的面积，单位平方脚（^-^）

8
00:00:34,347 --> 00:00:39,879
纵轴上是房价，单位 千美元。

9
00:00:39,879 --> 00:00:45,168
根据给定数据，假设你朋友有栋房子，750平尺（70平米）

10
00:00:45,168 --> 00:00:50,708
想知道这房子能卖多少，好卖掉。

11
00:00:50,708 --> 00:00:56,116
那么，学习算法怎么帮你呢？学习算法可以：

12
00:00:56,116 --> 00:01:01,524
绘出一条直线，让直线尽可能匹配到所有数据。

13
00:01:01,524 --> 00:01:07,111
基于此，看上去，那个房子应该、可能、也许、大概

14
00:01:07,111 --> 00:01:13,239
卖到15万美元（一平米两千刀！）。但这不是唯一的学习算法。

15
00:01:13,239 --> 00:01:18,536
可能还有更好的。比如不用直线了，

16
00:01:18,536 --> 00:01:23,620
可能平方函数会更好，

17
00:01:23,620 --> 00:01:29,110
即二次多项式更符合数据集。如果你这样做，

18
00:01:29,110 --> 00:01:34,667
预测结果就应该是20万刀（一平三千刀，涨价好快）。

19
00:01:34,667 --> 00:01:39,184
后面我们会介绍到如何选择

20
00:01:39,184 --> 00:01:43,792
是选择直线还是平方函数来拟合。

21
00:01:43,792 --> 00:01:48,631
没有明确的选择，就不知哪个能给你的朋友

22
00:01:48,631 --> 00:01:53,182
更好的卖房建议。只是这些每个都是很好的学习算法例子。

23
00:01:53,182 --> 00:01:57,834
也是监督学习的例子。

24
00:01:57,834 --> 00:02:03,736
术语监督学习，意指给出一个算法，

25
00:02:03,736 --> 00:02:09,089
需要部分数据集已经有正确答案。比如给定房价数据集，

26
00:02:09,089 --> 00:02:14,580
对于里面每个数据，算法都知道对应的正确房价，

27
00:02:14,580 --> 00:02:20,002
即这房子实际卖出的价格。算法的结果就是

28
00:02:20,002 --> 00:02:25,423
算出更多的正确价格，比如那个新房子，

29
00:02:25,423 --> 00:02:30,579
你朋友想卖的那个。用更术语的方式来定义，

30
00:02:30,579 --> 00:02:35,257
监督学习又叫回归问题，（应该是回归属于监督中的一种）

31
00:02:35,257 --> 00:02:40,467
意指要预测一个连续值的输出，比如房价。

32
00:02:40,467 --> 00:02:44,720
虽然从技术上，一般把房价记到美分单位。

33
00:02:44,720 --> 00:02:49,246
所以实际还是个离散值，但通常把它看作实际数字，

34
00:02:49,246 --> 00:02:53,608
是一个标量值，一个连续值的数，而术语回归，

35
00:02:53,608 --> 00:02:58,080
意味着要预测这类连续值属性的种类。

36
00:02:58,080 --> 00:03:02,060
另一个监督学习的例子，我和一些朋友

37
00:03:02,060 --> 00:03:06,427
之前研究的领域。让我们来看医学记录，

38
00:03:06,427 --> 00:03:11,675
并预测胸部肿瘤是恶性良性。

39
00:03:11,675 --> 00:03:16,856
如果某人发现有胸部肿瘤，恶性肿瘤有害又危险，

40
00:03:16,856 --> 00:03:22,300
良性肿瘤则是少害。

41
00:03:22,300 --> 00:03:27,876
显然人们很关注这个。让我们看一个收集好的数据集，

42
00:03:27,876 --> 00:03:33,164
假设在数据集中，横轴表示肿瘤的大小，

43
00:03:33,164 --> 00:03:39,317
纵轴我打算圈上0或1，是或否，

44
00:03:39,317 --> 00:03:45,184
即肿瘤是恶性的还是良性的。

45
00:03:45,184 --> 00:03:50,392
所以如图所示，可以看到这个大小的肿瘤块

46
00:03:50,392 --> 00:03:56,283
是良性的，还有这些大小的都是良性的。

47
00:03:56,283 --> 00:04:02,227
不幸地是也看到一些恶性肿瘤，比如这些大小的肿瘤。

48
00:04:02,227 --> 00:04:08,572
所以，有5个良性块，在这一块，

49
00:04:08,572 --> 00:04:15,159
还有5个恶性的，它们纵轴值为1.

50
00:04:15,159 --> 00:04:21,504
现在假设某人杯具地得胸部肿瘤了，

51
00:04:21,504 --> 00:04:28,097
大小大概是这么大。

52
00:04:28,097 --> 00:04:32,930
对应的机器学习问题就是，你能否估算出一个概率，

53
00:04:32,930 --> 00:04:37,819
即肿瘤为恶或为良的概率？

54
00:04:37,819 --> 00:04:42,719
专业地说，这是个分类问题。

55
00:04:42,719 --> 00:04:47,342
分类是要预测一个离散值输出。

56
00:04:47,342 --> 00:04:52,321
这里是0或1，恶性或良性。事实证明，

57
00:04:52,321 --> 00:04:58,331
在分类问题中，有时会有超过两个的值，

58
00:04:58,331 --> 00:05:03,852
输出的值可能超过两种。举个具体例子，

59
00:05:03,852 --> 00:05:09,947
胸部肿瘤可能有三种类型，所以要预测离散值0，1，2，3

60
00:05:09,947 --> 00:05:15,138
0就是良性肿瘤，没有癌症。

61
00:05:15,138 --> 00:05:19,836
1 表示1号癌症，假设总共有三种癌症。

62
00:05:19,836 --> 00:05:24,654
2 是2号癌症，3 就是3号癌症。

63
00:05:24,654 --> 00:05:29,111
这同样是个分类问题，因为它的输出的离散值集合

64
00:05:29,111 --> 00:05:33,929
分别对应于无癌，1号，2号，3号癌症

65
00:05:33,929 --> 00:05:39,094
我再露一小手，在分类问题中，还有另一种作图方式

66
00:05:39,094 --> 00:05:44,413
来描述数据。我画你猜。要用到些许不同的符号集合

67
00:05:44,413 --> 00:05:49,206
来描绘数据。如果肿瘤大小作为唯一属性，

68
00:05:49,206 --> 00:05:54,303
被用于预测恶性良性，可以把数据作图成这样。

69
00:05:54,303 --> 00:05:58,975
使用不同的符号来表示良性和

70
00:05:58,975 --> 00:06:03,707
恶性，即阴性和阳性。所以，不再统一画叉叉了，

71
00:06:03,707 --> 00:06:11,595
改用圈圈来代表良性肿瘤，就像这样。

72
00:06:11,595 --> 00:06:18,655
仍沿用X（叉叉）代表恶性肿瘤。希望你能明白。

73
00:06:18,655 --> 00:06:23,624
我所做的就是，把在上面的数据，

74
00:06:23,624 --> 00:06:30,894
映射下来。再用不同的符号，

75
00:06:30,894 --> 00:06:35,828
圈和叉来分别代表良性和恶性。

76
00:06:35,828 --> 00:06:41,091
在上例中，只使用了一个特征属性，即肿瘤块大小，

77
00:06:41,091 --> 00:06:46,289
来预测肿瘤是恶性良性。在其它机器学习问题里，

78
00:06:46,289 --> 00:06:51,355
有着不只一个的特征和属性。

79
00:06:51,355 --> 00:06:56,749
例子，现在不只是知道肿瘤大小，

80
00:06:56,749 --> 00:07:02,387
病人年龄和肿瘤大小都知道了。这种情况下，

81
00:07:02,387 --> 00:07:08,562
数据集如表图所示，有些病人，年龄、肿瘤已知，

82
00:07:08,562 --> 00:07:14,980
不同的病人，会有一点不一样，

83
00:07:15,600 --> 00:07:23,968
肿瘤恶性，则用叉来代表。所以，假设

84
00:07:23,968 --> 00:07:32,027
有一朋友得了肿瘤。肿瘤大小和年龄

85
00:07:32,027 --> 00:07:37,657
落在此处。那么依据这个给定的数据集，学习算法

86
00:07:37,657 --> 00:07:42,462
所做的就是画一条直线，分开

87
00:07:42,462 --> 00:07:47,710
恶性肿瘤和良性肿瘤，所以学习算法会

88
00:07:47,710 --> 00:07:53,004
画条直线，像这样，把两类肿瘤分开。

89
00:07:53,004 --> 00:07:57,644
然后你就能判断你朋友的肿瘤是...了

90
00:07:57,644 --> 00:08:02,322
如果它在那边，学习算法就说

91
00:08:02,322 --> 00:08:07,305
你朋友的肿瘤在良性一边，因此更可能

92
00:08:07,305 --> 00:08:12,044
是良性的。好，本例中，总共有两个特征，

93
00:08:12,044 --> 00:08:17,147
即病人年龄和肿瘤大小。在别的ML问题中，

94
00:08:17,147 --> 00:08:21,454
经常会用到更多特征，我朋友研究这个问题时，

95
00:08:21,454 --> 00:08:25,849
通常使用这些特征：比如块的厚度，即胸部肿瘤的厚度

96
00:08:25,849 --> 00:08:30,299
肿瘤细胞大小和形状的一致性，

97
00:08:30,299 --> 00:08:34,911
等等。它表明，

98
00:08:34,911 --> 00:08:39,907
最有趣的学习算法（本课中将学到）

99
00:08:39,907 --> 00:08:45,153
能够处理，无穷多个特征。不是3到5个这么少。

100
00:08:45,153 --> 00:08:50,150
在这张幻灯片中，我已经列举了总共5个不同的特征。

101
00:08:50,150 --> 00:08:54,482
但对于一些学习问题，

102
00:08:54,482 --> 00:08:58,497
真要用到的不只是三五个特征，

103
00:08:58,497 --> 00:09:02,566
要用到无数多个特征，非常多的属性，

104
00:09:02,566 --> 00:09:06,211
所以，你的学习算法要使用很多的属性

105
00:09:06,211 --> 00:09:10,333
或特征、线索来进行预测。那么，你如何处理

106
00:09:10,333 --> 00:09:14,439
无限多特征呢？甚至你如何存储无数的东西

107
00:09:14,439 --> 00:09:18,290
进电脑里，又要避免内存不足？

108
00:09:18,290 --> 00:09:22,188
事实上，等我们介绍一种叫支持向量机的算法时，

109
00:09:22,188 --> 00:09:26,675
就知道存在一个简洁的数学方法，能让电脑处理无限多的特征。

110
00:09:26,675 --> 00:09:31,214
想像下，我不是这边写两个特征，

111
00:09:31,214 --> 00:09:35,487
右边写三个特征。而是，写一个无限长的特征表，

112
00:09:35,487 --> 00:09:39,866
不停地写特征，似乎是个无限长的特征的表。

113
00:09:39,866 --> 00:09:44,192
但是，我们也有能力设计一个算法来处理这个问题。

114
00:09:44,192 --> 00:09:49,701
所以再从头复述一遍。本课中，我们介绍监督学习。

115
00:09:49,701 --> 00:09:54,167
其基本思想是，监督学习中，对于数据集中的每个数据，

116
00:09:54,167 --> 00:09:58,880
都有相应的正确答案，（训练集）

117
00:09:58,880 --> 00:10:03,960
算法就是基于这些来做出预测。就像那个房价，

118
00:10:03,960 --> 00:10:08,428
或肿瘤的性质。后面介绍了回归问题。

119
00:10:08,428 --> 00:10:13,202
即通过回归来预测一个连续值输出。

120
00:10:13,202 --> 00:10:17,977
我们还谈到了分类问题，

121
00:10:17,977 --> 00:10:22,690
目标是预测离散值输出。下面是个小测验题目：

122
00:10:22,690 --> 00:10:27,541
假设你有家公司，希望研究相应的学习算法去

123
00:10:27,541 --> 00:10:32,618
解决两个问题。第一个问题，你有一堆货物的清单。

124
00:10:32,618 --> 00:10:38,113
假设一些货物有几千件可卖，

125
00:10:38,113 --> 00:10:43,607
你想预测出，你能在未来三个月卖出多少货物。

126
00:10:43,607 --> 00:10:49,172
第二个问题，你有很多用户，

127
00:10:49,172 --> 00:10:54,145
你打算写程序来检查每个用户的帐目。

128
00:10:54,145 --> 00:10:59,193
对每个用户的帐目，

129
00:10:59,193 --> 00:11:04,178
判断这个帐目是否被黑过（hacked or compromised）。

130
00:11:04,178 --> 00:11:08,914
请问，这两个问题是分类问题，还是回归问题？

131
00:11:08,914 --> 00:11:14,087
当视频暂停时，请用你的鼠标进行选择，

132
00:11:14,087 --> 00:11:20,884
四选一，选择你认为正确的答案。

133
00:11:20,884 --> 00:11:25,871
好，希望你刚才答对了。问题一是个回归问题

134
00:11:25,871 --> 00:11:31,058
因为如果我有几千件货物，

135
00:11:31,058 --> 00:11:36,071
可能只好把它当作一个实际的值，一个连续的值。

136
00:11:36,290 --> 00:11:41,837
也把卖出的数量当作连续值。

137
00:11:41,837 --> 00:11:47,748
第二个问题，则是分类问题，因为可以把

138
00:11:47,748 --> 00:11:53,659
我想预测的一个值设为0，来表示账目没有被hacked

139
00:11:53,659 --> 00:11:58,850
另一个设为1，表示已经被hacked。

140
00:11:58,850 --> 00:12:03,287
就像乳癌例子中，0表示良性，1表示恶性。

141
00:12:03,287 --> 00:12:08,150
所以这个值为0或1，取决于是否被hacked，

142
00:12:08,150 --> 00:12:13,134
有算法能预测出是这两个离散值中的哪个。

143
00:12:13,134 --> 00:12:17,693
因为只有少量的离散值，所以这个就是个分类问题。

144
00:12:17,693 --> 00:12:23,075
这就是监督学习，下个视频将会介绍

145
00:12:23,075 --> 00:12:28,325
无监督学习，学习算法的另一主要类型。