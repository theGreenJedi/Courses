1
00:00:00,680 --> 00:00:01,740
在这段视频中

2
00:00:01,900 --> 00:00:02,960
介绍一些

3
00:00:03,210 --> 00:00:04,680
大间隔分类背后的数学原理

4
00:00:05,960 --> 00:00:08,390
本节为选学部分 你完全可以跳过它

5
00:00:09,260 --> 00:00:10,380
但是听听这节课可能让你对

6
00:00:10,650 --> 00:00:11,980
支持向量机中的优化问题

7
00:00:12,460 --> 00:00:13,830
以及如何得到

8
00:00:13,940 --> 00:00:15,540
大间距分类器

9
00:00:15,860 --> 00:00:17,150
产生更好的直观理解

10
00:00:21,180 --> 00:00:22,530
首先

11
00:00:22,600 --> 00:00:23,730
让我来给大家复习一下

12
00:00:23,970 --> 00:00:26,490
关于向量内积的知识

13
00:00:28,310 --> 00:00:29,280
假设我有两个向量

14
00:00:29,900 --> 00:00:32,180
u 和 v 我将它们写在这里

15
00:00:32,950 --> 00:00:34,180
两个都是二维向量

16
00:00:35,460 --> 00:00:36,940
我们看一下

17
00:00:37,440 --> 00:00:39,550
u 转置乘以 v 的结果

18
00:00:40,160 --> 00:00:42,180
u 转置乘以 v

19
00:00:42,300 --> 00:00:43,720
也叫做向量 u 和 v

20
00:00:44,490 --> 00:00:45,880
之间的内积

21
00:00:48,360 --> 00:00:49,960
由于是二维向量 我可以

22
00:00:50,380 --> 00:00:51,940
将它们画在这个图上

23
00:00:52,760 --> 00:00:53,860
我们说

24
00:00:54,040 --> 00:00:55,850
这就是向量 u

25
00:00:55,960 --> 00:00:56,930
即

26
00:00:57,110 --> 00:00:59,160
在横轴上

27
00:00:59,360 --> 00:01:00,820
取值为某个u1

28
00:01:01,560 --> 00:01:03,280
而在纵轴上

29
00:01:03,350 --> 00:01:04,820
高度是

30
00:01:05,100 --> 00:01:06,360
某个 u2 作为U的

31
00:01:07,340 --> 00:01:08,530
第二个分量

32
00:01:08,990 --> 00:01:12,580
现在

33
00:01:12,860 --> 00:01:13,760
很容易计算的

34
00:01:14,040 --> 00:01:15,430
一个量就是向量 u 的

35
00:01:16,500 --> 00:01:17,540
范数

36
00:01:17,860 --> 00:01:19,390
这是双竖线

37
00:01:19,540 --> 00:01:20,380
左边一个 右边一个

38
00:01:20,800 --> 00:01:22,610
表示 u 的范数

39
00:01:22,730 --> 00:01:23,930
即 u 的长度

40
00:01:24,200 --> 00:01:27,330
即向量 u 的欧几里得长度

41
00:01:27,410 --> 00:01:30,800
根据

42
00:01:31,350 --> 00:01:33,600
毕达哥拉斯定理 等于

43
00:01:33,940 --> 00:01:35,420
它等于 u1 平方

44
00:01:35,620 --> 00:01:37,300
加上 u2 平方

45
00:01:37,530 --> 00:01:40,190
开根号

46
00:01:40,300 --> 00:01:42,780
这是向量 u 的长度 它是一个实数

47
00:01:43,730 --> 00:01:44,750
现在你知道了

48
00:01:45,080 --> 00:01:46,120
这个的长度是多少

49
00:01:46,220 --> 00:01:48,900
这个向量的长度写在这里了

50
00:01:49,680 --> 00:01:50,490
我刚刚画的这个

51
00:01:50,760 --> 00:01:52,990
向量的长度就知道了

52
00:01:56,020 --> 00:01:57,300
现在让我们回头来看

53
00:01:57,450 --> 00:01:59,660
向量v 因为我们想计算内积

54
00:02:00,430 --> 00:02:01,380
v 是另一个向量

55
00:02:01,520 --> 00:02:03,150
它的两个分量 v1 和 v2

56
00:02:03,310 --> 00:02:06,900
是已知的

57
00:02:08,340 --> 00:02:10,490
向量 v

58
00:02:10,880 --> 00:02:15,050
可以画在这里

59
00:02:16,920 --> 00:02:18,260
现在让我们

60
00:02:18,640 --> 00:02:19,880
来看看如何计算

61
00:02:20,400 --> 00:02:21,610
u 和 v 之间的内积

62
00:02:21,860 --> 00:02:23,320
这就是具体做法

63
00:02:24,010 --> 00:02:25,780
我们将向量 v

64
00:02:26,200 --> 00:02:28,440
投影到

65
00:02:28,550 --> 00:02:29,700
向量 u 上

66
00:02:29,930 --> 00:02:31,900
我们做一个直角投影

67
00:02:31,970 --> 00:02:33,700
或者说一个90度投影

68
00:02:33,920 --> 00:02:35,490
将其投影到 u 上

69
00:02:36,650 --> 00:02:37,410
接下来我度量

70
00:02:38,130 --> 00:02:39,480
这条红线的

71
00:02:40,210 --> 00:02:41,520
长度

72
00:02:41,720 --> 00:02:42,620
我称这条红线的

73
00:02:42,730 --> 00:02:44,670
长度为 p 因此 p

74
00:02:45,530 --> 00:02:46,830
就是长度 或者说是

75
00:02:46,890 --> 00:02:48,230
向量 v 投影到

76
00:02:49,670 --> 00:02:51,670
向量 u 上的量

77
00:02:51,790 --> 00:02:54,380
我将它写下来

78
00:02:54,560 --> 00:02:55,600
p 是 v

79
00:02:57,500 --> 00:03:02,150
投影到

80
00:03:02,260 --> 00:03:05,800
向量 u 上的

81
00:03:05,920 --> 00:03:08,210
长度

82
00:03:08,430 --> 00:03:10,510
因此可以

83
00:03:10,790 --> 00:03:12,710
将 u 转置乘以 v

84
00:03:12,870 --> 00:03:13,540
写作

85
00:03:13,840 --> 00:03:16,330
p 乘以

86
00:03:16,430 --> 00:03:18,020
u 的范数或者说

87
00:03:18,110 --> 00:03:21,130
u的长度

88
00:03:21,460 --> 00:03:23,400
这是计算内积的一种方法

89
00:03:24,070 --> 00:03:25,590
如果你从几何上

90
00:03:25,780 --> 00:03:27,160
画出 p 的值

91
00:03:27,330 --> 00:03:29,280
同时画出 u 的范数

92
00:03:29,900 --> 00:03:30,690
你也会同样地

93
00:03:31,050 --> 00:03:32,330
计算出内积

94
00:03:32,680 --> 00:03:33,840
答案是一样的

95
00:03:34,860 --> 00:03:34,860
对吧

96
00:03:35,070 --> 00:03:36,140
另一个计算公式是

97
00:03:36,280 --> 00:03:38,150
 u 转置乘以 v 就是

98
00:03:39,000 --> 00:03:40,930
[u1 u2] 这个一行两列的矩阵

99
00:03:41,090 --> 00:03:42,650
乘以

100
00:03:43,220 --> 00:03:45,250
v 因此

101
00:03:45,620 --> 00:03:46,930
可以得到

102
00:03:47,490 --> 00:03:50,630
u1×v1 加上 u2×v2

103
00:03:51,700 --> 00:03:53,140
根据线性代数的知识

104
00:03:53,310 --> 00:03:55,010
这两个公式

105
00:03:55,180 --> 00:03:56,880
会给出同样的结果

106
00:03:57,890 --> 00:03:58,720
顺便说一句

107
00:03:59,290 --> 00:04:01,010
u 转置乘以 v

108
00:04:01,320 --> 00:04:03,490
等于 v 转置乘以 u

109
00:04:03,650 --> 00:04:04,510
因此如果你将 u 和 v 交换位置

110
00:04:05,050 --> 00:04:06,860
将 u 投影到 v 上

111
00:04:07,120 --> 00:04:08,130
而不是将 v 投影到 u 上

112
00:04:08,520 --> 00:04:09,940
然后做同样地计算

113
00:04:10,160 --> 00:04:12,410
只是把 u 和 v 的位置交换一下

114
00:04:13,170 --> 00:04:14,390
你事实上可以

115
00:04:14,710 --> 00:04:16,900
得到同样的结果

116
00:04:17,540 --> 00:04:18,790
申明一点

117
00:04:18,990 --> 00:04:20,850
在这个等式中

118
00:04:21,030 --> 00:04:21,920
u 的范数是一个实数

119
00:04:22,100 --> 00:04:25,260
p也是一个实数

120
00:04:25,760 --> 00:04:28,720
因此 u 转置乘以 v

121
00:04:29,410 --> 00:04:32,350
就是两个实数

122
00:04:33,040 --> 00:04:34,440
正常相乘

123
00:04:35,580 --> 00:04:36,960
最后一点

124
00:04:37,190 --> 00:04:38,240
需要注意的就是p值

125
00:04:38,330 --> 00:04:40,250
p事实上是有符号的

126
00:04:41,350 --> 00:04:43,240
即它可能是正值 也可能是负值

127
00:04:44,350 --> 00:04:45,530
我的意思是说

128
00:04:45,650 --> 00:04:46,740
如果 u

129
00:04:47,170 --> 00:04:49,360
是一个类似这样的向量

130
00:04:49,640 --> 00:04:51,360
v 是一个类似这样的向量

131
00:04:52,380 --> 00:04:53,890
u 和 v 之间的

132
00:04:54,130 --> 00:04:55,770
夹角大于90度

133
00:04:56,620 --> 00:04:57,960
则如果将 v

134
00:04:58,270 --> 00:05:00,220
投影到 u 上 会得到

135
00:05:00,420 --> 00:05:01,590
这样的一个投影

136
00:05:01,720 --> 00:05:03,860
这是 p 的长度

137
00:05:04,110 --> 00:05:05,490
在这个情形下

138
00:05:05,670 --> 00:05:06,900
我们仍然有

139
00:05:07,670 --> 00:05:09,510
u 转置乘以 v

140
00:05:09,660 --> 00:05:11,720
是等于 p 乘以

141
00:05:11,800 --> 00:05:14,070
u 的范数

142
00:05:14,200 --> 00:05:16,600
唯一一点不同的是 p 在这里是负的

143
00:05:19,150 --> 00:05:20,990
在内积计算中 如果 u 和 v 之间的夹角

144
00:05:21,320 --> 00:05:22,540
小于90度

145
00:05:22,790 --> 00:05:23,820
那么那条红线的长度

146
00:05:24,100 --> 00:05:26,480
p 是正值

147
00:05:27,130 --> 00:05:28,420
然而如果

148
00:05:28,720 --> 00:05:29,640
这个夹角

149
00:05:30,000 --> 00:05:31,890
大于90度 则p

150
00:05:32,130 --> 00:05:33,880
将会是负的

151
00:05:34,130 --> 00:05:37,260
就是这个小线段的长度是负的

152
00:05:37,650 --> 00:05:38,750
因此两个向量之间的内积

153
00:05:38,900 --> 00:05:40,130
也是负的

154
00:05:40,820 --> 00:05:42,900
如果它们之间的夹角大于90度

155
00:05:43,770 --> 00:05:45,100
这就是关于向量内积的知识

156
00:05:45,310 --> 00:05:46,490
我们接下来将会

157
00:05:46,930 --> 00:05:47,960
使用这些关于向量内积的

158
00:05:48,280 --> 00:05:49,610
性质 试图来

159
00:05:49,840 --> 00:05:51,880
理解支持向量机

160
00:05:52,400 --> 00:05:54,490
中的目标函数

161
00:05:54,630 --> 00:05:58,620
这就是我们先前给出的

162
00:05:58,650 --> 00:06:00,900
支持向量机模型中的目标函数

163
00:06:01,100 --> 00:06:02,070
为了讲解方便

164
00:06:02,120 --> 00:06:04,520
我做一点简化

165
00:06:04,910 --> 00:06:08,220
仅仅是为了让目标函数

166
00:06:08,670 --> 00:06:10,110
更容易被分析 我接下来忽略掉截距

167
00:06:10,270 --> 00:06:14,160
令 θ0 等于 0

168
00:06:16,510 --> 00:06:22,950
这样更容易画示意图 我将特征数 n 置为2 因此我们仅有

169
00:06:23,980 --> 00:06:24,710
两个特征 x1 和 x2

170
00:06:26,510 --> 00:06:27,980
现在 我们来看一下目标函数

171
00:06:28,470 --> 00:06:29,910
支持向量机的优化目标函数

172
00:06:30,160 --> 00:06:32,130
当我们仅有两个特征

173
00:06:32,630 --> 00:06:33,710
即 n=2 时

174
00:06:34,170 --> 00:06:35,340
这个式子可以写作

175
00:06:36,130 --> 00:06:37,900
二分之一

176
00:06:38,040 --> 00:06:40,080
θ1 平方加上 θ2 平方

177
00:06:40,620 --> 00:06:42,870
我们只有两个参数 θ1 和θ2

178
00:06:45,240 --> 00:06:46,730
接下来我重写一下

179
00:06:46,940 --> 00:06:47,900
我将其重写成

180
00:06:48,090 --> 00:06:49,980
二分之一 θ1 平方

181
00:06:50,190 --> 00:06:51,860
加上 θ2 平方

182
00:06:52,050 --> 00:06:54,160
开平方根后再平方

183
00:06:54,820 --> 00:06:55,760
我这么做的根据是

184
00:06:56,100 --> 00:06:58,990
对于任何数 w

185
00:07:00,830 --> 00:07:02,480
w的平方根 再取平方

186
00:07:02,570 --> 00:07:03,930
得到的就是

187
00:07:04,080 --> 00:07:05,650
w 本身 因此平方根 然后平方

188
00:07:05,840 --> 00:07:07,250
并不会改变值的大小

189
00:07:08,600 --> 00:07:09,500
你可能注意到

190
00:07:09,730 --> 00:07:11,870
括号里面的这一项

191
00:07:12,290 --> 00:07:13,450
是向量 θ

192
00:07:14,530 --> 00:07:16,460
的范数

193
00:07:16,690 --> 00:07:18,250
或者说是向量 θ 的长度

194
00:07:18,430 --> 00:07:20,020
我的意思是

195
00:07:20,200 --> 00:07:21,640
如果我们将

196
00:07:21,700 --> 00:07:22,590
向量 θ 写出来

197
00:07:23,080 --> 00:07:24,320
θ1 θ2

198
00:07:25,260 --> 00:07:26,260
那么我刚刚画红线的这一项

199
00:07:26,690 --> 00:07:28,230
就是向量 θ

200
00:07:28,640 --> 00:07:30,480
的长度或范数

201
00:07:30,900 --> 00:07:32,180
这里我们用的是之前

202
00:07:32,950 --> 00:07:35,050
学过的向量范数的定义

203
00:07:36,140 --> 00:07:37,040
事实上这就

204
00:07:37,400 --> 00:07:38,320
等于向量 θ

205
00:07:38,370 --> 00:07:39,760
的长度

206
00:07:40,020 --> 00:07:41,620
当然你可以将其写作  θ0 θ1 θ2

207
00:07:42,280 --> 00:07:45,230
如果 θ0等于0 

208
00:07:45,860 --> 00:07:46,770
那就是

209
00:07:46,900 --> 00:07:48,680
θ1 θ2 的长度

210
00:07:48,830 --> 00:07:50,450
在这里我将忽略 θ0

211
00:07:50,940 --> 00:07:52,710
将 θ 仅仅写作这样

212
00:07:53,150 --> 00:07:54,730
这样来写 θ

213
00:07:54,960 --> 00:07:56,360
θ 的范数

214
00:07:56,720 --> 00:07:58,480
仅仅和 θ1 θ2 有关

215
00:07:58,620 --> 00:08:00,180
但是

216
00:08:00,260 --> 00:08:01,220
数学上不管你是否包含 θ0

217
00:08:01,460 --> 00:08:03,790
其实并没有差别

218
00:08:03,970 --> 00:08:05,870
因此在我们接下来的推导中去掉θ0不会有影响

219
00:08:07,630 --> 00:08:09,120
这意味着

220
00:08:09,390 --> 00:08:11,440
我们的目标函数是

221
00:08:11,750 --> 00:08:13,100
等于二分之一

222
00:08:13,190 --> 00:08:14,610
θ范数的平方

223
00:08:16,190 --> 00:08:17,230
因此支持向量机

224
00:08:17,530 --> 00:08:19,010
做的全部事情就是

225
00:08:19,910 --> 00:08:21,500
极小化参数向量 θ

226
00:08:21,590 --> 00:08:23,100
范数的平方 或者说

227
00:08:23,470 --> 00:08:24,840
长度的平方

228
00:08:28,330 --> 00:08:29,160
现在我将要

229
00:08:29,370 --> 00:08:30,790
看看这些项

230
00:08:31,090 --> 00:08:33,670
θ 转置乘以x 更深入地理解它们的含义

231
00:08:34,230 --> 00:08:36,600
给定参数向量θ 给定一个样本 x

232
00:08:36,930 --> 00:08:39,880
这等于什么呢?

233
00:08:40,820 --> 00:08:42,120
在前一页幻灯片上

234
00:08:42,230 --> 00:08:44,070
我们画出了

235
00:08:44,870 --> 00:08:45,850
在不同情形下

236
00:08:46,110 --> 00:08:47,880
u转置乘以v的示意图

237
00:08:48,130 --> 00:08:50,340
我们将会使用这些概念

238
00:08:50,980 --> 00:08:52,300
θ 和 x(i) 就

239
00:08:52,410 --> 00:08:53,310
类似于 u 和 v

240
00:08:54,400 --> 00:08:57,430
让我们看一下示意图

241
00:08:57,860 --> 00:08:59,160
我们考察一个

242
00:08:59,430 --> 00:09:01,130
单一的训练样本

243
00:09:01,230 --> 00:09:03,360
我有一个正样本在这里

244
00:09:03,720 --> 00:09:05,050
用一个叉来表示这个样本

245
00:09:05,800 --> 00:09:09,310
x(i)

246
00:09:09,500 --> 00:09:10,970
意思是 在

247
00:09:12,100 --> 00:09:13,510
水平轴上

248
00:09:14,450 --> 00:09:16,210
取值为 x(i)1

249
00:09:17,140 --> 00:09:19,620
在竖直轴上

250
00:09:21,240 --> 00:09:22,290
取值为 x(i)2

251
00:09:22,650 --> 00:09:24,070
这就是我画出的训练样本

252
00:09:25,400 --> 00:09:27,160
尽管我没有将其

253
00:09:27,320 --> 00:09:28,310
真的看做向量

254
00:09:28,570 --> 00:09:29,600
它事实上

255
00:09:29,650 --> 00:09:30,910
就是一个

256
00:09:31,610 --> 00:09:33,520
始于原点

257
00:09:34,560 --> 00:09:36,210
终点位置在这个训练样本点的向量

258
00:09:37,830 --> 00:09:39,460
现在 我们有

259
00:09:39,980 --> 00:09:41,850
一个参数向量

260
00:09:42,080 --> 00:09:43,620
我会将它也

261
00:09:43,800 --> 00:09:45,720
画成向量

262
00:09:46,390 --> 00:09:48,410
我将 θ1 画在这里

263
00:09:49,100 --> 00:09:53,530
将 θ2 画在这里

264
00:09:56,230 --> 00:09:57,050
那么内积

265
00:09:57,290 --> 00:09:58,940
θ 转置乘以 x(i) 将会是什么呢

266
00:09:59,220 --> 00:10:01,240
使用我们之前的方法

267
00:10:01,990 --> 00:10:03,360
我们计算的方式就是

268
00:10:04,310 --> 00:10:06,170
我将训练样本

269
00:10:06,320 --> 00:10:08,710
投影到参数向量 θ

270
00:10:09,830 --> 00:10:10,700
然后我来看一看

271
00:10:10,950 --> 00:10:13,070
这个线段的长度

272
00:10:13,680 --> 00:10:14,660
我将它画成红色

273
00:10:15,090 --> 00:10:16,500
我将它称为

274
00:10:16,670 --> 00:10:19,480
p 上标 (i)

275
00:10:20,330 --> 00:10:21,330
用来表示这是

276
00:10:21,610 --> 00:10:22,920
第 i 个训练样本

277
00:10:24,860 --> 00:10:25,540
在参数向量 θ 上的投影

278
00:10:26,900 --> 00:10:28,140
根据我们之前幻灯片的内容

279
00:10:28,350 --> 00:10:30,790
我们知道的是

280
00:10:30,920 --> 00:10:32,830
θ 转置乘以 x(i)

281
00:10:32,960 --> 00:10:34,210
等于

282
00:10:34,430 --> 00:10:35,350
就等于

283
00:10:36,560 --> 00:10:40,000
p 乘以

284
00:10:40,090 --> 00:10:42,090
向量 θ 的长度 或 范数

285
00:10:43,410 --> 00:10:44,690
这就等于

286
00:10:44,750 --> 00:10:46,660
θ1 乘以 x1

287
00:10:47,920 --> 00:10:50,610
加上 θ2 x2

288
00:10:50,810 --> 00:10:52,360
这两种方式是等价的

289
00:10:52,680 --> 00:10:54,080
都可以用来计算

290
00:10:54,180 --> 00:10:56,160
θ 和 x(i) 之间的内积

291
00:10:57,780 --> 00:10:57,780
好

292
00:10:58,140 --> 00:10:59,040
这告诉了我们什么呢

293
00:10:59,280 --> 00:11:00,770
这里表达的意思是

294
00:11:01,020 --> 00:11:02,890
这个 θ 转置乘以 x(i)

295
00:11:03,130 --> 00:11:05,330
大于等于1 或者小于-1的

296
00:11:06,110 --> 00:11:06,860
约束是可以被

297
00:11:06,970 --> 00:11:07,830
p(i)乘以x大于等于1 

298
00:11:08,610 --> 00:11:12,000
这个约束

299
00:11:12,320 --> 00:11:13,500
所代替的

300
00:11:13,680 --> 00:11:16,280
因为 θ 转置乘以  x(i)

301
00:11:16,400 --> 00:11:19,470
等于 p(i) 乘以 θ 的范数

302
00:11:21,250 --> 00:11:23,080
将其写入我们的优化目标

303
00:11:23,910 --> 00:11:24,870
我们将会得到

304
00:11:25,130 --> 00:11:26,290
没有了约束

305
00:11:27,090 --> 00:11:28,400
θ 转置乘以x(i)

306
00:11:28,620 --> 00:11:30,920
而变成了 p(i) 乘以 θ 的范数

307
00:11:31,970 --> 00:11:32,970
需要提醒一点

308
00:11:33,090 --> 00:11:34,240
我们之前曾讲过

309
00:11:34,460 --> 00:11:36,310
这个优化目标函数可以

310
00:11:36,510 --> 00:11:38,130
被写成二分之一乘以

311
00:11:38,500 --> 00:11:39,910
θ 平方的范数

312
00:11:41,730 --> 00:11:43,490
现在让我们考虑

313
00:11:44,210 --> 00:11:45,550
下面这里的

314
00:11:45,700 --> 00:11:47,100
训练样本

315
00:11:47,450 --> 00:11:49,620
现在 继续使用之前的简化 即

316
00:11:50,180 --> 00:11:51,340
θ0 等于0

317
00:11:52,030 --> 00:11:54,810
我们来看一下支持向量机会选择什么样的决策界

318
00:11:55,860 --> 00:11:57,710
这是一种选择

319
00:11:57,870 --> 00:11:59,190
我们假设支持向量机会

320
00:11:59,340 --> 00:12:01,750
选择这个决策边界

321
00:12:02,690 --> 00:12:05,110
这不是一个非常好的选择 因为它的间距很小

322
00:12:05,530 --> 00:12:08,210
这个决策界离训练样本的距离很近

323
00:12:09,810 --> 00:12:12,360
我们来看一下为什么支持向量机不会选择它

324
00:12:14,130 --> 00:12:15,420
对于这样选择的参数 θ

325
00:12:16,410 --> 00:12:18,280
可以看到

326
00:12:19,030 --> 00:12:21,250
参数向量 θ 事实上

327
00:12:21,760 --> 00:12:23,350
是和决策界是90度正交的

328
00:12:24,060 --> 00:12:25,440
因此这个绿色的决策界

329
00:12:26,250 --> 00:12:27,550
对应着一个参数向量 θ 

330
00:12:27,920 --> 00:12:29,650
指向这个方向

331
00:12:30,730 --> 00:12:32,280
顺便提一句 θ0 等于0

332
00:12:32,510 --> 00:12:34,120
的简化仅仅意味着

333
00:12:34,300 --> 00:12:35,410
决策界必须

334
00:12:35,910 --> 00:12:37,960
通过原点 (0,0)

335
00:12:38,330 --> 00:12:40,350
现在让我们看一下

336
00:12:40,690 --> 00:12:41,780
这对于优化目标函数

337
00:12:41,840 --> 00:12:43,590
意味着什么

338
00:12:45,260 --> 00:12:46,420
比如这个样本

339
00:12:47,460 --> 00:12:48,560
我们假设它是我的第一个样本

340
00:12:50,480 --> 00:12:50,650
x(1)

341
00:12:51,690 --> 00:12:52,630
如果我考察这个样本

342
00:12:53,320 --> 00:12:54,870
到参数 θ 的投影

343
00:12:56,180 --> 00:12:56,520
这就是投影

344
00:12:57,660 --> 00:12:59,230
这个短的红线段

345
00:13:00,450 --> 00:13:01,720
就等于p(1)

346
00:13:02,380 --> 00:13:04,650
它非常短 对么

347
00:13:05,860 --> 00:13:08,590
类似地 这个样本

348
00:13:09,610 --> 00:13:10,710
如果它恰好是

349
00:13:11,170 --> 00:13:12,620
x(2) 是我的第二个训练样本

350
00:13:13,880 --> 00:13:16,620
则它到 θ 的投影在这里

351
00:13:18,080 --> 00:13:18,170
是因为你犯罪了 因为你做了错事

352
00:13:18,440 --> 00:13:20,460
我将它画成粉色

353
00:13:21,600 --> 00:13:23,690
这个短的粉色线段

354
00:13:24,000 --> 00:13:25,820
它是 p(2)

355
00:13:26,070 --> 00:13:27,370
第二个样本到

356
00:13:27,770 --> 00:13:28,870
我的参数向量 θ

357
00:13:30,100 --> 00:13:32,650
的投影

358
00:13:33,870 --> 00:13:34,250
因此

359
00:13:35,270 --> 00:13:35,270
这个投影非常短

360
00:13:36,850 --> 00:13:38,420
p(2) 事实上是一个负值

361
00:13:38,560 --> 00:13:42,490
p(2) 是在相反的方向

362
00:13:43,710 --> 00:13:45,250
这个向量

363
00:13:45,560 --> 00:13:47,130
和参数向量 θ 的夹角

364
00:13:47,270 --> 00:13:48,980
大于90度 p(2) 的值小于0

365
00:13:50,280 --> 00:13:51,580
我们会发现

366
00:13:51,850 --> 00:13:54,880
这些 p(i)

367
00:13:55,200 --> 00:13:57,230
将会是非常小的数

368
00:13:58,210 --> 00:13:59,080
因此当我们考察

369
00:13:59,110 --> 00:14:01,650
优化目标函数的时候 对于正样本而言

370
00:14:02,490 --> 00:14:04,860
我们需要 p(i) 乘以

371
00:14:05,220 --> 00:14:07,590
θ 的范数大于等于1

372
00:14:08,670 --> 00:14:10,640
但是如果 p(i) 在这里

373
00:14:10,860 --> 00:14:12,140
如果 p(1) 在这里

374
00:14:12,770 --> 00:14:14,160
非常小 那就意味着

375
00:14:14,410 --> 00:14:15,580
我们需要 θ 的范数

376
00:14:15,650 --> 00:14:18,420
非常大 对么

377
00:14:19,830 --> 00:14:20,840
因为如果 p(1) 很小

378
00:14:21,790 --> 00:14:23,110
而我们希望 p(1)

379
00:14:23,410 --> 00:14:24,600
乘以 θ

380
00:14:24,920 --> 00:14:25,890
大于等于1

381
00:14:26,400 --> 00:14:27,300
令其实现的

382
00:14:27,510 --> 00:14:28,440
唯一的办法就是

383
00:14:28,650 --> 00:14:29,750
这两个数较大

384
00:14:30,020 --> 00:14:31,120
如果 p(1) 小

385
00:14:31,240 --> 00:14:32,980
我们就希望 θ 的范数大

386
00:14:34,150 --> 00:14:36,450
类似地

387
00:14:36,650 --> 00:14:38,560
对于负样本而言 我们需要 p(2)

388
00:14:39,750 --> 00:14:41,070
乘以

389
00:14:41,350 --> 00:14:44,990
θ 的范数

390
00:14:45,160 --> 00:14:46,910
小于等于-1

391
00:14:47,760 --> 00:14:48,540
我们已经在这个样本中

392
00:14:48,710 --> 00:14:50,200
看到 p(2)

393
00:14:50,260 --> 00:14:51,520
会是一个非常小的数

394
00:14:52,040 --> 00:14:53,290
因此唯一的办法

395
00:14:53,420 --> 00:14:54,490
就是

396
00:14:54,530 --> 00:14:56,730
θ 的范数变大

397
00:14:57,010 --> 00:14:59,630
但是我们

398
00:14:59,790 --> 00:15:00,900
的目标函数是

399
00:15:01,290 --> 00:15:02,400
希望

400
00:15:02,540 --> 00:15:03,840
找到一个参数 θ

401
00:15:04,170 --> 00:15:05,320
它的范数

402
00:15:05,550 --> 00:15:07,100
是小的

403
00:15:07,830 --> 00:15:09,040
因此 这看起来

404
00:15:09,330 --> 00:15:10,070
不像是一个好的

405
00:15:10,610 --> 00:15:14,160
参数向量 θ 的选择

406
00:15:14,450 --> 00:15:15,510
相反的 来看一个不同的决策边界

407
00:15:17,040 --> 00:15:19,500
比如说 支持向量机选择了

408
00:15:20,510 --> 00:15:21,280
这个决策界

409
00:15:22,870 --> 00:15:23,980
现在状况会有很大不同

410
00:15:24,420 --> 00:15:25,890
如果这是决策界

411
00:15:26,190 --> 00:15:27,380
这就是

412
00:15:27,450 --> 00:15:28,770
相对应的参数 θ 的方向

413
00:15:29,210 --> 00:15:30,920
因此 在这个

414
00:15:31,000 --> 00:15:32,110
决策界之下

415
00:15:32,300 --> 00:15:33,560
垂直线是决策界

416
00:15:34,470 --> 00:15:35,960
使用线性代数的知识

417
00:15:36,190 --> 00:15:37,880
可以说明

418
00:15:38,070 --> 00:15:39,140
这个绿色的决策界

419
00:15:39,460 --> 00:15:41,190
有一个垂直于它的

420
00:15:41,390 --> 00:15:42,620
向量 θ

421
00:15:43,610 --> 00:15:44,470
现在如果你考察

422
00:15:44,560 --> 00:15:45,570
你的数据在横轴 x

423
00:15:45,710 --> 00:15:47,540
上的投影

424
00:15:48,800 --> 00:15:50,010
比如 这个我之前提到的样本

425
00:15:50,010 --> 00:15:52,620
我的样本 x(1)

426
00:15:52,890 --> 00:15:54,600
当我将它投影到横轴x上

427
00:15:55,410 --> 00:15:59,110
或说投影到θ上 就会得到这样的p(1)

428
00:16:00,650 --> 00:16:02,410
它的长度是 p(1)

429
00:16:03,750 --> 00:16:05,820
另一个样本

430
00:16:06,260 --> 00:16:08,620
那个样本是x(2)

431
00:16:08,840 --> 00:16:11,300
我做同样的投影

432
00:16:11,410 --> 00:16:12,580
我会发现

433
00:16:12,780 --> 00:16:14,680
这是 p(2) 的长度

434
00:16:15,610 --> 00:16:17,880
它是负值

435
00:16:18,830 --> 00:16:19,940
你会注意到

436
00:16:20,480 --> 00:16:22,490
现在 p(1) 和 p(2)

437
00:16:23,810 --> 00:16:24,740
这些投影长度

438
00:16:24,780 --> 00:16:26,800
是长多了

439
00:16:27,440 --> 00:16:28,460
如果我们仍然要满足这些约束

440
00:16:28,890 --> 00:16:30,700
p(1) 乘以 θ 的范数

441
00:16:30,800 --> 00:16:33,040
是比1大的

442
00:16:33,230 --> 00:16:35,670
则因为 p(1) 变大了

443
00:16:36,580 --> 00:16:39,110
θ 的范数就可以变小了

444
00:16:41,960 --> 00:16:43,090
因此这意味着

445
00:16:43,210 --> 00:16:44,320
通过选择

446
00:16:44,730 --> 00:16:45,760
右边的决策界

447
00:16:46,010 --> 00:16:47,610
而不是左边的那个

448
00:16:47,850 --> 00:16:49,000
支持向量机可以

449
00:16:49,080 --> 00:16:50,560
使参数 θ 的范数

450
00:16:50,840 --> 00:16:52,420
变小很多 因此如果我们想

451
00:16:52,550 --> 00:16:54,080
令 θ 的范数变小

452
00:16:54,260 --> 00:16:55,140
从而令 θ 范数的平方

453
00:16:55,590 --> 00:16:57,080
变小 就能让

454
00:16:57,210 --> 00:16:58,130
支持向量机

455
00:16:58,710 --> 00:17:00,920
选择右边的决策界

456
00:17:02,800 --> 00:17:04,260
这就是

457
00:17:05,580 --> 00:17:07,160
支持向量机如何能

458
00:17:07,500 --> 00:17:09,550
有效地产生大间距分类的原因

459
00:17:10,700 --> 00:17:11,620
看这条绿线

460
00:17:11,820 --> 00:17:13,250
这个绿色的决策界

461
00:17:13,490 --> 00:17:14,990
我们希望

462
00:17:15,070 --> 00:17:16,250
正样本和负样本投影到

463
00:17:17,190 --> 00:17:18,780
θ 的值大

464
00:17:19,200 --> 00:17:20,360
要做到这一点

465
00:17:20,710 --> 00:17:23,490
的唯一方式就是选择这条绿线做决策界

466
00:17:24,950 --> 00:17:27,710
这是大间距决策界

467
00:17:27,880 --> 00:17:31,460
来区分开

468
00:17:33,970 --> 00:17:37,240
正样本和负样本

469
00:17:38,020 --> 00:17:40,740
这个间距的值

470
00:17:41,080 --> 00:17:42,050
这个间距的值

471
00:17:43,040 --> 00:17:44,900
就是p(1) p(2) p(3)

472
00:17:45,060 --> 00:17:47,730
等等的值

473
00:17:47,890 --> 00:17:48,970
通过让间距变大

474
00:17:49,480 --> 00:17:51,270
通过这些p(1) p(2) p(3) 等等

475
00:17:51,470 --> 00:17:53,650
的值 支持向量机

476
00:17:53,830 --> 00:17:55,520
最终可以找到

477
00:17:55,670 --> 00:17:56,860
一个较小的 θ 范数

478
00:17:56,960 --> 00:17:59,450
这正是支持向量机中最小化目标函数的目的

479
00:18:00,250 --> 00:18:01,290
以上就是为什么

480
00:18:01,960 --> 00:18:03,300
支持向量机最终会找到

481
00:18:03,790 --> 00:18:05,510
大间距分类器的原因

482
00:18:05,640 --> 00:18:07,570
因为它试图极大化这些

483
00:18:07,720 --> 00:18:08,910
p(i) 的范数 它们是

484
00:18:09,060 --> 00:18:10,450
训练样本到决策边界的距离

485
00:18:14,360 --> 00:18:16,450
最后一点 我们的推导

486
00:18:17,200 --> 00:18:18,590
自始至终使用了这个简化假设

487
00:18:18,750 --> 00:18:21,150
就是参数 θ0 等于0

488
00:18:21,860 --> 00:18:23,440
就像我之前提到的

489
00:18:23,560 --> 00:18:25,380
这个的作用是

490
00:18:25,540 --> 00:18:26,560
θ0 等于 0

491
00:18:26,830 --> 00:18:28,280
的意思是

492
00:18:28,460 --> 00:18:29,770
我们让决策界

493
00:18:30,200 --> 00:18:31,510
通过原点

494
00:18:31,750 --> 00:18:33,640
让决策界通过原点

495
00:18:33,800 --> 00:18:35,510
就像这样

496
00:18:35,710 --> 00:18:37,980
如果你令

497
00:18:38,080 --> 00:18:39,540
θ0 不是0的话

498
00:18:39,870 --> 00:18:41,190
含义就是你希望

499
00:18:41,380 --> 00:18:43,120
决策界不通过原点

500
00:18:43,390 --> 00:18:45,730
比如这样

501
00:18:46,380 --> 00:18:47,940
我将不会做全部的推导

502
00:18:48,010 --> 00:18:49,540
实际上

503
00:18:49,650 --> 00:18:50,600
支持向量机产生大间距分类器的结论

504
00:18:51,060 --> 00:18:52,720
会被证明同样成立

505
00:18:52,780 --> 00:18:54,240
证明方式是非常类似的

506
00:18:54,390 --> 00:18:56,100
是我们刚刚做的

507
00:18:56,850 --> 00:18:57,830
证明的推广

508
00:18:58,030 --> 00:18:59,400
之前视频中说过

509
00:18:59,870 --> 00:19:01,540
即便 θ0

510
00:19:01,840 --> 00:19:03,690
不等于0

511
00:19:03,960 --> 00:19:06,940
支持向量机要做的事情都是优化这个目标函数

512
00:19:08,200 --> 00:19:09,620
对应着

513
00:19:09,720 --> 00:19:11,570
C值非常大的情况

514
00:19:14,010 --> 00:19:15,110
但是可以说明的是

515
00:19:15,290 --> 00:19:16,510
即便 θ0 不等于 0

516
00:19:16,810 --> 00:19:18,420
支持向量机

517
00:19:18,620 --> 00:19:19,750
仍然会

518
00:19:20,100 --> 00:19:21,360
找到

519
00:19:21,640 --> 00:19:22,650
正样本和负样本之间的

520
00:19:23,040 --> 00:19:24,060
大间距分隔

521
00:19:24,630 --> 00:19:28,200
总之

522
00:19:28,420 --> 00:19:31,060
我们解释了为什么支持向量机是一个大间距分类器

523
00:19:32,920 --> 00:19:34,020
在下一节我们

524
00:19:34,190 --> 00:19:35,080
将开始讨论

525
00:19:35,400 --> 00:19:36,480
如何利用支持向量机的原理

526
00:19:36,710 --> 00:19:37,980
应用它们

527
00:19:38,190 --> 00:19:39,200
建立一个复杂的

528
00:19:39,900 --> 00:19:41,370
非线性分类器 【教育无边界字幕组】翻译: shamolvzhou 校对/审核: 所罗门捷列夫