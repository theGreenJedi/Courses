कभी कभी लोग बात करते हैं सपोर्ट वेक्टर मशीञ्ज के बारे में, लार्ज मार्जिन क्लासिफाईर्स के तौर पर, इस विडियो में मैं आप को बताना चाहूँगा कि उसका क्या मतलब है, और यह भी देगा हमें एक उपयोगी पिक्चर उसकी कि कैसे एक एसवींएम हाईपोथीसिस दिख सकता है॰ यह है मेरा कोस्ट फंक्शन सपोर्ट वेक्टर मशीन के लिए जहां यहाँ बाए मैंने प्लॉट की है अपनी कोस्ट 1 ऑफ ज़ी फंक्शन जिसे मैंने इस्तेमाल किया पॉज़िटिव उदाहरण के लिए और दायीं तरफ मैंने प्लॉट किया है मेरा ज़ीरो ऑफ ज़ी फंक्शन, जहां मेरे पास है ज़ी यहाँ हॉरिजॉन्टल एक्सिस पर॰ अब, चलिए सोचते हैं कि कैसे इन कॉस्ट फंक्शन्स को कम किया जा सकता है. यदि आपके पास एक पॉजिटिव एग्जामपल है, तो यदि वाई बराबर है 1 के, तो कॉस्ट 1 ऑफ ज़ी है जीरो केवल तब जब ज़ी बड़ा है या बराबर है 1 के. अत: दूसरे शब्दों में, अगर आपके पास है एक पॉजिटिव एक्ज़ांम्पल, हम वास्तव में चाहते हैं कि थीटा ट्रांसपोज़ एक्स बड़ा हो या बराबर हो 1 के और इसके विपरीत अगर वाई है बराबर जीरो के, देखो यह कॉस्ट जीरो ऑफ ज़ी फंक्शन, तब यह केवल है इस क्षेत्र में जहाँ ज़ी है छोटा या बराबर 1 के हमारे पास कॉस्ट जीरो है क्योँकि ज़ी बराबर होता है जीरो के, और यह एक दिलचस्प प्रॉपर्टी / गुण है सप्पोर्ट वेक्टर मशीन का, जो है कि यदि आपके पास है एक पॉजिटिव एक्ज़ांम्पल ऐसे कि यदि वाई बराबर है एक के, तब वास्तव में हमें सिर्फ़ चाहिए कि थीटा ट्रांसपोज़ एक्स बड़ा हो या बराबर ज़ीरो के. और उसका मतलब होगा कि हमने सही क्लैसिफ़ाई किया है क्योंकि यदि थीटा ट्रांसपोज़ एक्स बड़ा होगा ज़ीरो से हमारी हायपॉथिसस प्रिडिक्ट करेगी ज़ीरो. और इसी प्रकार, अगर आप के पास है एक नेगेटिव इग्ज़ैम्पल, तब वास्तव में आप सिर्फ़ चाहते हैं कि थीटा ट्रान्स्पोज़ एक्स है कम ज़ीरो से और उससे सुनिश्चित होगा कि हमें इग्ज़ैम्पल सही मिला है. लेकिन सप्पोर्ट वेक्टर मशीन चाहती है उससे कुछ ज़्यादा. यह कहती है, आप जानते है, केवल सिर्फ़ इग्ज़ैम्पल्ज़ सही मत लीजिये / देखिए. इसलिए तब केवल नहीं लो इसे सिर्फ़ थोड़ा बड़ा ज़ीरो से. क्या मैं वास्तव में चाहता हूँ इसके लिए होना काफ़ी बड़ा ज़ीरो से कह लीजिए कुछ बड़ा या बराबर एक के और मैं इसे काफ़ी कम चाहता हूँ ज़ीरो से. शायद मैं चाहता हूँ इसे कम या बराबर -1 के. और इसलिए यह बनाता है भीतर एक अतिरिक्त सेफ़्टी फ़ैक्टर या सेफ़्टी मार्जिन फ़ैक्टर सपोर्ट वेक्टर मशीन में. लॉजिस्टिक रिग्रेशन भी करता है कुछ ऐसा ही निस्संदेह, लेकिन चलो देखते हैं क्या होता है या देखते हैं क्या परिणाम होते हैं इसके, सप्पोर्ट वेक्टर मशीन के संदर्भ में. वास्तव में, मैं क्या करना चाहता हूँ आगे कि लेना चाहता हूँ  एक केस जहाँ हम सेट करते है यह कॉन्स्टंट सी को एक बहुत बड़ी वैल्यू, तो चलिए कल्पना कीजिए हम सी को सेट करते हैं एक बहुत बड़ी वैल्यू पर, शायद एक सौ हज़ार / एक लाख, कोई बड़ा नम्बर. देखते हैं सप्पोर्ट वेक्टर मशीन क्या करेगी. अगर सी है बहुत, बहुत बड़ा, तब मिनमायज़ / न्यूनतम करते समय यह ऑप्टिमायज़ेशन ओबजेक्टिव, हम बहुत प्रेरित होने वाले है चयन करने के लिए एक वैल्यू, ताकि यह पहली टर्म बराबर हो ज़ीरो के. तो चलिए कोशिश करते हैं समझने की ऑप्टिमायज़ेशन प्रॉब्लम को संदर्भ में, कि क्या करना होगा बनाने में इस पहली टर्म ओबजेक्टिव में बराबर ज़ीरो के, क्योंकि आप जानते हैं, शायद हम सेट करेंगे सी को कोई बड़ा कांस्टेंट, और इसे शायद आशा है, देना चाहिए हमें अतिरिक्त इंट्यूशन / अनुभव कि किस प्रकार की हाइपोथिसिस एक सप्पोर्ट वैक्टर मशीन लर्न करती  है. तो हमने पहले देखा कि जब भी आपके पास होता है एक ट्रेनिंग एक्ज़ांम्पल लेबल के साथ वाई = 1 अगर आप बनाना चाहते हैं उस पहली टर्म को जीरो, क्या चाहिए आपको कि ढूंढे एक वैल्यू थीटा की ताकि थीटा ट्रांसपोस एक्स। बड़ा हो या बराबर हो 1 के. और इसी प्रकार, जब भी हमारे पास होता है एक एक्ज़ांम्पल, लेबल जीरो के साथ, यह सुनिश्चित करने के लिए कि कॉस्ट, कॉस्ट जीरो ज़ी की, यह सुनिश्चित करने के लिए कि कॉस्ट जीरो है हमें चाहिए वह थीटा ट्रांसपोस एक्स । छोटा है या बराबर -1 के. अत:, यदि हम सोचें हमारी ऑप्टिमाइजेशन प्रॉब्लम को जैसे अब, वास्तव में पैरामीटर्स का चुनाव और दिखाना कि यह पहली टर्म बराबर है जीरो के, क्या रह जाता है हमारे पास वह है निम्नलिखित ऑप्टिमाइजेशन प्रॉब्लम. हम करेंगे न्यूनतम वह पहली टर्म जीरो, अत: सी गुणा जीरो, क्योँकि हम करेंगे पैरामीटर्स का चुनाव ताकि वह बराबर हो जीरो, प्लस एक हाफ और तब आप जानते है कि दूसरी टर्म और यह पहली टर्म है सी गुणा जीरो, तो चलिए उसे काट देते हैं क्योंकि मैं जानता हूँ कि वह जीरो होगा. और यह होगा उस दशा में कि कॉन्सट्रेंट थीटा ट्रांसपोज़ एक्स (आई) हो बड़ा या बराबर एक के, यदि वाई (आई) बराबर है एक के और थीटा ट्रांसपोस एक्स (आई) छोटा हो या बराबर माइनस एक के जब भी आपके पास है एक नेगेटिव एग्जामपल और यह निष्कर्ष निकलता है कि जब आप हल करते हैं यह ऑप्टिमाइजेशन प्रॉब्लम, जब आप मिनीमाइज करते हैं इसे एक फंक्शन पैरामीटर्स थीटा का आपको मिलती है एक बहुत दिलचस्प डिसिशन बाउंड्री. वास्तव में अगर आप देखें एक डेटा सेट इस प्रकार का पॉजिटिव और नेगेटिव एग्जामपल्स के साथ, यह डेटा लीनियरली सेपेरेबल है और उससे, मेरा मतलब है कि वहाँ है, आप जानते हैं, एक स्ट्रैट लाइन, हालाँकि ऐसी विभिन्न स्ट्रैट लाइन्स हैं, वे अलग कर सकतीं हैं पॉजिटिव और नेगेटिव एग्जामपल्स को परफेक्टली / पूर्ण रूप से. उदाहरण के लिए, यहाँ एक  डिसिशन बाउंड्री है जो अलग करतीं है पॉजिटिव और नेगेटिव एग्जामपल्स, लेकिन किसी कारण से वह नहीं दिखता एक बहुत नेचुरल हल, सही है? या बनाते हुए एक इस से भी बुरी डिसिशन बाउंड्री, आप जानते हैं यहाँ एक और डिसिशन बाउंड्री है जो अलग करतीं है पॉजिटिव और नेगेटिव एग्जामपल्स लेकिन कुछ ही. लेकिन उन दोनो में से कोई भी ख़ास अच्छा विकल्प नहीं लगता. सप्पोर्ट वेक्टर मशीन इसके बजाय चुनेगी यह डिसिज़न बाउंड्री, जो मैं बना रहा हूँ काले रंग में. और वह लग रही एक काफ़ी बेहतर डिसिशन बाउंड्री है तुलना में उनके जो मैंने मजेंटा या हरे रंग में बनाई हैं. काली लाइन लगती है एक ज़्यादा सुदृढ़ सेपेरेटर, यह करता है एक बेहतर कार्य अलग करने का पॉजिटिव और नेगेटिव एग्जामपल्स. और गणितीय रूप में, वह क्या करता है कि, यह काली डिसिज़न बाउंड्री की बड़ी डिस्टेन्स / दूरी है. वह दूरी को कहते हैं मार्जिन, जब मैं बनाता हूँ यह दो अतिरिक्त नीली लाइन्स, हम देखते है कि काली डिसिज़न बाउंड्री है कुछ बड़ी न्यूनतम दूरी किसी भी मेरे ट्रेनिंग इग्ज़ैम्पल्ज़ से, जबकि मजेंटा और हरी लाइंज़ वे आ जाती है बहुत नज़दीक ट्रेनिंग इग्ज़ैम्पल्ज़ के, और तब वह लगता है एक कम अच्छा काम अलग करने का पॉजिटिव और नेगेटिव एग्जामपल्स को मेरी काली लाइन की तुलना में. और इसलिए इस दूरी को कहते हैं मार्जिन सप्पोर्ट वेक्टर मशीन का और यह देता है एसवीएम को एक पक्की सुदृढ़ता, क्योंकि यह कोशिश करता है अलग करने की डेटा को बड़े से बड़े मार्जिन के साथ जितना सम्भव है. अत: सप्पोर्ट वेक्टर मशीन को कभी कभी लार्ज मार्जिन क्लैसिफ़ायअर भी कहते हैं और यह वास्तव में परिणाम है ऑप्टिमायज़ेशन प्रॉब्लम का जो हमने पिछली स्लाइड में लिखी थी. मैं जानता हूँ आप शायद आश्चर्य कर रहे होंगे कि कैसे वह ऑप्टिमाइजेशन प्रॉब्लम जो मैंने लिखी पिछली स्लाइड में, कैसे वह लीड करती है / बन जाती है यह लार्ज मार्जिन क्लैसिफ़ायअर. मैं जानता हूँ मैंने वह नहीं समझाया है अब तक. और अगले विडीओ में मैं नक़्शा बनाऊँगा एक थोड़े से इंट्यूशन / अनुभव के लिए कि क्यों वह ऑप्टिमाइजेशन प्रॉब्लम देती है हमें यह लार्ज मार्जिन क्लैसिफ़ायअर. लेकिन यह एक लाभदायक फ़ीचर है मस्तिष्क में रखने के लिए अगर आप कोशिश कर रहे हैं समझने की कि किस प्रकार की हायपॉथिसस चुनेगी एक एसवीएम. अर्थात्, कोशिश अलग करने की पॉजिटिव और नेगेटिव एग्जामपल्स को बड़े से बड़े मार्जिन के साथ जितना सम्भव है. मैं कहना चाहता हूँ एक आख़िरी बात लार्ज मार्जिन क्लैसिफ़ायअर्स के बारे में इस अनुभव में, इसलिए हमने लिखी यह लार्ज मार्जिन क्लैसिफ़िकेशन सेट्टिंग उस केस में जब सी, वह रेग्युलराईज़ेशन सिद्धांत, बहुत बड़ा था, मैं सोचता हूँ मैंने उसे सेट किया था एक सौ हज़ार / एक लाख या ऐसे कुछ पर. तो एक डेटासेट दिया होने पर इस प्रकार का, शायद हम चुनेंगे वह डिसिशन बाउंड्री है जो जो अलग करतीं है पॉजिटिव और नेगेटिव एग्जामपल्स को एक बड़े मार्जिन के साथ. अब, एसवीएम वास्तव में थोड़ी ज़्यादा सफ़िस्टिकेटेड / प्रगतिशील है बजाय उसके जो यह लार्ज मार्जिन व्यू  सजेस्ट कर रहा हो. और ख़ासकर, अगर आप सिर्फ़ प्रयोग कर रहे हैं एक लार्ज मार्जिन क्लैसिफ़ायअर तब आपका लर्निंग एल्गोरिथ्म सेन्सिटिव होगा आउटलाएरस को, तो चलिए सिर्फ़ लेते हैं एक अतिरिक्त पॉज़िटिव इग्ज़ैम्पल जो स्क्रीन पर दिखाया है. अगर हमारे पास एक इग्ज़ैम्पल होता तब ऐसा लगता है कि अलग करने के लिए डेटा को एक लार्ज मार्जिन के साथ, शायद मैं अन्तत: पहुँचूँगा लर्न करते हुए एक डिसिज़न बाउंड्री उस तरह की, सही है? जो कि मजेंटा लाइन है और यह स्पष्ट नहीं है कि आधारित एक अकेले आउटलाएर पर, आधारित एक अकेले एग्जामपल पर और यह वास्तव में स्पष्ट नहीं है कि यह वास्तब में एक अच्छा विचार है बदलना मेरी डिसिज़न बाउंड्री को काले से मजेंटा वाली में. तो, यदि सी, यदि रेग्युलरेज़ेशन पेरामीटर सी होता बहुत बड़ा, तब यह ही वास्तव में एसवीएम करेगा, यह बदल देगा डिसिशन बाउंड्री काली से मजेंटा मैं लेकिन यदि सी होता उचित रूप से छोटा यदि आप प्रयोग करते सी को, न ज़्यादा बड़ा तब भी आप अन्तत: पहुँचते इस काली डिसिज़न बाउंड्री पर. और निस्संदेह अगर डाटा लिनीअरली सेपेरेबल नहीं होता अतः आपके पास कुछ पॉज़िटिव इग्ज़ैम्पल्ज़ होती यहाँ पर, या अगर आपके पास होते कुछ नेगेटिव एग्जामपल्स यहाँ पर तब एसवीएम भी करेगी सही काम ही. और इसलिए यह चित्र एक लार्ज मार्जिन क्लैसिफ़ायअर का जो वास्तव में, जो वास्तव में है चित्र जो देता है बेहतर अनुभव केवल उस केस में जब रेग्युलरेज़ेशन पेरामीटर सी होता है बहुत बड़ा, और सिर्फ़ आपको याद कराने के लिए कि यह बताता है कि सी अदा करता है रोल वैसे ही जैसे वन ओवर लैम्डा, जहाँ लैम्डा है रेग्युलरेज़ेशन पेरामीटर जो हमारे पास पहले था. और इसलिए यह है केवल यदि वन ओवर लैम्डा बहुत बड़ा है या इसी के अनुरूप यदि लैम्डा बहुत छोटा है तो आप पहुँचते इस प्रकार इस मजेंटा डिसिज़न बाउंड्री पर, लेकिन व्यावहारिक रूप में अब अप्लाई करते हैं सप्पोर्ट वेक्टर मशींज़ को, जब सी बहुत बड़ा नहीं होता उस प्रकार, यह कर सकता है एक बेहतर कार्य अनदेखा करते हुए कुछ आउटलायर्स को जैसे यहाँ. और करेगा भी सही और करेगा उचित कार्य तब भी जब आपका डेटा लिनीअरली सेपेरेबल न हो. पर जब हम बात करते हैं बायस और वेरीयंस की सप्पोर्ट वेक्टर मशीन्स के संदर्भ में जो हम करेंगे कुछ देर में, आशा है ये सब ट्रेड-ऑफ़ जो सम्बंधित है रेग्यूलराईज़ेशन पेरामिटर से अधिक स्पष्ट हो जाएगा उस समय. तो मैं उम्मीद करता हूँ वह देता है कुछ अनुभव कि कैसे यह सपोर्ट वेक्टर मशीन फ़ंक्शन करती है एक लार्ज मार्जिन क्लैसिफ़ायअर की तरह जो कोशिश करता है अलग करने की डेटा को एक लार्ज मार्जिन से, तकनीकी तौर पर यह चित्र इस व्यू का सत्य / ट्रु है केवल तब जब पेरामिटर सी काफ़ी बड़ा है, जो एक लाभप्रद तरीक़ा है सोचने का सप्पोर्ट वेक्टर मशीन के बारे में. एक स्टेप मिसिंग / ग़ायब था इस विडीओ में जो है, कि क्यों वह ऑप्टिमाइजेशन प्रॉब्लम जो हमने लिखी उन स्लाइड्ज़ पर, कैसे वह वास्तव में वह बन जाती है लार्ज मार्जिन क्लैसिफ़ायअर, मैंने वह नहीं किया इस विडीओ में. अगले वीडियो में, मैं ढाँचा बनाऊँगा केवल थोड़ा सा ज़्यादा गणित का उसके पीछे समझाने के लिए वे अलग रीजनिंग / विचार कि कैसे ऑप्टिमाइजेशन प्रॉब्लम जो हमने लिखी बदलती है एक लार्ज मार्जिन क्लैसिफ़ायअर में.