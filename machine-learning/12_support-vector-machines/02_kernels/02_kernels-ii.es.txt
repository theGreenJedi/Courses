En el video anterior hablamos de los kernels y de cómo los podemos utilizar para definir nuevas variables para la máquina de soporte vectorial. En este video me gustaría explicar algunos detalles faltantes y decir unas palabras acerca de cómo utilizar estas ideas en la práctica, tales como lo concerniente a la compensación del oscilación y la varianza en la máquina de soporte vectorial. En el video anterior también hablé acerca el proceso de elegir puntos de referencia como “L1”, “L2” y “L3” y de cómo esto nos ayudarían a definir la variable de similaridad también llamada kernel. En este ejemplo en particular, esta variable de similaridad es un kernel Gaussiano Lo anterior nos ayudó a construir esta formulación de una variable de hipótesis. Pero, ¿de dónde sacamos estos puntos de referencia? ¿De dónde sacamos “L1”, “L2” y “L3”? Parece que para los problemas de aprendizaje complejos necesitaremos más puntos de referencia que estos tres que consideramos por elección manual. En la práctica los puntos de referencia se eligen de la siguiente manera: En un problema de aprendizaje automático dado, tenemos un conjunto de datos con ejemplos positivos y negativos. Cuando tomo estos ejemplos, por cada ejemplo de entrenamiento que tenga, pondré un punto de referencia en la misma posición o la misma ubicación que los ejemplos de entrenamiento. Si tengo un ejemplo de entrenamiento “x1”, entonces elegiré mi primer punto de referencia en la misma ubicación que mi primer ejemplo de entrenamiento. Y si tengo otro ejemplo de entrenamiento “x2”, pondré el segundo punto de referencia en la ubicación de mi segundo ejemplo de entrenamiento. En la figura de la derecha utilicé puntos rojos y azules como representación. El color de los puntos en la figura de la derecha no es importante. Entonces, utilizando este método terminaré con un número “m” de puntos de referencia “L1”, “L2”, etc., hasta “L(m)”, si tengo “m” ejemplos de entrenamiento con un punto de referencia por ubicación de cada uno de mis ejemplos de entrenamiento. Esto es bueno porque indica que mis variables medirán qué tan cerca está un ejemplo de uno de los puntos que dibujé en mi conjunto de entrenamiento. Ahora, escribiré este esbozo un poco mejor tomando mis ejemplos de entrenamiento como referencia y eligiendo la ubicación de mis puntos de referencia para que sea exactamente cercana a mis “m” ejemplos de entrenamiento. Cuando tienes un ejemplo “x”, (que en este caso puede ser algo del conjunto de entrenamiento, en el conjunto de validación cruzada o en el de prueba) con este ejemplo “x” calcularemos las variables “f1”, “f2”, etc., donde “L1” es igual a “x1”, etc., y estas me darán un vector de variables que denotaré con una “f”. Tomaré estas “f1”, “f2”, etc., y las agruparé en un vector de variables que incluya todas estas, hasta “fm”. Sólo por costumbre, si queremos podemos añadir una variables adicional “f0” que siempre es igual a 1. Esta juega un rol muy similar al que teníamos anteriormente para “x0”, que era nuestro interceptor. Entonces, por ejemplo, si tenemos un ejemplo de entrenamiento “x(i), y(i)”, la variable que calcularíamos para este ejemplo de entrenamiento serán las que siguen: mapearemos “x(i)” a “f1(i)”, que es la similaridad y la abreviaré SIM en vez de escribir toda la palabra similaridad, ¿sí? Y,“f2(i)” es igual a la similaridad entre “x(i)” y “L2”, etc. hasta “fm(i)” igual a la similaridad de “x(i)” y “L(m)”. En algún lugar a lo largo de esta lista; es decir, en el componente i, tendré un componente característico “f” subíndice “i(i)” que será la similaridad entre “x” y “L(i)” en la que “L(i)” es igual a “x(i)” . “fi(i)” será la similaridad entre x y “fi(i)” misma. Si estás utilizando un kernel Gaussiano, esto es “e” a la menos 0 sobre 2 «sigma» cuadrada, por lo que será igual a 1, y es correcto. Una de mis variables para este ejemplo de entrenamiento será igual a 1. De manera similar a lo que tenemos arriba, puedo tomar todas estas variables “m” y agruparlas en un vector de variables. En vez de representar mi ejemplo utilizando “x(i)”, que es este vector R(n) más R(n)1 vector dimensional. Dependiendo de cómo hayas llamado tu interceptor, será R(n) o R(n) más 1. Ahora, podemos representar el conjunto de entrenamiento utilizando, en cambio, el vector de variables “f”. Escribiré “f” superíndice “i”  que tomará todas estas cosas y las agrupará en un vector. “f1(i)” hasta ·fm(i)” y si quieres añadir este “f0(i)” donde “f0(i)” es igual a 1. Este vector de aquí me dará mi nuevo vector de variables con el que representaré mi ejemplo de entrenamiento. A continuación explicaré cómo utilizar una máquina de soporte vectorial con estos kernels y variables de similaridad. Si ya tienes un conjunto de parámetros teta aprendidos o si ya le has dado un valor a “x” y quieres hacer una predicción, lo que harás es calcular las variables “f”, que son ahora un vector “R(m)” más 1 vector dimensional. Tenemos “m” aquí porque tenemos “m” ejemplos de entrenamiento y, por lo tanto “m” puntos de referencia. Lo que haremos será predecir 1 si teta transpuesta de “f” es mayor que o igual a 0. ¿Correcto? Entonces teta traspuesta de “f” es igual a teta 0, “f0” más teta 1, “f1” más todo esto más teta “m”, “f(m)”. Ahora, mi parámetro vector teta también será un vector “m” más 1 vector dimensional. Tenemos “m” aquí porque el número de puntos de referencia es igual al tamaño del conjunto de entrenamiento. De manera que “m” es el tamaño del conjunto de entrenamiento y ahora, el parámetro vectorial teta será “m” más 1 dimensional. Así es como se hace una predicción si ya tienes un valor fijo para el parámetro teta. ¿Cómo obtienes el parámetro teta? Lo puedes hacer utilizando el algoritmo de aprendizaje de las SVM. Específicamente, lo que puedes hacer es resolver este problema de minimización minimizando el parámetro teta de C por esta función de costo que teníamos antes. Ahora, en vez de hacer predicciones utilizando teta transpuesta de “x(i)” utilizando nuestras variables originales, “x(i)” tomamos las variables “x(i)” y las remplazamos por nuevas variables para utilizar teta transpuesta de “f(i)” para hacer una predicción en los ejemplos de entrenamiento “i” y vemos que en ambos casos podemos obtener los parámetros de la máquina de soporte vectorial resolviendo este problema de minimización. Un último detalle es que para este problema de optimización tenemos “n” igual a “m” variables; es decir el número efectivo de variables que tenemos, que es la dimensión de “f”. Entonces, “n” será igual a “m”. Si gustas, puedes pensar en esto como una suma. Realmente es una suma de “J” igual a 1 a “m”. Una manera de pensar en “n” es verla como igual a “m”, porque si “f” no es una variable nueva, entonces tendremos “m” más 1 variables donde más 1 viene del interceptor. Aquí, seguimos haciendo la suma de “J” igual a 1 a “n”, porque, al igual que en nuestros videos anteriores de la regularización, aún no hemos regularizado el parámetro teta cero, que es la razón de la suma de “J” igual a 1 a “m” en vez de “j” igual a cero a “m”.  Esto que expliqué fue la el algoritmo de aprendizaje de la máquina de soporte vectorial. Hay un detalle matemático adicional que debería mencionar: La manera en la que se implementa una máquina de soporte vectorial este último término se desarrolla de manera distinta. No necesitas saber este último detalle para utilizar máquinas de soporte vectorial. De hecho, las ecuaciones que están escritas aquí deberían darte todo el conocimiento que necesitas. Pero en la manera en la que se implementa una máquina de soporte vectorial, otra manera de escribir el término, la suma de “j” de teta “j” cuadrada es como teta transpuesta de teta si ignoramos el parámetro teta 0. Así que tenemos teta 1 hasta teta “m” ignorando  teta 0. La suma de “J” de teta “j” cuadrada también se puede escribir como teta transpuesta de teta. Lo que hacen la mayoría de las implementaciones de máquinas de soporte vectorial es remplazar esta teta transpuesta de teta con teta transpuesta por una matriz, que depende del número de kernel, por teta. Esto resulta en una medición ligeramente distinta. Esto nos da una métrica de la distancia un poco distinta. En vez de minimizar la norma de teta cuadrada o minimizamos algo muy similar, que es como la versión a escala del parámetro vector teta que depende del kernel. Este es un detalle matemático que le permite a la máquina de soporte vectorial ejecutarse con más eficiencia. La razón por la que la máquina de soporte vectorial hace esto es porque es esta modificación le permite escalarla a conjuntos de entrenamiento más grandes. Por ejemplo, si tienes un conjunto de entrenamiento con 10,000 ejemplos de entrenamiento, entonces, deberemos terminar con 10,000 puntos de referencia, por lo que teta se vuelve 10,000 dimensional. Tal vez funcione. Pero cuando “m” se hace muy muy grande para resolver todos estos parámetros, quizá 50,000 o 100,000, resolverlos puede resultar caro para el software de optimización de la máquina de vector de soporte que, por lo tanto, resolverá el problema que dibujé aquí abajo. Como detalle matemático, que realmente no es necesario que conozcas, de hecho modifica un poco el último término para optimizar algo ligeramente distinto que sólo minimizar la norma cuadrada de teta cuadrada de teta. Pero si gustas, puedes pesar esto como un detalle de implementación que cambia el objetivo un poco pero se realiza por eficiencia computacional. Usualmente no tienes que preocuparte por esto. Por cierto, en caso de que te estés preguntando por qué no aplicamos la idea del kernel a otras regresiones logísticas resulta que de hecho, si quieres, puedes aplicar el kernel y definir la fuente de las variables utilizando puntos de referencia para la regresión logística. Pero los trucos computacionales que aplican para la máquina de soporte vectorial no se generalizarán bien en otros algoritmos como la regresión logística. Utilizar kernels con la regresión logística puede ser lento pero debido a los trucos computacionales que modifican este término y los detalles de cómo se implementa el software de la máquina de soporte vectorial, estas máquinas y los kernels combinan muy bien juntos, mientras que la regresión logística y los kernels no son tan compatibles, se ejecutarían muy lentamente y no serán capaces de tomar las ventajas de las técnicas de optimización avanzadas que se han descubierto para el caso particular de ejecutar una máquina de soporte vectorial con un kernel. Todo esto se refiere a cómo puedes implementar software para minimizar la función de costos. Hablaré más al respecto en el siguiente video aunque realmente no necesitas tener conocimiento de cómo construir software para minimizar esta función de costos, porque puedes encontrar software ya desarrollado que resulta excelente para esto. Yo no recomendaría escribir código para invertir la matriz o para calcular la raíz cuadrara ni para minimizar la función de costo por ti mismo. En vez de ello, recomendaría utilizar paquetes de software ya desarrollados por otros que incluyen estos trucos de optimización numérica para que tú no te preocupes por ello. Otra cosa que vale la pena saber cuando aplicas una máquina de soporte vectorial es cómo elegir los parámetros para la máquina de soporte vectorial. Lo último que quiero hacer en este video es decir unas palabras acerca de la compensación entre el sesgo y la varianza cuando utilizamos una máquina de soporte vectorial. Cuando utilizamos una SVM, una de las cosas que debes elegir es el parámetro “C”, que teníamos en el objetivo de optimización. Recordemos que “C” jugaba un papel similar a 1 sobre «lambda», donde «lambda» era el parámetro de regularización para la regresión logística. Si tienes un gran valor de “C”, corresponde a lo que teníamos en la regresión logística: un valor pequeño de «lambda» quiere decir que no se está usando mucha regularización. Haciendo esto tenderemos a obtener una hipótesis con un sesgo bajo y una varianza más alta, mientras que si utilizamos un valor de “C” más bajo y estamos utilizando la regresión logística con un valor alto de «lambda», obtendremos una hipótesis con un sesgo más alto y una varianza más baja. La hipótesis con la “C” mayor tendrá una varianza más alta y será más propensa al sobreajuste, mientras que la hipótesis con la “C” menor tendrá un sesgo mayor y será más propensa al subajuste. Este parámetro “C” es uno de los parámetros que debemos elegir. El otro parámetro es «sigma» cuadrada que apareció en el kernel Gaussiano. Si en el kernel Gaussiano tenemos un valor alto para «sigma» cuadrada, en la variable de similaridad, que es “e” a la menos “x” menos punto de referencia cuadrado sobre 2 «sigma» cuadrada, y si tengo sólo una variable “x1” y un punto de referencia en esa ubicación y si el valor de «sigma» cuadrado es alto, el kernel Gaussiano tenderá a decrecer relativamente lento Esta de aquí sería mi variable “f(i)”, y representa una variable más suave, que varía más suavemente y que nos dará hipótesis con altas oscilaciones y varianzas bajas. Debido a que el kernel Gaussiano decrece suavemente, tiende a generar hipótesis que varían lentamente o suavemente a medida que cambiamos el valor de entrada “x”. En contraste, si «sigma» cuadrada tenía un valor bajo y si mi punto de referencia dado o mi variable “f1” mi kernel Gaussiano, o mi variable de similaridad tendrán una variación más abrupta. En ambos casos elegiría uno. Si «sigma» cuadrada es pequeña, entonces mis variables variarán menos suavemente así que tendremos pendientes más altas o derivadas más altas. Utilizando esto terminarás por ajustar una hipótesis de sesgo bajo y podrás tener una varianza más alta. Si observas esta curva de esta semana, podrás jugar con algunas de estas ideas y ver sus efectos por ti mismo. Eso es todo acerca de la máquina de soporte vectorial con algoritmos de kernel. Espero que esta discusión del sesgo y la varianza te hayan dado un mejor sentido de cómo puedes esperar que se comporte un algoritmo.