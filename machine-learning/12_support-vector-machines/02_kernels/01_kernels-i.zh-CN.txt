在本节课的视频中 我将对支持向量机算法做一些改变 以构造复杂的非线性分类器 我们用"kernels(核函数)"来达到此目的 我们来看看核函数是什么 以及如何使用 如果你有一个训练集 像这个样子 然后你希望拟合一个 非线性的判别边界 来区别正负样本 可能是这样的一个判别边界 一种办法 是构造 多项式特征变量 是吧 也就是像这样的特征变量集合 这样 你就能得到一个假设 如果θ0加上θ1*x1 加上其他的多项式特征变量 之和大于0 那么就预测为1 反之 则预测为0 这种方法 的另一种写法 这里介绍一个新的概念 之后将会用到 我们可以把假设函数 看成是用这个 来计算判别边界 那么 θ0+θ1×f1+ θ2×f2+θ3×f3 加上其他项 在这里 我将用这几个新的符号 f1 f2 f3等等 来表示一系列我将要计算的 新的特征变量 因此 f1就等于x1 f2就等于x2 f3等于这个 x1x2 f4等于x1的平方 f5等于x2的平方 等等 我们之前看到 通过加入这些 高阶项 我们可以得到更多特征变量 问题是 能不能选择别的特征变量 或者有没有比这些高阶项更好的特征变量 因为 我们并不知道 这些高阶项是不是我们真正需要的 我们之前谈到 计算机视觉的时候 提到过这时的输入是一个有很多像素的图像 我们看到如果用高阶项作为特征变量 运算量将是非常大的 因为 有太多的高阶项需要被计算 因此 我们是否有不同的选择 或者是更好的选择来构造特征变量 以用来 嵌入到 假设函数中 事实上 这里有一个可以构造 新特征f1 f2 f3的想法 在这一行中 我只定义三个 特征变量 但是对于实际问题而言 我们可以定义非常多的特征变量 但是在这里 对于这里的 特征 x1 x2 我不打算 把x0放在这里 截距x0 但是这里的x1 x2 我打算手动选取一些点 然后将这些点定义为l(1) 再选一个 不同的点 把它定为l(2) 再选第三个点 定为l(3) 现在 假设我打算 只手动选取三个点 将这三个点作为标记: 标记1，标记2，标记3 接下来我要做的是 这样定义新的特征变量 给出一个样本 x 将第一个特征变量f1 定义为 一种相似度的度量 度量样本 x 与 第一个标记的相似度 我将要用来度量相似度的 这个公式 是这样的 对括号的内容取exp (自然常数e为底的指数函数) 负号 x-l(1) 的长度 平方 除以2倍的 σ 平方 不知道你之前是否看了 上一个选修课程的视频 这个记号表示 向量 w 的长度 因此 这里的 x-l(1) 的意思 就是欧式距离 然后取平方 是点 x 与 l(1) 之间的 欧式距离 我们之后会更多地谈到这个 这是我的第一个特征向量 然后是f2 它等于 对x和l(2)使用相似度函数 度量x与l(2)的相似度 这个相似度函数同上 对如下值取exp x到第二个标记之间的欧式距离 这是分子 再除以2倍的σ平方 类似的 f3 等于x与l(3)之间的 相似度 公式同上 这个相似度函数是 用数学术语来说 它就是 核函数 这里我所说的核函数 实际上是高斯核函数 因此这个公式 我们选择的这个相似度函数是高斯核函数 但是这个术语 其实概括了 许多不同的相似度函数 它们都称作核函数 而我用的这个特定例子是高斯核函数 之后我们会见到别的核函数 但是现在就把这个当做相似度函数 我们通常不需要写 x和l的相似度 有时我们就直接这样写 小写的k 括号里是x和标记l(i) 现在 我们来看看核函数到底可以做什么 为什么这些相似度函数 这些表达式是正确的 先来看看我们的第一个标记 标记l(1) l(1)是我之前在图中选取的几个点中的其中一个 因此x和l(1)之间的核函数相似度是这样表达的 为了保证 你知道 这个分子项是什么 这个分子也可以 写为 对这个距离求和 j从1到n 这是向量x和l 各分量之间的距离 同样地 在这几张幻灯片中 我忽略了x0 因此我们暂时先不管截距项x0 x0总是等于1 那么 你现在明白 这就是你通过计算x和标记之间的相似度得到的核函数 让我们来看看这个函数计算的是什么 假设x与其中一个标记点非常接近 那么这个欧式距离 以及这个分子 就会接近于0 对吧 这是因为 这里的这个项 是距离的平方 x到l的距离 接近于0 因此f1 这个特征变量约等于 对-0取exp 然后除以2倍的σ平方 因此对0取exp 对-0取exp 约等于1 我把约等号放在这里 是因为这个距离 不是严格地等于0 但是x越接近于l 那么这个项就会越接近于0 因此f1越接近于1 相反地 如果x离l(1)越远 那么f1 就等于对一个非常大的数字 的平方除以2倍σ平方 再取exp 然后 对一个负的大数字取exp 接近于0 因此 这些特征变量的作用是度量 x到标记l的相似度 并且 如果x离l非常相近 那么特征变量f 就接近于1 如果x 离标记l非常远 那么f会约等于0 之前我所画的 那几个标记点 就是 l(1) l(2) l(3) 每一个标记点会定义一个新的特征变量 f1 f2 f3 也就是说 给出一个训练样本 x 我们就能计算三个新的特征变量 f1 f2和f3 基于我之前给的 三个标记点 但是首先 我们来看看这个指数函数 我们来看看这个相似度函数 我们画一些图 来更好地理解这些函数是什么样的 比如 假设我们有两个特征x1和x2 假设我们的第一个标记点 是l(1) 位于(3,5) 假设σ的平方等于1 如果我画出图 就是这样的 这个纵轴 这个曲面的高度是 f1的值 再看看水平的坐标 如果我把训练样本画在这里 这是x1 这是x2 给出一个特定的训练样本 选这里的一个样本 可以看到x1和x2的值 这个高度 可以看到这个f1相应的值 下面的这个图 内容是一样的 但我用的是一个等高线图 x1为水平轴 x2为竖直轴 那么 底下的这个图 就是这个3D曲面的等值线图 你会发现 当x等于(3,5)的时候 这个时候 f1就等于1 因为 它在最大值上 所以如果x往旁边移动 离这个点越远 那么从图中可以看到 f1的值就越接近0 这就是特征变量f1 计算的内容 也就是X与第一个标记点 的远近程度 这个值在0到1之间 具体取决于x 距离标记点l(1)到底有多近 我在这张幻灯片上要讲的另一项内容是 我们可以看到改变σ平方的值 能产生多大影响 σ平方是高斯核函数的参数 当你改变它的值的时 你会得到略微不同的结果 假设我们让σ平方 等于0.5 看看我们能得到什么 将σ平方设为0.5 你会发现 核函数看起来还是相似的 只是这个突起的宽度变窄了 等值线图也收缩了一些 所以如果我们将σ平方设为0.5 我们从x=(3 5) 开始 往旁边移动 那么特征变量f1 降到0的速度 会变得很快 与此相反地 如果你增大了σ平方的值 我们假设σ平方等于3 在这个例子中 如果我从点l往旁边移动 这里的这个点 就是l l(1)所在的坐标为(3,5) 从这里可以看到 如果σ平方很大 那么 当你从点l(1)移走的时候 特征变量的值减小的速度 会变得比较慢 因此 讲完了特征变量的定义 我们来看看 我们能得到什么样的预测函数 给定一个训练样本x 我们要计算出三个特征变量 f1 f2 f3 预测函数的预测值 会等于1 如果θ0加上 θ1*f1 加上 θ2*f2 等等的结果是大于或者等于0的 对于这个特定的例子而言 假设我们已经找到了一个学习算法 并且假设 我已经得到了 这些参数的值 因此如果θ0等于-0.5 θ1等于1 θ2等于1 θ3等于0 我想要做的是 我想要知道会发生什么 如果 我们有一个训练样本 它的坐标在这里 这个红点 我画的这个点 假设我们有一个训练样本x 我想知道我的预测函数会给出怎样的预测结果 看看这个公式 因为我的训练样本x 接近于l(1) 那么f1 就接近于1 又因为训练样本x 离l(2) l(3) 都很远 所以 f2就接近于0 f3也接近于0 所以 如果我们看看这个公式 θ0加上θ1 乘以1加上θ2乘以某个值 不是严格意义上等于0 但是接近于0 接着加上θ3乘以一个接近于0的值 这个等于... 再把这些值代入进去 这个是-0.5 加上1乘以1等于1  等等 最后等于0.5 这个值大于等于0 因此 这个点 我们预测出的y值是1 因为大于等于0 现在我们选择另一个不同的点 假设 我选择了另一个点 我用不同的颜色把它标出来 用蓝绿色 这个点 如果它是训练样本x 如果你进行和之前相同的计算 你发现f1 f2 f3都接近于0 因此 我们得到 θ0加上θ1×f1 加上其他项 最后的结果 会等于-0.5 因为θ0等于-0.5 并且f1 f2 f3都为0 因此最后结果是-0.5 小于0 因此 这个点 我们预测的y值是0 如果这样做 你自己来对大量的点 进行这样相应的处理 你应该可以确定 如果你有一个训练样本 它非常接近于l(2) 那么通过这个点预测的y值也是1 实际上 你最后得到的结果是 如果你看看这个边界线 这个区域 我们会发现 对于接近l(1)和l(2)的点 我们的预测值是1 对于远离 l(1)和l(2)的店 对于离这两个标记点非常远的点 我们最后预测的结果 是等于0的 我们最后会得到 这个预测函数的 判别边界 会像这样 在这个红色的判别边界里面 预测的y值等于1 在这外面预测的y值 等于0 因此这就是一个 我们如何通过标记点 以及核函数 来训练出非常复杂的非线性 判别边界的方法 就像我刚才画的那个判别边界 当我们接近两个标记点中任意一个时 预测值就会等于1 否则预测值等于0 如果这些点离标记点 非常远 这就是核函数这部分 的概念 以及我们如何 在支持向量机中使用它们 我们通过标记点和相似性函数 来定义新的特征变量 从而训练复杂的非线性分类器 我希望刚才讲的内容能够 帮助你更好的理解核函数的概念 以及我们如何使用它 在支持向量机中定义新的特征变量 但是还有一些问题我们并没有做出回答 其中一个是 我们如何得到这些标记点 我们怎么来选择这些标记点 另一个是 其他的相似度方程是什么样的 如果有其他的话 我们能够用其他的相似度方程 来代替我们所讲的这个高斯核函数吗 在下一个视频中 我们会回答这些问题 然后把所有东西都整合到一起 来看看支持向量机如何通过核函数的定义 有效地学习复杂非线性函数 【教育无边界字幕组】翻译: 御姐sama 校对: 王祖超 审核: 所罗门捷列夫