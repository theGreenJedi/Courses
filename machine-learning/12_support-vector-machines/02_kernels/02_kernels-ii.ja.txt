前回のビデオでは カーネルというアイデアと、 サポートベクタマシンにおいて、それを使う事で どうやって新しいフィーチャーを定義するかの議論を始めた。 このビデオでは、いくつかの 欠けている詳細を埋めるのと、 これらのアイデアを実際にどう使うのかについて 幾つか助言もしたいと思う。 例えば、バイアス-バリアンス間のトレードオフを サポートベクタマシンでどう取るのか、とか。 前回のビデオでは いくつかのランドマーク、l(1)、l(2)、l(3)を 選ぶプロセスについて言及した。 そしてそれで類似度関数を 定義することが出来た。 それはカーネル関数とも呼ばれるのだった。 そしてこの例の場合、また この類似度関数はガウスカーネルとも呼ばれるのだった。 そしてそれによって、 この形の仮説関数を定義出来るのだった。 だが、これらのランドマークをどこから得たらいいのだろうか？ どこから l(1)、l(2)、l(3)を得る事が出来るだろうか？ そしてまた、複雑な学習問題においては、 手動で選ぶたった三つだけよりも、 もっとたくさんのランドマークが欲しい事もあるだろう。 さて、実際には、こんな感じに ランドマークは選ばれる。 機械学習の問題が 与えられた時に、 ある陽性のデータセットと 陰性のデータセットがある訳だが、その時に、これがアイデアだ。 我らは手本を取って、 そして各手本に対し 我らは単にそれを ランドマークと呼ぶ事に、 つまりランドマークを そのトレーニング手本と 全く同じ場所に置く事にする。 だからもしあるトレーニング手本を 取ったら、それがx1だったとすると、 その時に、私は最初のランドマークを これと全く同じ場所に 最初のトレーニング手本と全く同じ場所に 選ぶ。 そして別のトレーニング手本x2が あったとすると、 二番目のランドマークには、 この二番目の手本の場所を選ぶ。 この右側の図では、 私は赤と青の点を イラストで示す目的の為に用いたが、 この図の色は、この右側の図の 点の色は、重要では無い。 だがこの手法を用いる事で 結局の所、 結局の所、m個のランドマーク l(1)、l(2)、、、、と l(m)まで、 もし私がトレーニング手本をm個持っていて、 各位置につき一つのランドマーク、 各トレーニング手本の位置につき 一つのランドマークを持つ事になる。 そしてこれはナイスだ。何故なら、それはようするに 私のフィーチャー達は、基本的には トレーニングセットに見られる物の一つに サンプルがどれだけ近いのか、を 測っているという事だからだ。 このアウトラインをもうちょっと 具体的に書くと、 m個のトレーニング手本が与えられた時に、 ランドマーク達の場所を トレーニング手本の場所達と 完全に同じになるように選ぶ。 手本xが与えられた時に、 この手本xは トレーニングセットの場合もあり得るし、 クロスバリデーションセットの場合もあり得るし、 テストセットの場合もあり得るが、 ある手本xが与えられた時に、 我らはこれらのフィーチャー、 f1, f2, などなどを 計算する事になる。 ここでl(1)は実際には x1に等しい、などなど。 そしてこの結果が、フィーチャーベクトルを与える。 フィーチャーベクトルをfと書く事にしよう。 これらのf1, f2, ...を持ってきて、 これを単にフィーチャーベクトルとして グループ化する。 これらをf(m)まで持ってくる。 そして、慣例により、 足したければ追加のフィーチャー、f(0)を、 それはいつもイコール1だが、それを足しても良い。 これは以前我らが持っていた物と、似たような働きをする。 x0は、切片項だった。 例えば、トレーニング手本x(i), y(i)が あったとすると、 このトレーニング手本に対して 我らが計算する事になるフィーチャーは、 以下のようになる： 所与のx(i)に対し、 それを以下のようにマップする、まずf1(i)、 これはsimilarity（類似度）だが、 全部のスペル、similarityと書く代わりに SIMと省略して 書く事にする。 そしてf2(i)はイコール、 x(i)とl(2)との類似度（similarity）だ。 以下同様に 降りていって、fm(i)= x(i)とl(m)のsimilarity。 そして間のどこかで、 このリストの途中のどこかで、 i番目の要素があり、 fの下付き添字iの(i)という フィーチャーの要素がある、 それはxとl(i)との 類似度 となる。 ここでl(i)はイコールx(i)だから、 つまり、 fi(i)は単に x同士の類似度、つまり自分自身との類似度となる。 もしガウスカーネルを使ってるなら、 これは実際に、eの指数乗の -0 割ることの 2シグマ二乗 となるから、これは1となる。これは問題無い。 つまり、このトレーニング手本の フィーチャーの一つは、イコール1となる。 そして上でやったのと同様にして、 これらのm個のフィーチャーに対して、 フィーチャーベクトルにグループ化出来る。 つまり、手本をx(i)を用いて 表現する代わりに、ここでx(i)は R(n)かR(n+1)次元のベクトル、 これは切片項を数えるかどうかによって R(n)となるか R(n+1)となる。 ここで我らは、トレーニング手本を 代わりにこの新しいフィーチャーベクトルfを 表現とする事が出来る。 私はこれをfの上付き添字iと書く事にする、 それはこれら全てを 積み上げてベクトルにした物だ。 つまり、このf1(i)から fm(i)まで。そしてもしお望みなら、 そして普通はそうするか、f0(i)を足しても良い。 ここでf0(i)は イコール1。 そしてこのここのベクトル、 これは新しいフィーチャーベクトルを 与えてくれる、それを用いて トレーニング手本の表現とする事が出来る。 つまり、これらのカーネルと similarity(類似度)関数が与えられた時に、 これがサポートベクターマシンの使い方だ。 もしあなたが既に、学習したパラメータセットのシータを 持っていたとして、所与のxの値に対して予測を行いたいとすると、 やるべき事は、フィーチャーfを計算して、 それはここではR(m+1)次元の フィーチャーベクトルとなるが、 ここでmとなるのは、 我らがトレーニング手本としてm個を持ち、 つまりはランドマークもm個だからだが、 そして我らがやる事は、 シータ転置fが0以上なら 必ず、 でしょ？ つまり、シータ転置f は、もちろん、 単なる シータ0 f0 + シータ1 f1 + .... +シータm f(m) となるが、 つまりパラメータベクトルシータも ここではm+1次元の ベクトルと なる。 そしてここでmとなるのは、 ランドマークの総数は トレーニングセットの数と等しいから。 つまり、mはトレーニングセットの数であり、 そしてここではパラメータベクトルシータもm+1次元となる。 以上が、予測を行う方法だ、 既にあなたがパラメータシータを得ている、という場合での。 どうやってパラメータシータを得たらいいだろうか？ あなたはSVMの学習アルゴリズムを使って それを行う事が出来る。具体的には、 あなたはこの最小化問題を解く事になる。 パラメータのシータを C掛けるこのコスト関数 を最小化するようにシータを選ぶ。 ただしここでは、ここを見ると、 シータ転置 x(i) を用いて 予測を行う代わりに、 元のフィーチャーx(i)を使う代わりに、 その代わりにフィーチャーx(i)の所を 新しいフィーチャーで 置き換える。 我らはシータ転置 f(i) を用いる、 i番目のトレーニング手本の 予測を行う為に。 これは両方にあるのを 見てくれ。 そしてこの最小化問題を解く事で、 サポートベクターマシンのパラメータが得られる。 そして最後に一つ細かい話を。 この最適化問題では、 我らは実際にはn=mのフィーチャーを 持っているから、 つまりここで、 我らが持ってるフィーチャーの総数は、 実際に効力のあるフィーチャーの数は、 fの次元となる。 つまり、nは実際に イコールmとなる。 だからもしお望みなら、 これを、和と、、、 j=1からmまでの和と 考える事が出来る。 それを考える一つの方法としては、 それを、 n=mと考える、という 方法がある。 何故なら、fを新しいフィーチャーと考えると、 m+1個のフィーチャーとなるが、 ここで+1は切片項から来るが、 ここで我らは和を j=1からmに渡って取っている、 何故なら以前正規化のビデオで やったのと同様に、 我らはここでもパラメータのシータ0を 正規化しない。 だから和はj=1からmに 渡って取るのであって、 j=0からmまででは無い理由だ。 以上がサポートベクタマシンの 学習アルゴリズムだ。 最後に一つ、 数学的な脇道の細かい話を 言及しておく。 それはサポートベクタマシンの実装を する時には、この最後の項は、 ちょっとだけ違った感じにする。 あなたは本当に サポートベクターマシンを使うに際し この最後の詳細を知っている必要は無い。 そして実際には、ここに書いた 方程式は、あたなが必要な直感的な理解の 全てを提供するはずだ。 だが、サポートベクターマシンを 実装する方法としては、この項、 シータjの二乗の和、 別の書き方をすると、 シータ転置 シータとなる、 もしパラメータ、シータ0を 無視すれば。 するとシータ1からシータmまで、 シータ0は無視。 するとこのjに渡って和を取ることの シータjの二乗は、 シータ転置 シータ と書く事も出来る訳だ。 そして多くのサポートベクターマシンの実装が やってる事としては、実際にはこの シータ転置 シータを置き換えて、 その代わりに、シータ転置に掛ける事の なんからの行列を中に入れる、ここでこの行列は あなたの用いるカーネルによって決まる物で、それに掛けるシータ。 つまりこれは、ちょっとだけ違った距離の計量を与える。 我らは最小化する対象として ちょっと別の指標を用いるのだ、 厳密なシータ二乗のノルムの代わりに。 つまり、何かしらそれに似た物を最小化している。 それはリスケールしたバージョンの パラメータベクトルシータ、みたいな物で、それはカーネルに依存している。 だが、これはある種、数学的な詳細に属する話だ、 そうする事で、サポートベクターマシンのソフトウェアが もっと効率的に実行出来るようになる。 そしてサポートベクターマシンがこれを行う理由は、 この修正を行う事で、 もっと大きなトレーニングセットに スケール出来るようになるからだ。 何故なら、例えばもしあなたが 1万個のトレーニング手本によるトレーニングセットを持っていたとすると、 我らのランドマークの定義の仕方では、 結果としては1万個のランドマークを得る事になる。 だからシータは1万次元になる。 この位ならなんとかなるかもしれないが、 mがもっと、もっと大きくなっていくと、 これらのパラメータ全てに対して 解く、というのは、 mが5万とか10万とかだとすると、 これらのパラメータ全てに関して 解いていく、というのは サポートベクタマシンの最適化ソフトウェアにとって 高くつく事態となりうる。 かくして、ここに書いた最小化問題を解くのに、 これはある種の数学的な詳細であって、 繰り返しになるがあなたは本当に知ってる必要の無い事だが、 それはこの最後の項を ちょっとだけ修正して、 単にシータのノルムの二乗を最小化するのとは、 ちょっとだけ違った物を最適化する。 だがお望みなら、 この事を、ある種の実装の詳細に過ぎない話で、 目的関数をちょっとだけ変更する、という物で、 その理由は主に 計算的な効率性を求めて、だ、と、 考えていただいて構わない。 だから通常は、この事に思い悩む必要は無い。 ところで、もしあなたが、 その他の学習アルゴリズムでも カーネルのアイデアを用いないのは何故かしら？と 不思議に思うなら、例えばロジスティック回帰とか、 実のところ、 もしお望みなら、 カーネルの考え方を適用する事は出来て、 ランドマークを用いたフィーチャーを 定義したりなどを、ロジスティック回帰に対して行う事は出来る。 だがサポートベクターマシンに使えた 計算的なトリックは その他のアルゴリズム、ロジスティック回帰みたいなのとかには、あまりうまく一般化出来ない。 つまり、カーネルをロジスティック回帰と共に用いると とても遅くなりすぎるだろう、 一方で、 計算的なトリックのおかげで、 それはサポートベクタマシンのソフトウェアの 詳細に埋め込まれた、これをどう変形するか、 などのトリックのおかげで、 サポートベクターマシンとカーネルは とりわけいい感じに、一緒に使えるのだ。 一方でロジスティック回帰とカーネルは、 使える事は使えるんだが、とても実行速度が遅い。 そしてロジスティック回帰では、 サポートベクタマシンとカーネルの組み合わせで 実行する時だけに使える人々が編みだした アドバンスドな最適化のテクニックの 恩恵が得られない。 だがこれは全て、 コスト関数を最小化するソフトウェアを 実際にどう実装するかに依存した話だ。 私は次のビデオでもうちょっとこの話をするが、 だがあなたは、本当に コスト関数を最小化するソフトウェアを どうやって書くかを 知る必要は無い。 何故ならあなたは、とても良い既製品のソフトウェアでこれを行ってくれるものを、見つける事が出来るからだ。 そしてまた、知っての通り、 私は行列の逆行列を計算するコードを 自分で書く事はオススメしないし、 ルートを計算するコードを自分で書く事もオススメしない。 コスト関数を最小化する関数を計算するソフトウェアを 自分で書く事も推奨しない。 代わりに既製品の ソフトウェアパッケージを使うべきだ、 人々が既に開発してくれている、 そしてそれらのソフトウェアパッケージには 既にこれらの数値計算の最適化のトリックが埋めこまれているので、 それについてあなたが心配する必要は無い。 だが、サポートベクタマシンを使う時に もう一つ知っておく 価値のある事として、 サポートベクタマシンのパラメータを どうやって選ぶのか？という事がある。 そしてこのビデオで最後に私が やりたい事は、 サポートベクターマシンを使う時の バイアス-バリアンスのトレードオフを取る事について、ちょっと言っておく事だ。 SVMを使う時には、 あなたが決める必要のある事の一つに、 パラメータCがある、 それはこの最適化の目的関数内にあった物で、 そしてCは 1/ラムダ に似たような 役割を果たす事を、思い出してくれ、 ここでラムダはロジスティック回帰にあった 正規化パラメータ。 さて、もしあなたが大きな値の Cを持つ時は、これは ロジスティック回帰において 小さなラムダの値をとる事に対応し、 それはつまり、あまり正規化しない、という事を意味する。 そうしておけば、 仮説を得る傾向にある。 一方でもしあなたがもっと小さいCの値を 使うとすると、その時は ロジスティック回帰において 大きなラムダの値を使う事に 対応するのだから、 これは高バイアス、低バリアンスの 仮説に対応する。 つまり、大きなCによる仮説は、 より高いバリアンスとなり、 そしてよりオーバーフィットしがちとなる。 一方で小さなCの仮説は、 より高いバイアスとなり、 そしてよりアンダーフィットしがちとなる。 つまり、このパラメータCが、我らが選ぶ必要がある一つ、という事だ。 別の我らが選ぶ必要がある物としては、 パラメータ、シグマ二乗がある。これはガウスカーネルに現れる物だ。 さて、もしガウスカーネルにおいて シグマ二乗が大きければ、 その時は、similarity関数の中で、 eの指数乗の マイナスの x引くランドマークi の二乗、を2シグマ二乗で割った物、 ここでフィーチャーが たった一つ、x1しか無かったとすると、 そしてランドマークがここに あったとすると、 もしシグマ二乗が大きければ、その時は ガウスカーネルは相対的に ゆっくりと落ちていく、 するとこれは、私のフィーチャーf(i)を つまりこれは、 よりスムースな関数となり、よりゆっくり変化する。 つまりこれは、 より高いバイアス、より低いバリアンスの仮説を あなたに与える。 何故ならガウスカーネルはよりスムースに落ちていくから。 それはゆっくり変化する傾向の仮説を得る事になり、 あるいは入力xを変化させると よりスムースに変化していく仮説となる。 一方で、対照的に、 もしシグマ二乗が 小さくて、そして これがランドマークとして、 所与の一つのフィーチャーx1に対して、 ガウスカーネル、類似度関数は、とても急速に変化する。 どちらのケースでも丘の頂点は1だ。 つまりシグマ二乗が小さければ、 私のフィーチャーはよりスムースで無く変化する。 つまりもっと高い傾き、あるいは より高い導関数となる。 そしてこれを用いる事で、 仮説のフィッティングを、 低バイアス、高バリアンスに行う事が出来る。 そしてこのカーブを見てみると、 実際にあなたは これらのアイデアの幾つかを自分自身で 試してみる事が出来て、その効果を自分自身で見てみる事が出来る。 以上がカーネルとサポートベクターマシンのアルゴリズムだ。 そしてこのバイアスとバリアンスの議論で あなたが、このアルゴリズムが どんな風に振舞うと期待したらいいか いくらかつかめたらいいな。