Sejauh ini kita telah berbicara tentang SVM secara abstrak. Dalam video ini saya ingin berbicara tentang apa yang sesungguhnya perlu anda lakukan untuk menjalankan atau menggunakan SVM. Algoritma Support Vector Machine merupakan suatu permasalahan optimasi spesifik. Namun sebagaimana telah saya sebutkan secara singkat pada video sebelumnya, saya betul-betul tidak merekomendasikan anda untuk menulis perangkat lunak (software) anda sendiri untuk mencari nilai parameter theta. Jadi sebagaimana situasi saat ini, sangat sedikit dari kita, atau mungkin bahkan hampir tidak ada dari kita yang berpikir untuk menulis kode sendiri untuk melakukan inversi matriks atau menghitung akar dari suatu angka, dan seterusnya. Kita hanya, anda tahu, memanggil suatu fungsi pustaka (library function) untuk melakukan hal itu. Dengan cara yang sama, perangkat lunak untuk menyelesaikan permasalahan optimasi SVM adalah sangat kompleks, dan telah ada periset-periset yang telah melakukan riset optimasi numerik selama bertahun-tahun. Jadi anda perlu menggunakan pustaka perangkat lunak (software library) dan paket perangkat lunak (software package) yang bagus untuk melakukan hal ini. Dan karenanya saya sangat merekomendasikan penggunaan salah satu dari pustaka perangkat lunak yang telah sangat teroptimasi ini daripada mencoba mengimplementasikannya sendiri. Dan ada banyak pustaka perangkat lunak yang bagus di luar sana. Dua hal yang kebetulan saya paling sering gunakan adalah liblinear dan libsvm, namun sebetulnya ada banyak pustaka perangkat lunak yang bagus untuk melakukan hal ini yang, anda tahu, dapat anda hubungkan dengan banyak dari bahasa pemrograman populer yang mungkin anda pergunakan untuk menulis kode algoritma pembelajaran. Meskipun anda sebaiknya tidak menulis perangkat lunak optimasi SVM anda sendiri, bagaimanapun, ada beberapa hal yang tetap perlu anda lakukan. Pertama adalah untuk memilih nilai dari parameter C. Kita telah sedikit membicarakan tentang sifat bias/variansi dari hal ini pada video sebelumnya. Kedua, anda juga perlu untuk memilih kernel atau fungsi kesamaan (similarity function) yang ingin anda pergunakan. Jadi salah satu pilihan yang mungkin adalah jika kita memutuskan untuk tidak menggunakan kernel apapun. Dan tidak menggunakan kernel diistilahkan juga sebagai kernel linear. Jadi jika seseorang mengatakan, saya menggunakan suatu SVM dengan kernel linear, arti dari hal itu adalah, anda tahu, ia mempergunakan SVM tanpa menggunakan kernel, dan itu adalah versi dari SVM yang hanya mempergunakan theta transpose X yang memprediksikan satu nilai theta0 dan theta1 X1 dan seterusnya dan thetaN XN lebih besar atau sama dengan 0. Istilah kernel linear ini dapat anda pandang sebagai, anda tahu, versi dari SVM yang menghasilkan suatu pengklasifikasi linear standar. Jadi itu mungkin adalah salah satu pilihan yang masuk akal untuk beberapa jenis permasalahan, dan anda tahu, ada banyak pustaka perangkat lunak seperti liblinear, yang merupakan salah satu contoh dari banyak pustaka perangkat lunak yang dapat melakukan pelatihan sebuah SVM tanpa mempergunakan kernel, yang disebut juga sebagai kernel linear. Jadi, apa alasan mengapa anda menginginkannya (kernel linear - penj.)? Jika anda memiliki sejumlah besar fitur, (dengan kata lain) jika N besar, dan M, yaitu jumlah dari data latih sedikit, maka anda tahu anda memiliki sejumlah besar fitur yang jika X, ini adalah suatu X adalah sebuah Rn, Rn+1. Jadi jika anda sudah memiliki jumlah fitur yang besar, dengan set data latih berukuran kecil, anda tahu, mungkin anda hanya ingin untuk mendapatkan suatu pembatas keputusan (decision boundary) yang linear dan tidak untuk mencari suatu fungsi nonlinear yang sangat rumit, karena anda mungkin tidak memiliki cukup banyak data. Dan anda akan mengalami resiko overfitting, jika anda mencoba untuk mencari suatu fungsi yang sangat rumit pada ruang fitur berdimensi sangat tinggi namun set data latih anda berukuran kecil. Jadi ini adalah salah satu setting yang masuk akal sehingga anda mungkin memutuskan untuk tidak menggunakan suatu kernel, atau ekuivalen dengan menggunakan apa yang diistilahkan sebagai kernel linear. Pilihan kedua untuk kernel yang mungkin anda pergunakan, adalah kernel Gaussian dan ini adalah yang telah kita lakukan sebelumnya. Dan jika anda melakukan hal ini, maka pilihan lain yang perlu anda buat adalah untuk memilih parameter sigma kuadrat ini ketika kita juga membicarakan sedikit mengenai timbal-balik bias dan variansi yang, jika sigma kuadrat nilainya besar, maka anda cenderung untuk memperoleh pengklasifikasi dengan bias yang lebih besar dan variansi yang lebih kecil, namun jika sigma kuadrat nilainya kecil, maka anda akan memperoleh pengklasifikasi dengan variansi yang lebih besar dan bias yang lebih kecil. Jadi apa alasan anda untuk memilih kernel Gaussian? Ya, jika omisi X dari fitur anda, maksud saya RN, dan jika N nilainya kecil, dan idealnya, anda tahu, jika N besar, jadi itu adalah jika kita memiliki, katakanlah suatu set data latih berdimensi dua, seperti pada contoh yang saya gambarkan sebelumnya. Jadi jika N sama dengan 2, namun kita memiliki set data latih yang bernilai besar. Jadi, anda tahu, saya telah memiliki data latih dalam jumlah yang cukup besar, maka mungkin anda sebaiknya menggunakan suatu kernel untuk dapat memperoleh suatu pembatas keputusan (decision boundary) yang kompleks dan nonlinear, dan kernel Gaussian adalah salah satu cara yang baik untuk melakukan hal ini. Saya akan mengatakan lebih banyak di penghujung video ini, sedikit lebih banyak mengenai mengapa anda mungkin memilih sebuah kernel linear, kernel Gaussian, dan seterusnya. Namun, secara konkret, jika anda memutuskan untuk menggunakan kernel Gaussian, maka inilah yang perlu anda lakukan. Bergantung pada paket perangkat lunak (software package) SVM apa yang anda pergunakan, paket itu mungkin akan meminta anda untuk mengimplementasikan suatu fungsi kernel, atau untuk mengimplementasikan fungsi kesamaan. Jadi jika anda mempergunakan suatu implementasi SVM pada Octave atau MATLAB, (implementasi tersebut) mungkin akan meminta anda untuk menyediakan suatu fungsi untuk menghitung suatu fitur tertentu dari kernel. Jadi ini sesungguhnya adalah menghitung f subskrip i untuk suatu nilai i tertentu, dengan f disini hanyalah sebuah bilangan real, jadi mungkin saya sebaiknya memindahkan ini, lebih baik ditulis sebagai f(i), namun apa yang perlu anda lakukan adalah menulis suatu fungsi kernel yang mengambil input ini, anda tahu, suatu contoh data latih atau suatu contoh data uji apapun yang diambilnya pada suatu vector X dan mengambil sebagai masukan salah satu dari penanda (landmark) dan namun saya hanya menuliskan X1 dan X2 disini, karena sesungguhnya penanda (landmark) adalah juga merupakan contoh data latih. Namun apa yang perlu anda lakukan adalah menulis perangkat lunak yang mengambil input ini, anda tahu, X1, X2, dan menghitung fungsi kesamaan semacam ini di antara mereka (masukan-masukan tersebut - penj.) dan menghasilkan suatu bilangan real. Jadi, apa yang beberapa paket perangkat lunak SVM lakukan adalah mengharapkan anda untuk menyediakan fungsi kernel ini yang mengambil masukan ini, X1, X2, dan menghasilkan suatu bilangan real. Dan kemudian paket tersebut akan mengambil alih dari situ dan akan menghasilkan secara otomatis seluruh fitur, dan dengan demikian secara otomatis mengambil X dan memetakannya terhadap f1, f2, sampai dengan f(m) menggunakan fungsi yang telah anda tulis tersebut, dan menghasilkan seluruh fitur dan melatih support vector machine dari situ. Namun kadangkala anda perlu untuk menyediakan fungsi ini sendiri. Selain itu, jika anda mempergunakan kernel Gaussian, beberapa implementasi SVM akan menyertakan juga kernel Gaussian dan juga beberapa kernel lain, karena kernel Gaussian mungkin merupakan kernel yang paling umum digunakan. Kernel Gaussian dan linear adalah benar-benar dua kernel yang jauh paling terkenal. Satu saja catatan mengenai implementasi. Jika anda memiliki fitur dengan skala yang sangat berbeda, adalah penting untuk melakukan penskalaan fitur sebelum menggunakan kernel Gaussian. Dan inilah alasannya. Jika anda membayangkan komputasi norma di antara X dan I, ya, jadi term ini disini, dan term numerator di sana. Apa yang dilakukan disini, (oleh) norma antara X dan I, itu sebetulnya mengatakan, anda tahu, mari menghitung vektor V, yang sama dengan X dikurangi I. Dan kemudian mari kita menghitung norma dari vektor V, yaitu selisih antara X. Jadi norma dari V sesungguhnya sama dengan V1 kuadrat ditambah V2 kuadrat ditambah titik titik titik, ditambah Vn kuadrat. Karena disini X adalah di dalam Rn, atau Rn+1, namun saya akan mengabaikan, anda tahu, X0. Jadi, mari kita bayangkan X adalah sebuah Rn, kuadrat pada sisi kiri adalah yang menjadikan hal ini benar. Jadi ini sama dengan itu, betul bukan? Jadi jika dituliskan dengan cara lain, ini akan menjadi X1 dikurangi I1 kuadrat, ditambah S2 dikurangi I2 kuadrat, ditambah titik titik titik ditambah Xn dikurangi In kuadrat. Dan sekarang jika fitur anda memiliki nilai pada kisaran yang sangat berbeda, jadi ambil sebagai contoh suatu prediksi perumahan, jika data anda adalah berbagai data mengenai rumah. Dan jika X berada pada kisaran ribuan kaki persegi (1ft²≈ 0.09m² - penj.) untuk fitur pertama, X1. Tetapi jika fitur kedua anda, X2, adalah jumlah kamar tidur, jadi jika ini adalah pada kisaran satu sampai lima kamar tidur, maka X1 dikurangi I1 akan besar nilainya, (nilai) ini bisa jadi sekitar seribu kuadrat sedangkan X2 dikurangi I2 akan jauh lebih kecil nilainya, dan jika seperti itu, maka pada term yang ini, kedua jarak itu akan hampir sepenuhnya didominasi oleh ukuran rumah dan jumlah kamar tidur pada dasarnya akan terabaikan. Dengan demikian, untuk menghindari hal ini sehingga mesin dapat bekerja dengan baik, lakukanlah penskalaan fitur. Dan hal itu (penskalaan fitur) akan memastikan bahwa SVM akan memberikan perhatian yang seimbang terhadap seluruh fitur yang anda pergunakan dan tidak hanya, pada contoh ini, pada ukuran rumah yang dominan terhadap fitur-fitur lainnya. Ketika anda mencoba suatu support vector machine, kemungkinannya adalah anda akan menggunakan dua kernel yang paling umum dipergunakan, yaitu kernel linear, yang berarti tidak menggunakan kernel, atau kernel Gaussian yang telah kita bicarakan. Dan satu lagi catatan peringatan yaitu bahwa tidak semua fungsi kesamaan yang mungkin anda pikirkan adalah kernel yang valid. Dan kernel Gaussian dan kernel linear serta kernel-kernel lain yang terkadang akan anda lihat dipergunakan oleh orang lain, semua kernel-kernel itu perlu untuk memenuhi suatu kondisi teknis. Kondisi teknis tersebut disebut Teorema Mercer dan alasan dari mengapa anda perlu melakukannya adalah karena algoritma support vector machine atau implementasi dari SVM memiliki banyak trik optimasi numerik yang cerdik. Untuk mencari solusi dari parameter theta secara efisien dan sesuai dengan gambaran dari rencana awal, keputusan-keputusan itu diambil untuk membatasi perhatian kita hanya terhadap kernel-kernel yang memenuhi kondisi teknis yang disebut Teorema Mercer tersebut. Dan apa yang dilakukan adalah untuk memastikan bahwa seluruh dari paket SVM ini, semua dari paket perangkat lunak SVM ini dapat mempergunakan sebagian besar dari kelas optimasi dan mendapatkan nilai parameter theta dengan sangat cepat. Jadi, apa yang akhirnya dilakukan oleh kebanyakan orang adalah mempergunakan salah satu dari kernel linear atau kernel Gaussian, namun terdapat pula beberapa kernel lain yang juga memenuhi Teorema Mercer, dan anda mungkin akan menjumpai orang lain mempergunakan (kernel-kernel tersebut), meskipun secara pribadi saya sangat, sangat jarang mempergunakan kernel-kernel lain tersebut. Sekedar menyebutkan beberapa dari kernel-kernel lain yang mungkin anda jumpai, salah satunya adalah kernel polinomial. Dan untuk kernel tersebut, kesamaan antara X dan I adalah didefinisikan sebagai, (salah satu) di antara banyak pilihan adalah anda dapat mengambil nilai dari X transpose I kuadrat. Jadi, ini adalah salah satu ukuran mengenai kemiripan dari X dan I. Jika X dan I sangat dekat satu sama lain, maka hasil kali (inner product) dari keduanya akan cenderung besar. Dan jadi, anda tahu, ini adalah suatu kernel yang agak tidak biasa dalam artian tidak sering dipergunakan, namun ada kemungkinan anda akan menjumpai penggunaannya oleh orang lain. Ini adalah salah satu versi dari sebuah kernel polinomial. Yang lain adalah X transpose I pangkat tiga. Berikut ini adalah contoh dari kernel polinomial. X transpos I ditambah satu pangkat tiga. X transpos I ditambah mungkin suatu angka selain 1, misalnya 5 dan, anda tahu, dipangkatkan 4 sehingga kernel polinomial sesungguhnya memiliki 2 parameter. Yang pertama adalah, angka berapa yang anda tambahkan di sini? Bisa jadi 0. Ini sebetulnya adalah ditambah 0 di sini, begitu pula dengan derajat dari polinomial di sana. Sehingga derajat pangkat dan angka-angka ini. Dan bentuk yang lebih umum dari kernel polinomial adalah X transpose I, ditambah suatu nilai konstanta, dan kemudian dipangkatkan dengan suatu nilai pada X1, sehingga kedua nilai ini adalah parameter dari kernel polinomial. Kernel polinomial hampir selalu, atau biasanya, memiliki performa yang lebih buruk. Dan tidak seperti kernel Gaussian, ini tidak banyak dipergunakan, namun ini mungkin akan anda temui. Biasanya ini hanya dipergunakan untuk data dengan X dan I adalah sepenuhnya non-negatif, sehingga itu memastikan bahwa hasil kali dalam ini tidak akan pernah bernilai negatif. Dan hal ini menangkap intuisi bahwa jika X dan I adalah sangat mirip satu sama lain, maka mungkin hasil kali dari keduanya akan bernilai besar. Mereka (kernel polinomial - penj.) juga memiliki beberapa sifat lain namun orang biasanya tidak banyak mempergunakannya. Dan kemudian, tergantung pada apa yang anda lakukan, ada jenis-jenis kernel lain pula yang lebih esoterik, yang mungkin akan anda jumpai. Anda tahu, ada kernel string, ini terkadang dipergunakan bila data masukan anda berupa string teks atau tipe-tipe string lainnya. Ada hal-hal seperti kernel chi-kuadrat, kernel interseksi histogram, dan sebagainya. Ada jenis-jenis kernel lain yang lebih esoterik yang dapat anda pergunakan untuk mengukur kesamaan di antara objek-objek yang berbeda. Jadi, sebagai contoh, jika anda berusaha untuk mengerjakan permasalahan klasifikasi teks tertentu, dengan input X berupa suatu string, maka mungkin kita ingin menemukan kesamaan di antara dua string dengan menggunakan kernel string, namun saya secara pribadi jarang sekali, atau hampir tidak sama sekali, menggunakan kernel-kernel yang lebih esoterik ini. Saya pikir saya pernah menggunakan kernel chi-kuadrat mungkin satu kali dalam hidup saya, dan kernel histogram mungkin sekali atau dua kali dalam hidup saya. Saya sesungguhnya belum pernah menggunakan kernel string. Namun seandainya anda menemui ini pada aplikasi-aplikasi lain, anda tahu, jika anda melalukan suatu pencarian web secara cepat mungkin dengan menggunakan Google atau dengan menggunakan Bing, anda seharusnya juga akan menemukan definisi dari kernel-kernel ini. Selanjutnya dua detail terakhir yang ingin saya bicarakan dalam video ini.
Yang pertama adalah tentang klasifikasi multikelas. Jadi, anda memiliki 4 kelas luaran, atau biasanya 3 kelas luaran dari pembatas keputusan (decision boundary) yang tepat diantara kelas-kelas yang anda miliki. Hampir semua paket SVM memiliki fasilitas klasifikasi multikelas yang sudah tersedia (built-in). Jadi jika anda menggunakan pola seperti itu, anda cukup menggunakan kedua fungsionalitas, dan itu seharusnya bekerja dengan cukup baik. Selain itu, satu cara untuk melakukan hal ini adalah menggunakan metode satu-versus-semua (one versus all) yang telah kita bicarakan saat kita berdiskusi tentang regresi logistik. Jadi apa yang anda lakukan adalah melatih k buah SVM (kSVM) jika anda memiliki k kelas, masing-masing untuk membedakan setiap kelompok dari anggota kelompok lainnya. Dan ini akan menghasilkan k vektor parameter, jadi ini akan memberikan pada anda theta1, yang akan mencoba untuk membedakan kelas y = 1 dari semua kelas lainnya kemudian anda mendapatkan parameter kedua, vektor theta2, yang akan anda dapatkan jika anda memandang y = 2 sebagai kelas positif dan seluruh kelas lainnya sebagai kelas negatif. Dan demikian seterusnya hingga parameter vektor theta k, yang merupakan vektor parameter untuk membedakan kelas terakhir y = k dari kelas-kelas lainnya, dan pada akhirnya, ini tepat sama dengan metode satu-versus-semua yang kita pergunakan pada regresi logistik dimana anda memprediksi kelas i yang memiliki nilai theta transpos x terbesar. Demikian pula dengan klasifikasi multikelas. Untuk kasus-kasus yang lebih umum yaitu bahwa kemungkinan besar bahwa paket perangkat lunak apapun yang anda gunakan, anda tahu, akan ada kemungkinan yang cukup beralasan bahwa (paket tersebut) telah memiliki fungsionalitas klasifikasi multikelas bawaan (built-in) dan dengan demikian anda tidak perlu khawatir tentang hal ini. Akhirnya, kita melakukan pengembangan support vector machine dengan bermula dari regresi logistik dan kemudian memodifikasi sedikit fungsi biayanya. Hal terakhir yang ingin kita lakukan dalam video ini adalah berbicara sedikit tentang kapan anda menggunakan salah satu dari kedua algoritma ini, jadi katakanlah n adalah jumlah fitur dan m adalah jumlah dari data latih. Jadi, kapankah kita seharusnya menggunakan satu algoritma ketimbang yang lainnya? Nah, jika n relatif besar dibandingkan dengan ukuran data latih anda, jadi sebagai contoh, jika anda berpikir mengenai hal ini dengan jumlah fitur yang jauh lebih besar daripada m, dan ini mungkin, sebagai contoh, jika anda memiliki suatu permasalahan klasifikasi teks, yang anda tahu, dimensi dari vektor fitur adalah, saya tidak tahu, mungkin, 10 ribu. Dan jika ukuran data latih anda, mungkin, 10 sampai dengan, anda tahu, sampai 1000. Jadi, bayangkanlah suatu permasalahan klasifikasi spam, dengan setiap e-mail mewakili 10.000 fitur yang mewakili 10.000 kata, namun anda (hanya) memiliki, anda tahu, mungkin 10 data latih atau mungkin sampai dengan 1000 data latih. Jadi jika n besar relatif terhadap m, maka yang biasanya akan saya lakukan adalah menggunakan regresi logistik atau menggunakannya sebagai m tanpa menggunakan kernel atau dengan kata lain, dengan kernel linear. Karena, jika anda memiliki begitu banyak fitur dan set data latih berukuran kecil, anda tahu, suatu fungsi linear kemungkinan akan berfungsi dengan baik, dan jika anda tidak benar-benar memiliki data yang cukup untuk melakukan fitting terhadap fungsi nonlinear yang sangat rumit. Sekarang jika n kecil, sedangkan m bernilai sedang, maksud saya disini adalah n mungkin besarnya 1 - 1000, nilai 1 akan dianggap sangat kecil. Namun mungkin sampai dengan 1000 fitur dan jika jumlah dari data latih adalah sekitar mulai dari 10, anda tahu, 10 sampai dengan mungkin 10.000 contoh, atau mungkin sampai dengan 50.000 contoh. Jika m cukup besar, misalnya kira-kira 10.000, namun tidak sampai satu juta, jadi jika m berukuran sedang maka sering kali suatu SVM dengan kernel linear akan bekerja dengan baik. Kita telah membicarakan tentang hal ini seawal mungkin, dengan satu contoh konkret, yaitu jika anda memiliki data latih berdimensi 2. Jadi jika n = 2 dimana anda telah memiliki, anda tahu, data latih dalam jumlah yang cukup besar. (dalam kasus ini) kernel Gaussian akan memberikan hasil yang cukup baik dalam memisahkan kelas positif dan negatif. Suatu skenario ketiga yang menarik adalah jika n bernilai kecil sedangkan m besar. Jadi jika n adalah, mungkin 1 sampai 1000, atau lebih besar, namun m, mungkin 50.000 atau lebih hingga jutaan. Jadi, 50 ribu, seratus ribu, satu juta, satu triliun. Artinya anda memiliki ukuran data latih yang sangat, sangat besar. Jadi dalam kasus ini, suatu SVM dengan kernel Gaussian akan berjalan dengan agak lambat. Paket-paket SVM yang tersedia saat ini, jika anda menggunakan kernel Gaussian, cenderung agak mengalami kesulitan. Jika anda memiliki, anda tahu, mungkin 50 ribu data masih dapat tertangani dengan baik, namun jika anda memiliki satu juta contoh data latih, mungkin atau bahkan 100 ribu dengan nilai m yang sangat besar. Paket SVM yang tersedia saat ini sudah sangat bagus, namun mereka bisa jadi masih mengalami sedikit kesulitan jika anda memiliki ukuran data pelatihan yang sangat, sangat besar ketika menggunakan Kernel Gaussian. Jadi pada kasus semacam itu, apa yang akan saya lakukan adalah mencoba untuk menciptakan lebih banyak fitur secara manual dan kemudian menggunakan regresi logistik atau sebuah SVM tanpa kernel. Dan seandainya anda melihat pada slide ini dan anda melihat regresi logistik atau SVM tanpa kernel, pada kedua tempat ini, saya telah semacam memasangkan keduanya. Ada alasan untuk itu, yaitu bahwa regresi logistik dan SVM tanpa kernel, keduanya adalah algoritma-algoritma yang cukup mirip, dan anda tahu, salah satu dari baik regresi logistik atau SVM tanpa kernel biasanya akan melakukan hal-hal yang hampir sama dan menghasilkan performa yang hampir sama, namun bergantung pada detail implementasi anda, salah satu mungkin lebih efisien daripada yang lainnya. Namun, dimana salah satu dari algoritma-algoritma ini dapat diterapkan, regresi logistik atau SVM tanpa kernel, yang satunya kemungkinan akan juga dapat bekerja dengan baik. Namun kekuatan dari SVM adalah apabila anda mempergunakan berbagai kernel yang berbeda untuk mempelajari fungsi-fungsi nonlinear kompleks. Dan rezim ini, anda tahu, ketika anda memiliki mungkin sampai dengan 10 ribu contoh, mungkin sampai dengan 50 ribu, dan jumlah fitur anda cukup besar. Itu adalah rezim yang cukup umum dan mungkin merupakan rezim dimana sebuah SVM dengan kernel Gaussian akan memberikan performa yang cemerlang. Mereka dapat melakukan hal-hal yang lebih sulit dilakukan jika hanya mempergunakan regresi logistik saja. Dan akhirnya, dimanakah posisi dari jaringan syaraf tiruan (neural network)? Nah, untuk semua dari permasalahan ini, dan juga untuk semua rezim yang berbeda ini, jaringan syaraf tiruan yang dirancang akan juga dapat bekerja dengan sama baiknya. Salah satu kerugian, atau salah satu alasan mengapa kita terkadang tidak mempergunakan jaringan syaraf tiruan adalah, untuk beberapa dari permasalahan ini, jaringan syaraf tiruan mungkin membutuhkan waktu lama dalam proses pelatihannya. Namun jika anda memiliki paket implementasi SVM yang sangat baik, itu bisa jadi dapat berjalan dengan lebih cepat daripada jaringan syaraf tiruan anda. Dan, meskipun kita tidak menunjukkan hal ini sebelumnya, ternyata permasalah optimasi yang dimiliki oleh SVM adalah suatu permasalahan optimasi konveks, sehingga paket perangkat lunak optimasi SVM yang baik akan selalu dapat menemukan titik minimum global atau sesuatu yang dekat dengan itu. Sehingga untuk SVM, anda tidak perlu khawatir mengenai optima lokal. Dalam praktek optima lokal bukanlah suatu permasalahan besar bagi jaringan syaraf tiruan namun ini adalah satu hal yang tidak perlu dikhawatirkan jika anda menggunakan SVM. Dan tergantung pada permasalahan anda, jaringan syaraf tiruan bisa jadi lebih lambat daripada SVM, terlebih pada rezim seperti ini. Seandainya panduan yang telah diberikan disini terkesan agak kurang jelas, dan jika anda sedang melihat pada suatu permasalahan dan berpikir, "Panduan ini masih agak kurang jelas, saya masih tidak sepenuhnya yakin, apakah seharusnya saya menggunakan algoritma ini atau algoritma itu?", hal ini betul-betul tidak mengapa. Ketika saya menghadapi suatu permasalahan pembelajaran mesin, anda tahu, terkadang tidak jelas apakah algoritma itu adalah yang terbaik untuk digunakan, namun sebagaimana anda lihat pada video-video sebelumnya, sungguh, anda tahu, memang algoritma itu penting, namun yang seringkali bahkan lebih penting adalah hal-hal seperti, berapa banyak data yang anda miliki dan seperapa terampilnya anda, seberapa bagusnya anda dalam melakukan analisis error dan melakukan debugging algoritma pembelajaran, menemukan cara untuk mendesain fitur baru dan menentukan fitur-fitur lain apa yang sebaiknya anda berikan kepada algoritma pembelajaran dan seterusnya. Dan seringkali hal-hal itu akan lebih berpengaruh daripada apakah anda menggunakan regresi logistik atau SVM. Namun, setelah mengatakan itu, SVM saat ini masih secara luas dianggap sebagai salah satu dari algoritma pembelajaran yang paling ampuh, dan ada kasus dimana ada cara yang sangat efektif untuk mempelajari fungsi nonlinear kompleks. Dan, karena itu saya, bersama dengan regresi logistik, jaringan syaraf tiruan, SVM, menggunakan algoritma-algoritma tersebut untuk pembelajaran dengan cepat, saya pikir anda berada pada posisi yang sangat baik untuk dapat membangun sistem pembelajaran mesin state-of-the-art untuk suatu jangkauan aplikasi yang luas, dan ini adalah satu lagi perangkat yang sangat ampuh untuk dimiliki dalam 'persenjataan' anda; sesuatu yang dipergunakan di seluruh tempat di Silicon Valley, atau oleh industri dan pada lingkungan akademik, untuk membangun banyak sistem pembelajaran mesin berperforma tinggi.