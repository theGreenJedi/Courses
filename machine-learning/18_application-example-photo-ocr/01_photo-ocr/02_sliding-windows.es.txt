En el video anterior, hablamos acerca flujo de proyecto para el «foto OCR» y de como funcionaba. En el que tomaríamos una imagen y pasarla a través de una secuencia de componentes de aprendizaje electrónico con el fin de intentar leer el texto que aparece en la imagen. En este vídeo, quiero platicarte un poquito mas acerca de como trabaja cada uno de los componentes del flujo de trabajo para el «foto OCR». Particularmente este video se centrará en discutir sobre lo que llamamos ventanas deslizables. La primer etapa del filtro del flujo del proyecto era la detección del texto, en donde observamos una imagen como esta e intentamos encontrar regiones de texto que aparezcan en esta imagen. Detectar texto es un problema inusual en la visión por computadora. Porque dependiendo de la longitud del texto que estás intentando encontrar, estos rectángulos que estas tratando de encontrar pueden tener una proporción diferente. Así que, para hablar acerca de detectar cosas en imágenes, comencemos con un ejemplo más sencillo de detección peatonal y luego regresamos a aplicar las ideas que fueron desarrolladas en detección peatonal en detección peatonal y las aplicaremos a detección de texto. Así que en la detección peatonal quieres tomar una imagen que se vea como esta y encontrar individualmente los peatones que aparecen en la imagen. Ahí encontramos un peatón, ahí hay un segundo, un tercero, un cuarto, un quinto, y un sexto. Este problema puede ser ligeramente mas sencillo que la detección de texto, por la sola razón que la proporción de la mayoría de los peatones son muy similares. Utilizando simplemente una proporción fija para estos rectángulos que estamos intentando encontrar. Cuándo me refiero a la proporción, lo que intento decir es a la relación entre la altura y ancho de estos rectángulos. Todos son iguales para los distintos peatones, pero para detección de texto, la proporción de altura y ancho es distinta para las diferentes lineas de texto Aunque para detección de peatones, los peatones pueden estar a distintas distancias de la cámara y por eso la altura de estos rectángulos pueden ser diferentes dependiendo que tan alejados se encuentren, pero la proporción es la misma. Con el fin de construir un sistema de detección de peatones, aquí está como podemos hacerlo. Digamos que decidimos estandarizar para esto una proporción de 80 x 36, pudimos haber escogido algún número redondeado como 80 x 40 o algo así, pero 82 x 36 parece ser el correcto. Lo que debemos hacer entonces, es recolectar un conjunto grande de ejemplos positivos y negativos. Aquí hay ejemplos de pedazos de imagen de 82 x 36 que contienen peatones y aquí hay ejemplos de imágenes que no. En esta diapositiva te muestro 12 ejemplos positivos de y=1 y 12 ejemplos de y=0. En una aplicación mas típica de detección de peatones, podríamos tener desde unos mil ejemplos de entrenamiento, hasta tal vez unos 10 mil ejemplos de entrenamiento, o tal vez mas si logras obtener conjuntos de entrenamiento mas grandes. Lo que puedes hacer, es entrenar en tu red o algún otro algoritmo de aprendizaje para obtener esta entrada. Un pedazo de imagen de dimensión 82 por 36, y clasificar ’y’ y para clasificar el pedazo de esa imagen ya se que contenga o no un peatón. Esto es una forma de aplicar aprendizaje supervisado, ocupando un pedazo de imagen y poder determinar si aparece o no un peatón en la imagen capturada. Ahora, digamos que obtuvimos una imagen nueva, un conjunto de imágenes de prueba como esta y queremos intentar encontrar un peatón que aparezca en la imagen. Lo que podemos hacer, es iniciar tomando un pedazo rectangular de esta imagen como se muestra aquí, y tal vez un pedazo de 82 x 36 de esta imagen y ejecutar a través de nuestro clasificador ese pedazo de imagen para determinar ya sea que hay o no un peatón en ese pedazo de imagen y con suerte nuestro clasificador nos regresará y=0 para este pedazo, ya que no hay un peatón. Después, tomamos ese rectángulo verde y lo deslizamos un poquito por encima y ejecutamos a ese nuevo pedazo de imagen nuestro clasificador para decidir si hay un peatón ahí. Después de haber hecho eso, deslizamos la ventana hacia adelante por la derecha y le ejecutamos a ese pedazo nuestro clasificador otra vez. La cantidad que intercalas por encima del rectángulo cada vez es un parámetro, a la que algunas veces se llama parámetro del tamaño de paso, algunas veces también llamado el parámetro de avance si pasas por encima a un pixel a la vez. Así que puedes usar el tamaño de paso o el parámetro de avance de 1, que generalmente se desempeña mejor, pero es mas «caro», y si usas un tamaño de paso de tal vez 4 pixeles cada vez, u 8 pixeles a la vez o un número grande de pixeles puede ser mas simple ya que estas moviendo el rectángulo un poquito mas cada vez. Entonces, utilizando este proceso, vas pasando por encima el rectángulo a la derecha un poquito a la vez y ejecutando a través del clasificador cada uno de los pedazos hasta que finalmente deslizaste esta ventana por encima de las diferentes posiciones en la imagen. Primero inicias por la primer fila y después avanzas por las siguientes filas de la imagen, habrás entonces ejecutado a través de tu clasificador todos los diferentes pedazos de imagen a algún un tamaño de paso o de avance. Ahora, ese era un rectángulo muy pequeño, que solo detecta peatones de un tamaño específico. Entonces lo que debemos hacer después es empezar a ver en pedazos de imagen mas grandes. Vamos a tomar pedazos de imagen mas grandes, como esos que se muestran aquí y ejecutar esos a través del fuego cruzado también. Por cierto, cuando digo tomar pedazos de imagen mas grandes, lo que realmente quiero decir es que cuando tomas un pedazo de imagen como este, lo que realmente estás haciendo es tomar es pedazo de imagen y reducirlo en tamaño a 82 x 36. Así que tomas ese pedazo mas grande y lo redimensionas a para que sea una imagen mas pequeña y sera la imagen mas pequeña que sera la que pases a través de tu clasificador para intentar y decidir si hay un peatón en ese pedazo. Y finalmente puedes hacer esto inclusive a escalas mayores y ejecutar ese tamaño de ventana al final. Y, después de todo este proceso, con suerte tu algoritmo detectará cuando aparece un peatón en la imagen. Así es como entrenas a tu supervisor de aprendizaje del clasificador, y después utilizas el clasificador de ventanas deslizantes, o utilizas un detector de ventanas deslizantes con el fin de encontrar peatones en la imagen. Regresemos al ejemplo de detección de texto y hablemos acerca de esa etapa en nuestro flujo de proyecto para el «foto OCR», donde nuestra meta es encontrar unidades de regiones de texto. Al igual que en la detección de peatones puedes salir con un conjunto mas grande de ejemplos positivos y ejemplos negativos, con ejemplos positivos correspondientes a regiones donde aparece texto. Entonces, en vez de intentar detectar peatones, ahora intentaremos detectar texto. Ahora los ejemplos positivos van a ser pedazos de imágenes donde hay texto. Y los ejemplos negativos van a ser pedazos de imágenes donde no hay texto. Habiendo entrenado este clasificador podemos aplicarlo a una nueva imagen, dentro de un conjunto de pruebas de imagen. Aquí esta la imagen que hemos utilizado como ejemplo. Ahora, vamos a ejecutar para este ejemplo, las ventanas deslizantes a una sola escala fija con el propósito de ilustración, me refiero a que solo voy a utilizar un solo tamaño de rectángulo. Pero digamos que ejecuto mi pequeño clasificador de ventanas en muchos pequeños pedazos de imagen como este, si hago eso, lo que obtendré al final será un resultado como este, que es una región blanca que muestra donde mi sistema de detección de texto encontró texto y si el eje de estas dos figuras son las misma entonces hay una región aquí, y por supuesto también una región aquí, entonces en virtud que aquí es negro representa que el clasificador piensa que no encontró ningún texto ahí, mientras que de hecho ahí hay muchas cosas blancas, que reflejan que el clasificador piensa que encontró un montón de texto sobre esa parte de la imagen. Lo que hice en esta parte inferior de la izquierda es en realidad usar blanco para mostrar donde el clasificador piensa que ha encontrado texto. Y las diferentes tonalidades de gris corresponden a la probabilidad que haya salido por el clasificador, entonces, como las tonalidades de gris corresponden a donde piensa que tal vez pueda haber texto pero tiene menos confianza por la respuesta a la brillantez del blanco donde ha salido con una mayor probabilidad, probabilidad estimada de que existan peatones en esa ubicación. Todavía no hemos terminado del todo porqué lo que realmente queremos hacer es dibujar rectángulos alrededor de toda la región donde hay texto en la imagen, entonces vamos a realizar un paso mas en donde tomaremos la salida del clasificador y le aplicaremos lo que es llamado operador de expansión. Pero, lo qué es, toma la imagen aquí, y toma cada una de las manchas blancas, toma cada una de las regiones blancas y la expande. Matemáticamente, la manera en que lo implementas es, si ves la imagen de la derecha, lo que hacemos para crear la imagen en la derecha es, por cada pixel nos vamos a preguntar si esta dentro de alguna distancia de un pixel blanco en la imagen de la izquierda Y, entonces, si un pixel específico esta dentro de digamos, 5 pixeles o 10 pixeles de un pixel blanco la imagen de hasta la izquierda, entonces también coloreamos ese pixel de blanco en la imagen de hasta la derecha. Así, el efecto de esto es, tomamos cada una de las machas blancas en la imagen de hasta la izquierda y las extendemos un poco, creciendolas un poquito, viendo donde los pixeles cercanos, los pixeles blancos, y coloreamos esos pixeles cercanos también de blanco. Finalmente, ya casi terminamos. Ahora podemos ver en esta imagen de hasta la derecha y solo ver los componentes que se conectan y ver las regiones blancas contiguas y dibujar cajas delimitadoras alrededor de ellas. De forma particular, si vemos todas la regiones blancas, como esta, esta, esta otra, y así sucesivamente, y si usamos una heurística simple para descartar rectángulos cuya proporción se ve rara, porque sabemos que las cajas alrededor de los textos deben ser mas anchas de que lo que son altas. Así que si ignoramos las manchas delgadas altas como esta y esta otras, y descartamos estas porque son muy altas y delgadas, y entonces dibujamos rectángulos alrededor de aquellas cuya proporción de su rango de altura la hace parecer a una región de texto, entonces podemos dibujar los rectángulos, cajas delimitadoras alrededor de la región del texto, esta región, y esa región de texto, correspondiente al logotipo de «Lula B´s antique mall», y la pequeña señal de «Abierto» de por allá. A este ejemplo por cierto, realmente le falta una pieza de texto. Esta es muy difícil de leer, pero ahí hay una pieza de texto. Que dice «Lula B's...» que corresponde a esto, pero su proporción se ve mal por lo que la descartamos. pero sabes que esta bien en esta imagen, pero en este ejemplo en particular el clasificador se salto esta pieza de texto. Es muy difícil de leer porque es una pieza de texto escrita sobre una ventana transparente. Entonces, esto es la detección de texto usando ventanas deslizables. Y habiendo encontrado estos rectángulos con texto adentro, ahora podemos cortar solo estas regiones de imagen y utilizarlas después en etapas posteriores del flujo para intentar conocer el texto. Ahora, recuerda que la segunda etapa del flujo del proyecto era la segmentación de caracteres, así que tomando una imagen como la que se muestra hasta arriba, ¿Cómo podemos segmentar individualmente los caracteres en esta imagen? Así que lo que podemos hacer es utilizar nuevamente un algoritmo de aprendizaje supervisado con algún conjunto de ejemplos positivos y algún conjunto de ejemplos negativos, lo que haremos es ver en el pedazo de imagen e intentar decidir si hay una división entre dos caracteres justo en medio de esa coincidencia de imagen. Así que para ejemplos positivos iniciales este primer ejemplo positivo, este pedazo de imagen se ve como el centro, de hecho es el centro que se ha dividido en dos caracteres y el segundo ejemplo de nuevo se ve como un ejemplo positivo, porque si separo dos caracteres mediante una linea justo en el centro, eso es lo que se debe hacer. Así, estos son ejemplos positivos, en los que el centro de la imagen representa un espacio o una separación entre dos caracteres distintos, a diferencia de los ejemplos negativos, bueno, como sabes, no quieres separar dos caracteres justo en el centro dos veces de esa forma, y así estos son ejemplos negativos porque no representan el punto medio entre dos caracteres. Así que lo que vamos a hacer es que vamos a entrenar al clasificador, tal vez utilizando una nueva red, tal vez utilizando un algoritmo de aprendizaje distinto, para intentar clasificar los ejemplos positivos y negativos. Habiendo entrenado a dicho clasificador, entonces podemos ejecutarlo en este tipo de texto que nuestro sistema de detección de texto ha obtenido. Mientras comenzamos a ver el rectángulo, y nos preguntamos, «Caramba, ¿se ve como el centro de aquel rectángulo verde?, ¿se ve como el punto medio entre dos caracteres?» Y con suerte, el clasificador dirá que no, entonces deslizamos la ventana por encima, este es un clasificador de deslizamiento de ventana unidimensional, porque vamos a deslizar la ventana solamente en una linea recta de izquierda a derecha, no hay distintas filas aquí. Aquí solo hay una sola fila. Pero ahora, con el clasificador en esta posición, nos preguntamos, ¿Debemos separar esos dos caracteres o debemos poner una división justo en medio de este rectángulo? Y con suerte, el clasificador dirá dará como salida y=0, siendo este caso decidiremos dibujar una linea ahí, para intentar dividir dos caracteres. Entonces deslizamos la ventana por encima de nuevo, proceso óptico, no cerramos el espacio, deslizamos por encima de nuevo, el óptico dice que si, lo separamos ahí y continuamos lentamente deslizando el clasificador por encima a la derecha y con suerte clasificará este como otro ejemplo positivo y así sucesivamente. Y deslizaremos esta ventana sobre la derecha, ejecutando el clasificador a cada paso, y con suerte nos dirá, como ya sabes, cuales son las ubicaciones correctas para separar estos caracteres, solo separa esta imagen en caracteres individuales. Y así es el deslizamiento 1D de ventanas para segmentación de caracteres. Así que, aquí esta de nuevo completo el flujo de proyecto para el «foto OCR». En este video hablamos acerca del paso de detección de texto, donde utilizamos ventanas deslizantes para detectar texto. También utilizamos ventanas deslizantes unidimensionales para realizar segmentación de caracteres para separarlos, como sabes, esta imagen de texto en división de caracteres. El paso final a través del flujo de proyecto es el paso de clasificación de caracteres y con ese paso ya deberías estar mucho mas familiarizado con los videos anteriores en el aprendizaje supervisado donde puedes aplicar un aprendizaje supervisado estándar dentro de, tal vez, tu red o tal vez algo mas con el fin de tomar las entradas, una imagen como esa y clasificarla como alfabeto de 26 caracteres, de la A a la Z, o tal vez deberíamos tener 36 caracteres si ocupas los dígitos numéricos también, el problema de la clasificación múltiple donde tomas las entradas y la imagen que contiene caracteres y decides ¿cual es el caracter que aparece en esa imagen? Así que, ese fue el flujo de proyecto para el «foto OCR» y como puedes utilizar ideas como el clasificador de ventanas deslizantes con el fin de unir estos diferentes componentes para desarrollar un sistema de «foto OCR». En los próximos videos seguiremos utilizando el problema de «foto OCR» para explorar de alguna forma situaciones interesantes alrededor de construir una aplicación similar.