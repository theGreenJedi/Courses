nei precedenti video, Ho precisato più volte che, quando sviluppate sistemi di machine learning, una delle più preziose risorse è il vostro tempo, in qualità di sviluppatori, nel selezionare i passi successivi. Oppure se avete un team di sviluppatori o un team di ingegneri che lavorano in concerto ad un sistema di autoapprendimento, una delle risorse più importanti è ancora rappresentata dal tempo che gli ingegneri e gli sviluppatori dedicano al progetto. Ciò che veramente dovrete evitare è che voi oppure i vostri colleghi od amici, spendiate parecchio tempo lavorando su un particolare componente, per realizzare solo dopo settimane o mesi che tutto quel lavoro, per qualche motivo, non ha apportato un gran miglioramento nelle performances del sistema. In questo video, ciò che mi impegno a fare, è parlare di un concetto chiamato ceiling analysis. Quando voi o il vostro team state lavorando ad un pipeline machine learning system, questo sistema può in qualche occasione, darvi un segnale forte o una guida su quale parte della pipeline sarà più proficuo investire il vostro tempo. Per illustrare la ceiling analysis, continuerò ad usare l'esempio della photo OCR pipeline e come già detto in precedenza, ognuno di questi riquadri: text detection (rilevamento testi), character segmentation (isolamento caratteri), character recognition (riconoscimento caratteri) ognuno di questi elementi, può avere un piccolo team di ingegneri che ci lavora, oppure l'intero sistema potrebbe essere gestito da voi ma, in ogni caso, la questione sarà relativa a come allocare le risorse. Quali di questi elementi merita di aggiudicarsi il vostro maggior sforzo, nel tentativo di aumentarne le prestazioni? Per spiegare il concetto della ceiling analysis, utilizzerò sempre l'esempio della nostra photo OCR pipeline. Come menzionato precedentemente, ogni elemento qui rappresentato, ciascuno di questi componenti potyrebbe rappresentare il lavoro di un piccolo team di ingegneri, oppure l'intero sistema potrebbe essere gestito da una sola persona. La domanda è, dove dovrò allocare le maggiori, seppure scarse, risorse? Su quali di questi componenti, o su quale, se uno solo oppure su due o su tutti e tre i componenti è più proficuo investire il proprio tempo nel tentativo di aumentare le prestazioni dell'intero sistema? Ecco a cosa ci servirà la ceiling analysis. Come nel processo di sviluppo per altri sistemi di machine learning, con l'intento di prendere decisioni su cosa fare per sviluppare il sistema, è sicuramente molto utile avere un sistema univoco di valutazione per questo sistema di autoapprendimento. Decidiamo di basarci sul livello di accuratezza dei caratteri. Così, scelto un arbitrario test set di immagini, otterremo che solo una frazione dell'alfabeto dei caratteri nell'immagine testata sarà riconosciuto correttamente. Potete anche utilizzare il numero di parole singole riconosciute come metrica di valutazione, se volete ma diciamo che qualunque metrica valutativa avrete scelto, otterremo che l'accuratezza del sistema risulta essere del 72%. In altre parole, abbiamo alcuni gruppi di immagini campione e ogni set di immagini, lo facciamo passare attraverso la text section, poi character segmentation ed infine character recognition, ottenendo che per il nostro set di test, l'accuratezza globale dello intero sistema risulta del 72%, in base alla metrica scelta. Ora, l'idea alla base della ceiling analysis è che adesso noi andremo a considerare il primo modulo della pipeline: text detection e ciò che andremo a fare sarà di "giocare" con il set di test. Noi altereremo il test set e per ogni campione di esempio noi forniremo al passo Text detection il corretto risultato. In altre parole, altereremo il test set manualmente dicendo noi all'algoritmo esattamente dove è presente testo in ognuno degli esempi di test. Così, in altre parole, simuleremo cosa accadrebbe se avessimo un algoritmo di text detection funzionante con il 100% di accuratezza, per il compito di rilevare la presenza di testo in un'immagine. E il modo in cui lo faremo è molto semplice, al posto di permettere al vostro algoritmo di apprendimento di individuare il testo all'interno delle immagini, voi accederete alle immagini e manualmente etichetterete quale è la posizione del testo nel set di test. In seguito aggiornerete con questi dati corretti, queste etichette contenenti la corretta posizione del testo, il vostro set di test e userete questi dati che avete fornito per passarli al prossimo stadio della pipeline, character segmentation pipeline. Così, diciamolo ancora, mettendo la spunta in questo punto, ciò che intendo è che prendo il mio set di test e lo aggiorno inserendo informazioni corrette, dando le corrette etichette per l'algoritmo di text detection della pipeline. Così come se simulassi un perfetto sistema di riconoscimento del testo sul mio set di test. una volta fatto girare questi dati attraverso il resto della pipeline Character segmentation e Character recognition. In seguito utilizzerò la stessa metrica di prima, per misurare l'accuratezza globale dell'intero sistema. E con un miglior text detection, le prestazioni aumenteranno. Diciamo che aumentano all'89%. Cosa faremo dopo? Ci sposteremo alla prossima sezione della pipeline, Character segmentation e questa volta andremo ad assegnare ai valori corretti del test set per il text detection anche i valori corretti del character segmentation e manuamente etichetteremo nel test set i segmenti di carattere del testo in caratteri individuali Per verificare quanto questo migliori il sistema. E diciamo che questo aumenta le prestazioni globali del sistema al 90%. Come sempre l'accuratezza è l'accuratezza globale del sistema. Così che qualsiasi sia l'output del sistema di riconoscimento dei caratteri, qualsiasi sia l'output finale dell'intera pipeline, noi misureremo l'accuratezza di quello. infine ci sposteremo al sistema di riconoscimento caratteri e forniremo manualmente le corrette etichette e, facendo questo, non ci stupiremo di rilevare un 100% di acuratezza globale. Ora, la cosa interessante che si evince dopo l'analisi appena fatta è che possiamo ora comprendere quale vantaggio comporterebbe il miglioramento di ogni singolo componente. Così abbiamo rilevato che con un perfetto text detection la nostra performance è aumentata dal 72 al 89 per cento, un 17% di guadagno in prestazioni.