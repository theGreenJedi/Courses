1
00:00:00,090 --> 00:00:01,270
我不止一次的提到

2
00:00:01,570 --> 00:00:03,160
要想获得一个比较高效的

3
00:00:03,300 --> 00:00:04,800
机器学习系统

4
00:00:05,040 --> 00:00:06,170
其中一种最可靠的办法是

5
00:00:06,550 --> 00:00:07,860
选择一个低偏差的学习算法

6
00:00:08,750 --> 00:00:10,220
然后用一个巨大的训练集来训练它

7
00:00:11,230 --> 00:00:12,830
但你从哪儿得到那么多的训练数据呢？

8
00:00:13,510 --> 00:00:14,440
其实在机器学习中

9
00:00:14,820 --> 00:00:16,520
有一个很棒的想法

10
00:00:17,220 --> 00:00:19,000
叫做“人工数据合成”（artificial data synthesis）

11
00:00:19,370 --> 00:00:20,740
这个概念不针对某一个具体的问题

12
00:00:20,980 --> 00:00:22,120
要解决某个具体的问题

13
00:00:22,360 --> 00:00:25,060
通常还是依赖某个具体的思想 方法和观点

14
00:00:25,780 --> 00:00:27,170
但如果你把这个概念

15
00:00:27,580 --> 00:00:29,120
应用到你的机器学习问题中

16
00:00:29,230 --> 00:00:30,270
你有时就能用

17
00:00:30,510 --> 00:00:31,600
一种很容易的方法

18
00:00:31,680 --> 00:00:33,470
来为学习算法获取大量的训练集数据

19
00:00:33,900 --> 00:00:35,520
人工数据合成的概念

20
00:00:36,230 --> 00:00:38,410
通常包含两种不同的变体

21
00:00:38,590 --> 00:00:40,210
第一种是

22
00:00:40,650 --> 00:00:41,940
我们白手起家

23
00:00:42,520 --> 00:00:44,940
来创造新的数据

24
00:00:45,380 --> 00:00:46,700
第二种是

25
00:00:46,930 --> 00:00:48,350
我们已经有了一小部分

26
00:00:48,590 --> 00:00:49,970
带标签的训练集

27
00:00:50,210 --> 00:00:51,490
我们可以扩大这个训练集

28
00:00:51,840 --> 00:00:52,680
就是说用一个小的训练集

29
00:00:52,980 --> 00:00:54,390
将它扩充为一个

30
00:00:54,660 --> 00:00:56,290
大的训练集

31
00:00:56,450 --> 00:00:58,120
这节课中 我们将对这两种方法进行介绍

32
00:01:00,350 --> 00:01:02,220
为了介绍人工数据合成的概念

33
00:01:02,440 --> 00:01:04,030
让我们还是用之前用过的

34
00:01:04,330 --> 00:01:06,930
照片OCR流水线中

35
00:01:07,090 --> 00:01:08,470
的字母识别问题

36
00:01:08,690 --> 00:01:09,710
我们输入一个图像数据

37
00:01:10,060 --> 00:01:11,370
然后想识别出是什么字母

38
00:01:13,330 --> 00:01:14,690
假如我们可以在别处

39
00:01:14,880 --> 00:01:16,270
收集到一大堆标签数据

40
00:01:16,890 --> 00:01:17,980
这就是这堆数据

41
00:01:18,580 --> 00:01:21,770
在这个例子中 我选择的是正方形长宽比的图像

42
00:01:22,130 --> 00:01:23,250
也就是我们选用正方形的图像块

43
00:01:24,180 --> 00:01:25,110
目标就是对任意一个图像块

44
00:01:25,770 --> 00:01:27,420
我们要能识别出

45
00:01:27,530 --> 00:01:29,270
图像中心的那个字符

46
00:01:31,090 --> 00:01:31,990
同时 为了方便

47
00:01:32,660 --> 00:01:33,740
我把这些图像都视为灰度图像

48
00:01:34,240 --> 00:01:36,380
而不是彩色图像

49
00:01:36,870 --> 00:01:38,550
实际上用彩色的图像

50
00:01:38,930 --> 00:01:41,180
对这个问题的解决也起不了多大作用

51
00:01:42,190 --> 00:01:43,530
所以对这个图像块

52
00:01:43,660 --> 00:01:44,890
我们会识别出中心的字符是一个T

53
00:01:45,010 --> 00:01:46,230
而考虑这个图像块

54
00:01:46,550 --> 00:01:47,920
我们会将它识别为一个S

55
00:01:49,540 --> 00:01:50,740
而对这个图像块

56
00:01:50,850 --> 00:01:52,950
我们会将它识别为一个I 等等

57
00:01:54,110 --> 00:01:55,310
所有这些

58
00:01:55,450 --> 00:01:57,240
就是我们的原始图像

59
00:01:57,380 --> 00:01:59,460
我们怎样获得一个更大的训练集呢

60
00:02:00,000 --> 00:02:01,580
现代计算机通常都有一个

61
00:02:01,640 --> 00:02:03,700
很大的字体库

62
00:02:03,890 --> 00:02:05,330
如果你使用一个文字处理软件

63
00:02:05,950 --> 00:02:07,090
你就会有所有这些字体

64
00:02:07,240 --> 00:02:08,580
或者别的很多很多字体

65
00:02:08,800 --> 00:02:09,980
已经储存在字体库中

66
00:02:10,120 --> 00:02:12,490
这取决于你用的是哪个文字处理软件

67
00:02:12,950 --> 00:02:14,350
同样地 如果你登陆一些的网站

68
00:02:14,680 --> 00:02:16,280
你依然会发现大量的

69
00:02:16,690 --> 00:02:18,200
免费的字体库可供你下载

70
00:02:18,370 --> 00:02:19,960
通常有成百上千种

71
00:02:20,250 --> 00:02:22,580
不同类型的字体样式

72
00:02:23,960 --> 00:02:25,180
所以 如果你想要获得

73
00:02:25,570 --> 00:02:27,020
更多的训练样本

74
00:02:27,100 --> 00:02:28,340
其中一种方法是你可以

75
00:02:28,870 --> 00:02:30,220
采集同一个字符的不同种字体

76
00:02:31,240 --> 00:02:32,870
然后将这些字符

77
00:02:33,290 --> 00:02:35,890
加上不同的随机背景

78
00:02:36,730 --> 00:02:39,500
比如你可以取这个字母C 然后把它粘贴到一个随机背景前面

79
00:02:40,680 --> 00:02:41,640
如果你这样做的话

80
00:02:42,060 --> 00:02:43,830
你现在就有了一个

81
00:02:44,080 --> 00:02:45,260
关于字母C的训练样本

82
00:02:46,360 --> 00:02:47,500
因此在一段时间的重复劳动之后

83
00:02:47,570 --> 00:02:48,920
你知道

84
00:02:48,980 --> 00:02:49,710
要合成这些看起来可靠的数据

85
00:02:49,830 --> 00:02:51,760
还是要花点功夫的

86
00:02:52,180 --> 00:02:53,080
但如果你做完这些工作以后

87
00:02:53,700 --> 00:02:56,130
你就得到了一个合成后的训练集 就像右图所示

88
00:02:57,180 --> 00:02:59,910
右图中每一个图像实际上都是一个合成后的图像

89
00:03:00,360 --> 00:03:02,080
你先得到一种字体

90
00:03:02,810 --> 00:03:04,240
也许是从网上随便下载的

91
00:03:04,400 --> 00:03:05,680
然后你把这个字符的图像

92
00:03:06,160 --> 00:03:07,320
或者一系列字符的图像

93
00:03:07,800 --> 00:03:08,870
粘贴到其他随机的

94
00:03:09,570 --> 00:03:11,440
背景图像前面

95
00:03:12,140 --> 00:03:12,840
然后应用某个模糊操作

96
00:03:13,540 --> 00:03:15,160
模糊的意思是

97
00:03:15,680 --> 00:03:17,380
让图像变形 

98
00:03:17,620 --> 00:03:18,650
比如均匀 等比例缩放

99
00:03:19,350 --> 00:03:20,740
或者一些旋转操作等等

100
00:03:21,000 --> 00:03:22,260
在完成这些操作后

101
00:03:22,370 --> 00:03:23,330
你就得到了这个合成后的训练集

102
00:03:23,580 --> 00:03:25,520
就是右边所示的

103
00:03:26,510 --> 00:03:28,050
而这项工作

104
00:03:28,530 --> 00:03:29,640
要完成这项工作

105
00:03:29,970 --> 00:03:31,460
还是需要仔细考虑

106
00:03:31,700 --> 00:03:33,250
才能得到比较真实的合成数据

107
00:03:34,020 --> 00:03:34,710
如果你搞得很草率的话

108
00:03:35,120 --> 00:03:36,200
你获得的合成数据很可能就不是那么好

109
00:03:36,250 --> 00:03:38,910
这取决于你合成的方法

110
00:03:39,620 --> 00:03:40,600
但如果你仔细看这些合成数据的话

111
00:03:40,790 --> 00:03:43,940
你会发现它们跟真实数据还是非常接近

112
00:03:45,120 --> 00:03:46,850
因此通过使用合成的数据

113
00:03:47,340 --> 00:03:48,550
你实际上已经获得了

114
00:03:48,990 --> 00:03:50,970
无限的训练样本

115
00:03:51,310 --> 00:03:53,060
这就是人工数据合成

116
00:03:53,150 --> 00:03:54,110
所以如果你使用这种

117
00:03:54,330 --> 00:03:55,820
合成数据的话

118
00:03:56,150 --> 00:03:58,100
你实际上也就有了

119
00:03:58,560 --> 00:04:00,000
无限的有标签数据

120
00:04:00,140 --> 00:04:01,610
你可以用它来进行监督学习

121
00:04:02,300 --> 00:04:03,990
解决这个字符识别的问题

122
00:04:05,120 --> 00:04:06,540
这便是一种人工数据合成的实例

123
00:04:07,000 --> 00:04:08,500
你基本上是在

124
00:04:09,040 --> 00:04:10,870
完全创造新的数据

125
00:04:11,080 --> 00:04:13,780
完全创造新的图像数据

126
00:04:14,880 --> 00:04:16,450
人工数据合成的

127
00:04:16,710 --> 00:04:18,210
第二种方法是使用

128
00:04:18,370 --> 00:04:19,610
你已经有的样本

129
00:04:19,740 --> 00:04:20,780
我们选取一个

130
00:04:21,020 --> 00:04:22,430
真实的样本

131
00:04:22,700 --> 00:04:24,130
也许是一个真实的图像

132
00:04:24,770 --> 00:04:26,130
然后你添加别的数据

133
00:04:26,380 --> 00:04:27,900
来扩大你的训练集

134
00:04:28,070 --> 00:04:28,810
这里这幅图像是一个字母A

135
00:04:28,910 --> 00:04:30,490
来自于一个真实的图像

136
00:04:31,410 --> 00:04:32,550
不是一个合成的图像

137
00:04:32,630 --> 00:04:33,790
我在图像上加了一些

138
00:04:33,880 --> 00:04:35,750
灰色的网格 方便描述

139
00:04:36,430 --> 00:04:36,880
实际上是没有这些格子的

140
00:04:36,970 --> 00:04:39,030
因此你要做的就是

141
00:04:39,100 --> 00:04:40,110
取出这个字母A

142
00:04:40,480 --> 00:04:41,500
取出这个图像

143
00:04:42,240 --> 00:04:43,760
进行人工扭曲

144
00:04:44,290 --> 00:04:45,810
或者人工变形

145
00:04:46,040 --> 00:04:47,030
这样从一个图像A

146
00:04:47,220 --> 00:04:48,240
就能生成

147
00:04:48,430 --> 00:04:50,060
16种新的样本

148
00:04:51,110 --> 00:04:52,000
所以用这种方法

149
00:04:52,450 --> 00:04:53,740
你可以把一个很小的

150
00:04:54,090 --> 00:04:55,360
带标签训练集

151
00:04:56,180 --> 00:04:57,190
突然一下扩大

152
00:04:57,300 --> 00:05:00,020
得到更多的训练样本

153
00:05:01,210 --> 00:05:02,360
同样地

154
00:05:02,560 --> 00:05:03,940
要把这个概念投入应用

155
00:05:04,120 --> 00:05:05,060
还是需要仔细考虑的

156
00:05:05,140 --> 00:05:06,270
比如要考虑

157
00:05:06,430 --> 00:05:07,840
什么样的变形是合理的

158
00:05:08,420 --> 00:05:09,460
或者说

159
00:05:09,720 --> 00:05:11,000
怎样才是合理的方法

160
00:05:11,470 --> 00:05:12,760
来扩大你的训练集

161
00:05:13,070 --> 00:05:15,130
对这个特定的

162
00:05:15,260 --> 00:05:17,170
字母识别的例子

163
00:05:17,480 --> 00:05:18,310
引入人工扭曲的方法

164
00:05:18,780 --> 00:05:19,910
可能是个自然的选择

165
00:05:20,090 --> 00:05:21,970
但对于其他一些机器学习应用来说

166
00:05:22,080 --> 00:05:24,180
可能别的变形方法会更加有效

167
00:05:24,860 --> 00:05:25,600
接下来我再演示另一个实例

168
00:05:26,180 --> 00:05:28,750
一个完全不同的领域 语音识别

169
00:05:30,230 --> 00:05:31,480
语音识别的问题是

170
00:05:31,580 --> 00:05:33,450
假如说你有一段音频片段

171
00:05:33,600 --> 00:05:35,010
你希望通过对这段音频的学习

172
00:05:35,350 --> 00:05:37,240
识别出这段音频中

173
00:05:37,460 --> 00:05:38,780
出现了哪些单词

174
00:05:39,510 --> 00:05:41,340
我们来听一下其中一组有标签的训练样本

175
00:05:42,290 --> 00:05:43,190
假如我们现在有一组

176
00:05:43,400 --> 00:05:45,000
带标签的训练样本

177
00:05:45,330 --> 00:05:46,660
是某个人念一组单词的声音

178
00:05:46,860 --> 00:05:48,720
我们现在播放这段音频

179
00:05:49,150 --> 00:05:51,230
0 1 2 3 4 5

180
00:05:51,570 --> 00:05:53,810
好了 这是有个人

181
00:05:54,220 --> 00:05:55,110
在那儿从0数到5

182
00:05:55,450 --> 00:05:57,180
因此你想要

183
00:05:57,290 --> 00:05:58,460
应用某个学习算法

184
00:05:59,380 --> 00:06:01,320
识别出那段音频中的单词

185
00:06:02,040 --> 00:06:04,030
那么 我们应该如何扩大数据呢？

186
00:06:04,390 --> 00:06:05,340
其中一种方法是

187
00:06:06,020 --> 00:06:09,180
为这组数据引入额外的音频变形

188
00:06:09,970 --> 00:06:10,960
这里我要增加一些背景声音

189
00:06:11,640 --> 00:06:14,700
来仿真一个很嘈杂的电话连线

190
00:06:15,360 --> 00:06:16,800
你会听见嘟嘟的声音

191
00:06:16,980 --> 00:06:17,710
那就是这个音轨

192
00:06:17,740 --> 00:06:20,350
跟说话者无关 现在开始播放

193
00:06:20,580 --> 00:06:20,580
0 1 2 3 4 5

194
00:06:21,380 --> 00:06:22,260
好的 这样你就能

195
00:06:22,640 --> 00:06:24,890
听这段音频片段

196
00:06:25,720 --> 00:06:28,600
然后识别出声音

197
00:06:28,960 --> 00:06:30,800
这就好像是另一个有用的训练样本

198
00:06:31,370 --> 00:06:33,230
接下来是另一个训练样本 嘈杂的环境

199
00:06:34,890 --> 00:06:36,870
0 1 2 3 4 5

200
00:06:37,560 --> 00:06:39,060
就好像有车开过去

201
00:06:39,090 --> 00:06:40,280
或者有人走过的声音

202
00:06:40,580 --> 00:06:42,200
还有最后一种

203
00:06:42,450 --> 00:06:43,880
因此 从最初的

204
00:06:44,430 --> 00:06:45,980
最干净清晰的音频片段

205
00:06:46,090 --> 00:06:47,810
也就是最开始无杂质的

206
00:06:47,990 --> 00:06:48,960
一个人从0数到5的声音

207
00:06:49,090 --> 00:06:50,490
我们可以自动地合成一系列

208
00:06:51,790 --> 00:06:54,090
额外的训练样本

209
00:06:54,470 --> 00:06:55,850
这样我们就把一组训练样本

210
00:06:56,410 --> 00:06:57,860
扩大到4组不同的训练样本

211
00:07:00,110 --> 00:07:00,940
好的

212
00:07:01,300 --> 00:07:03,180
让我把最后这段放完

213
00:07:03,340 --> 00:07:07,180
0 1 2 3 4 5

214
00:07:07,530 --> 00:07:08,510
因此有了一组带标签的样本

215
00:07:09,000 --> 00:07:10,260
一开始我们收集到了

216
00:07:10,360 --> 00:07:11,760
一组带标签的样本

217
00:07:11,950 --> 00:07:13,270
一个人从0数到5的声音

218
00:07:14,140 --> 00:07:16,520
然后通过合成一些额外的干扰

219
00:07:17,290 --> 00:07:18,560
引入不同的背景声音

220
00:07:19,000 --> 00:07:20,240
我们就把这一组训练样本

221
00:07:20,370 --> 00:07:21,810
扩大为许多组不同的样本

222
00:07:23,420 --> 00:07:24,480
也不需要费多大劲

223
00:07:25,270 --> 00:07:27,090
只需要自动地为纯净的音频片段

224
00:07:27,680 --> 00:07:30,510
添加这些不同的背景声音

225
00:07:30,740 --> 00:07:31,980
我想对人工合成数据中

226
00:07:33,190 --> 00:07:35,220
引入变形的方法提一点注意事项

227
00:07:35,310 --> 00:07:36,630
如果你想要自己试着做的话

228
00:07:36,810 --> 00:07:38,580
那么你选择要引入的干扰或变形

229
00:07:39,020 --> 00:07:40,300
要能代表你可能会在

230
00:07:40,660 --> 00:07:42,010
测试集中看到的

231
00:07:42,110 --> 00:07:43,680
噪音源或干扰项

232
00:07:44,010 --> 00:07:45,350
所以 对于字符识别这个例子

233
00:07:45,930 --> 00:07:47,230
这种扭曲的方法

234
00:07:47,440 --> 00:07:48,620
事实上还是很合理的

235
00:07:48,770 --> 00:07:49,980
因为像这种扭曲的

236
00:07:50,340 --> 00:07:51,510
图像A的情况

237
00:07:52,000 --> 00:07:53,020
我们确实有可能

238
00:07:53,210 --> 00:07:55,170
在测试集中会遇到

239
00:07:55,370 --> 00:07:57,180
比如这个胖胖的A

240
00:07:57,380 --> 00:08:00,200
还有右上角的这个

241
00:08:00,350 --> 00:08:01,800
我们可以想象会遇到这种写法

242
00:08:03,280 --> 00:08:04,570
而对于音频

243
00:08:04,740 --> 00:08:06,560
我们会希望识别语音

244
00:08:06,970 --> 00:08:07,990
即使是在连线不通畅的情况下

245
00:08:08,480 --> 00:08:09,440
或者是有各种背景杂音的时候

246
00:08:09,590 --> 00:08:10,920
因此对于音频识别

247
00:08:11,230 --> 00:08:12,800
我们同样也需要合成

248
00:08:13,530 --> 00:08:14,770
那些有代表性的样本

249
00:08:14,850 --> 00:08:15,830
那些我们想要分类

250
00:08:15,990 --> 00:08:17,360
并且希望正确识别的样本

251
00:08:18,770 --> 00:08:20,660
相对而言

252
00:08:20,770 --> 00:08:21,940
为你的数据添加一些纯随机的噪声

253
00:08:22,170 --> 00:08:23,760
通常来讲是没什么用的

254
00:08:24,420 --> 00:08:25,170
我不确定你从这里能否看出

255
00:08:25,440 --> 00:08:26,400
但在这里我做的是

256
00:08:26,620 --> 00:08:28,050
这四幅图像中

257
00:08:28,210 --> 00:08:29,540
每一个图像的每一个像素

258
00:08:29,720 --> 00:08:30,710
我都加了一些

259
00:08:30,990 --> 00:08:32,970
随机高斯噪声

260
00:08:33,240 --> 00:08:34,690
所以对每个像素点

261
00:08:35,060 --> 00:08:36,370
也就是像素点的亮度

262
00:08:36,500 --> 00:08:38,880
就只是加了一些高斯随机噪声

263
00:08:39,360 --> 00:08:40,940
因此这是完全没有意义的对吧？

264
00:08:41,650 --> 00:08:43,280
因此 除非你觉得你会在

265
00:08:43,800 --> 00:08:45,510
你的测试集中

266
00:08:45,910 --> 00:08:46,830
遇到这些像素的噪声

267
00:08:46,910 --> 00:08:48,190
否则的话这些随机的噪声

268
00:08:48,660 --> 00:08:51,540
是无意义的 起不来多大作用

269
00:08:52,880 --> 00:08:53,750
但是人工数据合成的过程

270
00:08:54,250 --> 00:08:55,570
怎么说呢

271
00:08:55,640 --> 00:08:56,660
它并没有什么技巧可言

272
00:08:56,710 --> 00:08:57,850
有时候你只能一遍遍地尝试 

273
00:08:58,140 --> 00:09:00,250
然后观察效果

274
00:09:01,280 --> 00:09:02,060
但你在确定需要添加

275
00:09:02,140 --> 00:09:03,170
什么样的变形时

276
00:09:03,870 --> 00:09:04,720
你一定要考虑好

277
00:09:04,820 --> 00:09:06,260
你添加的那些额外的变形量

278
00:09:06,670 --> 00:09:08,180
是有意义的

279
00:09:08,660 --> 00:09:09,720
能让你产生的训练样本

280
00:09:10,110 --> 00:09:11,370
至少在某种程度上

281
00:09:11,880 --> 00:09:13,410
是具有一定的代表性

282
00:09:13,480 --> 00:09:15,830
能代表你可能会在测试集中看到的某种图像

283
00:09:18,100 --> 00:09:19,000
最后 总结一下这节视频

284
00:09:19,150 --> 00:09:19,920
我还想多说一点

285
00:09:20,140 --> 00:09:21,420
关于这种

286
00:09:21,790 --> 00:09:23,360
通过人工数据合成

287
00:09:23,600 --> 00:09:25,610
获得大量数据的方法

288
00:09:26,920 --> 00:09:28,780
同往常一样

289
00:09:29,170 --> 00:09:30,280
在花费大量精力

290
00:09:30,450 --> 00:09:32,020
考虑如何产生大量人工训练样本之前

291
00:09:33,060 --> 00:09:34,140
通常最好应该

292
00:09:34,220 --> 00:09:35,310
先保证你已经有了一个

293
00:09:35,650 --> 00:09:36,540
低偏差的分类器

294
00:09:36,920 --> 00:09:38,350
这样得到大量的数据

295
00:09:38,460 --> 00:09:40,320
才真的会起作用

296
00:09:41,010 --> 00:09:41,840
标准的方法是

297
00:09:41,970 --> 00:09:42,810
画出学习曲线

298
00:09:43,030 --> 00:09:43,970
然后确保你

299
00:09:44,130 --> 00:09:44,920
已经有了一个低偏差

300
00:09:45,000 --> 00:09:47,470
或者高方差的分类器

301
00:09:47,760 --> 00:09:48,650
或者如果你没有

302
00:09:48,720 --> 00:09:50,090
得到一个低偏差的分类器

303
00:09:50,160 --> 00:09:51,040
你还可以尝试另一种方法

304
00:09:51,450 --> 00:09:53,270
那就是增大

305
00:09:53,540 --> 00:09:54,440
分类器的特征数

306
00:09:54,600 --> 00:09:55,650
或者在神经网络中

307
00:09:55,740 --> 00:09:56,710
增大隐藏层单元数

308
00:09:57,180 --> 00:09:58,470
直到你得到一个

309
00:09:58,540 --> 00:10:00,000
偏差比较小的分类器

310
00:10:00,310 --> 00:10:01,820
直到这时

311
00:10:02,040 --> 00:10:04,020
你再来考虑建立

312
00:10:04,260 --> 00:10:05,760
大量的人工训练集

313
00:10:05,860 --> 00:10:06,660
所以你一定要避免的是

314
00:10:06,870 --> 00:10:07,930
花了几个星期的时间

315
00:10:08,110 --> 00:10:08,890
或者几个月的工夫

316
00:10:09,090 --> 00:10:10,370
考虑好了怎么样

317
00:10:10,540 --> 00:10:11,720
能获得比较好的

318
00:10:12,450 --> 00:10:13,260
人工合成数据

319
00:10:13,820 --> 00:10:15,520
然后才意识到 即使获得了大量的训练数据

320
00:10:15,760 --> 00:10:17,410
自己的学习算法的表现

321
00:10:18,030 --> 00:10:20,730
依然没有提高多少

322
00:10:22,190 --> 00:10:23,060
这就是我对你的一点建议

323
00:10:23,420 --> 00:10:24,690
在你花费大量精力

324
00:10:25,030 --> 00:10:26,290
获得大量人工训练集数据之前

325
00:10:26,530 --> 00:10:27,760
建议你应该

326
00:10:28,080 --> 00:10:30,530
先做这样一个测试

327
00:10:31,960 --> 00:10:33,280
第二

328
00:10:33,590 --> 00:10:35,250
当我在解决机器学习问题时

329
00:10:35,690 --> 00:10:37,520
通常我会问我的团队

330
00:10:37,880 --> 00:10:39,210
或者我的学生

331
00:10:39,430 --> 00:10:40,550
我们要付出多少工作量

332
00:10:40,620 --> 00:10:42,810
来获得10倍于我们现有的数据量

333
00:10:46,720 --> 00:10:47,850
每当我面对一个

334
00:10:48,200 --> 00:10:49,760
新的机器学习应用问题

335
00:10:49,980 --> 00:10:50,940
我总会先跟团队坐在一起

336
00:10:51,210 --> 00:10:52,440
讨论这个问题

337
00:10:52,920 --> 00:10:53,870
我曾经一次又一次地

338
00:10:53,970 --> 00:10:55,870
问过这个问题

339
00:10:56,000 --> 00:10:57,540
但让我经常感到

340
00:10:58,390 --> 00:10:59,660
有一点吃惊的是

341
00:11:00,010 --> 00:11:01,070
他们的回答都是

342
00:11:01,680 --> 00:11:02,670
这并不是什么难事

343
00:11:02,930 --> 00:11:03,930
最多花上几天时间

344
00:11:04,250 --> 00:11:05,300
我们就能给一个机器学习问题

345
00:11:05,450 --> 00:11:06,650
获得十倍于我们

346
00:11:06,810 --> 00:11:08,820
现有数据量的数据

347
00:11:09,080 --> 00:11:09,830
而且通常来说

348
00:11:09,950 --> 00:11:11,030
如果你能得到10倍的数据量

349
00:11:11,270 --> 00:11:13,680
那么你一般都能让你的学习算法表现更好

350
00:11:14,060 --> 00:11:15,040
因此 如果你加入

351
00:11:15,260 --> 00:11:16,510
某个产品设计小组

352
00:11:17,820 --> 00:11:18,880
要设计某个

353
00:11:19,110 --> 00:11:20,430
机器学习的应用产品

354
00:11:20,550 --> 00:11:21,710
那么这也是一个很好的问题

355
00:11:22,290 --> 00:11:23,500
你可以问问自己 问问团队

356
00:11:23,650 --> 00:11:25,120
也不必太惊讶

357
00:11:25,240 --> 00:11:26,530
说不定几分钟的头脑风暴以后

358
00:11:26,650 --> 00:11:27,520
你的团队就会想出一种方法

359
00:11:27,660 --> 00:11:28,950
真的一下子能获得

360
00:11:29,200 --> 00:11:30,250
10倍的数据量

361
00:11:30,380 --> 00:11:31,320
这样的话

362
00:11:31,430 --> 00:11:32,330
我想你会成为这个团队的英雄

363
00:11:32,940 --> 00:11:34,000
因为有了10倍的数据

364
00:11:34,240 --> 00:11:35,360
你通过学习这么多的数据

365
00:11:35,450 --> 00:11:38,460
一定会获得更好的学习表现

366
00:11:39,650 --> 00:11:44,500
有很多办法你可以尝试 在本课中我们主要关注人工数据合成

367
00:11:47,450 --> 00:11:48,510
这既包括从零开始

368
00:11:48,970 --> 00:11:50,440
生成新数据

369
00:11:50,640 --> 00:11:53,050
比如使用随机的字体等等

370
00:11:53,570 --> 00:11:54,430
也包括第二种思路

371
00:11:54,840 --> 00:11:56,600
那就是在现有的样本中

372
00:11:56,670 --> 00:11:58,100
引入一些噪声或变形

373
00:11:58,280 --> 00:12:00,910
来扩大现有的训练样本

374
00:12:01,090 --> 00:12:02,150
有很多获取

375
00:12:02,280 --> 00:12:03,130
大量数据的方法

376
00:12:03,270 --> 00:12:04,610
是你自己收集

377
00:12:04,670 --> 00:12:06,600
或者标记数据

378
00:12:07,600 --> 00:12:09,090
因此我通常进行的

379
00:12:09,210 --> 00:12:11,580
一种计算是

380
00:12:11,780 --> 00:12:13,320
问问自己 需要花多少分钟

381
00:12:13,520 --> 00:12:15,140
或者多少小时

382
00:12:15,350 --> 00:12:16,420
来获得一定量的样本数

383
00:12:16,610 --> 00:12:17,780
所以我就坐下来

384
00:12:17,900 --> 00:12:19,410
然后算一算

385
00:12:19,550 --> 00:12:21,830
假如我需要花

386
00:12:22,060 --> 00:12:23,990
10秒的时间来标记一个样本

387
00:12:24,120 --> 00:12:25,820
假设对于

388
00:12:26,190 --> 00:12:29,050
我们的应用

389
00:12:29,190 --> 00:12:31,500
我们现在已经有了1,000组带标签的样本

390
00:12:31,620 --> 00:12:32,730
所以10乘以1,000

391
00:12:32,860 --> 00:12:34,090
等于10,000

392
00:12:34,200 --> 00:12:35,940
等于10,000

393
00:12:37,440 --> 00:12:40,260
获取大量数据的

394
00:12:40,400 --> 00:12:41,530
第二种方法是

395
00:12:41,800 --> 00:12:43,540
自己动手收集和标记数据

396
00:12:44,510 --> 00:12:45,380
我的意思是

397
00:12:45,690 --> 00:12:46,970
通常我会坐下来

398
00:12:47,240 --> 00:12:48,570
然后做一个计算

399
00:12:48,950 --> 00:12:50,190
算一算需要花多少时间

400
00:12:50,350 --> 00:12:51,140
或者说多少小时

401
00:12:52,640 --> 00:12:54,000
我或者别人

402
00:12:54,200 --> 00:12:55,130
要花多少小时

403
00:12:55,230 --> 00:12:56,890
多少天时间

404
00:12:57,020 --> 00:12:58,400
坐下来

405
00:12:58,640 --> 00:12:59,870
收集到10倍于

406
00:13:00,190 --> 00:13:01,490
我们现有数据量的数据

407
00:13:01,800 --> 00:13:03,560
通过我们自己收集数据标记数据的方法

408
00:13:05,260 --> 00:13:06,550
举例来讲

409
00:13:06,630 --> 00:13:08,200
假如说我们的机器学习应用

410
00:13:08,690 --> 00:13:10,180
现在已经有1,000组样本 m=1000

411
00:13:12,010 --> 00:13:12,750
我们要做的就是

412
00:13:12,870 --> 00:13:14,500
对自己提问

413
00:13:14,720 --> 00:13:16,930
要收集并且标记一个样本 我需要花多久

414
00:13:17,340 --> 00:13:18,480
有时候可能

415
00:13:18,600 --> 00:13:19,510
会花你10秒钟

416
00:13:19,790 --> 00:13:22,100
来标记一个

417
00:13:23,310 --> 00:13:25,120
新的样本

418
00:13:25,520 --> 00:13:27,720
因此如果我想要10倍的数据 我要做个计算

419
00:13:28,360 --> 00:13:30,400
如果获得一个样本需要10秒的话

420
00:13:31,370 --> 00:13:32,340
那如果我想要10倍的数据

421
00:13:32,580 --> 00:13:35,320
那么我需要10,000个样本

422
00:13:35,830 --> 00:13:38,470
那么计算一下

423
00:13:38,770 --> 00:13:40,380
我需要花多少时间

424
00:13:40,840 --> 00:13:42,640
才能手工地标记10,000个样本

425
00:13:43,340 --> 00:13:45,280
如果标记一个样本需要花10秒的话

426
00:13:47,070 --> 00:13:47,940
因此 如果你算一下的话

427
00:13:48,840 --> 00:13:49,920
通常 我会看到很多团队

428
00:13:50,390 --> 00:13:51,780
表现得相当惊讶

429
00:13:51,870 --> 00:13:53,140
所需要的时间那么少！

430
00:13:53,240 --> 00:13:54,730
有时候需要两三天

431
00:13:54,880 --> 00:13:55,560
有时候需要几天

432
00:13:55,780 --> 00:13:57,180
很多时候我都发现

433
00:13:57,500 --> 00:13:59,160
这些团队都表现得

434
00:13:59,340 --> 00:14:00,280
非常惊讶

435
00:14:00,410 --> 00:14:01,200
原来要获得这么多数据

436
00:14:01,370 --> 00:14:02,510
只需要这么短的时间

437
00:14:02,580 --> 00:14:03,470
就能让你的学习算法

438
00:14:03,580 --> 00:14:04,310
在表现上获得一个

439
00:14:04,640 --> 00:14:06,350
巨大的提高

440
00:14:06,450 --> 00:14:07,550
当然 如果你成功

441
00:14:07,790 --> 00:14:08,900
做到了这些

442
00:14:09,190 --> 00:14:10,780
你将成为你们开发组的英雄

443
00:14:11,360 --> 00:14:12,520
不管你在什么组开发什么产品

444
00:14:12,910 --> 00:14:14,150
因为这绝对是一种

445
00:14:14,320 --> 00:14:15,760
能让算法表现更好的方法

446
00:14:17,650 --> 00:14:19,490
第三点也是最后一点

447
00:14:20,020 --> 00:14:21,230
另一种很好的办法是

448
00:14:21,450 --> 00:14:22,650
我们称之为"众包"

449
00:14:23,080 --> 00:14:24,350
(crowd sourcing) 的办法

450
00:14:25,280 --> 00:14:26,350
现在已经有一些网站

451
00:14:26,520 --> 00:14:27,270
或者一些服务机构

452
00:14:27,460 --> 00:14:29,520
能让你通过网络

453
00:14:29,920 --> 00:14:32,210
雇一些人替你完成

454
00:14:32,350 --> 00:14:33,410
标记大量训练数据的工作

455
00:14:33,730 --> 00:14:36,140
通常都很廉价

456
00:14:36,810 --> 00:14:37,870
因此 这种众包的方法

457
00:14:38,190 --> 00:14:39,460
或者叫

458
00:14:39,950 --> 00:14:41,390
众包的数据标记

459
00:14:41,810 --> 00:14:43,180
很明显这种方法

460
00:14:43,340 --> 00:14:45,200
就像学术文献一样

461
00:14:45,660 --> 00:14:47,040
它也是很复杂的

462
00:14:47,210 --> 00:14:49,390
同时取决于标记人的可靠性

463
00:14:50,440 --> 00:14:51,470
也许世界上有

464
00:14:51,860 --> 00:14:53,420
成百上千的标记人

465
00:14:53,580 --> 00:14:55,530
用很低的收入帮你

466
00:14:55,630 --> 00:14:56,810
为数据加上标签

467
00:14:57,030 --> 00:14:58,580
就像我刚才说的

468
00:14:58,930 --> 00:15:00,120
这也是一种选择而已

469
00:15:00,390 --> 00:15:02,170
可能“亚马逊土耳其机器人”（Amazon Mechanical Turk）

470
00:15:02,510 --> 00:15:03,750
就是当前最流行的

471
00:15:03,900 --> 00:15:05,860
一个众包选择

472
00:15:06,860 --> 00:15:08,070
要让它工作

473
00:15:08,220 --> 00:15:10,040
要想获得比较高质量的标签

474
00:15:10,190 --> 00:15:10,940
通常还不是一件容易的事

475
00:15:11,150 --> 00:15:12,520
需要花一定的功夫

476
00:15:12,780 --> 00:15:14,160
但这也是一种

477
00:15:14,240 --> 00:15:15,760
可供选择的方法

478
00:15:17,330 --> 00:15:18,870
如果你能廉价地

479
00:15:19,320 --> 00:15:21,000
在网上雇佣一些人

480
00:15:21,810 --> 00:15:24,220
来帮你做这件事儿的话

481
00:15:26,320 --> 00:15:27,570
在这段视频中

482
00:15:27,660 --> 00:15:28,840
我们谈到了

483
00:15:29,100 --> 00:15:30,870
人工数据合成的概念

484
00:15:31,120 --> 00:15:32,440
这既包括

485
00:15:32,750 --> 00:15:34,400
从无到有地创造新的数据

486
00:15:34,640 --> 00:15:35,400
我们用到了随机字体的例子

487
00:15:35,830 --> 00:15:37,710
也包括

488
00:15:37,790 --> 00:15:38,980
扩大训练数据的办法

489
00:15:39,420 --> 00:15:41,340
通过对已有的标签样本

490
00:15:41,560 --> 00:15:42,980
引入新的扭曲或变形

491
00:15:43,240 --> 00:15:44,880
来制造新的标签样本

492
00:15:46,010 --> 00:15:47,450
最后 我希望你

493
00:15:47,630 --> 00:15:48,810
通过这段视频

494
00:15:49,120 --> 00:15:49,970
要记住的一点是

495
00:15:50,540 --> 00:15:51,540
如果你要解决某个机器学习问题

496
00:15:51,830 --> 00:15:54,350
通常有两件事情值得好好考虑

497
00:15:54,660 --> 00:15:55,830
第一是用学习曲线

498
00:15:56,160 --> 00:15:58,600
进行合理性检查 保证使用更多的数据能有效果

499
00:15:59,520 --> 00:16:00,340
第二点是

500
00:16:00,730 --> 00:16:01,780
自己坐下来

501
00:16:01,850 --> 00:16:03,670
认真地想一想

502
00:16:04,050 --> 00:16:05,150
想要得到现有数据的

503
00:16:05,260 --> 00:16:06,510
10倍数据量

504
00:16:06,630 --> 00:16:08,450
需要花费多少工作量

505
00:16:08,960 --> 00:16:10,440
有时候你会非常惊讶于

506
00:16:10,640 --> 00:16:12,310
你算出来的结果

507
00:16:12,580 --> 00:16:13,990
也许只需要几天

508
00:16:14,060 --> 00:16:15,020
几个星期的时间

509
00:16:15,150 --> 00:16:16,160
就能让你的学习算法

510
00:16:16,260 --> 00:16:18,700
的表现有巨大的提高【教育无边界字幕组】翻译：所罗门捷列夫 校对：竹二个 审核：Naplessss