前回のビデオでは Photo OCRのパイプラインについてと、それがどう機能するかについて議論してきた。 それは画像をとり、 それを一連の機械学習の コンポーネントを通過させて、 画像の中にあるテキストを 読み取ることを試みる、という物だった。 このビデオでは、 個々のパイプラインのコンポーネントが どう機能するかについてもう少し議論していきたい。 具体的には、このビデオの大半を、スライディングウィンドウ分類器(classifier)と呼ばれる物に 関する議論に費やしたいと思う。 PhotoOCRのパイプラインの 最初のステージは テキスト検出だった。そこでは こんな画像を見ていって この画像の中でテキストがある位置を見つける事を試みる。 テキスト検出はコンピュータビジョンにとっては普通でない問題だ。 何故なら見つけたいテキストの 長さに応じて 見つけようとするこれらの矩形も 異なるアスペクト比となるからだ。 だから画像の中の物事を 検出する話をする為に、 もっと簡単な例である、 歩行者の検出から始めよう。その後に話を戻して 歩行者の検出で構築したアイデアを テキスト検出に用いよう。 さて、歩行者検出においては、 こんな画像をとり、 画像の中に居る個々の歩行者を 見つける事を試みる物だ。 つまり歩行者が一人見つかり、 ここに二人目、 三人目、四人目、五人目、 そして六人目、と。 この問題はテキスト検出の問題よりも ちょっとだけ簡単だろう。 何故ならほとんどの歩行者のアスペクト比は きわめて似通っているからだ。 我らが見つけようと試みている矩形に対し 固定されたアスペクト比を用いる事で、 ここでアスペクト比という言葉は これらの矩形の高さと幅の比の事を言う。 それらは別々の歩行者に対しても 同じだ。だが、 テキスト検出の場合は、異なる行のテキストで 縦と横の比は 異なる。 歩行者の検出の場合は 歩行者の居る場所までの カメラからの距離が異なる事はあり得るので、 これらの矩形の高さは、どれだけ離れているかに応じて 違いうるけれど。 でもアスペクト比は同一だ。 歩行者検出システムを構築する為には こんな方法が考えられる。 このアスペクト比を 82 x 36に 標準化する事にしよう。 別に丸めた数字、 例えば80x40とかにしても良いんだけど、 82x36で特に問題無さそうなのでこれで行く。 そして次にやるべき事は 外に出て大量の陽性と陰性のトレーニングセットを集めてくる事だ。 こちらが82x36の画像で 歩行者を含んでいる 手本だ。そしてこちらは 含んでいない手本の画像。 このスライドには、 y =1となる12の陽性の手本と y=0となる12の手本をお見せしている。 もっと典型的な歩行者検出のアプリケーションでは 1000トレーニング手本から 1万トレーニング手本くらいまで、 またはもっとトレーニングセットが集められる時は それ以上の場合すら あるのが 一般的だ。 そしてその時にとれる手段としては、 ニューラルネットワークか、それ以外の何らかの 学習アルゴリズムを訓練して、 この画像のパッチ、 82 x 36の次元のパッチを入力として、 それをyかどうか、を分類出来るようにする。 つまりこれらの画像パッチに 歩行者が含まれているかどうかを分類出来るようにする。 以上のように、画像のパッチを受け取り そこに歩行者が居るかどうかを区別する為に 教師あり学習を用いる 事が出来る。 今、新しい画像を与えられたとして、 こんなテストセットの画像 だとして、 写真の画像から歩行者を見つけたいとする。 そこで我らがやる事は この画像から矩形のパッチをとっていき、 ここにあげたような感じで、 これは82 x 36の 画像のパッチとかで、 そしてその画像のパッチを 分類器に通して その画像パッチに 歩行者が居るかどうかを決定する。 そしてこのパッチについては 分類器がy =0を返すのを期待する。何故なら歩行者は居ないから。 次に、その緑の矩形を 少しだけスライドさせて、 その後にその 新しい画像パッチに対して 分類器を走らせて、歩行者がそこに居るかを判定する。 それを終えたら、その後はさらに ウィンドウを右にスライドさせて そのパッチを分類器に ふたたび通す。 矩形を一度にどれだけ シフトさせるかは パラメータだ。それはステップサイズのパラメータと 呼ばれる事もあるし、 また、ストライドパラメータと呼ばれる事も ある。そして もし一度に1ピクセルしか動かさなければ、 つまりステップ幅、あるいは歩幅1を 使う事が出来れば、それは普通 一番良い実行結果が得られるが、 計算量的にはより高価となる。 だからステップサイズで4ピクセルとか 8ピクセルとか、 またはそれより大きな適当なピクセルを 用いるのが より一般的だ。 何故ならその方が毎回 もうちょっとだけ 矩形を動かせるから。 このプロセスを用いる事で、 毎回ちょっとずつ矩形を 右に動かしていく事で、 そしてこれらの各パッチを 分類器にかけていく事で、 最終的に、、、 このウィンドウを画像の 異なる場所へとスライドし続けて 最初は最初の行から始めて その後に画像の さらなる先の行へと 進めていき、 なんらかのステップサイズで あるいはあるストライドのサイズで これら別々の画像のパッチに対し 実行していく。 ここまでは、とても小さな 矩形だった。これは一つの特定のサイズの歩行者しか 検出出来ない。 次にやる事は、 より大きな画像のパッチを見て、 つまりより大きな画像のパッチを取って、 ここに示したような、 そしてふたたび同様に分類器を走らせる。 ところで、より大きな 画像のパッチを取る、と言った時に 私が実際に意味している事は、 こんな画像パッチをとった時、 実際にやる事は、 この画像のパッチを取り、これを 82x36に縮小する、という事。 つまりこのより大きなパッチを取り、 それをより小さい画像に リサイズして、そして その小さくした画像こそが、 分類器に渡す物で、 そこで歩行者がパッチにいないか決定する事を試みる。 そして最後に、さらに大きなスケールで これを行う事が出来て、 そのスライディングウィンドウを最後まで 実行する。 そしてこれらのプロセスが全て終わったら、 あなたのアルゴリズムはこの画像の中に これらの歩行者が居るかを 検出する事が期待出来る訳だ。 以上が分類器を訓練する方法と、 そしてスライディングウィンドウの分類器、 またはスライディングウィンドウの検出器を 用いて、画像の中の歩行者を 探す方法だ。 テキスト検出の例に 立ち戻って、 PhotoOCRパイプラインでの テキスト検出のステージについて議論しよう、そこでは 我らの目標は画像内のテキストの領域を見つける事だ。 歩行者の検出と同様に、 テキストが現れる場所に 対応した陽性と陰性の 手本を 作り出す事ができる。 つまり歩行者を検出する代わりに、今度はテキストを検出したい。 つまり陽性の手本は テキストがあるイメージのパッチで 陰性の手本はテキストが無い 画像のパッチだ。 これで分類器をトレーニングし終えたら、 それを新規の画像、 テストセットの画像に 適用出来る。 これは例として使ってきた画像だ。 ここでは、この例においては、 スライディングウィンドウを たった一つの固定されたスケールの物で 実行する事にしよう。 これは例示の為だ。つまり 一つのサイズの矩形だけを用いる。 だが、小さな、スライディングウィンドウの 分類器を、たくさんのちいさな 画像のパッチに対して実行するとしよう、 こんな感じに。 そうすると、 結局はこんな結果が得らる。 ここで白い領域は テキスト検出のシステムが テキストを見つけた場所を表す。 つまりこれらの絵の軸は同一だ。 つまりこの領域は この領域に 対応している。 そしてここが黒であるという事実は、 分類器がここにテキストは 見つからない、と 思っている事を表している。 一方でここにはたくさんの 白い物があるという事実は、分類器が たくさんのテキストがここにある、と 思っている事を反映している。 この左下の絵で 私がやった事は 分類器がテキストを見つけた、と 実際に思った場所を見せる為に、白を使ったという事だ。 そしてグレイの影の違いは 分類器の出力した 確率に対応している。 つまりグレイの影は 分類器がテキストを発見したように思ってはいるが、 だがそんなに 自信は無い、と思っている所。 明るい白は分類器が とても高い確率で テキストがある場所だ、と 推計している場所に対応している。 まだやるべき事が全て終わった訳では無い。 何故なら我らが望んでいるのは、 画像の中のこのテキストの 全体の回りの領域に対して 四角で囲む、という事だからだ。 だからさらにもう一段階ステップを踏む、 それは分類器の出力をとり、 そこにexpansion operatorと呼ばれる物を 適用する、という事をする。 それがやる事は、 この画像に対して、 それぞれの白のシミに対して、 それぞれの白い領域に対して、 その白の領域を拡大する、という事をする。 数学的には、 それを実装する方法は、 右の画像を見てみると、 右の画像を作る為に やれる事としては、各ピクセルに対し、 以下のように尋ねてみる事だ： このピクセルは、左の画像の白いピクセルから 一定の距離以内に あるだろうか？と。 つまり、もしあるピクセルが、 一番左の画像で、例えば、そうだなぁ。 白いピクセルの 5ピクセルとか10ピクセル以内にあるのなら、 その時は一番右のそのピクセルも白に塗る。 このような操作が与える効果は、 一番左の画像の白いしみを 取り出して、ちょっとだけ 拡張したような物となる。 それらをちょっとだけ成長させるような。 付近のピクセルが 白いピクセルかどうか。 そしてそばのピクセルも同様に白に塗る。 最後に、これで終わりになるが、 この一番右の画像を 見ていき、 くっついている構成要素を見ていき、 つながった白い領域のバウンディングボックスを その回りに描く。 具体的には、これらの白い領域を 全部見ていくとすると、 例えばこれとか、これとか、 これとか。 そして簡単な経験則で アスペクト比がおかしい、と思うような物を 除外していくと、、、何故なら我らは テキストの回りの箱は 高さよりも幅の方が大きいべきだという事を知っているから。 だから痩せてて高い 箱を無視していくと、例えばこれとか これとか。 そしてこれらは捨てる、何故なら それらはあまりにも高くて薄いから。 そしてアスペクト比が テキストの領域っぽい物の回りを 囲んだ矩形を描く、ここで アスペクト比とは高さと幅の 比の事。次に 矩形を描く事が出来る。テキストの 範囲の回りの バウンディングボックス。ここのテキストの範囲と ここのテキストの範囲と、ここのテキストの範囲。 これらはそれぞれ、LULA B's ANTIQUE MALLのロゴと LULA B'sと、この小さなOPENのサインに対応している。 こっち側の。 所で、この例は実の所、一片のテキストを見逃している。 これはとても読みにくいが、だがここには実際は一片のテキストがある。 ここにもLULA B'sがあって、それはこれに対応しているのだが、 だがこのアスペクト比は 間違いっぽいので、それを捨てたのだった。 つまり、この画像に関しては 問題無さそうだが、 この具体例においては分類器は 実は一片のテキストを見逃している。 それは凄い読みにくい、 何故なら透明の窓に対して 書かれたテキストだから。 以上がスライディングウィンドウを用いた テキスト検出だ。 テキストを囲むこれらの矩形を 見つけたのちには、 我らはこれらの画像の領域を 切り抜いて、それをあとに続くパイプラインのステージで テキストを読む為に用いる事が出来る。 さて、パイプラインの 二番目のステージは 文字分割だったのを覚えているだろうか？ つまり上に見せたような画像を与えられた時に、 この画像の各文字に、どうやって分割出来るだろうか？ ここで取れる手段は、今回も 教師あり学習のアルゴリズムだ。 ある陽性の手本の集合と、 ある陰性の手本の集合を 共に用いた。 それでやる事は 画像のパッチを見て、 画像のパッチのちょうど真ん中に 二つの文字の区切りが あるかどうかを決めたい。 例えばこの最初の陽性の手本では、 この最初の手本は、 この画像パッチは ちょうど真ん中に、、、つまり 真ん中がちょうど二つの文字の分け目と なっている。そして二番目の手本も、 これもまた、 陽性の手本に見える。何故ならもし 真ん中に線を引いて 二つの文字を分けようとしたら、ちゃんと分けられるから。 つまり、これらは陽性の手本だ。 その画像の真ん中は、隙間、または 二つの文字を分ける 区切りで、 他方、陰性の手本は、 真ん中で二つの文字を 分割したい、と思わないような物。 つまりこれらは 陰性の手本だ、何故なら これらは二つの文字の真ん中を表していないからだ。 そこで我らが行う事は、 分類器をトレーニングする事で、 ニューラルネットワークを使ってもいいし、 別のアルゴリズムでもいいが、 とにかく陽性と陰性の手本を分類しようとするアルゴリズムをトレーニングする。 そんな分類器をトレーニングし終えたら、 その後我らはこれを テキスト検出器が取り出した こんな画像に対して走らせる。 この矩形から始めて、 こう問う： 緑の矩形の 真ん中は、、、 2つの文字の間っぽく 見えるか？と。 そして期待するのは、分類器は NO、と言ってくれる事。そしてウィンドウを スライドさせて、、、所でこれは 1次元のスライディングウィンドウの 分類器だ。何故なら ウィンドウを一直線に 左から右へとスライドさせるだけで ここでは別の行、というのが無いから。 ここには一行しか無い。 さて、ここで、分類器が この場所に来た時に、 二つの文字をここで分割すべきか、 または二つの文字の区切りをこの矩形の真ん中に置くべきか？と問う。 そして期待される事としては、分類器は y=1と出力する事。つまり その場合はそこに 線を引くと決定し、二つの文字を分割しようとする訳だ。 そして次にウィンドウをまたスライドさせて、 この場合は分類器はここでは分割しない、と 出力する事が期待されて、さらにまたスライドさせて、 yes、ここでスプリットせよ、と言う事が期待される。 などなど。 こうやってゆっくりと分類器をスライド させて右の方に行かせて、 ここをさらなる陽性のサンプルと 分類する事が期待される。 などなど。 そしてこのウィンドウを右側へと スライドさせていき、各ステップで 分類器を実行し、 そしてそれをもって我らに これらの文字列を分割する 適切な場所を教えてくれる事を期待する訳だ、 つまりこの画像を個々の文字へと分割する。 以上が1Dスライディングウィンドウによる 文字分割だ。 ここにPhoto OCRパイプラインの全体像を再掲した。 このビデオでは、テキスト検出のステップを 議論して来た。そこでは、 テキストを検出する為に、スライディングウィンドウを使った。 そしてまた、文字分割でも 1次元のスライディングウィンドウを 分割する為に使った。 このテキストの画像を、各文字に分割する。 パイプラインの最後のステップは 文字分類ステップだ。 そしてそのステップに関しては、 以前の教師あり学習のところの ビデオでやったので、 既になじみの物だろう、 そこでは、通常の教師あり学習の、 例えばニューラルネットワークとか それ以外のなんでも良いが、その辺を使って 画像を入力として、 こんなような、 そしてどのアルファベットか、言い換えると 26文字のaからzまでのどの文字か、 数字も入れるなら 36文字にすべき かもしれない。 何にせよ、複数クラスへの 分類の問題で、 文字を含んでいる 画像を引数に取り、 その画像にある文字は何なのかを決める、という問題だ。 以上がPhoto OCRのパイプラインだ。 そしてどうやって スライディングウィンドウの 分類器などのアイデアを、、、 これら別々のコンポーネントを組み合わせて Photo OCRシステムを開発するか、という話だ。 次の一連のビデオでは、 引き続きPhotoOCRの問題を用いて このようなアプリケーションを開発する時にまつわる いくらか興味深い問題を探求していく。