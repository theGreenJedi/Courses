1
00:00:00,120 --> 00:00:01,220
もし学習アルゴリズムを走らせて

2
00:00:01,710 --> 00:00:02,640
期待ほど良い結果で無ければ、

3
00:00:02,840 --> 00:00:04,520
だいたいいつも

4
00:00:04,740 --> 00:00:05,670
それは高いバイアス問題か、

5
00:00:06,100 --> 00:00:07,650
高い分散問題の

6
00:00:08,010 --> 00:00:09,530
どちらかだ。

7
00:00:09,860 --> 00:00:10,940
言い換えると、それは

8
00:00:11,130 --> 00:00:13,140
アンダーフィット問題かオーバーフィット問題のどちらか、という事。

9
00:00:14,260 --> 00:00:15,090
そしてこの場合、

10
00:00:15,350 --> 00:00:16,580
これらの問題のどちらなのかを

11
00:00:16,790 --> 00:00:17,970
見分けるのは凄く重要。

12
00:00:18,280 --> 00:00:19,500
バイアスなのか分散なのか。またはちょっとずつ

13
00:00:20,210 --> 00:00:20,430
両方があるのか。

14
00:00:21,050 --> 00:00:21,980
何故かといえば、これらのどちらが

15
00:00:22,440 --> 00:00:23,890
起きているのかを知ると、

16
00:00:24,060 --> 00:00:25,940
アルゴリズムを改善するのに

17
00:00:26,180 --> 00:00:27,490
将来のありそうな道がどちらかの

18
00:00:27,770 --> 00:00:29,030
とても強力な指標となるから。

19
00:00:30,230 --> 00:00:31,270
このビデオでは、

20
00:00:31,380 --> 00:00:33,030
バイアスと分散の問題について

21
00:00:33,220 --> 00:00:34,850
より深くつっこんで行き、

22
00:00:35,180 --> 00:00:36,530
それらをより深く理解すると同時に

23
00:00:36,790 --> 00:00:38,470
我らの問題がバイアス問題なのか分散問題なのかを見分ける為に

24
00:00:38,610 --> 00:00:42,910
学習アルゴリズムをどう見ていくか、どう評価して診断していくかも探求していきたい。

25
00:00:43,030 --> 00:00:45,750
何故ならあなたの実装した学習アルゴリズムのパフォーマンスを

26
00:00:45,900 --> 00:00:48,180
改善する方法を知るのに必須だから。

27
00:00:48,640 --> 00:00:52,270
この図は既に

28
00:00:52,680 --> 00:00:53,690
何度か見てきた。

29
00:00:54,190 --> 00:00:55,230
あまりにも単純過ぎる仮説だと

30
00:00:55,710 --> 00:00:57,900
たとえば単なる直接とか、これだとデータにアンダーフィットしてしまう。

31
00:00:59,660 --> 00:01:00,720
あまりにも複雑過ぎる仮説にフィットさせると

32
00:01:01,250 --> 00:01:02,870
それはトレーニングセットに

33
00:01:03,400 --> 00:01:05,050
完璧に一致するかもしれないが

34
00:01:05,270 --> 00:01:06,810
データにオーバーフィットするかもしれない。

35
00:01:06,930 --> 00:01:09,000
そしてこれは、中間の複雑さで、

36
00:01:09,340 --> 00:01:11,000
たとえば多項式の次数が

37
00:01:11,810 --> 00:01:13,120
高すぎもせず、低すぎもしない、という

38
00:01:13,390 --> 00:01:15,770
仮説の例。

39
00:01:16,560 --> 00:01:17,340
ちょうど良いケース。

40
00:01:17,560 --> 00:01:18,480
そしてこれらの選択肢の中では

41
00:01:19,100 --> 00:01:20,740
ベストな一般化した時の誤差を与える。

42
00:01:21,770 --> 00:01:22,960
今やトレーニング、バリデーション、テストセットという

43
00:01:23,030 --> 00:01:25,130
考え方で武装したので、

44
00:01:26,100 --> 00:01:27,550
バイアスと分散の概念を

45
00:01:28,290 --> 00:01:30,530
もうちょっと良く理解出来る。

46
00:01:31,310 --> 00:01:33,140
具体的にいこう。

47
00:01:33,370 --> 00:01:34,920
トレーニング誤差とクロスバリデーション誤差を

48
00:01:35,050 --> 00:01:36,620
前回のビデオ同様に

49
00:01:36,850 --> 00:01:38,440
定義しよう。

50
00:01:38,680 --> 00:01:40,110
誤差の自乗、トレーニングセットか

51
00:01:40,450 --> 00:01:41,420
クロスバリデーションセットに対して

52
00:01:41,830 --> 00:01:42,810
計測した誤差の自乗の

53
00:01:42,930 --> 00:01:44,710
平均の値。

54
00:01:46,560 --> 00:01:47,690
今、以下の図をプロットしよう。

55
00:01:48,470 --> 00:01:49,930
横軸には多項式の

56
00:01:50,010 --> 00:01:52,000
次数。

57
00:01:52,400 --> 00:01:53,380
つまり右に行くに連れて

58
00:01:54,810 --> 00:01:57,050
どんどん高い次元の多項式をフィッティングする事となる。

59
00:01:58,590 --> 00:01:59,630
つまりこの図の右側では

60
00:01:59,810 --> 00:02:01,100
d=1の時など、

61
00:02:01,720 --> 00:02:02,770
とても簡単な関数で

62
00:02:03,690 --> 00:02:05,600
フィッティングする事となる。

63
00:02:05,740 --> 00:02:06,680
他方、横軸の

64
00:02:07,150 --> 00:02:08,950
右側では

65
00:02:09,740 --> 00:02:11,550
より大きな数字となり、

66
00:02:11,650 --> 00:02:13,400
とても複雑な高い次元の多項式に

67
00:02:14,120 --> 00:02:17,020
フィッティングする事となる。

68
00:02:17,420 --> 00:02:19,980
つまりトレーニングセットとより複雑な関数でフィッティングする事となる。

69
00:02:23,550 --> 00:02:26,430
他方この

70
00:02:26,890 --> 00:02:27,980
横軸の右側では

71
00:02:28,160 --> 00:02:31,250
dはより大きな値となり

72
00:02:31,730 --> 00:02:34,350
多項式はより高い次数となる。

73
00:02:34,460 --> 00:02:35,560
だからここでは、

74
00:02:35,600 --> 00:02:37,490
より複雑な関数に

75
00:02:37,760 --> 00:02:39,820
対応する。

76
00:02:40,110 --> 00:02:41,920
ではトレーニング誤差と

77
00:02:42,010 --> 00:02:44,060
クロスバリデーション誤差を見てみて、

78
00:02:44,400 --> 00:02:45,610
この図にプロットしてみよう。

79
00:02:46,570 --> 00:02:49,080
トレーニング誤差から始めよう。

80
00:02:49,820 --> 00:02:50,570
多項式の次元を上げるに連れて

81
00:02:50,680 --> 00:02:52,220
トレーニングセットへの

82
00:02:53,260 --> 00:02:55,630
フィッティングもますます良くなる。

83
00:02:57,320 --> 00:02:58,300
もしd=1なら高いトレーニング誤差となるし、

84
00:02:58,430 --> 00:02:59,190
もしとても高い次数の

85
00:02:59,200 --> 00:03:00,410
多項式ならば

86
00:03:00,810 --> 00:03:02,580
我らのトレーニング誤差は極めて低くなる。

87
00:03:02,840 --> 00:03:05,230
ゼロにすらなるかも。何故ならそれはトレーニングセットにとても良くフィットするだろうから。

88
00:03:05,850 --> 00:03:06,910
つまり多項式の次数を

89
00:03:07,390 --> 00:03:08,750
高めれば高める程、

90
00:03:09,130 --> 00:03:10,150
典型的にはトレーニングの誤差は

91
00:03:10,550 --> 00:03:11,830
減少していく。

92
00:03:11,960 --> 00:03:15,210
だからJ下付き添字trainのシータを書くと

93
00:03:15,980 --> 00:03:17,920
こんな感じ。

94
00:03:18,210 --> 00:03:19,620
何故ならトレーニング誤差は

95
00:03:19,750 --> 00:03:22,380
データにフィットする多項式の

96
00:03:22,790 --> 00:03:25,180
次元の増加とともに減少していくから。

97
00:03:25,410 --> 00:03:28,240
次にクロスバリデーション誤差を見てみよう。

98
00:03:28,300 --> 00:03:30,680
仮にテストセットの誤差を見るとすると、

99
00:03:31,480 --> 00:03:32,940
そちらも似たような結果となるだろう。

100
00:03:33,510 --> 00:03:34,720
まるでクロスバリデーション誤差を

101
00:03:36,710 --> 00:03:39,790
プロットしたかのように。
もしd=1なら、とても簡単な関数に

102
00:03:40,620 --> 00:03:42,160
フィッティングする事になるので

103
00:03:42,340 --> 00:03:44,400
トレーニングセットにアンダーフィットするかもしれない。

104
00:03:44,540 --> 00:03:45,620
だからクロスバリデーション誤差は

105
00:03:45,710 --> 00:03:47,250
とても高いはず。

106
00:03:47,390 --> 00:03:49,620
もし中間の

107
00:03:49,680 --> 00:03:52,020
次数の多項式をフィッティングさせたら

108
00:03:52,110 --> 00:03:53,620
前のスライドの例だと

109
00:03:54,090 --> 00:03:55,010
d=2のケースとなるが、

110
00:03:55,390 --> 00:03:56,100
この場合はより低い

111
00:03:56,250 --> 00:03:57,440
クロスバリデーション誤差となるだろう。

112
00:03:57,570 --> 00:03:59,460
何故なら我らはより良く

113
00:03:59,860 --> 00:04:01,050
データにフィットするのを見つけたという事だから。

114
00:04:02,170 --> 00:04:03,230
そして、逆にdが

115
00:04:03,350 --> 00:04:04,310
大きすぎる時は

116
00:04:04,540 --> 00:04:05,990
例えばdが4の時は

117
00:04:06,290 --> 00:04:07,320
ふたたびオーバーフィットしてしまう。

118
00:04:07,730 --> 00:04:08,800
だから結果としては

119
00:04:08,950 --> 00:04:11,030
高いクロスバリデーション誤差となるだろう。

120
00:04:12,280 --> 00:04:13,560
だからこれをなめらかに

121
00:04:13,900 --> 00:04:15,180
つなげて、曲線をプロットすると

122
00:04:15,390 --> 00:04:16,390
結局こんな

123
00:04:17,040 --> 00:04:18,580
曲線となる。

124
00:04:19,210 --> 00:04:21,220
これがJcvのシータだ。

125
00:04:21,680 --> 00:04:23,240
そして繰り返しになるが、Jtestのシータを

126
00:04:23,460 --> 00:04:25,810
プロットしても、とても似た物となる。

127
00:04:27,130 --> 00:04:28,220
この種のプロットはまた、

128
00:04:28,530 --> 00:04:30,110
バイアスと分散という考え方を

129
00:04:30,530 --> 00:04:32,000
よりよく理解する

130
00:04:32,560 --> 00:04:34,760
助けともなる。
具体的に、

131
00:04:35,670 --> 00:04:37,000
もしいまいち期待通りには

132
00:04:37,240 --> 00:04:38,830
パフォーマンスの出ない

133
00:04:39,060 --> 00:04:40,660
機械学習のアルゴリズムがあったとする。

134
00:04:41,060 --> 00:04:43,420
どうやって学習アルゴリズムが何の被害を、、、

135
00:04:44,920 --> 00:04:46,550
具体的に、学習アルゴリズムを

136
00:04:46,780 --> 00:04:48,120
適用したとする、

137
00:04:48,250 --> 00:04:49,640
そして期待通りには

138
00:04:49,930 --> 00:04:52,010
パフォーマンスが出ていないとする。

139
00:04:52,240 --> 00:04:54,940
つまり、クロスバリデーションセット誤差とテストセット誤差が高い。

140
00:04:55,960 --> 00:04:56,910
どうやったら、

141
00:04:56,950 --> 00:04:58,250
その学習アルゴリズムは

142
00:04:58,580 --> 00:05:01,070
高いバイアスを被っているのか、高い分散を被っているのかを区別出来るのだろうか？

143
00:05:02,580 --> 00:05:03,260
クロスバリデーション誤差が高いという事なので

144
00:05:04,140 --> 00:05:06,330
このレジームかこのレジームに

145
00:05:07,150 --> 00:05:09,120
対応するはずだ。

146
00:05:10,470 --> 00:05:11,560
この左のレジームは

147
00:05:11,710 --> 00:05:13,550
高バイアス問題に

148
00:05:13,750 --> 00:05:15,190
対応している、つまり、

149
00:05:15,680 --> 00:05:17,040
もし単純すぎる多項式、

150
00:05:17,560 --> 00:05:19,210
例えばd=1でフィッティングしていて、

151
00:05:19,280 --> 00:05:21,010
でも本当はもっと高い次数で

152
00:05:21,170 --> 00:05:23,750
フィッティングする必要があるようなデータの時。

153
00:05:24,710 --> 00:05:26,380
他方、対照的に、このレジームは

154
00:05:26,850 --> 00:05:28,950
高分散の問題に対応する。

155
00:05:29,840 --> 00:05:31,280
そこではd、つまり多項式の次数が

156
00:05:32,820 --> 00:05:35,070
我らのデータセットに対しては大きすぎるという事。

157
00:05:35,990 --> 00:05:37,250
そしてこの図が、これら2つのケースを

158
00:05:37,740 --> 00:05:39,990
どうやって見分けるか、に関する手がかりを与えてくれる。

159
00:05:41,280 --> 00:05:42,730
具体的に、高バイアスのケースでは

160
00:05:43,140 --> 00:05:45,560
つまりアンダーフィットの

161
00:05:45,970 --> 00:05:47,470
ケースでは、

162
00:05:47,760 --> 00:05:49,170
この図を見ると、

163
00:05:50,230 --> 00:05:51,840
クロスバリデーション誤差とトレーニング誤差の

164
00:05:52,210 --> 00:05:54,220
両方とも高くなっている事が分かる。

165
00:05:54,990 --> 00:05:55,760
だからもしあなたのアルゴリズムが

166
00:05:56,220 --> 00:05:57,410
バイアスの問題を被っているなら、

167
00:05:59,550 --> 00:06:01,450
トレーニングセットの誤差も

168
00:06:03,080 --> 00:06:05,970
高くなるだろうし、

169
00:06:06,070 --> 00:06:07,520
またクロスバリデーションの誤差もまた

170
00:06:07,870 --> 00:06:11,150
高くなるはず。

171
00:06:11,680 --> 00:06:14,460
それら2つは、近い。

172
00:06:14,700 --> 00:06:16,250
トレーニング誤差よりちょっと高いだけかも。

173
00:06:17,100 --> 00:06:18,000
だから、この組み合わせを観測したら

174
00:06:19,240 --> 00:06:20,510
あなたのアルゴリズムが

175
00:06:21,000 --> 00:06:22,190
高バイアスの被害を被っているサインだ。

176
00:06:23,410 --> 00:06:25,760
対照的に

177
00:06:25,850 --> 00:06:26,930
アルゴリズムが高分散の被害を被ってるなら

178
00:06:27,210 --> 00:06:29,720
ここを見ると

179
00:06:30,710 --> 00:06:33,500
Jtrain、

180
00:06:33,730 --> 00:06:34,790
つまりトレーニング誤差が

181
00:06:35,320 --> 00:06:37,220
低くなっている事に気付くだろう。

182
00:06:39,480 --> 00:06:41,820
つまり、トレーニングセットにはとてもうまくフィッティング出来ている。

183
00:06:43,210 --> 00:06:47,540
一方、クロスバリデーション誤差は

184
00:06:48,280 --> 00:06:49,540
これが最小化したい

185
00:06:50,290 --> 00:06:51,320
誤差の二乗だと仮定するとーーー

186
00:06:51,660 --> 00:06:53,790
他方で対照的に、

187
00:06:53,990 --> 00:06:54,940
クロスバリデーションセットに対する誤差は

188
00:06:55,640 --> 00:06:56,850
つまりクロスバリデーションセットに対する

189
00:06:57,120 --> 00:06:58,600
コスト関数は

190
00:06:58,750 --> 00:07:01,410
トレーニングセットの誤差よりも、ずっと大きくなるだろう。

191
00:07:02,860 --> 00:07:03,910
この「大なり大なり」記号は

192
00:07:04,680 --> 00:07:06,840
ずっと大きいを意味する。
つまり、大きいに大きいを掛け合わせると、ずっと大きいになる。

193
00:07:10,480 --> 00:07:11,830
つまりこれは「大なり大なり」の記号で

194
00:07:12,110 --> 00:07:13,120
それは数学の記号で

195
00:07:13,270 --> 00:07:14,600
ずっと大きい、を意味するもので

196
00:07:14,910 --> 00:07:16,980
2つの大なりの記号で示す。

197
00:07:18,500 --> 00:07:19,400
だからもしこの組み合わせを見たら

198
00:07:19,580 --> 00:07:21,400
それはつまり、、、

199
00:07:21,550 --> 00:07:29,340
そしてつまりこの値の組み合わせ見たら、

200
00:07:29,580 --> 00:07:31,180
それは学習アルゴリズムが

201
00:07:31,400 --> 00:07:32,930
高分散を被っていて、

202
00:07:33,360 --> 00:07:35,180
オーバーフィットしてるという手がかりを得たという事。

203
00:07:36,380 --> 00:07:37,910
そしてこれら2つのケースを分けるキーとなるのは

204
00:07:38,070 --> 00:07:39,320
もし高バイアスの問題なら

205
00:07:39,410 --> 00:07:41,390
トレーニングセットの誤差も

206
00:07:41,530 --> 00:07:42,750
高くなるはずで、

207
00:07:42,960 --> 00:07:43,870
何故なら仮説が

208
00:07:44,050 --> 00:07:45,820
トレーニングセットにうまくフィッティング出来ていないだけだから。

209
00:07:46,940 --> 00:07:47,820
そしてもし高分散の問題なら、

210
00:07:47,940 --> 00:07:49,360
トレーニングセットの誤差は

211
00:07:49,780 --> 00:07:51,080
通常は低く、

212
00:07:51,360 --> 00:07:53,730
クロスバリデーション誤差とくらべると大きく低いはず。

213
00:07:55,780 --> 00:07:57,000
以上で、バイアスと分散の

214
00:07:57,100 --> 00:07:58,840
2つの問題が、

215
00:07:58,910 --> 00:08:00,400
いくらかでもより良く理解出来たら幸いです。

216
00:08:01,280 --> 00:08:02,190
バイアスと分散については、

217
00:08:02,360 --> 00:08:04,630
言うべき事がまだ幾つか残っています。次の幾つかのビデオで言います。

218
00:08:05,410 --> 00:08:06,590
のち程見るのは、

219
00:08:06,840 --> 00:08:08,460
学習アルゴリズムが

220
00:08:08,520 --> 00:08:11,010
高バイアスか高分散を被っているかを診断する事です。

221
00:08:11,900 --> 00:08:14,710
それをどうやるかについての更なる詳細を以後見ていきます。

222
00:08:15,600 --> 00:08:16,880
学習アルゴリズムが被っているのが

223
00:08:17,160 --> 00:08:18,570
高バイアスか両方の組み合わせかを

224
00:08:18,740 --> 00:08:20,280
区別する事により、

225
00:08:20,760 --> 00:08:22,370
学習アルゴリズムを改善する為に

226
00:08:22,530 --> 00:08:23,340
何をやるのが成果が期待出来そうな道かを

227
00:08:23,520 --> 00:08:24,670
知る、より良いガイダンスを

228
00:08:24,790 --> 00:08:25,930
提供してくれる事を

229
00:08:26,130 --> 00:08:28,190
見ていきます。