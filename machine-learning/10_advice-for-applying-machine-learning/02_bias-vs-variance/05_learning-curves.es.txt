En este video, me gustaría hablarles de las curvas de aprendizaje. Trazar una curva de aprendizaje es, a menudo, muy útil. Si quieres verificar que tu algoritmo funcione de manera correcta o si quieres mejorar el desempeño del algoritmo. Una curva de aprendizaje es una herramienta que utilizo mucho para diagnosticar si un algoritmo de aprendizaje en particular sufre de alta oscilación , varianza alta o un poco de ambos. A continuación definiré la curva de aprendizaje. Para trazar una curva de aprendizaje, lo que hago generalmente es trazar “J entrenamiento” que es, digamos, el error cuadrático promedio de mi conjunto de entrenamiento, o “Jvc” que es el error cuadrático promedio en mi conjunto de validación cruzada. Luego trazaré esto como una función de “m”; es decir, una función del número de mis ejemplos de entrenamiento. “M” será, generalmente, una constante, como, quizá, 100 ejemplos de aprendizaje. Lo que haré realmente es reducir artificialmente el tamaño de  mi conjunto de entrenamiento; es decir, limitarme intencionalmente a usar sólo, digamos, 10, 20, 30 o 40 ejemplos de entrenamiento y trazar el error de entrenamiento y el error de validación cruzada para los conjuntos de entrenamiento más pequeños.
Ahora, veamos cómo se ven estos trazos. Supongamos que sólo tenemos un ejemplo de entrenamiento, como el que se muestra en este primer ejemplo de aquí, y digamos que estoy ajustando una función cuadrática. Bien, sólo tengo un ejemplo de entrenamiento. Seré capaz de realizar un ajuste perfecto ¿si? Si ajusto la función cuadrática Tendré un error de 0 en este único ejemplo de entrenamiento. Si tuviera dos ejemplos de entrenamiento la función cuadrática también se ajustaría bien. Aún si estuviera usando la regularización, probablemente podría ajustar la función bastante bien o aún sin utilizar la regularización, probablemente ajustaría la función perfectamente. Ahora, si tuviera tres ejemplos de entrenamiento podría ajustar la función cuadrática perfectamente. Entonces si si “m” es igual a 1, o “m” es igual a 2 o “m” es igual a 3, mi error de entrenamiento en mi conjunto de entrenamiento será de 0, suponiendo que no estoy utilizando la regularización, o un poco más alto que 0 si suponemos que estoy utilizando la regularización. Si tengo un conjunto de entrenamiento grande y limito artificialmente el tamaño de mi conjunto de entrenamiento para trazar “J entrenamiento”. Si aquí establezco “m” igual a 3 y si lo entreno en sólo tres ejemplos solamente, entonces para esta figura, mediré mi error de entrenamiento sólo en los tres ejemplos en los que ajusté mis datos. Y aún si tuviera 100 ejemplos de entrenamiento pero quiero trazar el error de entrenamiento con “m” igual a tres lo que haré es medir mi error de entrenamiento solamente en los tres ejemplos a los que ajusté para mi hipótesis 2. Y en todos los otros ejemplos que deliberadamente omití del proceso de entrenamiento. Para recapitular, hemos visto que si el tamaño del conjunto de entrenamiento es pequeño, entonces el error de entrenamiento también será pequeño porque si tenemos un conjunto de entrenamiento pequeño será más fácil ajustar bien, o incluso perfectamente, el conjunto de entrenamiento. En cambio, si tenemos que “m” es igual a 4 entonces la función cuadrática ya no se ajustará perfectamente a este conjunto de datos y si tenemos que “m” es igual a 5, entonces quizá la función cuadrática no se ajuste tan bien. A medida que el conjunto de entrenamiento se hace más grande será cada vez más difícil asegurarme de que encontraré una función cuadrática que se ajuste perfectamente a todos mis ejemplos. Ahora, conforme crece el conjunto de entrenamiento encontraremos que el error de entrenamiento promedio en realidad aumenta y si trazas esta figura, lo que encontrarás será que el error del conjunto de entrenamiento; es decir, el error promedio en la hipótesis, crece a medida que “m” crece. Para aclarar, el concepto, cuando “m” es pequeña o cuando tenemos pocos ejemplos de entrenamiento, es muy fácil ajustar perfectamente cada uno de los ejemplos de entrenamiento por lo que el error será pequeño, mientas que a medida que "m" crece, será más difícil ajustar perfectamente todos los ejemplos de entrenamiento y, por lo tanto, el error del conjunto de aprendizaje se hace más grande. ¿Qué pasa con el error de validación cruzada? El error de validación cruzada es el error en el conjunto de validación cruzada que ya hemos visto. Cuando tenemos un conjunto de entrenamiento muy pequeño, no podrá generalizarse bien. Simplemente no se desempeñará bien y esta hipótesis de aquí no se verá como una buena hipótesis. Sin embargo, si tenemos un conjunto de aprendizaje más grande empezaremos a tener hipótesis que se ajustan mejor a los datos. De manera que el error de validación cruzada y el error del conjunto de prueba tenderán a disminuir a medida que aumenta el tamaño del conjunto de entrenamiento porque, entre más datos tengamos, mejor será la generalización con ejemplos nuevos. Es decir, entre más datos tengamos, la hipótesis se ajustará mejor. Si trazas “J entrenamiento” y “Jcv”, este es el tipo de resultado que obtienes. Ahora veamos cómo se verían las curvas de aprendizaje si tenemos ya sea un problema de alta oscilación  o alta varianza. Supongamos que tu hipótesis tiene un alta oscilación. Para explicar esto pondré un ejemplo ajustando una línea recta a datos que realmente no se pueden ajustar con una línea recta. Así, terminaremos con una hipótesis que quizá se vea como esta. Ahora pensemos qué pasaría si aumentáramos el tamaño del conjunto de entrenamiento. Imaginemos que en vez de cinco ejemplos, como lo he trazado aquí, tenemos muchos más. Lo que pasaría o lo que encontrarías si ajustas una línea recta a esto, seria una línea igual de recta. Una línea recta simplemente no puede ajustar estos datos y obtener una tonelada de datos adicionales simplemente no cambiará mucho la situación. Esta es la línea recta que mejor se ajusta a estos datos, pero una línea recta simplemente no puede ajustar bien estos datos. Aún si trazas el error de validación cruzada, se vería así. Aquí arriba a la izquierda, si tienes un conjunto de entrenamiento minúsculo con, digamos, un sólo ejemplo de entrenamiento, no resultará bien. Para cuando alcances un cierto número de ejemplos o de ejemplos de entrenamiento, has ajustado casi la mejor línea recta posible y aún si terminas con un conjunto de entrenamiento mayor o un valor de “m” mucho mayor, obtendrás básicamente la misma línea recta. Por lo tanto, el error de validación cruzada, voy a anotar esto, o el error del conjunto de prueba se aplanarán o se harán rectos muy pronto una vez que has pasado cierto número de ejemplos de aprendizaje o has ajustado la mejor línea recta posible. Y ¿qué hay el error de aprendizaje? El error de aprendizaje será pequeño de nuevo. Lo que encontrarás en un caso de alta oscilación  es que el error de entrenamiento terminará muy cerca del error de validación. Debido a que tenemos muy pocos parámetros y muchos datos, por lo menos cuando “m” tiene un valor alto, el desempeño del conjunto de entrenamiento y el conjunto de validación cruzada serán muy similares. Así es como lucirán las curvas de aprendizaje si tenemos un algoritmo con alta oscilación. Finalmente, el problema de alta oscilación se ve reflejado en el hecho de que ambos, el error de validación cursada y el error de entrenamiento son altos y terminaremos con un valor relativamente alto de “Jcv” y de “j entrenamiento”. Esto también implica algo muy interesante: Si un algoritmo de aprendizaje tiene un alta oscilación , a medida que tenemos más ejemplos de entrenamiento, es decir, que nos movemos hacia la derecha esta figura, nos daremos cuenta de que el error de validación cruzada no disminuye mucho sino que más bien permanece plano. Por lo tanto, si los algoritmos de aprendizaje tienen una oscilación realmente alta, el hecho de obtener más datos de entrenamiento no ayudará mucho. Un ejemplo concreto de esto es, en la figura de la derecha empezamos sólo cinco ejemplos de entrenamiento y ajustamos cierta línea recta y después tuvimos muchos más datos de entrenamiento y aún así terminamos con la misma línea recta. Si un algoritmo de aprendizaje tiene un alta oscilación , darle más datos de entrenamiento no ayudará a tener un error de validación cruzada o un error del conjunto de prueba más bajo. Saber si tu algoritmo de aprendizaje sufre de un sesgo alto es útil porque puede evitar que pases recolectando más ejemplos de entrenamiento datos de entrenamiento cuando quizá no sean útiles. A continuación veremos la situación de un algoritmo de aprendizaje con una varianza alta. Veamos, primero, el error de entrenamiento. Si tienes un conjunto de entrenamiento muy pequeño con, digamos, cinco ejemplos, como se muestra en la figura de la derecha, y estas ajustando un polinomio de alto grado ,aquí escribí un polinomio del 100mo grado que nadie utiliza realmente, sólo como ejemplo, con un valor de «lambda» relativamente pequeño que quizá no llegue a cero, pero sí un valor pequeño para «lambda», entonces acabaremos ajustando mejor estos datos que con una función que causa sobreajuste. Entonces, si el conjunto de entrenamiento es pequeño, nuestro error de entrenamiento, es decir, “J entrenamiento” de «theta» también será pequeño. A medida que este conjunto de aprendizaje aumenta, quizá sigamos sobreajustando estos datos un poco y se volverá cada vez más difícil ajustar este conjunto de datos perfectamente y a medida que crece el conjunto de entrenamiento, encontraremos que “j entrenamiento” también se incrementa y será un poco más difícil ajustar perfectamente el conjunto de entrenamiento cuando tenemos más ejemplos, aunque el error del conjunto de entrenamiento será aún muy bajo. Pero ¿Qué pasa con el error de validación cruzada? En una situación de alta varianza, la hipótesis se sobreajusta, por lo que nuestro error de validación cruzada se mantendrá alto, aún si tenemos un número moderado de ejemplos de entrenamiento. El error de validación cruzada, entonces, se vería así. Un diagnóstico indicativo de que tenemos un problema de alta varianza es el hecho de tener este gran espacio entre el error de entrenamiento y el error de validación cruzada. Al mirar esta figura, si pensamos en añadir más datos de entrenamiento, es decir, si tomamos esta figura y la extrapolamos a la derecha, podemos predecir que las dos curvas, la curva azul y la curva magenta, convergerán una con la otra y si extrapolamos esta figura a la derecha, parece probable que el error de entrenamiento seguirá subiendo y que el error de validación cruzada seguirá bajando. Lo que realmente nos importa es el error de validación cruzada o el error del conjunto de aprendizaje ¿cierto? En este tipo de figuras, podemos predecir que si seguimos añadiendo ejemplos de entrenamiento y extrapolándolos a la derecha, nuestro error de validación cruzada seguirá disminuyendo. Por lo tanto, es probable que en una situación de varianza alta, obtener más datos de entrenamiento sea, efectivamente, de ayuda. De nuevo, saber si tu algoritmo tiene un problema de varianza alta es útil porque indica que puede valer la pena averiguar si puedes obtener más datos de entrenamiento. Ahora, en la diapositiva anterior y en esta dibujé curvas muy idealizadas y limpias. Si trazas estas curvas en un algoritmo de aprendizaje real, lo que verás en son curvas, como las que dibujé aquí, pero algunas veces serán más irregulares y con más ruido que estas. Trazar las curvas de aprendizaje, como estas, puede decirte o puede ayudarte a saber si tu algoritmo de aprendizaje sufre de un alta oscilación o una alta varianza o un poco de los dos. Algo que siempre hago cuando intento mejorar el desempeño de un algoritmo de aprendizaje, es trazar estas líneas de aprendizaje. Esto, generalmente, te dará una mejor idea de si hay un problema de oscilación o de varianza. En el siguiente video veremos cómo esto puede sugerir acciones específicas que se deben realizar o no para mejorar el desempeño de un algoritmo de aprendizaje.