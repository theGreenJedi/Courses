1
00:00:00,390 --> 00:00:02,440
现在你应该已经知道

2
00:00:02,610 --> 00:00:04,660
算法正则化可以有效地防止过拟合

3
00:00:04,960 --> 00:00:06,230
但正则化跟算法的偏差和方差

4
00:00:06,460 --> 00:00:08,070
又有什么关系呢？

5
00:00:08,630 --> 00:00:09,890
在这段视频中

6
00:00:10,020 --> 00:00:11,180
我想更深入地

7
00:00:11,550 --> 00:00:13,300
探讨一下偏差和方差的问题

8
00:00:13,520 --> 00:00:14,450
讨论一下两者之间

9
00:00:15,070 --> 00:00:15,880
是如何相互影响的

10
00:00:16,070 --> 00:00:18,470
以及和算法的正则化之间的相互关系

11
00:00:22,180 --> 00:00:23,390
假如我们要对这样一个高阶多项式进行拟合

12
00:00:23,700 --> 00:00:24,880
为了防止过拟合现象 我们要使用一个正则化项

13
00:00:25,250 --> 00:00:27,460
因此我们试图通过这样一个正则化项

14
00:00:27,670 --> 00:00:28,670
来让参数的值尽可能小

15
00:00:28,790 --> 00:00:30,880
正则化项的求和范围照例取为 j 等于1到 m

16
00:00:31,560 --> 00:00:32,780
而非 j 等于0到 m

17
00:00:33,190 --> 00:00:34,690
然后我们来分析以下三种情形

18
00:00:35,120 --> 00:00:36,320
第一种情形是正则化参数 λ 取一个比较大的值

19
00:00:36,760 --> 00:00:37,770
比如 λ 的值取为10000甚至更大

20
00:00:37,910 --> 00:00:39,540
在这种情况下 所有这些参数

21
00:00:39,910 --> 00:00:41,070
θ1 θ2 θ3 等等 将被大大惩罚

22
00:00:41,880 --> 00:00:43,050
其结果是 这些参数的值将近似等于0

23
00:00:43,390 --> 00:00:45,280
并且假设模型 h(x) 的值将等于或者近似等于 θ0

24
00:00:45,720 --> 00:00:47,400
因此我们最终得到的假设函数 应该是这个样子

25
00:00:47,770 --> 00:00:49,190
近似是一条平滑的直线

26
00:00:49,290 --> 00:00:50,480
因此这个假设处于高偏差 对数据集欠拟合(underfit)

27
00:00:50,600 --> 00:00:53,130
因此一条水平直线 对这个数据集来讲不是一个好的假设

28
00:00:53,740 --> 00:00:55,590
与之对应的另一种情况是 λ值很小

29
00:00:55,660 --> 00:00:56,900
比如说 λ 的值等于0

30
00:00:56,960 --> 00:00:59,250
在这种情况下 如果我们要拟合一个高阶多项式的话

31
00:00:59,490 --> 00:01:00,640
那么我们通常会处于过拟合(overfitting)的情况

32
00:01:00,790 --> 00:01:01,600
在拟合一个高阶多项式时

33
00:01:01,780 --> 00:01:04,100
如果没有进行正则化 或者正则化程度很微小的话

34
00:01:04,370 --> 00:01:05,510
我们通常会得到高方差和过拟合的结果

35
00:01:05,660 --> 00:01:07,250
因为 λ 的值等于0相当于没有正则化项

36
00:01:07,580 --> 00:01:08,310
因此会对假设过拟合

37
00:01:08,490 --> 00:01:10,390
只有当我们取一个中间大小的 既不大也不小的 λ 值时

38
00:01:10,570 --> 00:01:12,660
我们才会得到一组合理的 对数据刚好拟合的 θ 参数值

39
00:01:13,110 --> 00:01:14,440
那么我们应该怎样自动地选择出一个最合适的正则化参数 λ 呢？

40
00:01:14,790 --> 00:01:17,000
重申一下 我们的模型和学习参数 以及最优化目标是这样的

41
00:01:17,180 --> 00:01:17,940
让我们假设在使用正则化的情形中

42
00:01:18,280 --> 00:01:19,980
定义 Jtrain(θ) 为另一种不同的形式

43
00:01:20,270 --> 00:01:21,530
同样定义为最优化目标 但不使用正则化项

44
00:01:21,690 --> 00:01:23,560
在先前的授课视频中 当我们没有使用正则化时

45
00:01:23,800 --> 00:01:25,250
我们定义的Jtrain(θ) 就是代价函数J(θ)

46
00:01:25,370 --> 00:01:28,130
但当我们使用正则化多出这个 λ 项时

47
00:01:28,410 --> 00:01:30,320
我们就将训练集误差 也就是Jtrain 定义为

48
00:01:30,660 --> 00:01:32,630
训练集数据预测误差的平方求和

49
00:01:32,970 --> 00:01:34,520
或者说是训练集的平均误差平方和 但不考虑正则化项

50
00:01:34,840 --> 00:01:35,810
与此类似 我们来定义交叉验证集误差和测试集误差

51
00:01:35,940 --> 00:01:38,100
和之前一样定义为 对交叉验证集和测试集进行预测的平均误差平方和

52
00:01:38,700 --> 00:01:39,870
总结一下 我们对于训练误差Jtrain Jcv Jtest的定义

53
00:01:40,250 --> 00:01:41,560
都是平均误差平方和

54
00:01:41,850 --> 00:01:43,310
或者准确地说 是训练集 验证集和测试集进行预测

55
00:01:43,710 --> 00:01:45,630
在不使用正则化项时 平均误差平方和的一半

56
00:01:45,720 --> 00:01:46,940
下面就是我们自动选取正则化参数 λ 的方法

57
00:01:47,080 --> 00:01:48,240
通常我的做法是 选取一系列我想要尝试的 λ 值

58
00:01:48,390 --> 00:01:49,690
因此首先我可能考虑不使用正则化的情形

59
00:01:49,940 --> 00:01:51,590
以及一系列我可能会试的值

60
00:01:52,750 --> 00:01:53,990
比如说我可能从0.01 0.02 0.04开始 一直试下去

61
00:01:54,190 --> 00:01:55,240
通常我会将步长设为2倍速度增长 直到一个比较大的值

62
00:01:56,170 --> 00:01:58,050
在本例中以两倍步长递增的话 我们最终取值10.24

63
00:01:58,230 --> 00:02:00,170
实际上我们取的是10 但已经非常接近了

64
00:02:00,350 --> 00:02:02,180
因为小数点后的24对最终的结果不会有太大影响

65
00:02:02,810 --> 00:02:03,900
因此 这样我就得到了12个不同的正则化参数 λ

66
00:02:04,630 --> 00:02:05,650
对应的12个不同的模型

67
00:02:05,790 --> 00:02:08,310
当然了 你也可以试小于0.01的值或者大于10的值

68
00:02:08,440 --> 00:02:14,460
但在这里我就不讨论这些情况了

69
00:02:15,700 --> 00:02:16,570
得到这12组模型后 接下来我们要做的事情是

70
00:02:16,730 --> 00:02:18,720
选用第一个模型 也就是 λ 等于0

71
00:02:19,220 --> 00:02:20,380
然后最小化我们的代价函数 J(θ)

72
00:02:20,770 --> 00:02:22,050
这样我们就得到了某个参数向量 θ

73
00:02:22,890 --> 00:02:23,810
与之前视频的做法类似

74
00:02:24,610 --> 00:02:26,080
我使用θ上标(1) 来表示第一个参数向量θ

75
00:02:26,580 --> 00:02:28,090
然后我再取第二个模型 λ 等于0.01的模型

76
00:02:29,100 --> 00:02:31,370
最小化代价方差 当然现在 λ 等于0.01

77
00:02:33,670 --> 00:02:36,580
那么会得到一个完全不同的参数向量 θ 用 θ(2)来表示

78
00:02:37,410 --> 00:02:39,540
同理 接下来我会得到 θ(3) 对应于我的第三个模型

79
00:02:40,410 --> 00:02:42,370
以此类推 一直到最后一个 λ 等于10或10.24的模型

80
00:02:43,170 --> 00:02:44,800
对应 θ(12)

81
00:02:45,540 --> 00:02:47,400
接下来我就可以用交叉验证集来评价这些假设和参数了

82
00:02:47,750 --> 00:02:48,670
因此我可以从第一个模型开始

83
00:02:49,040 --> 00:02:50,800
然后是第二个模型

84
00:02:51,650 --> 00:02:54,780
对每一个不同的正则化参数 λ 进行拟合

85
00:02:55,030 --> 00:02:57,440
然后用交叉验证集来评价每一个模型

86
00:02:58,480 --> 00:03:00,840
也即测出每一个参数 θ 在交叉验证集上的平均误差平方和

87
00:03:01,080 --> 00:03:02,230
然后我就选取这12个模型中交叉验证集误差最小的

88
00:03:02,500 --> 00:03:03,610
那个模型作为最终选择

89
00:03:03,830 --> 00:03:05,070
对于本例而言 假如说

90
00:03:05,410 --> 00:03:06,900
最终我选择了 θ(5) 也就是五次多项式

91
00:03:07,120 --> 00:03:10,060
因为此时的交叉验证集误差最小

92
00:03:10,940 --> 00:03:12,250
做完这些 最后

93
00:03:12,410 --> 00:03:13,690
如果我想看看该模型在测试集上的表现

94
00:03:14,210 --> 00:03:16,170
我可以用经过学习得到的模型 θ(5)

95
00:03:16,270 --> 00:03:17,370
来测出它对测试集的预测效果如何

96
00:03:17,830 --> 00:03:19,720
再次重申 这里我们依然是用交叉验证集来拟合模型

97
00:03:20,320 --> 00:03:21,990
这也是为什么我之前预留了一部分数据作为测试集的原因

98
00:03:23,240 --> 00:03:25,270
这样我就可以用这部分测试集比较准确地估计出

99
00:03:25,820 --> 00:03:27,060
我的参数向量 θ 对于新样本的泛化能力

100
00:03:27,490 --> 00:03:28,410
这就是模型选择在选取正则化参数 λ 时的应用

101
00:03:28,620 --> 00:03:29,820
在这段视频中我想讲的最后一个问题是

102
00:03:30,050 --> 00:03:31,010
当我们改变正则化参数 λ 的值时

103
00:03:31,410 --> 00:03:32,610
交叉验证集误差和训练集误差

104
00:03:32,990 --> 00:03:34,600
会随之发生怎样的变化

105
00:03:34,840 --> 00:03:36,770
我想提醒一下 我们最初的代价函数 J(θ)

106
00:03:38,310 --> 00:03:39,290
但在这里我们把训练误差

107
00:03:39,360 --> 00:03:41,500
定义为不包括正则化项

108
00:03:43,950 --> 00:03:45,600
交叉验证集误差也定义为不包括正则化项

109
00:03:45,720 --> 00:03:48,040
我要做的是绘制出 Jtrain和 Jcv 的曲线

110
00:03:48,220 --> 00:03:49,740
表达的是随着我增大正则化项参数 λ 的值

111
00:03:49,880 --> 00:03:51,050
看看我的假设

112
00:03:52,430 --> 00:03:53,560
在训练集上的表现如何变化

113
00:03:53,780 --> 00:03:54,740
以及在交叉验证集上表现如何变化

114
00:03:55,210 --> 00:03:57,390
就像我们之前看到的 如果 λ 的值很小

115
00:03:57,980 --> 00:03:59,400
那也就是说我们几乎没有使用正则化

116
00:03:59,660 --> 00:04:02,110
因此我们有很大可能处于过拟合

117
00:04:02,310 --> 00:04:04,850
而如果 λ 的值取的很大的时候

118
00:04:04,960 --> 00:04:06,140
也就是说取值在横坐标的右端

119
00:04:06,370 --> 00:04:07,890
那么由于 λ 的值很大 我们很有可能处于高偏差的问题

120
00:04:08,160 --> 00:04:10,700
所以 如果你画出 Jtrain 和 Jcv 的曲线

121
00:04:10,870 --> 00:04:12,130
你就会发现 当 λ 的值取得很小时

122
00:04:12,750 --> 00:04:14,210
对训练集的拟合相对较好

123
00:04:14,500 --> 00:04:16,720
因为没有使用正则化

124
00:04:19,830 --> 00:04:21,610
因此 对于 λ 值很小的情况正则化项可以忽略

125
00:04:22,330 --> 00:04:24,160
你只需要对平方误差求最小值即可

126
00:04:24,300 --> 00:04:26,040
所以当 λ 值很小时 你最终能得到一个值很小的Jtrain

127
00:04:26,230 --> 00:04:27,900
而如果 λ 的值很大时你将处于高偏差问题 不能对训练集很好地拟合

128
00:04:28,210 --> 00:04:34,120
因此你的误差值可能位于这个位置

129
00:04:34,270 --> 00:04:35,400
因此 当 λ 增大时

130
00:04:35,600 --> 00:04:37,530
训练集误差Jtrain的值

131
00:04:37,610 --> 00:04:38,800
会趋于上升

132
00:04:38,900 --> 00:04:41,070
因为 λ 的值比较大时对应着高偏差的问题

133
00:04:46,400 --> 00:04:47,260
此时你连训练集都不能很好地拟合

134
00:04:47,590 --> 00:04:48,740
反过来 当 λ 的值取得很小的时候

135
00:04:48,970 --> 00:04:49,770
你的数据能随意地与高次多项式很好地拟合

136
00:04:50,800 --> 00:04:52,100
而交叉验证集误差的曲线是这样的

137
00:04:52,480 --> 00:04:53,850
在曲线的右端 当 λ 的值取得很大时

138
00:04:54,050 --> 00:04:56,110
我们会处于欠拟合问题

139
00:04:56,390 --> 00:04:58,550
因此这对应着偏差问题

140
00:04:58,780 --> 00:05:00,310
那么此时交叉验证集误差将会很大

141
00:05:00,850 --> 00:05:02,000
我写在这里 这是交叉验证集误差Jcv(θ)

142
00:05:02,200 --> 00:05:04,060
由于高偏差的原因我们不能很好地拟合

143
00:05:05,550 --> 00:05:06,650
我们的假设不能在交叉验证集上表现地比较好

144
00:05:08,580 --> 00:05:09,440
而曲线的左端对应的是高方差问题

145
00:05:09,620 --> 00:05:11,210
此时我们的 λ 值取得很小很小

146
00:05:11,690 --> 00:05:13,220
因此我们会对数据过度拟合

147
00:05:13,850 --> 00:05:15,810
所以由于过拟合的原因 交叉验证集误差也会很大

148
00:05:15,940 --> 00:05:17,560
好的 这就是当我们改变正则化参数 λ 的值时

149
00:05:17,660 --> 00:05:18,770
交叉验证集误差和训练集误差随之发生的变化

150
00:05:18,960 --> 00:05:19,980
当然 在中间取的某个 λ 的值

151
00:05:20,530 --> 00:05:21,420
表现得刚好合适 这种情况下表现最好

152
00:05:21,550 --> 00:05:22,690
交叉验证集误差或者测试集误差都很小

153
00:05:22,930 --> 00:05:24,210
当然由于我在这里画的图显得太卡通 也太理想化了

154
00:05:24,410 --> 00:05:25,280
对于真实的数据

155
00:05:25,350 --> 00:05:27,090
你得到的曲线可能比这看起来更凌乱 会有很多的噪声

156
00:05:27,620 --> 00:05:28,980
对某个实际的数据集 你或多或少能看出像这样的一个趋势

157
00:05:29,450 --> 00:05:32,050
通过绘出这条曲线 通过交叉验证集误差的变化趋势

158
00:05:32,050 --> 00:05:35,150
你可以用自己选择出 或者编写程序自动得出

159
00:05:36,340 --> 00:05:37,810
能使交叉验证集误差最小的那个点

160
00:05:38,050 --> 00:05:39,710
然后选出那个与之对应的参数 λ 的值

161
00:05:39,790 --> 00:05:41,850
当我在尝试为学习算法选择正则化参数 λ 的时候

162
00:05:42,160 --> 00:05:44,200
我通常都会画出像这样一个图

163
00:05:44,940 --> 00:05:46,440
帮助我更好地理解各种情况

164
00:05:47,120 --> 00:05:48,420
同时也帮助我确认 我选择的正则化参数值到底好不好

165
00:05:48,770 --> 00:05:49,370
希望这节课的内容让你更深入地理解了正则化

166
00:05:49,400 --> 00:06:00,290
以及它对学习算法的偏差和方差的影响

167
00:06:00,440 --> 00:06:01,320
到目前为止你已经从不同角度认识了方差和偏差问题

168
00:06:01,570 --> 00:06:02,150
在下一节视频中我要做的是

169
00:06:02,240 --> 00:06:03,910
基于我们已经介绍过的所有这些概念

170
00:06:04,250 --> 00:06:05,800
将它们结合起来 建立我们的诊断法

171
00:06:05,960 --> 00:06:07,400
也称为学习曲线

172
00:06:07,570 --> 00:06:10,050
这种方法通常被用来诊断一个学习算法

173
00:06:11,050 --> 00:06:11,790
到底是处于偏差问题还是方差问题 还是两者都有 【果壳教育无边界字幕组】翻译/时间轴：所罗门捷列夫

174
00:06:12,070 --> 00:06:13,660
假如说

175
00:06:13,950 --> 00:06:15,570
最终我选择了theta(5)

176
00:06:15,650 --> 00:06:18,260
也就是五次多项式

177
00:06:18,650 --> 00:06:21,240
因为此时的交叉验证集误差最小

178
00:06:22,010 --> 00:06:24,220
做完这些 最后

179
00:06:24,390 --> 00:06:25,220
如果我想看看该模型

180
00:06:25,490 --> 00:06:26,630
在测试集上的表现

181
00:06:27,370 --> 00:06:28,690
我可以用经过学习

182
00:06:29,000 --> 00:06:30,890
得到的模型theta(5)

183
00:06:31,040 --> 00:06:32,550
来测出它对测试集的

184
00:06:32,670 --> 00:06:34,710
预测效果如何

185
00:06:34,840 --> 00:06:36,310
再次重申一下

186
00:06:36,480 --> 00:06:37,670
这里我们依然是用

187
00:06:38,230 --> 00:06:40,440
交叉验证集来拟合模型

188
00:06:41,270 --> 00:06:42,460
这也是为什么我之前

189
00:06:42,660 --> 00:06:43,940
预留了一部分数据

190
00:06:44,420 --> 00:06:45,810
作为测试集的原因

191
00:06:45,860 --> 00:06:47,060
这样我就可以用这部分测试集

192
00:06:47,350 --> 00:06:48,470
比较准确地估计出

193
00:06:48,730 --> 00:06:49,940
我的参数向量theta

194
00:06:50,190 --> 00:06:51,690
对于新样本的泛化能力

195
00:06:54,120 --> 00:06:55,870
这就是模型选择在选取

196
00:06:56,260 --> 00:06:58,310
正则化参数lambda时的应用

197
00:06:59,260 --> 00:07:00,350
在这段视频中

198
00:07:00,490 --> 00:07:01,520
我想讲的最后一个问题是

199
00:07:01,770 --> 00:07:02,890
当我们改变

200
00:07:02,970 --> 00:07:05,080
正则化参数lambda的值时

201
00:07:05,650 --> 00:07:07,340
交叉验证集误差

202
00:07:07,680 --> 00:07:10,420
和训练集误差会随之

203
00:07:10,530 --> 00:07:12,830
发生怎样的变化

204
00:07:13,460 --> 00:07:15,060
我想提醒一下

205
00:07:15,360 --> 00:07:16,760
我们最初的代价函数J(θ)

206
00:07:16,840 --> 00:07:18,230
原来是这样的形式

207
00:07:18,400 --> 00:07:19,350
但在这里我们把训练误差

208
00:07:20,450 --> 00:07:21,830
定义为不包括正则化项

209
00:07:22,240 --> 00:07:24,180
交叉验证集误差

210
00:07:24,860 --> 00:07:26,150
也定义为不包括

211
00:07:26,360 --> 00:07:28,810
正则化项

212
00:07:29,210 --> 00:07:30,770
我要做的是

213
00:07:31,750 --> 00:07:34,420
绘制出Jtrain和Jcv的曲线

214
00:07:34,700 --> 00:07:35,820
随着我增大正则化项参数

215
00:07:35,920 --> 00:07:38,250
lambda的值

216
00:07:38,580 --> 00:07:39,760
看看我的假设

217
00:07:39,920 --> 00:07:41,280
在训练集上的表现如何变化

218
00:07:41,340 --> 00:07:43,250
以及在交叉验证集上

219
00:07:43,320 --> 00:07:45,230
表现如何变化

220
00:07:45,700 --> 00:07:49,170
就像我们之前看到的

221
00:07:49,320 --> 00:07:51,740
如果正则化项参数

222
00:07:52,070 --> 00:07:53,730
lambda的值很小

223
00:07:53,920 --> 00:07:56,320
那也就是说我们几乎没有使用正则化

224
00:07:56,770 --> 00:07:58,860
因此我们有很大可能处于过拟合

225
00:07:59,950 --> 00:08:01,680
而如果lambda的值

226
00:08:01,930 --> 00:08:03,090
取的很大的时候

227
00:08:03,310 --> 00:08:04,210
也就是说取值在

228
00:08:05,190 --> 00:08:07,400
横坐标的右端

229
00:08:07,690 --> 00:08:08,770
那么由于lambda的值很大

230
00:08:09,560 --> 00:08:12,060
我们很有可能处于高偏差的问题

231
00:08:13,040 --> 00:08:14,650
所以 如果你画出

232
00:08:15,280 --> 00:08:16,900
Jtrain和Jcv的曲线

233
00:08:16,980 --> 00:08:18,730
你就会发现

234
00:08:19,100 --> 00:08:21,170
当lambda的值取得很小时

235
00:08:22,010 --> 00:08:23,040
对训练集的拟合相对较好

236
00:08:23,640 --> 00:08:24,690
因为没有使用正则化

237
00:08:25,600 --> 00:08:26,890
因此 对于lambda值很小的情况

238
00:08:26,990 --> 00:08:28,750
正则化项基本可以忽略

239
00:08:28,960 --> 00:08:30,100
你只需要对平方误差

240
00:08:30,420 --> 00:08:32,460
做最小化处理即可

241
00:08:32,870 --> 00:08:34,490
所以当lambda值很小时

242
00:08:34,630 --> 00:08:35,580
你最终能得到一个

243
00:08:36,170 --> 00:08:37,790
值很小的Jtrain

244
00:08:37,900 --> 00:08:39,180
而如果lambda的值很大时

245
00:08:39,740 --> 00:08:42,480
你将处于高偏差问题 不能对训练集很好地拟合

246
00:08:42,640 --> 00:08:43,800
因此你的误差值可能位于这个位置

247
00:08:44,550 --> 00:08:48,800
因此 当lambda增大时

248
00:08:48,930 --> 00:08:50,130
训练集误差Jtrain的值

249
00:08:50,320 --> 00:08:52,290
会趋于上升

250
00:08:53,050 --> 00:08:54,720
因为lambda的值比较大时

251
00:08:54,920 --> 00:08:55,850
对应着高偏差的问题

252
00:08:56,400 --> 00:08:57,400
此时你连训练集都不能很好地拟合

253
00:08:57,590 --> 00:08:59,160
反过来 当lambda的值

254
00:08:59,290 --> 00:09:01,380
取得很小的时候

255
00:09:01,650 --> 00:09:03,500
你的数据能随意地与高次多项式

256
00:09:03,850 --> 00:09:06,690
很好地拟合

257
00:09:06,920 --> 00:09:10,860
交叉验证集误差的曲线是这样的

258
00:09:12,080 --> 00:09:13,600
在曲线的右端

259
00:09:13,930 --> 00:09:15,460
当lambda的值

260
00:09:15,530 --> 00:09:16,470
取得很大时

261
00:09:17,440 --> 00:09:18,600
我们会处于欠拟合问题

262
00:09:19,900 --> 00:09:21,280
也对应着偏差问题

263
00:09:22,950 --> 00:09:25,750
那么此时交叉验证集误差

264
00:09:26,030 --> 00:09:27,680
将会很大

265
00:09:27,920 --> 00:09:29,060
我写在这里

266
00:09:29,250 --> 00:09:31,760
这是交叉验证集误差Jcv

267
00:09:32,270 --> 00:09:33,440
由于高偏差的原因我们不能很好地拟合

268
00:09:34,430 --> 00:09:36,580
我们的假设不能在交叉验证集上表现地比较好

269
00:09:38,050 --> 00:09:41,000
而曲线的左端对应的是高方差问题

270
00:09:42,120 --> 00:09:43,620
此时我们的lambda值

271
00:09:44,020 --> 00:09:45,910
取得很小很小

272
00:09:46,070 --> 00:09:47,190
因此我们会对数据过度拟合

273
00:09:47,870 --> 00:09:49,140
所以由于过拟合的原因

274
00:09:49,230 --> 00:09:51,320
交叉验证集误差Jcv

275
00:09:51,710 --> 00:09:52,610
结果也会很大

276
00:09:53,700 --> 00:09:55,380
好的 这就是

277
00:09:56,620 --> 00:09:58,270
当我们改变正则化参数

278
00:09:58,510 --> 00:09:59,860
lambda的值时

279
00:10:00,130 --> 00:10:01,410
交叉验证集误差

280
00:10:01,820 --> 00:10:04,270
和训练集误差

281
00:10:04,950 --> 00:10:06,920
随之发生的变化

282
00:10:07,110 --> 00:10:08,220
当然 在中间取的某个

283
00:10:08,430 --> 00:10:10,100
lambda的值

284
00:10:10,790 --> 00:10:13,220
表现得刚好合适

285
00:10:13,720 --> 00:10:14,990
这种情况下表现最好

286
00:10:15,120 --> 00:10:16,470
交叉验证集误差

287
00:10:16,770 --> 00:10:19,710
或者测试集误差都很小

288
00:10:19,920 --> 00:10:20,980
当然由于我在这里画的图

289
00:10:21,300 --> 00:10:23,630
显得太卡通 也太理想化了

290
00:10:24,650 --> 00:10:25,670
对于真实的数据

291
00:10:26,210 --> 00:10:27,400
你得到的曲线可能

292
00:10:27,510 --> 00:10:28,470
比这看起来更凌乱

293
00:10:28,690 --> 00:10:30,580
会有很多的噪声

294
00:10:31,540 --> 00:10:32,640
对某个实际的数据集

295
00:10:33,180 --> 00:10:34,450
你或多或少能看出

296
00:10:34,740 --> 00:10:36,180
像这样的一个趋势

297
00:10:36,450 --> 00:10:37,340
通过绘出这条曲线

298
00:10:37,900 --> 00:10:38,930
通过交叉验证集误差的变化趋势

299
00:10:39,820 --> 00:10:41,460
你可以用自己选择出

300
00:10:41,600 --> 00:10:43,370
或者编写程序自动得出

301
00:10:43,680 --> 00:10:45,100
能使交叉验证集误差

302
00:10:45,550 --> 00:10:48,590
最小的那个点

303
00:10:48,880 --> 00:10:50,600
然后选出那个与之对应的

304
00:10:51,280 --> 00:10:52,780
参数lambda的值

305
00:10:53,560 --> 00:10:54,790
当我在尝试为学习算法

306
00:10:54,920 --> 00:10:56,870
选择正则化参数

307
00:10:57,200 --> 00:10:59,300
lambda的时候

308
00:10:59,420 --> 00:11:00,520
我通常都会得出

309
00:11:00,800 --> 00:11:02,470
类似这个图的结果

310
00:11:02,750 --> 00:11:04,520
帮助我更好地理解各种情况

311
00:11:04,780 --> 00:11:06,320
同时也帮助我确认

312
00:11:06,880 --> 00:11:08,140
我选择的正则化参数值

313
00:11:08,320 --> 00:11:09,670
到底好不好

314
00:11:10,520 --> 00:11:12,320
希望这节课的内容

315
00:11:12,520 --> 00:11:14,160
让你更深入地理解了正则化

316
00:11:15,650 --> 00:11:16,890
以及它对学习算法的

317
00:11:17,400 --> 00:11:18,470
偏差和方差的影响

318
00:11:19,970 --> 00:11:21,510
到目前为止你已经从不同角度

319
00:11:21,670 --> 00:11:23,410
见识了方差和偏差问题

320
00:11:24,180 --> 00:11:25,470
在下一节视频中

321
00:11:25,700 --> 00:11:27,000
我要做的是

322
00:11:27,230 --> 00:11:28,110
基于我们已经浏览过的

323
00:11:28,280 --> 00:11:30,070
所有这些概念

324
00:11:30,320 --> 00:11:31,210
将它们结合起来

325
00:11:31,920 --> 00:11:33,770
建立我们的诊断法

326
00:11:34,050 --> 00:11:35,100
也称为学习曲线

327
00:11:35,150 --> 00:11:36,300
这种方法通常被用来

328
00:11:36,720 --> 00:11:37,920
诊断一个学习算法

329
00:11:38,190 --> 00:11:39,630
到底是处于偏差问题

330
00:11:40,040 --> 00:11:41,330
还是方差问题

331
00:11:41,560 --> 00:11:42,950
还是两者都有【教育无边界字幕组】翻译、校对、审核：所罗门捷列夫