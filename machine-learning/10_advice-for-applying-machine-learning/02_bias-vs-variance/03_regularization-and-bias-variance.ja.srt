1
00:00:00,390 --> 00:00:02,440
正規化がどうオーバーフィットを

2
00:00:02,610 --> 00:00:04,660
防止するかは、これまで見てきた。

3
00:00:04,960 --> 00:00:06,230
でもそれは、どんな風に

4
00:00:06,460 --> 00:00:08,070
学習アルゴリズムのバイアスと分散に影響を与えるか？

5
00:00:08,630 --> 00:00:09,890
このビデオでは、

6
00:00:10,020 --> 00:00:11,180
バイアスと分散の問題について

7
00:00:11,550 --> 00:00:13,300
より深く見ていきたい。

8
00:00:13,520 --> 00:00:14,450
そして学習アルゴリズムの

9
00:00:15,070 --> 00:00:15,880
正規化とどう相互作用し、

10
00:00:16,070 --> 00:00:18,470
影響を与えるか議論していきたい。

11
00:00:22,180 --> 00:00:23,390
とても高い次数の多項式を

12
00:00:23,700 --> 00:00:24,880
線形回帰で

13
00:00:25,250 --> 00:00:27,460
フィッティングしたとする。

14
00:00:27,670 --> 00:00:28,670
だがオーバーフィットを防ぐ為に、

15
00:00:28,790 --> 00:00:30,880
ここにあるような正規化を行うとする。

16
00:00:31,560 --> 00:00:32,780
このような高次の多項式を

17
00:00:33,190 --> 00:00:34,690
フィッティングするが、

18
00:00:35,120 --> 00:00:36,320
そこでオーバーフィットを

19
00:00:36,760 --> 00:00:37,770
避けるために

20
00:00:37,910 --> 00:00:39,540
ここに示したような正規化を行うとする。

21
00:00:39,910 --> 00:00:41,070
つまりこの正規化の項で

22
00:00:41,880 --> 00:00:43,050
パラメータを値を

23
00:00:43,390 --> 00:00:45,280
小さく保とうとするという訳。

24
00:00:45,720 --> 00:00:47,400
そしていつも通り、正規化の和は

25
00:00:47,770 --> 00:00:49,190
jが1からmまで取り、

26
00:00:49,290 --> 00:00:50,480
jが0からmでは無い。

27
00:00:50,600 --> 00:00:53,130
では3つのケースを考えてみよう。

28
00:00:53,740 --> 00:00:55,590
最初のケースは

29
00:00:55,660 --> 00:00:56,900
正規化パラメータのラムダの値が

30
00:00:56,960 --> 00:00:59,250
とても大きな場合。

31
00:00:59,490 --> 00:01:00,640
例えば ラムダ=10,000 とか

32
00:01:00,790 --> 00:01:01,600
巨大な値の時。

33
00:01:01,780 --> 00:01:04,100
この場合、

34
00:01:04,370 --> 00:01:05,510
これらのパラメータ全て

35
00:01:05,660 --> 00:01:07,250
シータ1、シータ2、シータ3などなど、が、

36
00:01:07,580 --> 00:01:08,310
とても重く

37
00:01:08,490 --> 00:01:10,390
ペナルティを課される。

38
00:01:10,570 --> 00:01:12,660
すると、これらのパラメータの値の

39
00:01:13,110 --> 00:01:14,440
ほとんどがゼロになり、

40
00:01:14,790 --> 00:01:17,000
結果として、仮説はだいたい

41
00:01:17,180 --> 00:01:17,940
h(x)は単にだいたい

42
00:01:18,280 --> 00:01:19,980
近似としてはイコール

43
00:01:20,270 --> 00:01:21,530
シータ0となる。

44
00:01:21,690 --> 00:01:23,560
だから仮説は多かれ少なかれ

45
00:01:23,800 --> 00:01:25,250
そんな感じに見える。

46
00:01:25,370 --> 00:01:28,130
これは多かれ少なかれフラットで、定数の直線。

47
00:01:28,410 --> 00:01:30,320
つまり仮説は高バイアスで、

48
00:01:30,660 --> 00:01:32,630
これらのデータセットに対してアンダーフィットしている。

49
00:01:32,970 --> 00:01:34,520
だから水平の直線は

50
00:01:34,840 --> 00:01:35,810
単にこれらのデータセットの

51
00:01:35,940 --> 00:01:38,100
とても良い仮説という訳では無い。

52
00:01:38,700 --> 00:01:39,870
反対側の極端では、

53
00:01:40,250 --> 00:01:41,560
とても小さい値ラムダの時、

54
00:01:41,850 --> 00:01:43,310
たとえばラムダが

55
00:01:43,710 --> 00:01:45,630
イコール0の時。

56
00:01:45,720 --> 00:01:46,940
その場合、高次の多項式で

57
00:01:47,080 --> 00:01:48,240
フィッティングしているなら、

58
00:01:48,390 --> 00:01:49,690
これは良くある

59
00:01:49,940 --> 00:01:51,590
オーバーフィットの状況だ。

60
00:01:52,750 --> 00:01:53,990
その場合、高次の多項式で

61
00:01:54,190 --> 00:01:55,240
フィッティングしていて、

62
00:01:56,170 --> 00:01:58,050
基本的には正規化無しか

63
00:01:58,230 --> 00:02:00,170
とても少ない正規化しかしないとすると、

64
00:02:00,350 --> 00:02:02,180
通常の高分散と、オーバーフィットの状況となる。

65
00:02:02,810 --> 00:02:03,900
何故ならもしラムダがイコール0なら

66
00:02:04,630 --> 00:02:05,650
それは単に

67
00:02:05,790 --> 00:02:08,310
正規化無しでフィッティングしているのだから、

68
00:02:08,440 --> 00:02:14,460
仮説はオーバーフィットする事となる。

69
00:02:15,700 --> 00:02:16,570
そしてもしラムダの値を中間に

70
00:02:16,730 --> 00:02:18,720
大きすぎず、小さすぎずにパラメータを設定出来た時だけ、

71
00:02:19,220 --> 00:02:20,380
データに対して

72
00:02:20,770 --> 00:02:22,050
リーズナブルにフィッティング出来る。

73
00:02:22,890 --> 00:02:23,810
では、どうやったら正規化パラメータのラムダの

74
00:02:24,610 --> 00:02:26,080
良い値を自動的に

75
00:02:26,580 --> 00:02:28,090
選ぶ事が出来るだろうか？

76
00:02:29,100 --> 00:02:31,370
ここに、我らのモデル、学習アルゴリズムの目的関数を再掲しておく。

77
00:02:33,670 --> 00:02:36,580
正規化を使っている状況として、

78
00:02:37,410 --> 00:02:39,540
Jtrainのシータを最適化の目的関数とは

79
00:02:40,410 --> 00:02:42,370
分けて定義しよう。

80
00:02:43,170 --> 00:02:44,800
正規化項を抜いて定義する。

81
00:02:45,540 --> 00:02:47,400
以前は、前のビデオで

82
00:02:47,750 --> 00:02:48,670
正規化をしていない時は

83
00:02:49,040 --> 00:02:50,800
JtrainのシータをJのシータ、つまり

84
00:02:51,650 --> 00:02:54,780
コスト関数と同じ物として定義していた。

85
00:02:55,030 --> 00:02:57,440
だが正規化を用いるべく追加のラムダの項を足したら、

86
00:02:58,480 --> 00:03:00,840
Jtrain、つまりトレーニングセットの誤差を

87
00:03:01,080 --> 00:03:02,230
トレーニングセットの

88
00:03:02,500 --> 00:03:03,610
誤差の二乗の和だけで定義する、

89
00:03:03,830 --> 00:03:05,070
トレーニングセットの

90
00:03:05,410 --> 00:03:06,900
平均の誤差の二乗で

91
00:03:07,120 --> 00:03:10,060
正規化項を考慮に入れないで定義するのだ。

92
00:03:10,940 --> 00:03:12,250
そして同様に

93
00:03:12,410 --> 00:03:13,690
クロスバリデーションセット誤差とテストセット誤差も

94
00:03:14,210 --> 00:03:16,170
以前と同様に定義する、つまり

95
00:03:16,270 --> 00:03:17,370
クロスバリデーションセットとテストセットの

96
00:03:17,830 --> 00:03:19,720
誤差の二乗の和の

97
00:03:20,320 --> 00:03:21,990
平均。

98
00:03:23,240 --> 00:03:25,270
まとめると、

99
00:03:25,820 --> 00:03:27,060
JtrainとJcvと

100
00:03:27,490 --> 00:03:28,410
Jtestの定義は

101
00:03:28,620 --> 00:03:29,820
単なる誤差の二乗の

102
00:03:30,050 --> 00:03:31,010
平均、、、じゃなくて

103
00:03:31,410 --> 00:03:32,610
トレーニングセットとバリデーションセットと

104
00:03:32,990 --> 00:03:34,600
テストセットの誤差の二乗の平均で

105
00:03:34,840 --> 00:03:36,770
追加の正規化項が無しの物と

106
00:03:38,310 --> 00:03:39,290
定義する。

107
00:03:39,360 --> 00:03:41,500
そしてこんな風に正規化パラメータのラムダを自動で選ぶ。

108
00:03:43,950 --> 00:03:45,600
普通やるのは、試したいラムダの値の範囲を

109
00:03:45,720 --> 00:03:48,040
あらかじめ持っておく。

110
00:03:48,220 --> 00:03:49,740
例えば正規化しない、

111
00:03:49,880 --> 00:03:51,050
というのもあるかもしれないし、

112
00:03:52,430 --> 00:03:53,560
幾つかの試してみたい値も入れてあるかもしれない。

113
00:03:53,780 --> 00:03:54,740
例えばラムダを

114
00:03:55,210 --> 00:03:57,390
0.01、0.02、0.04、、、などに渡って構築するかもしれない。

115
00:03:57,980 --> 00:03:59,400
そして見ての通り、普通私は、

116
00:03:59,660 --> 00:04:02,110
これらのステップを

117
00:04:02,310 --> 00:04:04,850
2倍づつで進めて、ある程度の大きい数字までやる。

118
00:04:04,960 --> 00:04:06,140
これを二の倍数とすると、

119
00:04:06,370 --> 00:04:07,890
実際は10.24だ。

120
00:04:08,160 --> 00:04:10,700
ぴったり10じゃないけど

121
00:04:10,870 --> 00:04:12,130
だいたい同じだ。

122
00:04:12,750 --> 00:04:14,210
桁数で三桁目とか四桁目の

123
00:04:14,500 --> 00:04:16,720
数は結果にはそんなに影響を与えない。

124
00:04:19,830 --> 00:04:21,610
これは、えーと、

125
00:04:22,330 --> 00:04:24,160
12個の異なるモデルを与える。

126
00:04:24,300 --> 00:04:26,040
私が試す事になるモデルの選択肢を、

127
00:04:26,230 --> 00:04:27,900
12個の異なる

128
00:04:28,210 --> 00:04:34,120
正規化パラメータに対応した。

129
00:04:34,270 --> 00:04:35,400
もちろん、0.01以下の値とか

130
00:04:35,600 --> 00:04:37,530
10より大きい値を試したって

131
00:04:37,610 --> 00:04:38,800
いい。

132
00:04:38,900 --> 00:04:41,070
でもここでは簡単のためにこんだけで切った。

133
00:04:46,400 --> 00:04:47,260
これらの12のモデルを所与とすると

134
00:04:47,590 --> 00:04:48,740
我らが行うのは

135
00:04:48,970 --> 00:04:49,770
以下の事だ:

136
00:04:50,800 --> 00:04:52,100
この最初のモデル

137
00:04:52,480 --> 00:04:53,850
ラムダ=0を取り、

138
00:04:54,050 --> 00:04:56,110
コスト関数Jのシータを

139
00:04:56,390 --> 00:04:58,550
最小化する。

140
00:04:58,780 --> 00:05:00,310
この結果、あるパラメータベクトルのシータが得られ

141
00:05:00,850 --> 00:05:02,000
前回のビデオと同様に

142
00:05:02,200 --> 00:05:04,060
これをシータの上付き添字1で

143
00:05:05,550 --> 00:05:06,650
示す事にしよう。

144
00:05:08,580 --> 00:05:09,440
そして次に、二番目のモデル、

145
00:05:09,620 --> 00:05:11,210
ラムダを0.01として取り、

146
00:05:11,690 --> 00:05:13,220
コスト関数を

147
00:05:13,850 --> 00:05:15,810
最小化する。

148
00:05:15,940 --> 00:05:17,560
今回は当然

149
00:05:17,660 --> 00:05:18,770
ラムダ=0.01を使って

150
00:05:18,960 --> 00:05:19,980
さっきとは別のパラメータベクトル、シータを得る。

151
00:05:20,530 --> 00:05:21,420
それをシータ2と記す。

152
00:05:21,550 --> 00:05:22,690
次は三番目のモデルから

153
00:05:22,930 --> 00:05:24,210
シータ3を

154
00:05:24,410 --> 00:05:25,280
得て、

155
00:05:25,350 --> 00:05:27,090
それを以下同様に

156
00:05:27,620 --> 00:05:28,980
最後のモデルである

157
00:05:29,450 --> 00:05:32,050
ラムダ=10 まで、

158
00:05:32,050 --> 00:05:35,150
または10.24までやり、結局このシータ12を得る。

159
00:05:36,340 --> 00:05:37,810
次に、これらの仮説全て、

160
00:05:38,050 --> 00:05:39,710
これら全てのパラメータを取り、

161
00:05:39,790 --> 00:05:41,850
クロスバリデーションセットを

162
00:05:42,160 --> 00:05:44,200
それらを評価する為に使う。

163
00:05:44,940 --> 00:05:46,440
最初のモデル、

164
00:05:47,120 --> 00:05:48,420
二番目のモデルを見て、

165
00:05:48,770 --> 00:05:49,370
これら異なる正規化パラメータの値に対し

166
00:05:49,400 --> 00:06:00,290
フィッティングして、

167
00:06:00,440 --> 00:06:01,320
それらをクロスバリデーションセットに対して

168
00:06:01,570 --> 00:06:02,150
評価する。
基本的にはこれらのパラメータ毎に、誤差の二乗の平均を

169
00:06:02,240 --> 00:06:03,910
クロスバリデーションセットに対して測る。

170
00:06:04,250 --> 00:06:05,800
そしてこれら12個のモデルから

171
00:06:05,960 --> 00:06:07,400
一番低いクロスバリデーションセット誤差が得られる物を

172
00:06:07,570 --> 00:06:10,050
選びだす。

173
00:06:11,050 --> 00:06:11,790
そして、ここで話を進める為に

174
00:06:12,070 --> 00:06:13,660
結果として

175
00:06:13,950 --> 00:06:15,570
シータ5、つまり5次の多項式の

176
00:06:15,650 --> 00:06:18,260
モデルを選んだとしよう。

177
00:06:18,650 --> 00:06:21,240
何故ならこれが一番クロスバリデーションの誤差が小さかったから、とする。

178
00:06:22,010 --> 00:06:24,220
それを終えて、最後に

179
00:06:24,390 --> 00:06:25,220
テストセットの誤差を

180
00:06:25,490 --> 00:06:26,630
レポートしたければ、やることは、

181
00:06:27,370 --> 00:06:28,690
パラメータのシータ5、

182
00:06:29,000 --> 00:06:30,890
これは私の選んだ物だが、

183
00:06:31,040 --> 00:06:32,550
それを取って、それが

184
00:06:32,670 --> 00:06:34,710
テストセットに対してとれくらい良いかを見る。

185
00:06:34,840 --> 00:06:36,310
ここでも、このパラメータの

186
00:06:36,480 --> 00:06:37,670
シータはクロスバリデーションセットに対して

187
00:06:38,230 --> 00:06:40,440
フィッティングしたのだから、

188
00:06:41,270 --> 00:06:42,460
テストセットはそれとは別に

189
00:06:42,660 --> 00:06:43,940
とっておいて、

190
00:06:44,420 --> 00:06:45,810
初めて見る手本に対して

191
00:06:45,860 --> 00:06:47,060
どれくらいうまく一般化出来ているかを

192
00:06:47,350 --> 00:06:48,470
見積もるのを

193
00:06:48,730 --> 00:06:49,940
よりうまくやる為に

194
00:06:50,190 --> 00:06:51,690
使うのです。

195
00:06:54,120 --> 00:06:55,870
以上がモデル選択を

196
00:06:56,260 --> 00:06:58,310
正規化パラメータのラムダを選ぶのに

197
00:06:59,260 --> 00:07:00,350
適用した場合です。

198
00:07:00,490 --> 00:07:01,520
このビデオで最後にやりたい事は、

199
00:07:01,770 --> 00:07:02,890
正規化パラメータのラムダを

200
00:07:02,970 --> 00:07:05,080
変化させていくと、

201
00:07:05,650 --> 00:07:07,340
クロスバリデーションとトレーニングの誤差が

202
00:07:07,680 --> 00:07:10,420
どう変化していくかを

203
00:07:10,530 --> 00:07:12,830
より良く理解する事です。

204
00:07:13,460 --> 00:07:15,060
備忘録として、

205
00:07:15,360 --> 00:07:16,760
これが元のコスト関数、Jのシータでした。

206
00:07:16,840 --> 00:07:18,230
だが今回の目的では、

207
00:07:18,400 --> 00:07:19,350
正規化パラメータ無しで

208
00:07:20,450 --> 00:07:21,830
トレーニング誤差と

209
00:07:22,240 --> 00:07:24,180
クロスバリデーション誤差を

210
00:07:24,860 --> 00:07:26,150
定義する、

211
00:07:26,360 --> 00:07:28,810
正規化パラメータ無しで。

212
00:07:29,210 --> 00:07:30,770
そしてこのJtrainと

213
00:07:31,750 --> 00:07:34,420
Jcvをプロットしたい。

214
00:07:34,700 --> 00:07:35,820
意図する所は、

215
00:07:35,920 --> 00:07:38,250
仮説がどれくらい

216
00:07:38,580 --> 00:07:39,760
トレーニングセットと

217
00:07:39,920 --> 00:07:41,280
クロスバリデーションセットに対して

218
00:07:41,340 --> 00:07:43,250
良いか、が、

219
00:07:43,320 --> 00:07:45,230
正規化パラメータのラムダを変化させていくと

220
00:07:45,700 --> 00:07:49,170
どう変わっていくかを見ていきたい。

221
00:07:49,320 --> 00:07:51,740
で、以前に見たように、

222
00:07:52,070 --> 00:07:53,730
ラムダが小さい時は、

223
00:07:53,920 --> 00:07:56,320
あまり正規化をしない、という事なので

224
00:07:56,770 --> 00:07:58,860
よりオーバーフィットの危険性にさらされる。

225
00:07:59,950 --> 00:08:01,680
他方、ラムダが大きくなると、

226
00:08:01,930 --> 00:08:03,090
つまり、この横軸の

227
00:08:03,310 --> 00:08:04,210
右側の部分だと、

228
00:08:05,190 --> 00:08:07,400
その時は

229
00:08:07,690 --> 00:08:08,770
より大きなラムダとなるので、

230
00:08:09,560 --> 00:08:12,060
バイアスの問題に遭遇するリスクが上がる。

231
00:08:13,040 --> 00:08:14,650
という訳でJtrainとJcvを

232
00:08:15,280 --> 00:08:16,900
プロットすると、以下の事に気付く。

233
00:08:16,980 --> 00:08:18,730
小さなラムダの値では

234
00:08:19,100 --> 00:08:21,170
相対的にはトレーニングセットには

235
00:08:22,010 --> 00:08:23,040
良くフィット出来る、何故なら

236
00:08:23,640 --> 00:08:24,690
あまり正規化しないという事だから。

237
00:08:25,600 --> 00:08:26,890
だから小さなラムダの値では

238
00:08:26,990 --> 00:08:28,750
正規化の項は基本的には

239
00:08:28,960 --> 00:08:30,100
どっかに行ってしまうような物で、

240
00:08:30,420 --> 00:08:32,460
単に誤差の二乗を最小化しているのに、極めて近い事をしている。

241
00:08:32,870 --> 00:08:34,490
だからラムダが小さい時は

242
00:08:34,630 --> 00:08:35,580
結果としてはJtrainは小さくなるが、

243
00:08:36,170 --> 00:08:37,790
他方ラムダが大きいと、

244
00:08:37,900 --> 00:08:39,180
高バイアス問題となり

245
00:08:39,740 --> 00:08:42,480
トレーニングセットにはうまくフィットしなくなる。

246
00:08:42,640 --> 00:08:43,800
だから値は結局、上昇する。

247
00:08:44,550 --> 00:08:48,800
つまり、Jtrainのシータは

248
00:08:48,930 --> 00:08:50,130
ラムダを増加させると

249
00:08:50,320 --> 00:08:52,290
それに連れて増加する傾向にある。

250
00:08:53,050 --> 00:08:54,720
というのは、ラムダの大きな値は

251
00:08:54,920 --> 00:08:55,850
高バイアスに対応していて、

252
00:08:56,400 --> 00:08:57,400
そこではトレーニングセットに対してすら

253
00:08:57,590 --> 00:08:59,160
うまくフィット出来ないだろう。

254
00:08:59,290 --> 00:09:01,380
他方で小さな値のラムダは

255
00:09:01,650 --> 00:09:03,500
考えてみれば分かるが

256
00:09:03,850 --> 00:09:06,690
自由にとても高い次数の多項式でデータにフィッティング出来る。

257
00:09:06,920 --> 00:09:10,860
クロスバリデーション誤差については、結局こんな図となる。

258
00:09:12,080 --> 00:09:13,600
この右側は、

259
00:09:13,930 --> 00:09:15,460
ラムダの値が

260
00:09:15,530 --> 00:09:16,470
大きい時は

261
00:09:17,440 --> 00:09:18,600
結果としてはアンダーフィットしがち。

262
00:09:19,900 --> 00:09:21,280
だからこれはバイアスのレジームとなる。

263
00:09:22,950 --> 00:09:25,750
えーと、だから、クロスバリデーション誤差は

264
00:09:26,030 --> 00:09:27,680
高くなり

265
00:09:27,920 --> 00:09:29,060
ちょっとラベルをつけておこう、

266
00:09:29,250 --> 00:09:31,760
これはJcvのシータで、

267
00:09:32,270 --> 00:09:33,440
高バイアスではフィッティングしない、、、

268
00:09:34,430 --> 00:09:36,580
クロスバリデーションセットに対しては良く無いだろう。

269
00:09:38,050 --> 00:09:41,000
他方、ここ、左の方では、これは高分散のレジームで、

270
00:09:42,120 --> 00:09:43,620
そこではラムダの値が小さすぎて、

271
00:09:44,020 --> 00:09:45,910
だからデータにオーバーフィットしている

272
00:09:46,070 --> 00:09:47,190
可能性がある。

273
00:09:47,870 --> 00:09:49,140
だからデータにオーバーフィットしている事により、

274
00:09:49,230 --> 00:09:51,320
クロスバリデーション誤差も

275
00:09:51,710 --> 00:09:52,610
高くなるだろう。

276
00:09:53,700 --> 00:09:55,380
以上で、これがクロスバリデーション誤差と

277
00:09:56,620 --> 00:09:58,270
トレーニング誤差が

278
00:09:58,510 --> 00:09:59,860
どんな見た目になるか、だ。

279
00:10:00,130 --> 00:10:01,410
パラメータのラムダを

280
00:10:01,820 --> 00:10:04,270
変更していった時に。

281
00:10:04,950 --> 00:10:06,920
正規化パラメータのラムダを変更していった時に。

282
00:10:07,110 --> 00:10:08,220
繰り返しておくと、

283
00:10:08,430 --> 00:10:10,100
しばしば、ある中間のラムダの値が

284
00:10:10,790 --> 00:10:13,220
いわゆる「ちょうどぴったし」の

285
00:10:13,720 --> 00:10:14,990
またはクロスバリデーション誤差か

286
00:10:15,120 --> 00:10:16,470
テストセット誤差が

287
00:10:16,770 --> 00:10:19,710
どれだけ小さいかという観点で最良となる。

288
00:10:19,920 --> 00:10:20,980
ところでここで描いた曲線は

289
00:10:21,300 --> 00:10:23,630
いくらか漫画的というか、理想化された物だ。

290
00:10:24,650 --> 00:10:25,670
だから実際のデータセットにおいては、

291
00:10:26,210 --> 00:10:27,400
得られるプロットの結果は

292
00:10:27,510 --> 00:10:28,470
もうちょっとごちゃごちやしていて、

293
00:10:28,690 --> 00:10:30,580
もっとノイジーかもしれない。

294
00:10:31,540 --> 00:10:32,640
データセットによっては、

295
00:10:33,180 --> 00:10:34,450
あまりトレンドらしき物が

296
00:10:34,740 --> 00:10:36,180
分からない事もある。

297
00:10:36,450 --> 00:10:37,340
全体やクロスバリデーション誤差の

298
00:10:37,900 --> 00:10:38,930
プロットを見る事で

299
00:10:39,820 --> 00:10:41,460
人力で、または

300
00:10:41,600 --> 00:10:43,370
自動でクロスバリデーション誤差を

301
00:10:43,680 --> 00:10:45,100
最小化する点を

302
00:10:45,550 --> 00:10:48,590
選び、

303
00:10:48,880 --> 00:10:50,600
そして低いクロスバリデーション誤差に対応する

304
00:10:51,280 --> 00:10:52,780
ラムダの値を選ぶ。

305
00:10:53,560 --> 00:10:54,790
学習アルゴリズムの

306
00:10:54,920 --> 00:10:56,870
正規化パラメータラムダを選ぶ時は

307
00:10:57,200 --> 00:10:59,300
このような図を

308
00:10:59,420 --> 00:11:00,520
プロットすることは

309
00:11:00,800 --> 00:11:02,470
何が起きているのか

310
00:11:02,750 --> 00:11:04,520
理解しやすくしてくれて、

311
00:11:04,780 --> 00:11:06,320
実際に正しい正規化パラメータの値を

312
00:11:06,880 --> 00:11:08,140
選んでいる、という事を

313
00:11:08,320 --> 00:11:09,670
確認しやすくしてくれる事が多い。

314
00:11:10,520 --> 00:11:12,320
以上で、正規化と

315
00:11:12,520 --> 00:11:14,160
その学習アルゴリズムのバイアスや分散への

316
00:11:15,650 --> 00:11:16,890
影響に関する洞察を

317
00:11:17,400 --> 00:11:18,470
深めてくれてるといいな。

318
00:11:19,970 --> 00:11:21,510
今や、バイアスと分散を

319
00:11:21,670 --> 00:11:23,410
たくさんの異なる視点から見てきた事になる。

320
00:11:24,180 --> 00:11:25,470
次のビデオでやりたい事としては、

321
00:11:25,700 --> 00:11:27,000
ここまで見てきた

322
00:11:27,230 --> 00:11:28,110
たくさんの洞察を組み合わせて

323
00:11:28,280 --> 00:11:30,070
その上に学習曲線と言われる

324
00:11:30,320 --> 00:11:31,210
診断を

325
00:11:31,920 --> 00:11:33,770
作り上げたい、

326
00:11:34,050 --> 00:11:35,100
それは学習アルゴリズムが

327
00:11:35,150 --> 00:11:36,300
バイアス問題にあっているか、

328
00:11:36,720 --> 00:11:37,920
分散問題にあっているか、

329
00:11:38,190 --> 00:11:39,630
またはその両方かを診断する為に

330
00:11:40,040 --> 00:11:41,330
私が良く使う

331
00:11:41,560 --> 00:11:42,950
ツールです。