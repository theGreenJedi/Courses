Nós falamos sobre como avaliar algoritmos de aprendizado, sobre seleção de modelos e falamos muito sobre bias e variância. Então, como isso nos ajuda a descobrir quais técnicas são potencialmente aproveitáveis ou não para melhorar o desempenho de um algoritmo de aprendizagem. Vamos voltar ao nosso exemplo motivador original e vamos ao resultado. Aqui está o nosso exemplo anterior de como ajustar uma regressão linear regularizada e verificamos que ele não funciona tão bem como nós esperávamos. Dissemos que tínhamos esta lista de opções. Então, há algum jeito de sabermos qual dessas opções pode ser aproveitadas? A primeira coisa disso tudo era pegar mais exemplos de treinamento. Isto é bom para ajudar a fixar alta variância. De fato, se ao invés disso você tem um problema de bias alto e não tem qualquer problema de variância, então, como vimos no vídeo anterior, obter mais exemplos de treinamento, mesmo que isso talvez não ajude muito no total. Assim, a primeira opção é útil somente se você, por exemplo, traçar as curvas de aprendizagem e descobrir que você tem, pelo menos um pouco de variância, mostrando que que o erro de validação cruzada é um pouco maior que o seu erro de treinamento. Que tal experimentar um conjunto menor de variáveis? Bem, tentar um conjunto menor de variáveis, é algo que corrige a alta variância. Em outras palavras, se você descobrir olhando para as curvas de aprendizagem ou qualquer outra coisa que você usou, que tem um problema de bias alto então, pelo amor de Deus, não perca o seu tempo tentando selecionar cuidadosamente um conjunto menor de variáveis usar. Porque, se você tem um problema de bias alto, utilizar menos variáveis não vai ajudar. Por outro lado, se você olhar para as curvas de aprendizagem ou outra coisa e descobrir que você tem um problema de alta variância, então, de fato tente selecionar um conjunto menor de variáveis que assim pode ser um bom uso do seu tempo. Que tal tentar obter variáveis adicionais, acrescentando atributos? Normalmente, não sempre, mas normalmente nós pensamos nisso como uma solução para corrigir problemas de alto bias. Se você está adicionando variáveis extras, normalmente é porque a sua hipótese atual é muito simples e por isso tentamos obter atributos adicionais para tornar a nossa hipótese mais propensa a se ajustar ao conjunto de treinamento. Da mesma forma, podemos adicionar recursos polinomiais. Esta é uma outra maneira de adicionar variáveis e assim é uma outra maneira de tentar corrigir o problema de alto bias. De fato, se suas curvas de aprendizado lhe mostram que você ainda tem um problema de alta variância, então, mais uma vez, este não seja um bom uso do seu tempo. Finalmente, diminuir e aumentar "lambda". Estes são rápidos e fáceis de tentar, eu acho que eles são menos propensos a serem um desperdício de muitos meses de sua vida. Mas diminuindo "lambda" você sabe que ajusta o bias alto. Se isso não está claro para você, eu acho melhor que você pause o vídeo, pense e se convença que diminuir o valor de "lambda" ajuda a corrigir o alto bias, enquanto que aumentá-lo corrige a alta variância. E se você não tem certeza por que este é o caso, pause o vídeo e certifique-se de que você se convenceu de que este é o caso ou dê uma olhada nas curvas que nós estávamos plotando no final do vídeo anterior e certifique-se que você entendeu o por quê desses casos. Finalmente, vamos juntar tudo do que aprendemos e relacioná-las de volta às redes neurais. Aqui estão alguns conselhos práticos de como eu costumo escolher a arquitetura ou o padrão de conectividade das redes neurais que eu uso. Então, se você está ajustando uma rede neural, uma opção seria ajustar, por exemplo, uma rede neural bem pequena com poucas unidades ocultas, talvez apenas uma unidade oculta. Se você estiver ajustando uma rede neural, uma opção seria ajustar uma rede neural relativamente pequena com poucas, talvez apenas uma camada escondida e talvez um número relativamente pequeno de unidades ocultas. Assim, uma rede como esta pode ter relativamente poucos parâmetros e ser mais propensas a subajuste. A principal vantagem destas pequenas redes neurais é que o cálculo será mais rápido. Uma alternativa seria ajustar uma rede neural relativamente grande com uma ou mais unidades escondidas, com várias unidades ocultas em uma camada ou uma com mais camadas ocultas. E assim, estas redes neurais tendem a ter mais parâmetros e, portanto, ser mais propensas ao overfitting. Uma desvantagem, normalmente não das mais importantes mas algo para se pensar é que, se você tem um grande número de neurônios em sua rede, então ele pode ser mais caro computacionalmente. Embora dentro da razão, muitas vezes espero que isto não seja um problema enorme. O principal problema em potencial dessas redes neurais muito maiores é que elas poderiam ser mais propensas a overfitting e observe que, se você está usando redes neurais, muitas vezes usando uma grande rede neural, normalmente quanto mais, melhor mas se ela sofre de overfitting, você pode então usar a regularização para resolver o overfitting.
Geralmente usando uma rede neural maior com regularização para resolver o overfitting, isto muitas vezes é mais eficaz do que a utilização de uma rede neural menor. A principal desvantagem possível é que ela pode ser mais dispendiosa. Finalmente, uma das outras decisões é o número de camadas ocultas que você quer ter, certo? Então, você quer uma ou três camadas ocultas, como temos mostrado aqui, ou você quer duas camadas ocultas? Normalmente, como eu disse no vídeo anterior, utilizar uma única única camada oculta é um padrão razoável mas, se você quiser escolher o número de camadas ocultas, uma outra coisa que você pode tentar é fazer uma divisão de conjuntos de treinamento, validação cruzada e teste e tentar treinar redes neurais com uma, duas ou três camadas ocultas e ver qual dessas redes neurais tem o melhor desempenho nos conjuntos de validação cruzada. Você pega suas três redes neurais com uma, duas e três camadas ocultas e calcula o erro de validação cruzada em Jcv(θ) e todos eles e utiliza isto para selecionar qual deles é a que você acha a melhor rede neural. Então, isto é tudo para bias e variância e as técnicas como as curvas de aprendizado, que tentam diagnosticar esses problemas. Tanto quanto você achar que está implícito, para alguém pode valer a pena ou não tentar melhorar o desempenho de um algoritmo de aprendizagem. Se você entendeu o conteúdo dos últimos vídeos e se você aplicá-los, você realmente já estará muito mais eficiente para trabalhar com algoritmos em vários problemas. Até mesmo uma grande fração, talvez a maioria dos praticantes de aprendizado de máquina aqui no Vale do Silício, hoje, fazem estas coisas como seus empregos de tempo integral. Portanto, espero que estes conselhos de experiência sobre diagnósticos irão ajudá-lo muito a usar os algoritmos de aprendizagem e fazê-los funcionarem muito bem.
Tradução: Clóvis Teodoro Alves | Revisão: Caio H. K. Miyashiro