Ya has visto cómo la regularización nos puede ayudar a evitar el sobreajuste, pero ¿cómo afecta la oscilación y la varianza de un algoritmo de aprendizaje? En este video, me gustaría ahondar en el tema de oscilación y varianza y hablar acerca de cómo interactúan con y se ven afectadas por la regularización de tu algoritmo de aprendizaje. Supongamos que ajustamos un modelo modelo de regresión lineal con un polinomio de alto grado, pero para evitar el sobreajuste, vamos a regularizarlo como se muestra aquí. Imaginemos que estamos ajustando un polinomio de alto orden como el que se muestra aquí, pero para evitar el sobreajuste, utilizaremos la regularización como la que se muestra aquí. De manera que tenemos este término de regularización para intentar mantener bajos los valores de los parámetros. Como de costumbre, la regularización es la suma de “J” igual a 1 a la “m”, en vez de “J” igual a 0 a la “m”.  Consideremos estos tres casos. En el primero es el caso con un valor muy alto del parámetro de regularización «lambda», como si «lambda» fuera igual a 10,000. Es un valor enorme. En este caso, todos estos parámetros, «theta» 1, «theta» 2, «theta» 3, etc., estarán muy penalizados y terminaremos con la mayoría de estos parámetros cercanos a cero y la hipótesis será aproximadamente “H” de “X” justo igual o aproximadamente igual a «theta» 0. Terminaremos con una hipótesis que lucirá más o menos así; como una línea más o menos recta y constante. Entonces, esta hipótesis tiene una oscilación alta y subajusta el conjunto de datos. Esta línea recta horizontal no es un buen modelo para este conjunto de datos. En el otro extremo tenemos un valor muy pequeño de «lambda», como si «lambda» fuera igual a 0. En este caso, debido a que estamos ajustando un polinomio de alto orden, resulta generalmente en una situación de sobreajuste. En este caso, debido a que estamos ajustando un polinomio de alto orden, sin regularización o con una regularización mínima, terminaremos con nuestra situación usual de varianza alta o de sobreajuste, porque «lambda» es igual a cero y estamos ajustandola con nuestra regularización para que sobreajuste la hipótesis. Y sólo si tenemos un valor intermedio de «lambda», es decir, ni muy alto ni muy bajo, tendremos unos parámetros «theta» que nos darán un ajuste razonable con estos datos. Entonces, ¿Cómo podemos elegir automáticamente un buen valor para el parámetro de regularización «lambda»? Sólo para recapitular, aquí tenemos nuestro modelo y nuestro objetivo del algoritmo de aprendizaje. Para la situación en la que utilizamos la regularización, definiré “J entrenamiento” de «theta» como algo diferente como el objetivo de optimización pero sin el término de regularización. Anteriormente, en otro video, cuando no utilizamos la regularización, definí “J entrenamiento” de «theta» como igual a “J” de «theta» o la función de costo, pero cuando utilizamos la regularización con este término «lambda» adicional definiremos “j entrenamiento” o el error del conjunto de aprendizaje como la suma de los errores cuadráticos en el conjunto de aprendizaje o el error cuadrático promedio del conjunto de entrenamiento, sin tomar en cuenta el término de regularización. De manera similar, definiré también el error de validación cruzada o el error del conjunto de prueba como antes, para que sea la suma promedio de los errores cuadráticos en los conjuntos de prueba y de validación cruzada. Para resumir, mis definiciones de “J entrenamiento”, “Jcv” y “J prueba” son sólo el error cuadrático promedio o un medio del error cuadrático promedio de mi conjunto de validación, entrenamiento y conjuntos de prueba sin el término de regularización adicional. Así es como podemos elegir automáticamente el parámetro de regularización «lambda». Lo que hago usualmente es tener un rango de valores de «lambda» para probarlos. Puedo considerar no utilizar la regularización o intentar algunos valores que he considerado como “O1”, “O2”, “O4”, etc. Usualmente escalo estos en múltiplos de dos hasta llegar a un valor más alto. Si lo hago con múltiplos de dos terminaré con 10.24 en vez de 10 exactamente, pero está suficientemente cerca y unos puntos decimales no afectarán mucho el resultado. Esto me arroja, tal vez, doce modelos diferentes que intentaré seleccionar en correspondencia con 12 valores diferentes del parámetro de regularización «lambda». Por supuesto, puedes tener valores menores de 0.01 o valores mayores a 10. pero yo lo he reducido por conveniencia. Con estos 12 modelos, podemos hacer lo siguiente: Podemos tomar este primer modelo donde «lambda» es igual a 0, y minimizar la función de costos de “J” de «theta». Esto nos daría un parámetro vector «theta». Al igual que en el video anterior, denotaré esto como «theta» superíndice 1. Luego puedo tomar mi segundo modelo con «lambda» igual a 0.01 y minimizar la función de costo usando ahora «lambda» igual a 0.01. para obtener un vector parámetro «theta» diferente que denotaremos como «theta» 2. Con esto, terminaré con «theta» 3 si es correcto para mi tercer modelo, y así sucesivamente, hasta mi último modelo, designado como «theta» 12, donde «lambda» está determinado como 10, o 10.14. Ahora, puedo tomar todas estas hipótesis, todos estos parámetros, y utilizar mi conjunto de validación cruzada para evaluarlos. Puedo ver mi primer modelo o mi segundo modelo ajustado a los diferentes valores del parámetro de regularización y evaluarlos en mi conjunto de validación cruzada. Aquí básicamente mido el error cuadrático promedio de cada uno de los parámetros vector «theta» en mi conjunto de validación cruzada. Después elegiré de entre estos 12 modelos el que me de el error más bajo en el conjunto de validación cruzada. Digamos que, por ejemplo, elijo «theta» 5, el polinomio del quinto orden, porque tiene el error de validación más bajo. Una vez hecho esto, lo que haré, finalmente, si quiero reportar el error del conjunto de prueba es tomar el parámetro «theta» 5 que seleccioné y evaluar qué tan bien se desempeña en mi conjunto de prueba. Una vez más, aquí ajustamos este parámetro «theta» al conjunto de validación cruzada. Por esto guardamos otro conjunto de prueba aparte que utilizaremos para obtener un mejor estimado de qué tan bien se generalizará mi parámetro vector «theta» con ejemplos que no se han visto anteriormente. Esto fue la selección de modelos aplicada a la elección del parámetro de regularización «lambda». Lo último que quisiera hacer en este video es obtener un mejor entendimiento de cómo varían los errores de validación cruzada y de entrenamiento a medida que variamos el parámetro de regularización «lambda». Sólo como resumen, esta era nuestra función de costo original “J” de «theta», pero para este caso definiremos el error de entrenamiento sin utilizar el parámetro de regularización y el error de validación cruzada sin utilizar el parámetro de validación. Lo que me gustaría hacer ahora es trazar “J entrenamiento” y trazar este “Jcv”; es decir, ver qué tan bien se desempeña mi hipótesis en el conjunto de entrenamiento y qué tan bien se desempeña mi hipótesis en el conjunto de validación cruzada a medida que varío mi parámetro de regularización «lambda». Entonces, como vimos anteriormente, si «lambda» es baja, entonces no estaremos aplicando una gran regularización y correremos un riesgo más alto de sobreajuste. Mientras que si «lambda» es alta; es decir, si estuviéramos en el extremo derecho de este eje horizontal, correremos un riesgo alto de tener un problema de oscilación, por el valor alto de «lambda». Si trazas “J entrenamiento” y “Jcv”, lo que encontrarás es que, con valores pequeños de «lambda», puedes ajustar el conjunto de entrenamiento relativamente bien porque no estás usando regularización. Con valores pequeños de «lambda», el término de regularización básicamente desaparece y minimizas, solamente, el error cuadrático. Así que, cuando «lambda» es pequeña, terminaremos con un valor pequeño de “J entrenamiento” mientras que si «lambda» es alta, entonces tendremos un problema de alta oscilación y no estaremos ajustando bien nuestro conjunto de entrenamiento. Así que terminan con un valor acá, hasta arriba. Así, “J entrenamiento” de «theta» tenderá a aumentar cuando «lambda» aumenta, porque un valor alto de «lambda» corresponde a una oscilación alta y quizá no puedas ajustar bien tu conjunto de entrenamiento, mientras que un valor bajo de «lambda» corresponde a que puedes ajustar libremente polinomios de un grado alto a tu conjunto de datos. En cuanto al error de validación cruzada, nos encontramos con una figura como esta. Dónde si tenemos un valor alto de «lambda» aquí a la derecha, quizá generaremos un subajuste. Por lo tanto, este es un régimen de oscilación. Aquí, el error de validación cruzada será alto. Pérmítanme anotar esto. Esta es “Jcv” de «theta». Entonces, con una oscilación alta no tendremos buenos resultados en el conjunto de validación cruzada. Y, a la izquierda tenemos un régimen de varianza alta donde si tenemos un valor muy pequeño de «lambda», sobreajustaremos los datos. Al sobreajustar los datos, el error de validación también será alto. Así es como se pueden ver los errores de validación y de entrenamiento en un conjunto de entrenamiento a medida que variamos el parámetro «lambda» o el parámetro de regularización «lambda». Una vez más, será un valor intermedio de «lambda» el que funcione bien, o se adapte mejor cuando tenemos un error de validación o un conjunto de prueba pequeños. Las curvas que he dibujado son caricaturescas e idealizadas, de alguna manera, pero en un conjunto de datos real las curvas que obtendría serían un poco más irregulares o con más ruido que estas. En algunos conjuntos de datos podrás ver estos cuatro tipos de tendencias y al mirar el trazo del error de validación cruzada podrás seleccionar, manual o automáticamente, un punto que minimice el error de validación cruzada y seleccionar el valor de «lambda» que corresponda al error de validación cruzada más bajo. Cuando intento elegir el parámetro de regularización «lambda» para un algoritmo de aprendizaje, seguido veo que trazar una figura como esta que acabo de hacer, me ayuda a entender mejor qué es lo que está pasando y a verificar que de hecho estoy eligiendo un buen valor para el parámetro de regularización «lambda». Con suerte, esto te dará un mayor entendimiento de la regularización y sus efectos en la oscilación y la varianza de un algoritmo de aprendizaje. Para este momento ya has visto la oscilación y a la varianza desde muchas perspectivas diferentes. Ahora, lo que me gustaría hacer en el video siguiente es tomar el conocimiento que hemos adquirido y elaborarlo para generar un diagnóstico llamado curva de aprendizaje que es una herramienta que utilizo seguido para diagnosticar si un si el algoritmo tiene un de un problema de oscilación o de varianza o un poco de ambos.