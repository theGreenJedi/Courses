1
00:00:00,260 --> 00:00:01,340
我们已经介绍了怎样评价一个学习算法

2
00:00:01,960 --> 00:00:03,360
我们讨论了模型选择问题

3
00:00:04,150 --> 00:00:06,490
偏差和方差的问题

4
00:00:06,970 --> 00:00:08,110
那么这些诊断法则怎样帮助我们判断

5
00:00:08,330 --> 00:00:09,730
哪些方法可能有助于

6
00:00:10,340 --> 00:00:11,710
改进学习算法的效果

7
00:00:11,950 --> 00:00:13,980
而哪些可能是徒劳的呢

8
00:00:15,480 --> 00:00:16,660
让我们再次回到最开始的例子

9
00:00:16,940 --> 00:00:18,890
在那里寻找答案

10
00:00:21,030 --> 00:00:22,570
这就是我们之前的例子

11
00:00:23,000 --> 00:00:24,120
我们使用正则化的线性回归拟合模型

12
00:00:24,720 --> 00:00:27,640
却发现该算法没有达到预期效果

13
00:00:28,300 --> 00:00:30,080
我们提到我们有如下这些选择

14
00:00:30,910 --> 00:00:32,430
那么如何判断

15
00:00:32,590 --> 00:00:34,530
哪些方法更可能是有效的呢

16
00:00:35,480 --> 00:00:36,490
第一种可供选择的方法

17
00:00:36,660 --> 00:00:38,770
是使用更多的训练集数据

18
00:00:39,550 --> 00:00:40,700
这种方法对于高方差的情况

19
00:00:40,880 --> 00:00:42,890
是有帮助的

20
00:00:45,320 --> 00:00:46,610
也就是说

21
00:00:47,150 --> 00:00:48,550
如果你的模型不处于高方差问题

22
00:00:48,680 --> 00:00:50,530
而是处于高偏差的时候

23
00:00:50,830 --> 00:00:52,000
那么通过前面的视频

24
00:00:52,500 --> 00:00:53,560
我们已经知道 获取更多的训练集数据

25
00:00:54,640 --> 00:00:56,380
并不会有太明显的帮助

26
00:00:57,360 --> 00:00:58,320
所以 要选择第一种方法

27
00:00:58,780 --> 00:01:00,230
你应该先画出

28
00:01:00,580 --> 00:01:01,620
学习曲线

29
00:01:01,720 --> 00:01:02,820
然后看出你的模型

30
00:01:02,860 --> 00:01:03,970
应该至少有那么一点方差问题

31
00:01:04,170 --> 00:01:06,530
也就是说你的交叉验证集误差

32
00:01:06,680 --> 00:01:08,800
应该比训练集误差大一点

33
00:01:08,910 --> 00:01:10,400
第二种方法情况又如何呢

34
00:01:10,940 --> 00:01:11,920
第二种方法是

35
00:01:12,350 --> 00:01:13,570
少选几种特征

36
00:01:13,970 --> 00:01:16,060
这同样是对高方差时有效

37
00:01:17,100 --> 00:01:18,080
换句话说

38
00:01:18,420 --> 00:01:19,440
如果你通过绘制学习曲线

39
00:01:19,820 --> 00:01:20,830
或者别的什么方法

40
00:01:21,190 --> 00:01:22,110
看出你的模型处于高偏差问题

41
00:01:22,370 --> 00:01:23,460
那么切记

42
00:01:23,670 --> 00:01:25,000
千万不要浪费时间

43
00:01:25,540 --> 00:01:27,250
试图从已有的特征中

44
00:01:27,450 --> 00:01:29,130
挑出一小部分来使用

45
00:01:29,330 --> 00:01:31,190
因为你已经发现高偏差的问题了

46
00:01:32,060 --> 00:01:33,220
使用更少的特征不会有任何帮助

47
00:01:33,890 --> 00:01:35,270
反过来 如果你发现

48
00:01:35,490 --> 00:01:36,730
从你的学习曲线

49
00:01:36,900 --> 00:01:38,020
或者别的某种诊断图中

50
00:01:38,360 --> 00:01:39,780
你看出了高方差的问题

51
00:01:40,320 --> 00:01:41,730
那么恭喜你

52
00:01:42,160 --> 00:01:43,180
花点时间挑选出一小部分合适的特征吧

53
00:01:43,440 --> 00:01:45,380
这是把时间用在了刀刃上

54
00:01:45,790 --> 00:01:47,120
方法三 选用更多的特征又如何呢

55
00:01:47,710 --> 00:01:49,640
通常来讲

56
00:01:50,170 --> 00:01:51,380
尽管不是所有时候都适用

57
00:01:51,490 --> 00:01:53,020
但增加特征数

58
00:01:54,070 --> 00:01:56,920
一般可以帮助解决高偏差问题

59
00:01:57,600 --> 00:01:58,700
所以如果你需要增加

60
00:01:58,980 --> 00:02:00,640
更多的特征时

61
00:02:01,750 --> 00:02:03,150
一般是由于你现有的

62
00:02:03,280 --> 00:02:04,280
假设函数太简单

63
00:02:04,540 --> 00:02:06,520
因此我们才决定增加一些

64
00:02:06,730 --> 00:02:08,540
别的特征来让假设函数

65
00:02:09,060 --> 00:02:10,800
更好地拟合训练集

66
00:02:11,420 --> 00:02:13,460
类似的

67
00:02:13,770 --> 00:02:14,930
增加更多的多项式特征

68
00:02:15,140 --> 00:02:16,420
这实际上也是属于增加特征

69
00:02:16,570 --> 00:02:18,220
因此也是用于

70
00:02:18,430 --> 00:02:19,950
修正高偏差问题

71
00:02:21,020 --> 00:02:22,820
具体来说

72
00:02:23,210 --> 00:02:24,350
如果你画出的学习曲线告诉你

73
00:02:24,570 --> 00:02:25,410
你还是处于高方差问题

74
00:02:25,520 --> 00:02:27,190
那么采取这种方法

75
00:02:27,320 --> 00:02:29,360
就是浪费时间

76
00:02:30,640 --> 00:02:32,690
最后 增大和减小λ

77
00:02:33,200 --> 00:02:34,090
这种方法尝试起来很方便

78
00:02:34,470 --> 00:02:36,000
我想 尝试这个方法

79
00:02:36,140 --> 00:02:38,190
不至于花费你几个月时间

80
00:02:39,070 --> 00:02:41,530
但我们已经知道

81
00:02:41,650 --> 00:02:43,400
减小λ可以修正高偏差

82
00:02:45,360 --> 00:02:46,340
如果我说的你还不清楚的话

83
00:02:46,500 --> 00:02:47,340
我建议你暂停视频

84
00:02:47,810 --> 00:02:50,350
仔细回忆一下

85
00:02:50,990 --> 00:02:52,790
想明白 减小λ的值

86
00:02:53,620 --> 00:02:55,030
为何有助于修正高偏差

87
00:02:55,590 --> 00:02:57,480
而增大λ的值为何解决高方差

88
00:02:59,870 --> 00:03:00,930
如果你确实不明白

89
00:03:01,270 --> 00:03:02,470
其中的原因

90
00:03:02,650 --> 00:03:04,130
那就暂停一下好好想想

91
00:03:04,150 --> 00:03:05,820
直到真的弄清楚这个道理

92
00:03:06,580 --> 00:03:07,320
或者看看

93
00:03:07,800 --> 00:03:09,040
上一节视频最后

94
00:03:09,190 --> 00:03:10,590
我们绘制的学习曲线

95
00:03:10,720 --> 00:03:11,650
试着理解清楚

96
00:03:12,170 --> 00:03:13,670
为什么是那样的

97
00:03:15,080 --> 00:03:16,120
最后 我们回顾一下

98
00:03:16,440 --> 00:03:17,840
这几节课介绍的这些内容

99
00:03:18,400 --> 00:03:19,980
并且看看它们和神经网络的联系

100
00:03:20,130 --> 00:03:21,190
我想介绍一些

101
00:03:21,720 --> 00:03:22,720
很实用的经验或建议

102
00:03:23,520 --> 00:03:25,060
这些也是我平时为神经网络模型

103
00:03:25,530 --> 00:03:28,660
选择结构或者连接形式的一些技巧

104
00:03:30,070 --> 00:03:31,190
当你在进行神经网络拟合的时候

105
00:03:31,410 --> 00:03:33,160
如果你要进行神经网络的拟合

106
00:03:33,400 --> 00:03:34,680
比如说

107
00:03:34,840 --> 00:03:36,540
一个相对比较简单的神经网络模型

108
00:03:37,530 --> 00:03:38,670
相对来讲 它的隐藏单元比较少

109
00:03:38,930 --> 00:03:40,430
甚至只有一个隐藏单元

110
00:03:40,890 --> 00:03:42,670
如果你要进行神经网络的拟合

111
00:03:42,800 --> 00:03:44,440
其中一个选择是

112
00:03:44,920 --> 00:03:46,500
选用一个相对简单的网络结构

113
00:03:48,030 --> 00:03:49,630
比如说只有一个

114
00:03:49,980 --> 00:03:51,760
隐藏层

115
00:03:52,070 --> 00:03:53,370
或者可能相对来讲

116
00:03:53,750 --> 00:03:55,160
比较少的隐藏单元

117
00:03:55,570 --> 00:03:56,580
因此像这样的一个简单的神经网络

118
00:03:57,050 --> 00:03:59,170
参数就不会很多 很容易出现欠拟合

119
00:04:00,450 --> 00:04:01,850
这种比较小型的神经网络

120
00:04:02,260 --> 00:04:04,760
其最大优势在于计算量较小

121
00:04:05,820 --> 00:04:06,910
与之相对的另一种情况

122
00:04:07,010 --> 00:04:08,470
是相对较大型的神经网络结构

123
00:04:08,900 --> 00:04:10,790
要么隐藏层单元比较多

124
00:04:10,970 --> 00:04:12,370
比如这一层中的隐藏单元数就很多

125
00:04:12,560 --> 00:04:14,940
要么隐藏层比较多

126
00:04:16,200 --> 00:04:17,800
因此这种比较复杂的神经网络

127
00:04:18,010 --> 00:04:20,870
参数一般较多 也更容易出现过拟合

128
00:04:22,410 --> 00:04:24,010
这种结构的一大劣势

129
00:04:24,050 --> 00:04:25,160
也许不是主要的 但还是需要考虑

130
00:04:25,250 --> 00:04:26,440
那就是当网络中的

131
00:04:27,000 --> 00:04:28,450
神经元数量很多的时候

132
00:04:28,960 --> 00:04:30,040
这种结构会显得

133
00:04:30,230 --> 00:04:31,920
计算量较大

134
00:04:33,070 --> 00:04:35,790
虽然有这个情况 但通常来讲这不是大问题

135
00:04:36,840 --> 00:04:38,420
这种大型网络结构最主要的问题

136
00:04:38,540 --> 00:04:39,710
还是它更容易出现过拟合现象

137
00:04:39,980 --> 00:04:44,120
事实上 如果你经常应用神经网络

138
00:04:44,700 --> 00:04:46,900
特别是大型神经网络的话

139
00:04:47,240 --> 00:04:48,900
你就会发现越大型的网络性能越好

140
00:04:50,610 --> 00:04:51,700
但如果发生了过拟合

141
00:04:51,890 --> 00:04:53,800
你可以使用正则化的方法

142
00:04:54,230 --> 00:04:56,510
来修正过拟合

143
00:04:56,910 --> 00:04:58,480
一般来说 使用一个大型的神经网络

144
00:04:58,720 --> 00:04:59,980
并使用正则化来修正过拟合问题

145
00:05:00,310 --> 00:05:01,910
通常比使用一个小型的神经网络

146
00:05:02,130 --> 00:05:04,160
效果更好

147
00:05:05,100 --> 00:05:06,940
但主要可能出现的问题

148
00:05:07,130 --> 00:05:09,420
是计算量相对较大

149
00:05:10,470 --> 00:05:11,940
最后 你还需要选择

150
00:05:12,280 --> 00:05:14,340
隐藏层的层数

151
00:05:14,480 --> 00:05:16,400
你是应该用一个

152
00:05:17,030 --> 00:05:18,130
隐藏层呢

153
00:05:18,380 --> 00:05:19,700
还是应该用三个呢 就像我们这里画的

154
00:05:20,040 --> 00:05:21,790
或者还是用两个隐藏层呢

155
00:05:23,250 --> 00:05:24,850
通常来说

156
00:05:24,980 --> 00:05:25,720
正如我在前面的视频中讲过的

157
00:05:26,190 --> 00:05:27,420
默认的情况是

158
00:05:27,640 --> 00:05:29,570
使用一个隐藏层

159
00:05:29,780 --> 00:05:30,800
但是如果你确实想要选择

160
00:05:30,890 --> 00:05:32,400
多个隐藏层

161
00:05:32,580 --> 00:05:33,610
你也可以试试

162
00:05:34,270 --> 00:05:35,800
把数据分割为训练集 验证集

163
00:05:36,660 --> 00:05:38,320
和测试集 然后使用交叉验证的方法

164
00:05:38,730 --> 00:05:40,070
比较一个隐藏层的神经网络

165
00:05:40,260 --> 00:05:41,210
然后试试两个 三个隐藏层

166
00:05:41,490 --> 00:05:42,810
以此类推

167
00:05:43,230 --> 00:05:44,300
然后看看哪个神经网络

168
00:05:44,460 --> 00:05:47,460
在交叉验证集上表现得最理想

169
00:05:48,180 --> 00:05:49,190
也就是说 你得到了三个神经网络模型

170
00:05:49,660 --> 00:05:50,510
分别有一个 两个 三个隐藏层

171
00:05:50,780 --> 00:05:52,410
然后你对每一个模型

172
00:05:52,570 --> 00:05:53,870
都用交叉验证集数据进行测试

173
00:05:54,140 --> 00:05:55,120
算出三种情况下的

174
00:05:55,240 --> 00:05:56,630
交叉验证集误差Jcv

175
00:05:56,960 --> 00:05:58,350
然后选出你认为最好的

176
00:05:58,690 --> 00:06:00,290
神经网络结构

177
00:06:02,580 --> 00:06:04,020
好了 这就是

178
00:06:04,230 --> 00:06:05,490
偏差和方差问题

179
00:06:05,780 --> 00:06:08,170
以及诊断该问题的学习曲线方法

180
00:06:08,560 --> 00:06:09,860
在改进学习算法的表现时

181
00:06:09,930 --> 00:06:11,020
你可以充分运用

182
00:06:11,250 --> 00:06:12,480
以上这些内容来判断

183
00:06:12,630 --> 00:06:13,500
哪些途径可能是有帮助的

184
00:06:13,910 --> 00:06:15,720
而哪些方法可能是无意义的

185
00:06:16,960 --> 00:06:18,000
如果你理解了以上几节视频中

186
00:06:18,990 --> 00:06:20,700
介绍的内容

187
00:06:20,790 --> 00:06:22,020
并且懂得如何运用

188
00:06:22,630 --> 00:06:24,300
那么你已经可以使用机器学习方法有效的解决实际问题了

189
00:06:24,430 --> 00:06:25,890
你也能像硅谷的

190
00:06:26,610 --> 00:06:27,970
大部分机器学习从业者一样

191
00:06:28,560 --> 00:06:29,810
他们每天的工作就是

192
00:06:30,540 --> 00:06:31,860
使用这些学习算法

193
00:06:32,060 --> 00:06:34,760
来解决众多实际问题

194
00:06:35,820 --> 00:06:37,560
我希望这几节中

195
00:06:37,990 --> 00:06:39,110
提到的一些技巧

196
00:06:39,560 --> 00:06:41,420
关于方差 偏差 以及学习曲线为代表的诊断法

197
00:06:42,730 --> 00:06:44,110
能够真正帮助你更有效率地

198
00:06:44,790 --> 00:06:47,270
应用机器学习

199
00:06:48,000 --> 00:06:49,300
让它们高效地工作【教育无边界字幕组】翻译：所罗门捷列夫 校对：王祖超 审核：Naplessss