Se você rodar o algoritmo de aprendizagem e ele não se sair tão bem quanto esperado, quase sempre a causa será ou por problema de bias (viés) alto ou por problema de alta variância. Por outras palavras, eles são ou um problema de subajuste ou de sobreajuste. E nesse caso é muito importante descobrir com quais desses problemas, viés, ou variância ou um pouco dos dois, estamos lidando. Por que conhecendo quais dessas duas situações então presentes daria um indicador muito forte sobre quais são as maneiras úteis e promissoras para tentar melhorar o algoritmo. Nesse vídeo, eu gostaria de me aprofundar nos problemas de viés e variância e entendê-los melhor, bem como encontrar um jeito de olhar e avaliar a existência de problemas relacionados com viés ou variância, já que isso é crítico para melhorar a performance do algoritmo de aprendizagem que você implementar. Então, você já viu essa figura algumas vezes, onde se você ajustar uma hipótese muito simples, como uma linha reta, temos subajuste aos dados. Se você ajustar uma hipótese complexa demais, então ela poderia se ajustar ao conjunto de treino perfeitamente, mas sobreajustar aos dados. E isso seria uma hipótese de complexidade intermédia, talvez com um polinômio com grau nem tão baixo nem tão elevado. No ponto certo. E isso nos dá um melhor erro de generalização entre as três opções. Agora que estamos munidos com a noção de treino e validação em conjuntos de teste, nós podemos entender esses conceitos de viés e variância um pouco melhor. Na prática, digamos que nosso erro de treino e nosso erro de validação cruzada são definidos como nos vídeos anteriores, ou seja, como a média do erro quadrático, medido nos conjuntos de treino e de validação cruzada. Agora vamos desenhar a seguinte figura. No eixo horizontal eu vou colocar o eixo do polinômio, de forma que ao ir para a direita eu vou ajustar um polinômio de grau progressivamente mais alto. Então, eu vou fazer isso nessa figura, onde d talvez possa ser igual a 1, nós vamos ajustar funções bem simples enquanto que mais à direita este poderia ser d=4 ou números ainda maiores, eu estaria ajustando polinômios de grau muito complexos que podem se ajustar ao conjunto de treino com funções muito mais complexas, enquanto que aqui à direita no eixo horizontal, eu tenho valores muito maiores para o grau do polinômio, e isso irá corresponder a ajustar funções muito mais complexas ao conjunto de treino. Vamos dar uma olhada no erro de treino e erro de validação cruzada, e traçá-los nessa figura. Vamos começar com o erro de treino. Conforme aumentemos o grau do polinômio, nós vamos nos ajustar ao conjunto progressivamente melhor, ou seja, se d=1 eu terei um erro de treino alto e se o grau do polinômio for muito alto, nosso erro de treino será bem baixo. Talvez até zero, por que eu estou ajustando ao conjunto de treino muito bem. E assim conforme aumentamos o grau do polinômio observamos tipicamente que o erro de treino diminui, então eu vou escrever J subscrito train de θ, porque o nosso erro de treino tende a diminuir com o aumento do grau do polinômio que ajustamos aos dados. Agora, vamos dar uma olhada no erro de validação cruzada. Isso geralmente é importante, se olharmos para o erro de teste nós teremos um resultado bem similar ao visto no traçado do erro de validação cruzada. Então, sabemos que se d=1, nós estamos ajustando uma função bem simples, e talvez estejamos subajustando ao conjunto de treino, e então nós teremos um erro de validação bem alto. Se ajustarmos um polinômio de grau intermédio, onde d=2 no nosso exemplo do slide anterior, teremos um erro de validação muito mais baixo, porque nós encontramos um ajuste muito melhor para os dados. E analogamente se d for muito alto, então se d assumir um valor de 4, então estaríamos novamente sobreajustando e acabaríamos com um valor alto para o erro de validação. Então, se você fosse variar isso suavemente e traçar a curva você poderia acabar com uma curva como essa, onde isso é Jcv(θ) e novamente, se você traçar Jtest(θ) você terá algo muito similar. E esse tipo de gráfico nos ajuda a entender melhor as noções de viés e variância. Na prática, se você tiver um algoritmo de aprendizagem que não está funcionando tão bem quanto você desejava, como descobrir a causa do problema? Na prática, suponha que você aplicou um algoritmo de aprendizagem e ele não funciona tão bem como o desejado, então os seus erros de teste e validação cruzada são altos. Como poderíamos descobrir se o algoritmo de aprendizagem está sofrendo de viés alto ou de variância alta? Então, o cenário do erro de validação cruzada ser alto corresponde a esse caso ou a esse caso. Então, esse caso na esquerda corresponde ao problema de viés alto, ou seja, se você estiver ajsutando um polinômio de ordem muito baixa como a+1, quando na realidade precisamos de um polinômio de grau muito mais alto. Enquanto que, em contraste, esse caso corresponde ao problema de variância elevada, ou seja, se d, o grau do polinômio, for muito alto para o conjunto de dados que temos. E essa figura nos dá uma ideia sobre como distinguir entre esses dois casos. Na prática, para o caso de viés alto, ou seja, o caso de subajuste, o que vemos é que ambos os erros de validação e treino serão altos. Então se o seu algoritmo estiver sofrendo de um problema de viés, o erro no conjunto de teste seria alto e você descobriria que o erro de validação também seria alto. Poderia ser perto, talvez só um pouco maior que o de treino. E assim, se você encontrar essa combinação, isso é um sinal de que o algoritmo talvez esteja sofrendo de viés alto. Em contraste, se o  seu algoritmo estiver sofrendo de alta variância, então se você olhar aqui, iremos notar que Jtrain, o erro de treino, será baixo. Isto é, você está ajustando o conjunto de dados muito bem. Enquanto que o seu erro de validação, assumindo que isso é o erro quadrático que estamos minimizando, enquanto que o erro no seu conjunto de validação ou função de validação ou erro de validação, será muito maior que o seu erro de treino. Esse sinal de maior duplicado aqui, significa muito maior que. Então é muito maior que multiplicar maior por maior. Então isso é o sinal de duplo maior, que é o símbolo matemático para muito maior que, indicado por esses dois sinais de maior. Então se você ver essa combinação, o que você encontrará é uma dica de que o seu algoritmo de aprendizagem esteja sofrendo de variância alta e talvez esteja sobreajustado. E a chave para diferenciar esses dois casos é se você tiver problema de viés alto seu erro de treino também será alto, já que a sua hipótese não está se ajustando muito bem. E se você tiver alta variância, seu erro de treino será normalmente baixo, muito mais baixo que o erro de validação cruzada. Então, eu espero que isso lhe dê uma compreensão melhor sobre os problemas de viés e variância. Eu ainda tenho muito mais a dizer sobre viés e variância nos próximos vídeos. Mas o que veremos mais tarde é que ao diagnosticarmos se o algoritmo está sofrendo de viés alto ou variância alta, e veremos ainda mais detalhes nos próximos vídeos, veremos que ao descobrirmos se o algoritmo de aprendizagem está sofrendo de viés alto ou talvez uma combinação de ambos nós teremos uma ideia muito melhor sobre o que pode der promissor para tentar melhorar a performance do algoritmo.
Tradução: Eduardo Bonet | Revisão: Inês Lopes da Fonseca