ここまで、学習アルゴリズムをどう評価するか、 モデルの選択、バイアスとバリアンスについて 議論してきた。 ではこれらがどのように 学習アルゴリズムのパフォーマンスを改善しようとする時に 何が潜在的に実りが多そうで 何はそんなに良く無さそうかを見分けるのに役立たせる事が出来るだろうか？ もとの動機づけ目的の例に戻り、 その結果を見てみよう。 さて、これは前に見た例で 正規化した線形回帰をフィッティングして 期待通りには振る舞ってない、と判明した物だ。 そしてこんな選択肢のメニューがあると言った。 ではこの選択肢のうちどれが 実り多そうな選択肢かを見分けるは方法が無いものか？ これらのうちの最初の物は もっと多くのトレーニング手本を得る、という物だった。 これは高バリアンスを直すのに 良い物だった。 そして例えば、 代わりに高バイアスの問題にかかっていて、 そしてバリアンスの問題は無ければ、 その場合は前のビデオで見たように トレーニング手本の数を増やす事は そんなに役には立たないと思われる。 つまり、この最初の選択肢が有用なのは 学習曲線を プロットしてみて 最低でもちょっとはバリアンスがある、と 確認出来た場合のとにだけだ。 つまり、クロスバリデーション誤差は トレーニングセット誤差よりもかなり大きい時という事。 フィーチャーの数を減らして試す、という件についてはどうだろう？ フィーチャーの数を減らして試す、というのは これまた高バリアンスを 治す為の物だ。 言い換えると、学習曲線なり それ以外の何かしらなりで 高バイアスの問題だ、と 分かったなら、 おお、どうか より少ない数のフィーチャーにする為に何を残すか、を 慎重に選びだす事に 時間を使わないでください。 何故ならもし高バイアスの問題にかかっているなら より少ない数のフィーチャーを使うというのは、きっと役には立たないから。 一方で、 学習曲線なりなんなりを見て 高バリアンスの問題を 見つけた時には、 まさにフィーチャーを減らす事を 試してみるべきだ。 それはきっとあなたの時間の、とても有効な使い方に違いない。 フィーチャーを追加する、という選択肢はどうだろうか？ フィーチャーを追加する、というのは 必ずという訳では無いにせよ普通は 高バイアスの問題の 修正方法だとみなしている。 つまりフィーチャーを追加する時は 普通は現在の仮説が あまりにもシンプル過ぎる為、 さらなるフィーチャーを追加する事で 仮説がトレーニングセットに もっと良くフィットするように しようとしたいからだ。 同様に、多項式のフィーチャーを追加するのも、 これはフィーチャーを追加する もう一つの方法で、つまり 高バイアスの問題を修正する もう一つの方法がある訳だ。 そして例えば、 学習曲線が 高バリアンスの問題を示していたら、 その時はこの場合も あなたの時間の有効な使い方とはならないだろう。 そして最後にラムダを増減させる。 これは手早く、簡単に試す事が出来る。 これらはあなたの人生の何ヶ月とかを 無駄にする可能性は、まぁ無いだろう。 だがラムダを現象させるのは 高バイアスを修正するという事を、既に知っている。 もしこれが当然、と感じられなければ、 ひとまずビデオを止めて、 ラムダを減らすのが高バイアスの問題を修正するのに有効で、 ラムダを増加させるのか高バリアンスの問題を修正する事を しっかり納得出来るまで よく考えてみて欲しい。 どうしてそうなるのか いまいち自信が持てなければ、 ビデオを止めてそうだと納得出来るまで 確認して欲しい。 または前回のビデオの最後で プロットしたカーブを見て そしてこれらが そうだと言う事を しっかりと納得してくれ。 最後に、学んだ事全てを あわせて、それをニューラルネットワークに 関連づけると、 ニューラルネットワークの 接続のパターンを、 普段どうやって選んでいるかの 実践的なアドバイスをしておく。 ニューラルネットワークをフィッティングする時は 考えられる一つの選択肢としては とても小さなニューラルネット、 相対的に少しの隠れユニットしか無いような、 例えば一つの隠れユニットだけのような物に フィッティングする、というのが考えられる、、、 ニューラルネットワークをフィッティングする時には 考えられる一つの選択肢としては 相対的に小さめのニューラルネットワーク、 相対的に少しだけの、たとえば隠れレイヤが一つだけの物で 隠れユニットの数も相対的に少しだけのネットワークに フィッティングするというのが 考えられる。 さて、このようなネットワークは 相対的にはより少しのパラメータしか持たず、アンダーフィッティングしがちだ。 これらの小さなネットワークの主な利点は 計算量がより安上がり、という所。 これに対して代替的な方法としては 相対的により大きな ニューラルネットワークを用いる事で、 もっと多くの隠れユニットなり、 この場合は一層内にたくさんの隠れユニットがあるとか。またはもっと多くの隠れレイヤがあるような物も考えられる。 するとこれらのネットワークはより多くのパラメータを持つ傾向にあり、 ゆえによりオーバーフィッティングしやすい。 一つの欠点としては しばしばそれほど大きな問題とはならないが たまに考える必要がある事としては、 ネットワークに多くのニューロンがあると、 より計算量的に 高くつく場合がある、という事。 だが様々な理由から、これはたいていの場合は大きな問題とはならない。 これらより大きなニューラルネットワークの 主要な問題点たりえるのは、よりオーバーフィッティングしやすい、という物で、 ニューラルネットワークを用いてみると、 ネットワークは大きければ大きいほど 良い事が分かる。 だがもしオーバーフィットしてしまったら 正規化を用いてオーバーフィッティングの問題に対処出来る、 通常は大きめのネットワークに 正規化を適用して オーバーフィットに対処する方が 小さめのニューラルネットワークを使うよりも 効果的な事が多い。 そして主要な想定される短所としては そちらの方が計算量的により高価になりえる、という所。 最後に、決断すべき別の問題として、 隠れレイヤの数を幾つにすべきか、というのがある。 つまり隠れレイヤは 一つにすべきか、 あるいはここに示したように3つの隠れレイヤにすべきか？ あるいは2つの隠れレイヤにすべきか？ そして普段は 前回のビデオで言った通り 一つの隠れレイヤを用いるのは リーズナブルなデフォルトだ。 たが隠れレイヤの数を 選ぼうという時に、 もう一つ試せる事としては、 トレーニングセット、クロスバリデーションセット、 そしてテストセットに分けて、 そして隠れレイヤ一つ、または隠れレイヤ二つ、 または隠れレイヤ三つで ニューラルネットワークをトレーニングしてみて、 それらのネットワークのどれが クロスバリデーションセットで最も良いパフォーマンスを出すかを見てみる。 隠れレイヤを一つ、二つ、三つの ニューラルネットワークに対して クロスバリデーション誤差のJcvを それら全てに対して 計算してみて、 そしてそれを用いて これらのうちのどのニューラルネットワークを用いるのが ベストかを選ぶのに使う事が出来る。 以上が、バイアスとバリアンス、 そして学習曲線などを用いて これらの問題を診断する方法だ。 それを用いて、 学習アルゴリズムのパフォーマンスを改善するのに 何は実り多そうで 何はあまり実りが無さそうかを 判断出来る。 あなたがもしここ数回のビデオの内容を 理解出来ていたら、 そしてそれを実践出来るのなら、 あなたはすでに、、、 学習アルゴリズムを問題に対して適用出来、しかもそれを効率的に行う事が出来る、 しかもそれを、ここシリコンバレーで こんにちフルタイムの仕事としてやっているエンジニアの かなりの割合、ひょっとしたら大多数の 実践家よりもうまく、だ。 さて、これらの 診断の時の経験に対する アドバイスが、 学習アルゴリズムを 効率的に適用し、 とてもうまく機能出来るようになる、助けとなるといいな。