Si ejecutas el algoritmo de aprendizaje y no resulta tan bien como esperabas, la mayoría de las veces será porque existe ya sea un problema de sesgo alto o de varianza alta. En otras palabras, un problema de sobreajuste o de subajuste. En este caso es muy importante entender cual de estos dos problemas tenemos: de sesgo o varianza, o un poco de ambos. Ya que saber cuál de ellos sucede nos daría un indicador certero de de las maneras útiles y prometedoras para mejorar tu algoritmo. En este video, me gustaría desarrollar más el asunto de sesgo y varianza para entenderlos mejor y para encontrar la manera de ver un algoritmo de entrenamiento y evaluar o diagnosticar si tenemos, o no, un problema de varianza o de sesgo. Esto es crítico para entender cómo mejorar el desempeño del algoritmo de aprendizaje que intentas implementar. Ya has visto esta figura varias veces. En ella puedes aplicar una hipótesis simple que resulta en una línea recta que subajusta los datos. Si aplicas una hipótesis compleja, entonces quizá se ajustará al conjunto de entrenamiento perfectamente, pero sobreajustará los datos y esta puede ser una hipótesis de complejidad media con polinomios de segundo grado; es decir, de un grado no muy alto y no muy bajo, sino justo. Lo que resulta en un error de generalización de estas opciones. Ahora que tenemos el conocimiento de entrenamiento y validación en los conjuntos de prueba, podemos entender los conceptos de sesgo y varianza un poco mejor. Definamos nuestro error de entrenamiento y error de validación como en los videos anteriores. Es decir, el error cuadrático o el error cuadrático promedio como se calculó en el conjunto de entrenamiento o en el conjunto de validación cruzada. Ahora, tracemos la siguiente figura. En el eje horizontal trazaré el grado del polinomio. Conforme me acerque a la derecha ajustaré polinomios de un orden cada vez más grande. Haremos esto con esta figura donde “d” es quizá igual a 1 y ajustaremos funciones muy simples, mientras que a la derecha del esto podría ser, d es igual a 4 o podría ser un número aún mayor. Ajustaré órdenes de polinomios muy complejos que podrían ajustarse al conjunto de entrenamiento con variables mucho más complejas mientras que estamos en el extremo derecho del eje horizontal tendremos valores de “d” mayores o polinomios de grado más alto. Y esto corresponderá al ajuste de funciones más complejas a tu conjunto de entrenamiento.
Ahora veamos el error de entrenamiento y el error de validación cruzada y tracémoslo en esta figura. Empecemos con el error de entrenamiento. A medida que aumenta el grado del polinomio, podremos ajustar el conjunto de entrenamiento cada vez mejor. Si “d” es igual a 1 tendremos un error de entrenamiento relativamente alto. Mientras que si tenemos un polinomio de grado alto nuestro error de entrenamiento será realmente bajo. Quizá incluso sea cero porque se ajustará muy bien al conjunto de entrenamiento. Entonces, mientras aumentamos el grado del polinomio encontramos típicamente que el error de entrenamiento disminuye. Escribiré aquí “J” subíndice “entrenamiento” de theta, porque nuestro error de entrenamiento tiende a disminuir con el grado del polinomio que ajustamos a los datos. A continuación veremos el error de validación cruzada. O, para el caso, si vemos al error del conjunto de prueba obtendremos un resultado muy similar como si trazáramos el error de validación cruzada. Sabemos que si “d” es igual a 1, estaremos ajustando una función muy simple y quizá subajustaremos el conjunto de entrenamiento y tendremos un error de validación muy alto. Si ajustamos un polinomio de grado intermedio, de un polinomio de grado intermedio como “d” igual a 2 que presentamos en el ejemplo de la diapositiva anterior, tendremos un error de validación cruzada mucho menor porque estamos encontrando un valor más adecuado para los datos. un ajuste mucho mejor para los datos. Por el contrario, si “d” fuera muy alta, con un valor de cuatro, entonces estaremos sobreajustando de nuevo y acabaremos con un valor alto de error de validación cruzada. Si se mantuviera una variación uniforme y se trazara la curva, obtendríamos una curva como esta, donde esta sería “Jcv” de theta. Y, de nuevo, si trazamos “J” “prueba” de theta obtendríamos algo muy similar. Este tipo de trazos nos ayudan a entender mejor las nociones de sesgo y varianza. supongamos que tienes un algoritmo de aprendizaje que no funciona tan bien como quisieramos que lo hiciera, ¿cómo saber si tu algoritmo de aprendizaje tiene problemas? Ahora, supongamos que has aplicado un algoritmo de aprendizaje que no funciona tan bien como quieres porque ya sea el error del conjunto de validación o el error del conjunto de prueba son muy altos. ¿Cómo podemos averiguar si el algoritmo de aprendizaje sufre de un sesgo alto o de una varianza alta? La determinación de un error de validación alto corresponde a, ya sea este régimen o este otro régimen. Este régimen de la izquierda corresponde a un problema de sesgo alto; es decir, cuando se ajusta un polinomio de orden muy bajo, como “d” igual a 1, en donde en realidad se necesita un polinomio de orden más alto para ajustar los datos. Por el contrario, este régimen corresponde a un problema de varianza alta. Es decir, si “d”, el grado del polinomio, fuera muy grande para nuestro conjunto de datos. Esta figura nos da una pista para distinguir entre los dos casos. De forma concreta, para el caso de sesgo alto, es decir, el caso de subajuste, lo que encontramos es que tanto el error de validación cruzada como el error de entrenamiento serán altos. Por lo tanto, si tu algoritmo sufre de un problema de sesgo, el error del conjunto de entrenamiento sería alto y se podrá ver que el error de validación cruzada también sería alto y cercano o quizá un poco más alto que el error de entrenamiento. Y, si observas esta combinación tienes un signo de que tu algoritmo quizá sufra de un sesgo alto. Por el contrario, en el caso de que tu algoritmo sufra de una varianza alta, si miramos aquí nos daremos cuenta de que “J” subíndice “entrenamiento”; que es el error de entrenamiento, será bajo. Esto indica que estás ajustando bien el conjunto de entrenamiento. En cambio, en el error de validación cruzada, asumiendo que es un error cuadrático que intentamos minimizar, Este, el error en el conjunto de validación cruzada o la función de costo del conjunto de validación cruzada, será mayor que el error del conjunto de entrenamiento. Este signo doble de mayor es el símbolo matemático para “mucho mayor que”, Así que esto es un doble mayor que el signo, que es el símbolo matemático para mucho mayor y se denota con dos símbolos de “mayor que”. Si observas esta combinación, es lo que Así que, verás que esta combinación de valores es una pista de que tu algoritmo de aprendizaje sufre de una varianza alta y puede estar sobreajustado. Y la clave para distinguir estos dos casos es el hecho de que, si tienes un problema de sesgo alto, el error de tu conjunto de entrenamiento también será alto dado que la hipótesis no se está ajustando bien al conjunto de entrenamiento. Y si tienes un problema de varianza alta, tu error del conjunto de entrenamiento será generalmente bajo; es decir, mucho más bajo que el error de validación cruzada. Ojalá esto te de un mejor entendimiento de los problemas de varianza y sesgo. Aún te tengo más información del sesgo y la varianza en los siguientes videos. Pero lo que veremos después es que, al diagnosticar, veremos si un algoritmo de aprendizaje sufre de una varianza o un sesgo alto. Les mostraré más detalles de cómo hacer esto en los videos siguientes. Veremos que al encontrar si un algoritmo de aprendizaje sufre de un sesgo alto o una varianza alta o una combinación de ambos, tendremos una mejor guía de cuáles son las cosas más prometedoras que podemos intentar para mejorar el desempeño de un algoritmo de aprendizaje.