もし学習アルゴリズムを走らせて 期待ほど良い結果で無ければ、 だいたいいつも それは高いバイアス問題か、 高い分散問題の どちらかだ。 言い換えると、それは アンダーフィット問題かオーバーフィット問題のどちらか、という事。 そしてこの場合、 これらの問題のどちらなのかを 見分けるのは凄く重要。 バイアスなのか分散なのか。またはちょっとずつ 両方があるのか。 何故かといえば、これらのどちらが 起きているのかを知ると、 アルゴリズムを改善するのに 将来のありそうな道がどちらかの とても強力な指標となるから。 このビデオでは、 バイアスと分散の問題について より深くつっこんで行き、 それらをより深く理解すると同時に 我らの問題がバイアス問題なのか分散問題なのかを見分ける為に 学習アルゴリズムをどう見ていくか、どう評価して診断していくかも探求していきたい。 何故ならあなたの実装した学習アルゴリズムのパフォーマンスを 改善する方法を知るのに必須だから。 この図は既に 何度か見てきた。 あまりにも単純過ぎる仮説だと たとえば単なる直接とか、これだとデータにアンダーフィットしてしまう。 あまりにも複雑過ぎる仮説にフィットさせると それはトレーニングセットに 完璧に一致するかもしれないが データにオーバーフィットするかもしれない。 そしてこれは、中間の複雑さで、 たとえば多項式の次数が 高すぎもせず、低すぎもしない、という 仮説の例。 ちょうど良いケース。 そしてこれらの選択肢の中では ベストな一般化した時の誤差を与える。 今やトレーニング、バリデーション、テストセットという 考え方で武装したので、 バイアスと分散の概念を もうちょっと良く理解出来る。 具体的にいこう。 トレーニング誤差とクロスバリデーション誤差を 前回のビデオ同様に 定義しよう。 誤差の自乗、トレーニングセットか クロスバリデーションセットに対して 計測した誤差の自乗の 平均の値。 今、以下の図をプロットしよう。 横軸には多項式の 次数。 つまり右に行くに連れて どんどん高い次元の多項式をフィッティングする事となる。 つまりこの図の右側では d=1の時など、 とても簡単な関数で フィッティングする事となる。 他方、横軸の 右側では より大きな数字となり、 とても複雑な高い次元の多項式に フィッティングする事となる。 つまりトレーニングセットとより複雑な関数でフィッティングする事となる。 他方この 横軸の右側では dはより大きな値となり 多項式はより高い次数となる。 だからここでは、 より複雑な関数に 対応する。 ではトレーニング誤差と クロスバリデーション誤差を見てみて、 この図にプロットしてみよう。 トレーニング誤差から始めよう。 多項式の次元を上げるに連れて トレーニングセットへの フィッティングもますます良くなる。 もしd=1なら高いトレーニング誤差となるし、 もしとても高い次数の 多項式ならば 我らのトレーニング誤差は極めて低くなる。 ゼロにすらなるかも。何故ならそれはトレーニングセットにとても良くフィットするだろうから。 つまり多項式の次数を 高めれば高める程、 典型的にはトレーニングの誤差は 減少していく。 だからJ下付き添字trainのシータを書くと こんな感じ。 何故ならトレーニング誤差は データにフィットする多項式の 次元の増加とともに減少していくから。 次にクロスバリデーション誤差を見てみよう。 仮にテストセットの誤差を見るとすると、 そちらも似たような結果となるだろう。 まるでクロスバリデーション誤差を プロットしたかのように。
もしd=1なら、とても簡単な関数に フィッティングする事になるので トレーニングセットにアンダーフィットするかもしれない。 だからクロスバリデーション誤差は とても高いはず。 もし中間の 次数の多項式をフィッティングさせたら 前のスライドの例だと d=2のケースとなるが、 この場合はより低い クロスバリデーション誤差となるだろう。 何故なら我らはより良く データにフィットするのを見つけたという事だから。 そして、逆にdが 大きすぎる時は 例えばdが4の時は ふたたびオーバーフィットしてしまう。 だから結果としては 高いクロスバリデーション誤差となるだろう。 だからこれをなめらかに つなげて、曲線をプロットすると 結局こんな 曲線となる。 これがJcvのシータだ。 そして繰り返しになるが、Jtestのシータを プロットしても、とても似た物となる。 この種のプロットはまた、 バイアスと分散という考え方を よりよく理解する 助けともなる。
具体的に、 もしいまいち期待通りには パフォーマンスの出ない 機械学習のアルゴリズムがあったとする。 どうやって学習アルゴリズムが何の被害を、、、 具体的に、学習アルゴリズムを 適用したとする、 そして期待通りには パフォーマンスが出ていないとする。 つまり、クロスバリデーションセット誤差とテストセット誤差が高い。 どうやったら、 その学習アルゴリズムは 高いバイアスを被っているのか、高い分散を被っているのかを区別出来るのだろうか？ クロスバリデーション誤差が高いという事なので このレジームかこのレジームに 対応するはずだ。 この左のレジームは 高バイアス問題に 対応している、つまり、 もし単純すぎる多項式、 例えばd=1でフィッティングしていて、 でも本当はもっと高い次数で フィッティングする必要があるようなデータの時。 他方、対照的に、このレジームは 高分散の問題に対応する。 そこではd、つまり多項式の次数が 我らのデータセットに対しては大きすぎるという事。 そしてこの図が、これら2つのケースを どうやって見分けるか、に関する手がかりを与えてくれる。 具体的に、高バイアスのケースでは つまりアンダーフィットの ケースでは、 この図を見ると、 クロスバリデーション誤差とトレーニング誤差の 両方とも高くなっている事が分かる。 だからもしあなたのアルゴリズムが バイアスの問題を被っているなら、 トレーニングセットの誤差も 高くなるだろうし、 またクロスバリデーションの誤差もまた 高くなるはず。 それら2つは、近い。 トレーニング誤差よりちょっと高いだけかも。 だから、この組み合わせを観測したら あなたのアルゴリズムが 高バイアスの被害を被っているサインだ。 対照的に アルゴリズムが高分散の被害を被ってるなら ここを見ると Jtrain、 つまりトレーニング誤差が 低くなっている事に気付くだろう。 つまり、トレーニングセットにはとてもうまくフィッティング出来ている。 一方、クロスバリデーション誤差は これが最小化したい 誤差の二乗だと仮定するとーーー 他方で対照的に、 クロスバリデーションセットに対する誤差は つまりクロスバリデーションセットに対する コスト関数は トレーニングセットの誤差よりも、ずっと大きくなるだろう。 この「大なり大なり」記号は ずっと大きいを意味する。
つまり、大きいに大きいを掛け合わせると、ずっと大きいになる。 つまりこれは「大なり大なり」の記号で それは数学の記号で ずっと大きい、を意味するもので 2つの大なりの記号で示す。 だからもしこの組み合わせを見たら それはつまり、、、 そしてつまりこの値の組み合わせ見たら、 それは学習アルゴリズムが 高分散を被っていて、 オーバーフィットしてるという手がかりを得たという事。 そしてこれら2つのケースを分けるキーとなるのは もし高バイアスの問題なら トレーニングセットの誤差も 高くなるはずで、 何故なら仮説が トレーニングセットにうまくフィッティング出来ていないだけだから。 そしてもし高分散の問題なら、 トレーニングセットの誤差は 通常は低く、 クロスバリデーション誤差とくらべると大きく低いはず。 以上で、バイアスと分散の 2つの問題が、 いくらかでもより良く理解出来たら幸いです。 バイアスと分散については、 言うべき事がまだ幾つか残っています。次の幾つかのビデオで言います。 のち程見るのは、 学習アルゴリズムが 高バイアスか高分散を被っているかを診断する事です。 それをどうやるかについての更なる詳細を以後見ていきます。 学習アルゴリズムが被っているのが 高バイアスか両方の組み合わせかを 区別する事により、 学習アルゴリズムを改善する為に 何をやるのが成果が期待出来そうな道かを 知る、より良いガイダンスを 提供してくれる事を 見ていきます。