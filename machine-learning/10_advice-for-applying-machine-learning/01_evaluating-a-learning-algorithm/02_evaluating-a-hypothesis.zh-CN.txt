在本节视频中我想介绍一下 怎样用你学过的算法来评估假设函数 在之后的课程中 我们将以此为基础来 讨论如何避免 过拟合和欠拟合的问题 当我们确定学习算法的参数的时候 我们考虑的是选择参量来使训练误差最小化 有人认为 得到一个非常小的训练误差 一定是一件好事 但我们已经知道 仅仅是因为这个假设具有很小的训练误差 并不能说明它就一定是一个好的假设函数 而且我们也学习了过拟合假设函数的例子 所以这推广到新的训练集上是不适用的 那么 你该如何判断一个假设函数是过拟合的呢 对于这个简单的例子 我们可以 对假设函数 h(x) 进行画图 然后观察图形趋势 但对于特征变量不止一个的这种一般情况 还有像有很多特征变量的问题 想要通过画出假设函数来进行观察 就会变得很难甚至是不可能实现 因此 我们需要另一种方法来评估我们的假设函数 如下给出了一种评估假设函数的标准方法 假设我们有这样一组数据组 在这里我只展示出10组训练样本 当然我们通常可以有 成百上千组训练样本 为了确保我们可以评估我们的假设函数 我们要做的是 将这些数据分成两部分 第一部分将成为我们的常用训练集 而第二部分将成为我们的测试集 将所有数据分成训练集和测试集 其中一种典型的分割方法是 按照7:3的比例 将70%的数据作为训练集 30%的数据作为测试集 因此 现在如果我们有了一些数据 我们只用其中的70% 作为我们的训练集 这里的m依然表示训练样本的总数 而剩下的那部分数据 将被用作测试集 在这里 我使用m下标test 来表示测试样本的总数 因此 这里的下标test将表示 这些样本是来自测试集 因此x(1)test y(1)test将成为我的 第一组测试样本 我想应该是这里的这一组样本 最后再提醒一点 在这里我是选择了前70%的数据作为训练集 后30%的数据作为测试集 但如果这组数据有某种规律或顺序的话 那么最好是 随机选择70%作为训练集 剩下的30%作为测试集 当然如果你的数据已经随机分布了 那你可以选择前70%和后30% 但如果你的数据不是随机排列的 最好还是打乱顺序 或者使用一种随机的顺序来构建你的数据 然后再取出前70%作为训练集 后30%作为测试集 接下来 这里展示了一种典型的方法 你可以按照这些步骤训练和测试你的学习算法 比如线性回归算法 首先 你需要对训练集进行学习得到参数θ 具体来讲就是最小化训练误差J(θ) 这里的J(θ)是使用那70%数据 来定义得到的 也就是仅仅是训练数据 接下来 你要计算出测试误差 我将用J下标test来表示测试误差 那么你要做的就是 取出你之前从训练集中学习得到的参数θ放在这里 来计算你的测试误差 可以写成如下的形式 这实际上是测试集 平方误差的 平均值 这也不难想象 因此 我们使用包含参数θ的假设函数对每一个测试样本进行测试 然后通过假设函数和测试样本 计算出mtest个平方误差 当然 这是当我们使用线性回归 和平方误差标准时 测试误差的定义 那么如果是考虑分类问题 比如说使用逻辑回归的时候呢 训练和测试逻辑回归的步骤 与之前所说的非常类似 首先我们要从训练数据 也就是所有数据的70%中 学习得到参数θ 然后用如下的方式计算测试误差 目标函数和我们平常 做逻辑回归的一样 唯一的区别是 现在我们使用的是mtest个测试样本 这里的测试误差Jtest(θ) 其实不难理解 有时这是另一种形式的测试集 更易于理解 这里的误差其实叫误分类率 也被称为0/1错分率 0/1表示了 你预测到的正确或错误样本的情况 比如说 可以这样定义一次预测的误差 关于假设h(x) 和标签y的误差 那么这个误差等于1 当你的假设函数h(x)的值大于等于0.5 并且y的值等于0 或者当h(x)小于0.5 并且y的值等于1 因此 这两种情况都表明 你的假设对样本进行了误判 这里定义阈值为0.5 那么也就是说 假设结果更趋向于1 但实际是0 或者说假设更趋向于0 但实际的标签却是1 否则 我们将误差值定义为0 此时你的假设值能够正确对样本y进行分类 然后 我们就能应用错分率误差 来定义测试误差 也就是1/mtest 乘以 h(i)(xtest)和y(i)的错分率误差 从i=1到mtest 的求和 这样我就写出了我的定义方式 这实际上就是我的假设函数误标记的 那部分测试集中的样本 这也就是使用 0/1错分率或误分类率 的准则来定义的测试误差 以上我们介绍了一套标准技术 来评价一个已经学习过的假设 在下一段视频中我们要应用这些方法 来帮助我们进行诸如特征选择一类的问题 比如多项式次数的选择 或者正则化参数的选择【果壳教育无边界字幕组】翻译：所罗门捷列夫 校对/审核: 柳桦