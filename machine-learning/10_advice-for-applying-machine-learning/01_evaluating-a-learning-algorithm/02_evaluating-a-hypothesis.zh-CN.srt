1
00:00:00,146 --> 00:00:02,515
在本节视频中我想介绍一下

2
00:00:02,523 --> 00:00:06,662
怎样用你学过的算法来评估假设函数

3
00:00:06,685 --> 00:00:09,200
在之后的课程中 我们将以此为基础来

4
00:00:09,231 --> 00:00:11,846
讨论如何避免

5
00:00:11,869 --> 00:00:14,908
过拟合和欠拟合的问题

6
00:00:15,615 --> 00:00:19,023
当我们确定学习算法的参数的时候

7
00:00:19,038 --> 00:00:23,154
我们考虑的是选择参量来使训练误差最小化

8
00:00:23,169 --> 00:00:26,077
有人认为 得到一个非常小的训练误差

9
00:00:26,100 --> 00:00:28,108
一定是一件好事

10
00:00:28,108 --> 00:00:29,562
但我们已经知道

11
00:00:29,562 --> 00:00:32,400
仅仅是因为这个假设具有很小的训练误差

12
00:00:32,400 --> 00:00:35,254
并不能说明它就一定是一个好的假设函数

13
00:00:35,254 --> 00:00:40,223
而且我们也学习了过拟合假设函数的例子

14
00:00:40,415 --> 00:00:45,785
所以这推广到新的训练集上是不适用的

15
00:00:45,962 --> 00:00:50,000
那么 你该如何判断一个假设函数是过拟合的呢

16
00:00:50,015 --> 00:00:54,346
对于这个简单的例子 我们可以

17
00:00:54,365 --> 00:00:56,338
对假设函数 h(x) 进行画图 然后观察图形趋势

18
00:00:56,346 --> 00:01:00,538
但对于特征变量不止一个的这种一般情况

19
00:01:00,554 --> 00:01:03,531
还有像有很多特征变量的问题

20
00:01:03,546 --> 00:01:06,692
想要通过画出假设函数来进行观察

21
00:01:06,708 --> 00:01:09,515
就会变得很难甚至是不可能实现

22
00:01:09,531 --> 00:01:13,046
因此 我们需要另一种方法来评估我们的假设函数

23
00:01:13,062 --> 00:01:17,315
如下给出了一种评估假设函数的标准方法

24
00:01:17,331 --> 00:01:19,308
假设我们有这样一组数据组

25
00:01:19,323 --> 00:01:21,977
在这里我只展示出10组训练样本

26
00:01:21,992 --> 00:01:23,969
当然我们通常可以有

27
00:01:23,985 --> 00:01:27,254
成百上千组训练样本

28
00:01:27,269 --> 00:01:30,246
为了确保我们可以评估我们的假设函数

29
00:01:30,262 --> 00:01:32,808
我们要做的是

30
00:01:32,823 --> 00:01:35,554
将这些数据分成两部分

31
00:01:35,569 --> 00:01:40,723
第一部分将成为我们的常用训练集

32
00:01:42,638 --> 00:01:47,446
而第二部分将成为我们的测试集

33
00:01:47,462 --> 00:01:50,398
将所有数据分成训练集和测试集

34
00:01:50,413 --> 00:01:53,482
其中一种典型的分割方法是

35
00:01:53,498 --> 00:01:57,936
按照7:3的比例

36
00:01:57,952 --> 00:02:00,052
将70%的数据作为训练集

37
00:02:00,067 --> 00:02:02,367
30%的数据作为测试集

38
00:02:02,382 --> 00:02:05,782
因此 现在如果我们有了一些数据

39
00:02:05,790 --> 00:02:08,459
我们只用其中的70%

40
00:02:08,475 --> 00:02:11,529
作为我们的训练集

41
00:02:11,544 --> 00:02:14,336
这里的m依然表示训练样本的总数

42
00:02:14,352 --> 00:02:16,913
而剩下的那部分数据

43
00:02:16,929 --> 00:02:19,310
将被用作测试集

44
00:02:19,325 --> 00:02:23,410
在这里 我使用m下标test

45
00:02:23,425 --> 00:02:27,187
来表示测试样本的总数

46
00:02:27,202 --> 00:02:32,225
因此 这里的下标test将表示

47
00:02:32,241 --> 00:02:34,987
这些样本是来自测试集

48
00:02:35,002 --> 00:02:40,810
因此x(1)test y(1)test将成为我的

49
00:02:40,825 --> 00:02:43,648
第一组测试样本

50
00:02:43,664 --> 00:02:45,656
我想应该是这里的这一组样本

51
00:02:45,671 --> 00:02:47,495
最后再提醒一点

52
00:02:47,510 --> 00:02:50,795
在这里我是选择了前70%的数据作为训练集

53
00:02:50,810 --> 00:02:54,479
后30%的数据作为测试集

54
00:02:54,495 --> 00:02:57,518
但如果这组数据有某种规律或顺序的话

55
00:02:57,533 --> 00:03:01,048
那么最好是

56
00:03:01,048 --> 00:03:02,948
随机选择70%作为训练集

57
00:03:02,964 --> 00:03:05,556
剩下的30%作为测试集

58
00:03:05,571 --> 00:03:08,579
当然如果你的数据已经随机分布了

59
00:03:08,595 --> 00:03:12,110
那你可以选择前70%和后30%

60
00:03:12,125 --> 00:03:14,718
但如果你的数据不是随机排列的

61
00:03:14,733 --> 00:03:16,756
最好还是打乱顺序

62
00:03:16,771 --> 00:03:19,718
或者使用一种随机的顺序来构建你的数据

63
00:03:19,733 --> 00:03:23,310
然后再取出前70%作为训练集

64
00:03:23,325 --> 00:03:26,669
后30%作为测试集

65
00:03:27,054 --> 00:03:30,169
接下来 这里展示了一种典型的方法

66
00:03:30,185 --> 00:03:32,008
你可以按照这些步骤训练和测试你的学习算法

67
00:03:32,023 --> 00:03:34,492
比如线性回归算法

68
00:03:34,508 --> 00:03:38,115
首先 你需要对训练集进行学习得到参数θ

69
00:03:38,131 --> 00:03:41,798
具体来讲就是最小化训练误差J(θ)

70
00:03:41,813 --> 00:03:44,713
这里的J(θ)是使用那70%数据

71
00:03:44,729 --> 00:03:47,059
来定义得到的

72
00:03:47,075 --> 00:03:49,759
也就是仅仅是训练数据

73
00:03:49,882 --> 00:03:52,167
接下来 你要计算出测试误差

74
00:03:52,182 --> 00:03:56,298
我将用J下标test来表示测试误差

75
00:03:56,313 --> 00:03:59,229
那么你要做的就是

76
00:03:59,259 --> 00:04:02,190
取出你之前从训练集中学习得到的参数θ放在这里

77
00:04:02,205 --> 00:04:04,875
来计算你的测试误差

78
00:04:04,890 --> 00:04:08,529
可以写成如下的形式

79
00:04:08,698 --> 00:04:11,275
这实际上是测试集

80
00:04:11,290 --> 00:04:15,244
平方误差的

81
00:04:15,269 --> 00:04:18,154
平均值

82
00:04:18,169 --> 00:04:19,915
这也不难想象

83
00:04:19,931 --> 00:04:23,415
因此 我们使用包含参数θ的假设函数对每一个测试样本进行测试

84
00:04:23,431 --> 00:04:28,008
然后通过假设函数和测试样本

85
00:04:28,023 --> 00:04:33,338
计算出mtest个平方误差

86
00:04:33,354 --> 00:04:37,054
当然 这是当我们使用线性回归

87
00:04:37,069 --> 00:04:40,815
和平方误差标准时

88
00:04:40,831 --> 00:04:44,362
测试误差的定义

89
00:04:44,377 --> 00:04:47,477
那么如果是考虑分类问题

90
00:04:47,492 --> 00:04:50,654
比如说使用逻辑回归的时候呢

91
00:04:50,669 --> 00:04:53,877
训练和测试逻辑回归的步骤

92
00:04:53,892 --> 00:04:57,085
与之前所说的非常类似

93
00:04:57,100 --> 00:04:59,985
首先我们要从训练数据 也就是所有数据的70%中

94
00:05:00,000 --> 00:05:02,331
学习得到参数θ

95
00:05:02,346 --> 00:05:05,115
然后用如下的方式计算测试误差

96
00:05:05,131 --> 00:05:07,015
目标函数和我们平常

97
00:05:07,031 --> 00:05:09,592
做逻辑回归的一样

98
00:05:09,608 --> 00:05:11,569
唯一的区别是

99
00:05:11,585 --> 00:05:15,115
现在我们使用的是mtest个测试样本

100
00:05:15,131 --> 00:05:17,600
这里的测试误差Jtest(θ)

101
00:05:17,631 --> 00:05:20,238
其实不难理解

102
00:05:20,254 --> 00:05:22,231
有时这是另一种形式的测试集

103
00:05:22,246 --> 00:05:25,469
更易于理解

104
00:05:25,485 --> 00:05:27,877
这里的误差其实叫误分类率

105
00:05:27,892 --> 00:05:30,792
也被称为0/1错分率

106
00:05:30,808 --> 00:05:32,692
0/1表示了

107
00:05:32,708 --> 00:05:36,146
你预测到的正确或错误样本的情况

108
00:05:36,162 --> 00:05:37,910
比如说

109
00:05:37,925 --> 00:05:41,795
可以这样定义一次预测的误差

110
00:05:41,825 --> 00:05:44,202
关于假设h(x)

111
00:05:44,218 --> 00:05:47,518
和标签y的误差

112
00:05:47,533 --> 00:05:51,848
那么这个误差等于1

113
00:05:51,864 --> 00:05:54,633
当你的假设函数h(x)的值大于等于0.5

114
00:05:54,641 --> 00:05:57,510
并且y的值等于0

115
00:05:57,525 --> 00:06:03,718
或者当h(x)小于0.5

116
00:06:03,733 --> 00:06:05,402
并且y的值等于1

117
00:06:05,418 --> 00:06:08,118
因此 这两种情况都表明

118
00:06:08,133 --> 00:06:11,833
你的假设对样本进行了误判

119
00:06:11,833 --> 00:06:14,518
这里定义阈值为0.5

120
00:06:14,533 --> 00:06:18,171
那么也就是说 假设结果更趋向于1 但实际是0

121
00:06:18,187 --> 00:06:20,733
或者说假设更趋向于0

122
00:06:20,748 --> 00:06:23,556
但实际的标签却是1

123
00:06:23,571 --> 00:06:28,471
否则 我们将误差值定义为0

124
00:06:28,487 --> 00:06:34,841
此时你的假设值能够正确对样本y进行分类

125
00:06:34,864 --> 00:06:38,841
然后 我们就能应用错分率误差

126
00:06:38,856 --> 00:06:42,371
来定义测试误差

127
00:06:42,387 --> 00:06:46,779
也就是1/mtest 乘以

128
00:06:46,795 --> 00:06:49,941
h(i)(xtest)和y(i)的错分率误差

129
00:06:49,956 --> 00:06:55,164
从i=1到mtest

130
00:06:55,179 --> 00:06:57,971
的求和

131
00:06:57,987 --> 00:07:02,010
这样我就写出了我的定义方式

132
00:07:02,025 --> 00:07:05,587
这实际上就是我的假设函数误标记的

133
00:07:05,602 --> 00:07:08,864
那部分测试集中的样本

134
00:07:08,871 --> 00:07:10,602
这也就是使用

135
00:07:10,618 --> 00:07:13,687
0/1错分率或误分类率

136
00:07:13,718 --> 00:07:16,948
的准则来定义的测试误差

137
00:07:16,971 --> 00:07:19,995
以上我们介绍了一套标准技术

138
00:07:20,010 --> 00:07:22,833
来评价一个已经学习过的假设

139
00:07:22,848 --> 00:07:25,579
在下一段视频中我们要应用这些方法

140
00:07:25,595 --> 00:07:28,525
来帮助我们进行诸如特征选择一类的问题

141
00:07:28,541 --> 00:07:31,641
比如多项式次数的选择

142
00:07:31,656 --> 00:07:34,964
或者正则化参数的选择【果壳教育无边界字幕组】翻译：所罗门捷列夫 校对/审核: 柳桦