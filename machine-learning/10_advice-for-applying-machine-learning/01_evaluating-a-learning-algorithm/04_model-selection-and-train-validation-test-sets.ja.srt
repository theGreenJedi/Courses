1
00:00:00,160 --> 00:00:04,570
データセットに

2
00:00:04,570 --> 00:00:08,750
何次の多項式まで含めて

3
00:00:08,750 --> 00:00:13,160
フィットさせたいか決めたい、としよう。

4
00:00:13,160 --> 00:00:14,550
つまり学習アルゴリズムになんのフィーチャーを含めるか、という話だ。

5
00:00:14,550 --> 00:00:15,830
または学習アルゴリズムの正規化パラメータ、ラムダを

6
00:00:15,830 --> 00:00:17,510
選びたいとしよう。

7
00:00:17,510 --> 00:00:22,411
どうやる？

8
00:00:22,411 --> 00:00:27,031
これらはモデル選択問題と呼ばれている。

9
00:00:27,031 --> 00:00:31,020
これをどう行うかの議論をするにあたり、

10
00:00:31,020 --> 00:00:33,860
データをどうトレーニングセットと

11
00:00:33,860 --> 00:00:36,890
テストセットに

12
00:00:36,890 --> 00:00:40,350
分割するかだけでなく、

13
00:00:40,350 --> 00:00:44,380
データを、

14
00:00:44,380 --> 00:00:47,490
やがて見る事になる、

15
00:00:47,490 --> 00:00:52,290
トレインバリデーションと呼ばれる物と

16
00:00:52,290 --> 00:00:56,000
テストセットにデータをどう分割するかを扱う。

17
00:00:56,000 --> 00:00:59,150
このビデオの中で

18
00:00:59,150 --> 00:01:02,810
以上の事がいったいなんなのか、

19
00:01:02,810 --> 00:01:07,210
そしてそれらを使ってどうモデル選択をするかを見ていく。

20
00:01:07,210 --> 00:01:11,630
ここまでに何度も

21
00:01:11,630 --> 00:01:15,970
オーバーフィティングの問題を見てきた。

22
00:01:15,970 --> 00:01:18,730
そこでは学習アルゴリズムが

23
00:01:18,730 --> 00:01:21,290
トレーニングセットに良くフィットしているからといって

24
00:01:21,290 --> 00:01:23,720
必ずしも良い仮説だとは限らないのだった。

25
00:01:23,720 --> 00:01:27,900
より一般的には、これこそが

26
00:01:27,900 --> 00:01:29,600
トレーニングセットの誤差が

27
00:01:29,600 --> 00:01:33,380
新しいサンプルに対してどれだけ

28
00:01:33,380 --> 00:01:38,330
良い予測器かの良い指標にはならない理由だった。

29
00:01:38,330 --> 00:01:41,170
具体的には、

30
00:01:41,170 --> 00:01:45,100
あるパラメータの集まり、

31
00:01:45,100 --> 00:01:48,800
シータ0、シータ1、シータ2など、

32
00:01:48,800 --> 00:01:50,740
をトレーニングセットにフィットしようと

33
00:01:51,940 --> 00:01:55,810
しているとしよう。

34
00:01:55,810 --> 00:02:01,210
その時に仮説がトレーニングセットに対して

35
00:02:01,210 --> 00:02:02,310
良いという事実は、

36
00:02:02,310 --> 00:02:06,610
仮説が新たな、トレーニングセットに無い

37
00:02:06,610 --> 00:02:10,680
サンプルをどれだけうまく予言するかという

38
00:02:10,680 --> 00:02:14,940
観点からは、

39
00:02:14,940 --> 00:02:19,760
多くは

40
00:02:19,760 --> 00:02:24,830
意味しない、という事。

41
00:02:24,830 --> 00:02:28,880
より一般的な原則としては、

42
00:02:28,880 --> 00:02:33,110
一旦パラメータをあるデータの集合に

43
00:02:33,110 --> 00:02:37,920
フィッティングしたら、

44
00:02:37,920 --> 00:02:42,570
それがトレーニングセットであれそれ以外であれ、

45
00:02:42,570 --> 00:02:44,130
その同じデータセットに対して

46
00:02:44,130 --> 00:02:49,790
測った仮説の誤差というのは、

47
00:02:49,790 --> 00:02:53,260
たとえばトレーニング誤差などは

48
00:02:53,260 --> 00:02:58,600
それは恐らく

49
00:02:58,600 --> 00:03:01,290
実際の一般のケースの誤差を

50
00:03:01,290 --> 00:03:03,040
推計するには良い物では無い。

51
00:03:03,040 --> 00:03:06,790
つまりどれだけ仮説が

52
00:03:06,790 --> 00:03:11,550
新しいサンプルに対してうまく一般化されているか、という事については。

53
00:03:11,550 --> 00:03:16,170
では、モデル選択問題を検討してみよう。

54
00:03:16,170 --> 00:03:19,130
データをフィットするのに、 何次の多項式を

55
00:03:19,130 --> 00:03:23,940
含めるかを選ぼうとしている、としよう。

56
00:03:23,940 --> 00:03:30,500
つまり、あなたは線形関数を選びたい、

57
00:03:30,500 --> 00:03:36,200
二次関数、三次関数、

58
00:03:36,200 --> 00:03:38,800
、、、と10乗の多項式まで。

59
00:03:38,800 --> 00:03:46,330
つまり、それはまるで、一つ追加のパラメータ、

60
00:03:47,410 --> 00:03:51,930
それをdで表すが、

61
00:03:53,050 --> 00:03:57,546
何次の多項式まで含めるか、を表す

62
00:03:57,546 --> 00:04:00,270
パラメータがアルゴリズムにあるみたいな物だ。

63
00:04:00,270 --> 00:04:05,010
つまりまるで、

64
00:04:05,010 --> 00:04:09,160
パラメータのシータに追加して

65
00:04:09,160 --> 00:04:09,930
さらにもう一つ、

66
00:04:09,930 --> 00:04:14,480
パラメータdという物が

67
00:04:14,480 --> 00:04:16,940
追加されていて、それをデータセットを用いて決めたい、と考える。

68
00:04:16,940 --> 00:04:21,060
最初の選択肢はd=1で

69
00:04:21,060 --> 00:04:26,080
それは線形関数となる。

70
00:04:27,190 --> 00:04:30,560
d=2も、d=3も、、、と

71
00:04:30,560 --> 00:04:34,710
d=10までの

72
00:04:34,710 --> 00:04:39,450
選択肢がある。

73
00:04:39,450 --> 00:04:42,360
つまりこの、ある意味で追加のパラメータについて

74
00:04:42,360 --> 00:04:48,140
フィッティングしたい、という訳だ。

75
00:04:48,140 --> 00:04:50,870
それをdで示していて、

76
00:04:50,870 --> 00:04:54,720
具体的には、

77
00:04:54,720 --> 00:05:00,310
モデルを選びたいと、

78
00:05:00,310 --> 00:05:06,340
これら10個のモデルから

79
00:05:06,340 --> 00:05:11,160
一つの多項式の次数を選びたいとする。

80
00:05:11,160 --> 00:05:15,640
そしてそのモデルをフィッティングして

81
00:05:15,640 --> 00:05:21,410
そのフィッティングした仮説が

82
00:05:21,410 --> 00:05:25,900
どれくらいうまく、

83
00:05:25,900 --> 00:05:29,430
新しいサンプルに対して一般化されているかを

84
00:05:29,430 --> 00:05:33,650
評価する。

85
00:05:33,650 --> 00:05:36,140
一つ、ありえる事としては、こんなのがある:

86
00:05:36,140 --> 00:05:41,050
最初のモデルを取って

87
00:05:41,050 --> 00:05:45,210
トレーニング誤差を最小化し、

88
00:05:45,210 --> 00:05:50,300
それであるパラメータベクトルが

89
00:05:50,300 --> 00:05:53,500
得られる。

90
00:05:53,500 --> 00:05:56,770
そして次に、二番目のモデル、二次関数を

91
00:05:56,770 --> 00:05:59,110
とってきて、

92
00:05:59,110 --> 00:06:03,200
トレーニングセットに対してーー

93
00:06:03,200 --> 00:06:07,460
別のパラメータベクトル、シータを得る事になる。

94
00:06:07,460 --> 00:06:13,060
これら別々のパラメータベクトルを

95
00:06:13,060 --> 00:06:16,770
区別する為に、

96
00:06:16,770 --> 00:06:22,010
下付き添字1、2、、、を使っていく。

97
00:06:22,010 --> 00:06:26,670
ここでシータの下付き添字1は、

98
00:06:26,670 --> 00:06:30,630
このモデルをトレーニングデータに対して

99
00:06:30,630 --> 00:06:35,550
フィッティングして

100
00:06:35,550 --> 00:06:40,200
得られたパラメータを意味するに過ぎない。

101
00:06:40,200 --> 00:06:43,930
シータ下付き添字2は単に

102
00:06:43,930 --> 00:06:49,130
この二次関数をトレーニングデータに対して

103
00:06:50,130 --> 00:06:53,300
フィッティングして得られたパラメータを表すだけ、などなど。

104
00:06:54,780 --> 00:07:00,056
そして三次のモデルをフィッティングする事で、パラメータ、シータ3を得て、

105
00:07:00,056 --> 00:07:04,711
これをシータ10まで続ける事が出来る。

106
00:07:04,711 --> 00:07:08,860
そしてここまて来た後にやれる事としては、一つには

107
00:07:08,860 --> 00:07:13,520
これらのパラメータに対し

108
00:07:13,520 --> 00:07:18,060
テストセットの誤差を見ていく。

109
00:07:18,060 --> 00:07:21,930
つまり、テストセットに対して

110
00:07:21,930 --> 00:07:24,990
Jのtestのシータ1、

111
00:07:24,990 --> 00:07:29,290
Jのtestのシータ2、

112
00:07:29,290 --> 00:07:33,600
みたいに。

113
00:07:33,600 --> 00:07:38,922
Jのtestのシータ3

114
00:07:38,922 --> 00:07:44,860
とか。

115
00:07:44,860 --> 00:07:47,290
つまり、対応する仮説を

116
00:07:47,290 --> 00:07:50,860
一つずつ見ていって

117
00:07:52,040 --> 00:07:59,110
テストセットに対するパフォーマンスを

118
00:07:59,110 --> 00:08:02,720
ただ計測していくだけ。

119
00:08:02,720 --> 00:08:07,290
そこから出来る事としては、一つには

120
00:08:07,290 --> 00:08:11,420
これらのモデルを選ぶ為に

121
00:08:11,420 --> 00:08:14,570
どのモデルが

122
00:08:14,570 --> 00:08:16,740
一番低い

123
00:08:16,740 --> 00:08:21,420
テストセットの誤差となっているかを見る、

124
00:08:21,420 --> 00:08:23,790
というのがある。

125
00:08:23,790 --> 00:08:26,820
そしてこの例では、仮に

126
00:08:26,820 --> 00:08:29,030
5次の多項式を選ぶ事になったとしよう。

127
00:08:29,030 --> 00:08:32,260
ここまではリーズナブルっぽいね。

128
00:08:32,260 --> 00:08:37,110
だがここで、フィットさせた仮説、

129
00:08:37,110 --> 00:08:41,470
この5次のモデルに

130
00:08:41,470 --> 00:08:45,970
対して、このモデルが

131
00:08:45,970 --> 00:08:48,450
どれだけうまく一般化されているか知りたいとする。

132
00:08:49,530 --> 00:08:53,410
一つ考えられるのは、

133
00:08:53,410 --> 00:08:58,709
五次の多項式の仮説がどれだけテストセットに対して

134
00:08:58,709 --> 00:09:04,580
うまく機能するかを見る、という事だが、、、

135
00:09:04,580 --> 00:09:10,570
だがこれには問題がある。

136
00:09:10,570 --> 00:09:13,580
これは我らの仮説がどれだけうまく

137
00:09:13,580 --> 00:09:17,520
一般化出来ているかを見積もるには

138
00:09:17,520 --> 00:09:20,300
フェアなやり方じゃないって事だ。

139
00:09:20,300 --> 00:09:23,560
その理由は、我らがやった事はそもそも、

140
00:09:23,560 --> 00:09:25,660
この追加のパラメータdを

141
00:09:25,660 --> 00:09:27,927
それは多項式の次数だが、

142
00:09:27,927 --> 00:09:31,601
これをフィッティングたのだった。

143
00:09:31,601 --> 00:09:35,470
そしてこのdは、

144
00:09:35,470 --> 00:09:40,440
テストセットを使ってフィッティングしたのだった。

145
00:09:40,440 --> 00:09:43,130
ようするに、我らはdの値を

146
00:09:43,130 --> 00:09:46,600
テストセットに対して最も高いパフォーマンスが出るように

147
00:09:46,600 --> 00:09:52,180
選んだのだった。

148
00:09:53,250 --> 00:09:57,180
だから、

149
00:09:57,180 --> 00:10:00,180
パラメータベクトルのシータ5の

150
00:10:00,180 --> 00:10:06,550
テストセットに対してのパフォーマンスは

151
00:10:06,550 --> 00:10:11,070
たぶん一般化の誤差を見積もるには

152
00:10:11,070 --> 00:10:15,250
過剰に楽観的に

153
00:10:15,250 --> 00:10:17,200
なってしまうはず。

154
00:10:17,200 --> 00:10:20,270
でしょ？だってパラメータdは

155
00:10:20,270 --> 00:10:25,040
テストセットに対してフィッティングしたんだから。

156
00:10:25,040 --> 00:10:27,290
だからもはや、

157
00:10:27,290 --> 00:10:32,320
仮説をテストセットに対して用いるのは

158
00:10:32,320 --> 00:10:39,260
フェアじゃ無くなってしまっているよ。

159
00:10:39,260 --> 00:10:44,325
だってパラメータのフィッティングにテストセットを使っちゃったんだから。

160
00:10:44,325 --> 00:10:47,680
多項式の次数、dを

161
00:10:47,680 --> 00:10:51,140
テストセットを使って選んだんだった。

162
00:10:51,140 --> 00:10:54,310
だから我らの仮説は

163
00:10:54,310 --> 00:10:57,310
たぶんテストセットに対しての方が

164
00:10:57,310 --> 00:10:58,570
まだ見ぬ新しいサンプルに対してより

165
00:10:59,630 --> 00:11:02,860
うまく振舞ってしまうだろう。

166
00:11:02,860 --> 00:11:06,210
そしてその新しいサンプルに対してこそが知りたい事だ。

167
00:11:06,210 --> 00:11:10,470
前のスライドを

168
00:11:10,470 --> 00:11:15,360
繰り返すと、

169
00:11:15,360 --> 00:11:19,590
もしあるパラメータの集合、

170
00:11:19,590 --> 00:11:24,120
例えばシータ0とかシータ1とかを、

171
00:11:24,120 --> 00:11:27,840
なんらかのトレーニングセットに対して

172
00:11:27,840 --> 00:11:31,160
フィッティングしたら、

173
00:11:31,160 --> 00:11:35,550
そのトレーニングセットにフィットさせたモデルの（そのトレーニングセットに対する）パフォーマンスは

174
00:11:35,550 --> 00:11:38,090
新しいサンプルに対して

175
00:11:38,090 --> 00:11:42,360
どれだけうまく一般化出来た仮説と

176
00:11:42,360 --> 00:11:45,760
なっているかを予測するのには

177
00:11:45,760 --> 00:11:46,728
使えない。
何故ならこれらのパラメータは

178
00:11:46,728 --> 00:11:50,620
当然このトレーニングセットにはフィットするだろうから。

179
00:11:50,620 --> 00:11:54,320
つまりそれらはトレーニングセットに対しては

180
00:11:54,320 --> 00:11:57,430
良いだろうと思われる。

181
00:11:57,430 --> 00:12:00,020
たとえそのパラメータが、他のサンプルには良くなくても。

182
00:12:00,020 --> 00:12:03,090
そしてこのスライドで記述した手順では、