1
00:00:00,160 --> 00:00:04,570
假如你想要确定对于某组数据 最合适的多项式次数是几次

2
00:00:04,570 --> 00:00:08,750
怎样选用正确的特征来构造学习算法

3
00:00:08,750 --> 00:00:13,160
或者假如你需要正确选择

4
00:00:13,160 --> 00:00:14,550
学习算法中的正则化参数λ

5
00:00:14,550 --> 00:00:15,830
你应该怎样做呢？

6
00:00:15,830 --> 00:00:17,510
这些问题我们称之为模型选择问题

7
00:00:17,510 --> 00:00:22,411
在我们对于这一问题的讨论中 我们还将提到

8
00:00:22,411 --> 00:00:27,031
如何将数据分为三组 也就是训练集、验证集和测试集

9
00:00:27,031 --> 00:00:31,020
而不仅仅是前面提到的两组数据

10
00:00:31,020 --> 00:00:33,860
在这节视频中 我们将会介绍这些内容的含义

11
00:00:33,860 --> 00:00:36,890
以及如何使用它们进行模型选择

12
00:00:36,890 --> 00:00:40,350
我们已经多次接触到过拟合现象 在过拟合的情况中 

13
00:00:40,350 --> 00:00:44,380
学习算法在适用于训练集时表现非常完美 

14
00:00:44,380 --> 00:00:47,490
但这并不代表此时的假设也很完美

15
00:00:47,490 --> 00:00:52,290
更一般地说 这也是为什么训练集误差

16
00:00:52,290 --> 00:00:56,000
通常不能正确预测出该假设是否能很好地拟合新样本的原因

17
00:00:56,000 --> 00:00:59,150
具体来讲 如果你把这些参数集 比如θ0 θ1 θ2等等

18
00:00:59,150 --> 00:01:02,810
调整到非常拟合你的训练集

19
00:01:02,810 --> 00:01:07,210
那么结果就是 你的假设会在训练集上表现地很好 

20
00:01:07,210 --> 00:01:11,630
但这并不能确定 当你的假设推广到训练集之外的新的样本上时 

21
00:01:11,630 --> 00:01:15,970
预测的结果是怎样的

22
00:01:15,970 --> 00:01:18,730
而更为普遍的规律是 只要你的参数非常拟合某个数据组

23
00:01:18,730 --> 00:01:21,290
比如说 非常拟合训练集 当然也可以是其他数据集

24
00:01:21,290 --> 00:01:23,720
那么你的假设对于相同数据组的预测误差 比如说训练误差

25
00:01:23,720 --> 00:01:27,900
是不能够用来推广到一般情况的 或者说 是不能作为实际的泛化误差的

26
00:01:27,900 --> 00:01:29,600
也就是说 不能说明你的假设对于新样本的效果

27
00:01:29,600 --> 00:01:33,380
下面我们来考虑模型选择问题

28
00:01:33,380 --> 00:01:38,330
假如说你现在要选择能最好地拟合你数据的多项式次数

29
00:01:38,330 --> 00:01:41,170
换句话说 你应该选择一次函数 二次函数 还是三次函数呢

30
00:01:41,170 --> 00:01:45,100
等等一直到十次函数

31
00:01:45,100 --> 00:01:48,800
所以似乎应该有这样一个参数

32
00:01:48,800 --> 00:01:50,740
这里我用 d 来表示 d表示的就是你应该选择的多项式次数

33
00:01:51,940 --> 00:01:55,810
所以 似乎除了你要确定的参数θ之外

34
00:01:55,810 --> 00:02:01,210
你还要考虑确定一个参数 你同样需要用你的数据组来确定这个多项式的次数d

35
00:02:01,210 --> 00:02:02,310
第一个选择是 d=1 也就表示线性(一次)方程

36
00:02:02,310 --> 00:02:06,610
我们也可以选择d=2或者3 等等一直到d=10

37
00:02:06,610 --> 00:02:10,680
因此 我们想确定这个多出来的参数d最适当的取值

38
00:02:10,680 --> 00:02:14,940
具体地说 比如你想要选择一个模型 

39
00:02:14,940 --> 00:02:19,760
那就从这10个模型中 选择一个最适当的多项式次数

40
00:02:19,760 --> 00:02:24,830
并且用这个模型进行估计

41
00:02:24,830 --> 00:02:28,880
预测你的假设能否很好地推广到新的样本上

42
00:02:28,880 --> 00:02:33,110
那么你可以这样做

43
00:02:33,110 --> 00:02:37,920
你可以先选择第一个模型 然后求训练误差的最小值

44
00:02:37,920 --> 00:02:42,570
这样你就会得到 一个参数向量θ

45
00:02:42,570 --> 00:02:44,130
然后你再选择第二个模型 二次函数模型

46
00:02:44,130 --> 00:02:49,790
 进行同样的过程 这样你会得到另一个参数向量 θ

47
00:02:49,790 --> 00:02:53,260
为了区别这些不同的 参数向量θ

48
00:02:53,260 --> 00:02:58,600
我想用上标(1) 上标(2)来表示

49
00:02:58,600 --> 00:03:01,290
这里的上标(1)表示的是 在调整第一个模型

50
00:03:01,290 --> 00:03:03,040
使其拟合训练数据时得到的参数θ 同样地 θ上标(2)表示的是

51
00:03:03,040 --> 00:03:06,790
二次函数在和训练数据拟合的过程中得到的参数 以此类推

52
00:03:06,790 --> 00:03:11,550
在拟合三次函数模型时我又得到一个参数θ(3) 等等 直到θ(10) 

53
00:03:11,550 --> 00:03:16,170
接下来我们要做的是 对所有这些模型

54
00:03:16,170 --> 00:03:19,130
求出测试集误差

55
00:03:19,130 --> 00:03:23,940
因此 我可以算出 Jtest(θ(1)) 

56
00:03:23,940 --> 00:03:30,500
Jtest(θ(2)) Jtest(θ(3)) 以此类推

57
00:03:30,500 --> 00:03:36,200
也就是对于每一个模型对应的假设

58
00:03:36,200 --> 00:03:38,800
都计算出其作用于测试集的表现如何

59
00:03:38,800 --> 00:03:46,330
接下来为了确定选择哪一个模型最好 我要做的是

60
00:03:47,410 --> 00:03:51,930
看看这些模型中 哪一个对应的测试集误差最小

61
00:03:53,050 --> 00:03:57,546
那么对于这一个例子

62
00:03:57,546 --> 00:04:00,270
我们假设最终选择了五次多项式模型

63
00:04:00,270 --> 00:04:05,010
目前看来还比较合理

64
00:04:05,010 --> 00:04:09,160
那么现在 我确定了我的模型 我得到了我的假设 也就是这个五次函数模型

65
00:04:09,160 --> 00:04:09,930
现在我想知道 这个模型能不能很好地推广到新样本

66
00:04:09,930 --> 00:04:14,480
我们可以观察这个五次多项式假设模型

67
00:04:14,480 --> 00:04:16,940
 对测试集的拟合情况

68
00:04:16,940 --> 00:04:21,060
但这里有一个问题是

69
00:04:21,060 --> 00:04:26,080
这样做仍然不能公平地说明 我的假设推广到一般时的效果

70
00:04:27,190 --> 00:04:30,560
其原因在于 我们刚才是使用的测试集

71
00:04:30,560 --> 00:04:34,710
跟假设拟合 来得到的

72
00:04:34,710 --> 00:04:39,450
多项式次数d 这个参数

73
00:04:39,450 --> 00:04:42,360
这也就是说 我们选择了一个

74
00:04:42,360 --> 00:04:48,140
能够最好地拟合测试集的 参数d的值

75
00:04:48,140 --> 00:04:50,870
因此 我们的参数向量θ(5) 在拟合测试集时的结果 

76
00:04:50,870 --> 00:04:54,720
很可能导致一个比实际泛化误差更完美的预测结果

77
00:04:54,720 --> 00:05:00,310
对吧？ 因为我是找了一个最能拟合测试集的参数d

78
00:05:00,310 --> 00:05:06,340
因此我再用测试集 来评价我的假设就显得不公平了

79
00:05:06,340 --> 00:05:11,160
因为我已经选了一个能够最拟合测试集的参数

80
00:05:11,160 --> 00:05:15,640
我选择的多项式次数d 本身就是按照最拟合测试集来选择的

81
00:05:15,640 --> 00:05:21,410
因此我的假设 很可能很好地拟合测试集

82
00:05:21,410 --> 00:05:25,900
而且这种拟合的效果很可能会比对那些没见过的新样本拟合得更好

83
00:05:25,900 --> 00:05:29,430
而我们其实是更关心对新样本的拟合效果的

84
00:05:29,430 --> 00:05:33,650
所以 再回过头来说 在前面的幻灯片中 我们看到

85
00:05:33,650 --> 00:05:36,140
如果我们 用训练集来拟合参数 θ0 θ1 等等参数时

86
00:05:36,140 --> 00:05:41,050
那么 拟合后的模型 在作用于训练集上的效果

87
00:05:41,050 --> 00:05:45,210
是不能预测出 我们将这个假设推广到新样本上时效果如何的

88
00:05:45,210 --> 00:05:50,300
这是因为这些参数能够很好地拟合训练集

89
00:05:50,300 --> 00:05:53,500
因此它们很有可能 在对训练集的预测中表现地很好

90
00:05:53,500 --> 00:05:56,770
但对其他的新样本来说 就不一定那么好了

91
00:05:56,770 --> 00:05:59,110
而在刚才这一页幻灯片上 我讲到的步骤 也是在做同样的事

92
00:05:59,110 --> 00:06:03,200
具体来讲 我们做的实际上是用测试集来拟合参数d

93
00:06:03,200 --> 00:06:07,460
通过用测试集来拟合这个参数

94
00:06:07,460 --> 00:06:13,060
同样也意味着 这并不能较为公平地预测出

95
00:06:13,060 --> 00:06:16,770
假设函数的在遇到新样本时的表现

96
00:06:16,770 --> 00:06:22,010
为了解决这一问题 在模型选择中

97
00:06:22,010 --> 00:06:26,670
如果我们想要评价某个假设 我们通常采用以下的方法

98
00:06:26,670 --> 00:06:30,630
给定某个数据集 和刚才将数据分为

99
00:06:30,630 --> 00:06:35,550
训练和测试集不同的是 我们要将其分为三段

100
00:06:35,550 --> 00:06:40,200
第一部分还是叫训练集

101
00:06:40,200 --> 00:06:43,930
所以 我们还是称这部分为训练集

102
00:06:43,930 --> 00:06:49,130
第二部分我把它叫做交叉验证集（cross validation set）

103
00:06:50,130 --> 00:06:53,300
Cross validation

104
00:06:54,780 --> 00:07:00,056
我用CV来简写“交叉验证”

105
00:07:00,056 --> 00:07:04,711
有时候也直接叫验证集

106
00:07:04,711 --> 00:07:08,860
不叫交叉验证集

107
00:07:08,860 --> 00:07:13,520
最后一部分依然和以前一样是测试集

108
00:07:13,520 --> 00:07:18,060
同时 一种典型的分割比例是 将60%的数据

109
00:07:18,060 --> 00:07:21,930
分给训练集 大约20%的数据给交叉验证集

110
00:07:21,930 --> 00:07:24,990
最后20%给测试集

111
00:07:24,990 --> 00:07:29,290
这个比例可以稍微调整

112
00:07:29,290 --> 00:07:33,600
但这种分法是最典型的

113
00:07:33,600 --> 00:07:38,922
所以现在我们的训练集就只占总数据的60%了

114
00:07:38,922 --> 00:07:44,860
然后交叉验证集

115
00:07:44,860 --> 00:07:47,290
或者说验证集 将拥有一部分样本 我把它的数量用m下标CV来表示

116
00:07:47,290 --> 00:07:50,860
这是交叉验证集样本的数量

117
00:07:52,040 --> 00:07:59,110
按照之前我们的符号表示习惯 我将用(x(i)CV, y(i)CV)

118
00:07:59,110 --> 00:08:02,720
来表示第i个交叉验证样本

119
00:08:02,720 --> 00:08:07,290
最后 我们还是有这样一些测试集样本

120
00:08:07,290 --> 00:08:11,420
用m下标test来表示测试样本的总数

121
00:08:11,420 --> 00:08:14,570
好的 现在我们就定义了训练集、交叉验证集

122
00:08:14,570 --> 00:08:16,740
以及测试集 我们随之也可以定义训练误差 交叉验证误差

123
00:08:16,740 --> 00:08:21,420
和测试误差

124
00:08:21,420 --> 00:08:23,790
因此这便是我定义的训练误差 我用J下标train来表示

125
00:08:23,790 --> 00:08:26,820
这跟我们之前定义的

126
00:08:26,820 --> 00:08:29,030
J(θ)没有任何区别

127
00:08:29,030 --> 00:08:32,260
也就是对训练集数据进行预测得到的误差

128
00:08:32,260 --> 00:08:37,110
然后J下标CV定义为交叉验证集误差

129
00:08:37,110 --> 00:08:41,470
这也不难想象

130
00:08:41,470 --> 00:08:45,970
跟训练误差类似的定义

131
00:08:45,970 --> 00:08:48,450
只不过是在交叉验证集上预测得到的误差

132
00:08:49,530 --> 00:08:53,410
然后这是测试集 跟前面一样

133
00:08:53,410 --> 00:08:58,709
好的 那么我们的模型选择问题是这样的

134
00:08:58,709 --> 00:09:04,580
和之前使用测试集来选择模型不同

135
00:09:04,580 --> 00:09:10,570
我们现在要使用验证集 或者说交叉验证集来选择模型

136
00:09:10,570 --> 00:09:13,580
具体来讲 首先我们用第一个假设函数 也就是第一个模型

137
00:09:13,580 --> 00:09:17,520
然后求代价函数的最小值

138
00:09:17,520 --> 00:09:20,300
然后我们会得到这个线性模型对应的参数向量θ

139
00:09:20,300 --> 00:09:23,560
和之前一样 我们还是用上表(1)来表示

140
00:09:23,560 --> 00:09:25,660
这个参数是对应于线性模型的

141
00:09:25,660 --> 00:09:27,927
对二次函数 我们也做同样的事情 这样可以得到θ(2)

142
00:09:27,927 --> 00:09:31,601
然后是θ(3)

143
00:09:31,601 --> 00:09:35,470
等等以此类推 一直到10次多项式

144
00:09:35,470 --> 00:09:40,440
然后我要做的是 跟之前用测试集来预测这些假设不同

145
00:09:40,440 --> 00:09:43,130
我要在交叉验证集中测试这些假设的表现

146
00:09:43,130 --> 00:09:46,600
我要测出Jcv来看看

147
00:09:46,600 --> 00:09:52,180
这些假设在交叉验证集中表现如何

148
00:09:53,250 --> 00:09:57,180
然后我要选择的是交叉验证集误差最小的那个假设

149
00:09:57,180 --> 00:10:00,180
因此 对于这个例子 假如是

150
00:10:00,180 --> 00:10:06,550
四次函数的模型有最小的交叉验证误差

151
00:10:06,550 --> 00:10:11,070
因此 我们就选择这个四次多项式模型

152
00:10:11,070 --> 00:10:15,250
最后 这样做的意义是 参数d

153
00:10:15,250 --> 00:10:17,200
别忘了参数d 是多项式的次数

154
00:10:17,200 --> 00:10:20,270
d=2 d=3 一直到d=10

155
00:10:20,270 --> 00:10:25,040
我们刚才做的是拟合出最好的系数d等于4

156
00:10:25,040 --> 00:10:27,290
并且我们是通过交叉验证集来完成的

157
00:10:27,290 --> 00:10:32,320
因此 这样一来这个参数d

158
00:10:32,320 --> 00:10:39,260
这个多项式的次数 就没有跟测试集进行拟合

159
00:10:39,260 --> 00:10:44,325
这样我们就回避了测试集的嫌疑

160
00:10:44,325 --> 00:10:47,680
我们可以光明正大地使用测试集

161
00:10:47,680 --> 00:10:51,140
来估计所选模型的泛化误差了

162
00:10:51,140 --> 00:10:54,310
好的 这就是模型选择了 以及你应该怎样

163
00:10:54,310 --> 00:10:57,310
将数据分成训练集、验证集和测试集

164
00:10:57,310 --> 00:10:58,570
以及使用你的交叉验证集数据来选择模型

165
00:10:59,630 --> 00:11:02,860
最后用测试集来评价模型的表现

166
00:11:02,860 --> 00:11:06,210
最后我还想提醒的一点是

167
00:11:06,210 --> 00:11:10,470
在如今的机器学习应用中

168
00:11:10,470 --> 00:11:15,360
确实也有很多人是像我之前介绍的那样做的

169
00:11:15,360 --> 00:11:19,590
我说过这并不是一个好的方法

170
00:11:19,590 --> 00:11:24,120
也就是用测试集来选择模型

171
00:11:24,120 --> 00:11:27,840
然后用同样的测试集来

172
00:11:27,840 --> 00:11:31,160
评价模型的表现 报告测试误差

173
00:11:31,160 --> 00:11:35,550
看起来好像还能得到比较不错的泛化误差

174
00:11:35,550 --> 00:11:38,090
这的确是一种做法 但不幸的是 现在还有很多人这样做

175
00:11:38,090 --> 00:11:42,360
如果你有很多很多测试集的话 这也许还能行得通

176
00:11:42,360 --> 00:11:45,760
但大多数的机器学习开发人员

177
00:11:45,760 --> 00:11:46,728
还是不会选择这样做

178
00:11:46,728 --> 00:11:50,620
因为最佳做法还是把数据分成训练集、验证集、测试集

179
00:11:50,620 --> 00:11:54,320
但我还是告诉你 在现实中确实有很大一部分人

180
00:11:54,320 --> 00:11:57,430
有时会使用同样一组数据 既作为验证集 也作为测试集

181
00:11:57,430 --> 00:12:00,020
也就是只有训练集和测试集

182
00:12:00,020 --> 00:12:03,090
你的确可能会看到很多人选择这种方法 但如果可能的话