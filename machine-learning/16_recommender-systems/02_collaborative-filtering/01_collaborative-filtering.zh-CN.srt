1
00:00:01,060 --> 00:00:02,420
在这段视频中 我们要讲

2
00:00:02,620 --> 00:00:03,900
一种构建推荐系统的方法

3
00:00:03,970 --> 00:00:06,390
叫做协同过滤(collaborative filtering)

4
00:00:07,540 --> 00:00:08,880
我们所讲的算法

5
00:00:09,180 --> 00:00:10,400
有一个值得一提的

6
00:00:10,680 --> 00:00:11,830
特点 那就是它能实现

7
00:00:12,120 --> 00:00:13,290
对特征的学习

8
00:00:13,790 --> 00:00:14,800
我的意思是

9
00:00:14,960 --> 00:00:16,270
这种算法能够

10
00:00:16,450 --> 00:00:19,010
自行学习所要使用的特征

11
00:00:21,130 --> 00:00:22,100
我们建一个数据集

12
00:00:22,220 --> 00:00:23,440
假定是为每一部电影准备的

13
00:00:23,720 --> 00:00:25,030
对每一部电影

14
00:00:25,690 --> 00:00:27,000
我们找一些人来

15
00:00:27,320 --> 00:00:28,640
告诉我们这部电影

16
00:00:28,840 --> 00:00:30,550
浪漫指数是多少 动作指数是多少

17
00:00:31,680 --> 00:00:32,880
但想一下就知道

18
00:00:33,020 --> 00:00:34,320
这样做难度很大

19
00:00:34,500 --> 00:00:36,390
也很花费时间

20
00:00:36,490 --> 00:00:37,860
你想想 要让每个人

21
00:00:38,050 --> 00:00:39,440
看完每一部电影

22
00:00:39,700 --> 00:00:40,880
告诉你你每一部电影有多浪漫 多动作

23
00:00:41,410 --> 00:00:42,570
这是一件不容易的事情

24
00:00:42,660 --> 00:00:44,270
而且通常

25
00:00:44,390 --> 00:00:46,760
你还会希望得到除这两个特征之外的其他指数

26
00:00:46,980 --> 00:00:48,130
那么你怎样才能得到这些特征呢？

27
00:00:49,890 --> 00:00:50,920
所以 让我们转移一下问题

28
00:00:51,500 --> 00:00:53,220
假如我们

29
00:00:53,980 --> 00:00:55,160
有某一个数据集

30
00:00:55,410 --> 00:00:57,980
我们并不知道特征的值是多少

31
00:00:58,380 --> 00:00:59,280
所以比如我们得到一些

32
00:00:59,640 --> 00:01:01,140
关于电影的数据

33
00:01:01,270 --> 00:01:03,550
不同用户对电影的评分

34
00:01:03,760 --> 00:01:05,190
我们并不知道每部电影

35
00:01:05,370 --> 00:01:06,140
到底有多少浪漫的成分

36
00:01:06,310 --> 00:01:07,660
也不知道到底每部电影里面动作成分是多少

37
00:01:07,820 --> 00:01:09,940
于是我把所有的问题都打上问号

38
00:01:11,310 --> 00:01:12,330
现在我们稍稍改变一下这个假设

39
00:01:13,870 --> 00:01:15,570
假设我们采访了每一位用户 而且每一位用户都告诉我们

40
00:01:15,980 --> 00:01:18,510
他们是否喜欢

41
00:01:18,820 --> 00:01:20,040
爱情电影 以及

42
00:01:20,220 --> 00:01:22,320
他们是否喜欢动作电影

43
00:01:22,830 --> 00:01:26,090
这样 Alice 就有了对应的参数 θ(1)

44
00:01:26,820 --> 00:01:27,470
Bob 的是 θ(2)

45
00:01:27,910 --> 00:01:28,440
Carol 的是 θ(3)

46
00:01:28,970 --> 00:01:30,330
Dave 的是 θ(4)

47
00:01:30,500 --> 00:01:31,530
我们还有这样的假设

48
00:01:31,780 --> 00:01:33,040
假如 Alice 告诉我们

49
00:01:33,380 --> 00:01:35,340
她十分喜欢

50
00:01:35,610 --> 00:01:36,960
爱情电影

51
00:01:37,140 --> 00:01:38,780
于是 Alice 的特征 x1

52
00:01:39,280 --> 00:01:41,210
对应的值就是5

53
00:01:41,570 --> 00:01:42,680
假设 Alice 告诉我们

54
00:01:42,840 --> 00:01:45,030
她非常不喜欢动作电影 于是这一个特征就是0

55
00:01:46,060 --> 00:01:47,190
Bob 也有相似的喜好

56
00:01:48,660 --> 00:01:49,770
所以也就有了 θ(2) 的数据

57
00:01:50,630 --> 00:01:52,460
但 Carol 说

58
00:01:53,570 --> 00:01:54,720
她非常喜欢动作电影

59
00:01:55,240 --> 00:01:56,450
于是这个特征就被记录为5

60
00:01:56,900 --> 00:01:58,600
也就是 x2 的值

61
00:01:58,980 --> 00:02:00,160
别忘了

62
00:02:01,210 --> 00:02:03,490
我们仍然有等于1的 x0

63
00:02:03,770 --> 00:02:05,390
假设 Carol 告诉我们

64
00:02:05,610 --> 00:02:07,000
她不喜欢爱情电影之类的

65
00:02:07,390 --> 00:02:09,640
而且戴夫也是这样

66
00:02:09,840 --> 00:02:11,030
于是 我们假定 某种程度上

67
00:02:11,440 --> 00:02:12,830
我们就可以着眼于用户

68
00:02:13,290 --> 00:02:14,600
看看任意的用户 j

69
00:02:15,020 --> 00:02:16,160
对应的 θ(j) 是怎样的

70
00:02:17,090 --> 00:02:18,870
这样就明确地告诉了我们

71
00:02:19,450 --> 00:02:22,190
他们对不同题材电影的喜欢程度

72
00:02:24,060 --> 00:02:25,280
如果我们能够从用户那里

73
00:02:25,990 --> 00:02:27,890
得到这些 θ 参考值

74
00:02:28,050 --> 00:02:29,820
那么我们理论上就能

75
00:02:29,960 --> 00:02:31,210
推测出每部电影的

76
00:02:31,310 --> 00:02:33,710
 x1 以及 x2 的值

77
00:02:34,800 --> 00:02:35,140
我们来看个例子

78
00:02:35,730 --> 00:02:36,560
假如我们看电影1

79
00:02:38,690 --> 00:02:39,790
于是电影1就对应于

80
00:02:40,580 --> 00:02:42,050
表示特征的向量 x1 联系在一起了

81
00:02:42,890 --> 00:02:45,420
这部电影的名字叫《爱到最后》 但这不重要

82
00:02:45,770 --> 00:02:46,750
假设我们不知道

83
00:02:46,870 --> 00:02:49,060
这部电影的主要内容 所以也不要在意电影的名字

84
00:02:50,180 --> 00:02:52,270
我们知道的就是 Alice 喜欢这部电影

85
00:02:52,450 --> 00:02:53,110
Bob 喜欢这部电影

86
00:02:53,750 --> 00:02:55,370
Carol 和 Dave 不喜欢它

87
00:02:56,450 --> 00:02:57,450
那么我们能推断出什么呢？

88
00:02:57,830 --> 00:02:58,900
好的 我们从

89
00:02:58,990 --> 00:03:00,510
特征向量知道了

90
00:03:00,780 --> 00:03:03,190
Alice 和 Bob 喜欢爱情电影

91
00:03:03,700 --> 00:03:05,660
因为他们都在这里评了5分

92
00:03:06,290 --> 00:03:07,480
然而 Carol 和 Dave

93
00:03:08,380 --> 00:03:10,150
我们知道他们不喜欢

94
00:03:10,510 --> 00:03:11,920
爱情电影

95
00:03:12,300 --> 00:03:13,990
但喜欢动作电影

96
00:03:14,730 --> 00:03:16,050
由于你知道这些

97
00:03:16,340 --> 00:03:18,830
是可以从 第3和第4个参数看出来的

98
00:03:20,110 --> 00:03:20,950
同时 由于我们知道

99
00:03:21,390 --> 00:03:22,340
Alice 和 Bob

100
00:03:22,880 --> 00:03:24,120
喜欢电影1

101
00:03:24,340 --> 00:03:26,460
而 Carol 和 Dave 不喜欢它

102
00:03:26,910 --> 00:03:30,810
我们可以推断 这可能是一部爱情片

103
00:03:31,180 --> 00:03:34,240
而不太可能是动作片

104
00:03:35,290 --> 00:03:36,360
这个例子在数学上

105
00:03:36,520 --> 00:03:38,090
可能某种程度上简化了

106
00:03:38,260 --> 00:03:40,330
但我们真正需要的是

107
00:03:40,590 --> 00:03:42,010
特征向量 x(1) 应该是什么

108
00:03:42,840 --> 00:03:45,370
才能让 θ(1) 的转置

109
00:03:46,030 --> 00:03:48,940
乘以x(1) 约等于5

110
00:03:49,660 --> 00:03:51,700
也就是 Alice 的评分值

111
00:03:51,920 --> 00:03:55,360
然后 θ(2) 的转置乘以 x(1)

112
00:03:55,510 --> 00:03:56,660
也近似于5

113
00:03:57,670 --> 00:03:59,100
而 θ(3) 的转置 乘以 x(1)

114
00:03:59,310 --> 00:04:02,180
约等于0

115
00:04:03,020 --> 00:04:05,250
这是 Carol 的评分

116
00:04:06,970 --> 00:04:09,780
而 θ(4) 的转置乘以 x(1)

117
00:04:10,740 --> 00:04:11,630
也约等于0

118
00:04:12,590 --> 00:04:13,520
由此可知

119
00:04:13,770 --> 00:04:16,000
x(1) 应该用

120
00:04:16,870 --> 00:04:18,770
[1 1.0 0.0] 这个向量表示

121
00:04:19,080 --> 00:04:20,960
第一个1 是截距项

122
00:04:21,310 --> 00:04:22,390
这样才能得出

123
00:04:22,790 --> 00:04:24,110
Alice Bob Carol 和 Dave 四个人

124
00:04:24,770 --> 00:04:25,940
对电影评分的结果

125
00:04:27,700 --> 00:04:29,080
由此及之 我们可以

126
00:04:29,220 --> 00:04:30,210
继续列举 试着

127
00:04:30,430 --> 00:04:31,520
弄明白

128
00:04:31,700 --> 00:04:35,260
其他电影的合理特征

129
00:04:39,160 --> 00:04:41,890
让我们将这一学习问题标准化到任意特征 x(i)

130
00:04:42,410 --> 00:04:44,220
假设我们的用户

131
00:04:44,340 --> 00:04:45,860
告诉了我们的偏好

132
00:04:46,580 --> 00:04:47,950
就是说用户们

133
00:04:48,130 --> 00:04:49,100
已经给我们提供了

134
00:04:49,330 --> 00:04:50,800
θ(1) 到 θ(nu) 的值

135
00:04:50,890 --> 00:04:52,990
θ(1) 到 θ(nu) 的值

136
00:04:53,280 --> 00:04:54,430
而我们想知道

137
00:04:54,790 --> 00:04:56,130
电影 i 的

138
00:04:56,540 --> 00:04:58,020
特征向量 x(i) 我们能做的

139
00:04:58,200 --> 00:05:00,830
是列出以下的最优化的问题

140
00:05:01,220 --> 00:05:02,210
所以 我们想要把

141
00:05:02,840 --> 00:05:04,600
所有指数 j 相加

142
00:05:04,930 --> 00:05:06,280
得到对电影 i 的评分

143
00:05:06,950 --> 00:05:08,340
因为我们

144
00:05:08,750 --> 00:05:10,040
想要求得电影 i 的特征

145
00:05:10,950 --> 00:05:13,560
也就是向量 x(i)

146
00:05:14,650 --> 00:05:15,660
所以现在我们

147
00:05:15,780 --> 00:05:18,450
要做的是最小化这个平方误差

148
00:05:19,020 --> 00:05:20,160
我们要选择

149
00:05:20,420 --> 00:05:22,430
特征 x(i)

150
00:05:22,900 --> 00:05:25,000
使得 我们预测的用户 j

151
00:05:25,200 --> 00:05:26,820
对该电影 i 评分的预测值评分值

152
00:05:27,110 --> 00:05:28,170
跟我们从用户 j 处

153
00:05:28,900 --> 00:05:30,130
实际得到的评分值

154
00:05:30,440 --> 00:05:31,910
不会相差太远

155
00:05:32,530 --> 00:05:35,330
也就是这个差值

156
00:05:35,530 --> 00:05:37,130
不要太大

157
00:05:38,310 --> 00:05:40,790
所以 总结一下

158
00:05:41,040 --> 00:05:42,320
这一阶段要做的

159
00:05:42,840 --> 00:05:44,060
就是为所有

160
00:05:45,040 --> 00:05:46,590
为电影评分的

161
00:05:46,960 --> 00:05:48,210
用户 j

162
00:05:48,360 --> 00:05:50,190
选择特征 x(i)

163
00:05:50,860 --> 00:05:52,830
这一算法同样也预测出一个值

164
00:05:52,900 --> 00:05:55,490
表示该用户将会如何评价某部电影

165
00:05:56,170 --> 00:05:57,720
而这个预测值

166
00:05:57,810 --> 00:05:59,730
在平方误差的形式中

167
00:06:00,000 --> 00:06:02,310
与用户对该电影评分的实际值尽量接近

168
00:06:03,380 --> 00:06:04,560
这就是那个平方误差项了

169
00:06:05,420 --> 00:06:07,200
和之前一样

170
00:06:07,310 --> 00:06:08,430
我们可以加上一个正则化项

171
00:06:08,520 --> 00:06:09,850
来防止特征的数值

172
00:06:10,300 --> 00:06:11,870
变得过大

173
00:06:13,720 --> 00:06:15,610
这就是我们

174
00:06:15,760 --> 00:06:16,910
如何从一部特定的电影中

175
00:06:17,420 --> 00:06:19,140
学习到特征的方法

176
00:06:19,690 --> 00:06:20,480
但我们要做的是

177
00:06:20,740 --> 00:06:22,060
学习出所有电影的

178
00:06:22,230 --> 00:06:23,820
所有特征

179
00:06:24,080 --> 00:06:25,050
所以我现在要做的是

180
00:06:25,240 --> 00:06:26,620
在此加上另外的一个求和

181
00:06:26,780 --> 00:06:28,840
我要对所有的电影 nm 求和

182
00:06:29,260 --> 00:06:33,140
n 下标 m 个电影

183
00:06:33,830 --> 00:06:34,670
然后最小化整个这个目标函数

184
00:06:35,010 --> 00:06:37,080
针对所有的电影

185
00:06:37,410 --> 00:06:39,930
这样你就会得到如下的最优化的问题

186
00:06:40,950 --> 00:06:42,320
如果你将这个最小化

187
00:06:42,890 --> 00:06:44,520
就应该能得到所有电影的

188
00:06:44,680 --> 00:06:47,440
一系列合理的特征

189
00:06:48,650 --> 00:06:50,080
好的 把我们

190
00:06:50,210 --> 00:06:51,050
前一个视频讨论的算法

191
00:06:51,330 --> 00:06:52,730
以及我们刚刚

192
00:06:53,180 --> 00:06:54,810
在这个视频中讲过的算法合在一起

193
00:06:55,730 --> 00:06:57,070
上一个视频中

194
00:06:57,180 --> 00:06:58,710
我们讲的是

195
00:06:58,820 --> 00:06:59,700
如果你有一系列

196
00:06:59,790 --> 00:07:00,640
对电影的评分 那么如果你

197
00:07:00,640 --> 00:07:03,960
有r(i,j) 和 y(i,j)

198
00:07:04,090 --> 00:07:06,100
也就是对电影的评分

199
00:07:08,500 --> 00:07:09,650
于是 根据不同电影的特征

200
00:07:09,800 --> 00:07:11,800
我们可以得到参数 θ

201
00:07:12,340 --> 00:07:13,110
这样 如果你知道了特征

202
00:07:13,830 --> 00:07:15,000
你就能学习出不同用户的

203
00:07:15,650 --> 00:07:16,850
参数 θ 值

204
00:07:18,250 --> 00:07:19,770
我们之前

205
00:07:19,930 --> 00:07:21,400
这个视频中讲的是

206
00:07:21,790 --> 00:07:22,860
如果用户愿意

207
00:07:23,000 --> 00:07:25,450
为你提供参数 那么你就

208
00:07:25,560 --> 00:07:28,060
可以为不同的电影估计特征

209
00:07:29,270 --> 00:07:31,490
这有点像鸡和蛋的问题

210
00:07:31,770 --> 00:07:32,290
到底先有鸡还是先有蛋？

211
00:07:32,900 --> 00:07:35,570
就是说 如果我们能知道 θ 就能学习到 x

212
00:07:36,060 --> 00:07:38,160
如果我们知道 x 也会学出 θ 来

213
00:07:39,500 --> 00:07:40,500
而这样一来 你能做的

214
00:07:40,680 --> 00:07:41,790
就是

215
00:07:41,910 --> 00:07:43,000
如果这真的可行的话

216
00:07:43,110 --> 00:07:44,530
实际上你能做的就是

217
00:07:45,170 --> 00:07:47,160
随机猜de θ 的值

218
00:07:48,210 --> 00:07:49,200
基于你一开始随机

219
00:07:49,530 --> 00:07:50,630
猜测出的 θ 的值

220
00:07:50,940 --> 00:07:52,530
继你可以继续下去

221
00:07:53,160 --> 00:07:54,210
运用我们刚刚讲到的

222
00:07:54,460 --> 00:07:55,810
步骤 我们可以学习出

223
00:07:56,060 --> 00:07:57,740
不同电影的特征

224
00:07:58,800 --> 00:07:59,990
给出已有的一些电影的

225
00:08:00,130 --> 00:08:01,160
原始特征

226
00:08:01,240 --> 00:08:02,730
你可以运用

227
00:08:03,050 --> 00:08:04,060
我们在上一个视频中讨论过的

228
00:08:04,130 --> 00:08:06,180
第一种方法 可以得到

229
00:08:06,360 --> 00:08:08,590
对参数 θ 的更好估计

230
00:08:09,560 --> 00:08:12,420
这样就会为用户提供更好的参数 θ 集

231
00:08:12,860 --> 00:08:13,850
我们就可以用这些

232
00:08:14,070 --> 00:08:15,140
得到更好的

233
00:08:15,240 --> 00:08:17,110
特征集或者其他数据

234
00:08:17,380 --> 00:08:18,400
然后我们可以继续

235
00:08:18,600 --> 00:08:19,440
迭代 不停重复

236
00:08:19,790 --> 00:08:21,270
优化θ x θ

237
00:08:21,560 --> 00:08:24,000
x θ 这非常有效

238
00:08:24,270 --> 00:08:25,290
如果你

239
00:08:25,410 --> 00:08:26,340
这样做的话

240
00:08:26,800 --> 00:08:28,360
你的算法将会收敛到

241
00:08:28,930 --> 00:08:30,430
一组合理的电影的特征

242
00:08:31,340 --> 00:08:32,650
以及一组对合理的

243
00:08:32,790 --> 00:08:34,880
对不同用户参数的估计

244
00:08:36,080 --> 00:08:38,870
这就是基本的协同过滤算法

245
00:08:39,770 --> 00:08:40,850
这实际并不是最后

246
00:08:41,020 --> 00:08:42,890
我们将要使用的算法

247
00:08:43,120 --> 00:08:44,100
下一个视频中

248
00:08:44,790 --> 00:08:45,610
我们将改进这个算法

249
00:08:45,920 --> 00:08:47,430
让其在计算时更为高效

250
00:08:48,390 --> 00:08:49,510
但是这节课希望能让你

251
00:08:49,640 --> 00:08:50,600
基本了解如何

252
00:08:50,680 --> 00:08:51,980
构建一个问题

253
00:08:52,040 --> 00:08:52,990
在这个问题中

254
00:08:53,930 --> 00:08:57,200
从不同的电影处学到参数以及特征

255
00:08:58,440 --> 00:08:59,660
对于这个问题

256
00:08:59,740 --> 00:09:01,100
对于推荐系统

257
00:09:01,390 --> 00:09:02,950
可能就根据每个用户

258
00:09:03,490 --> 00:09:04,840
对多部电影的评分

259
00:09:05,100 --> 00:09:06,410
以及每部电影由

260
00:09:06,790 --> 00:09:08,710
由不同用户的评分

261
00:09:09,280 --> 00:09:10,150
这样你就可以反复进行这样的过程

262
00:09:10,270 --> 00:09:11,150
来估计出 θ 和 x

263
00:09:11,200 --> 00:09:14,400
总结一下

264
00:09:14,830 --> 00:09:15,910
在这个视频中

265
00:09:16,140 --> 00:09:18,710
我们了解了最基本的协同过滤算法

266
00:09:19,680 --> 00:09:21,550
协同过滤算法指的是

267
00:09:22,020 --> 00:09:23,620
当你执行这个算法时

268
00:09:23,760 --> 00:09:25,020
你通过一大堆用户

269
00:09:25,210 --> 00:09:26,790
得到的数据

270
00:09:26,960 --> 00:09:28,410
这些用户实际上在高效地

271
00:09:29,070 --> 00:09:31,300
进行了协同合作

272
00:09:31,490 --> 00:09:32,770
来得到每个人

273
00:09:33,010 --> 00:09:34,610
对电影的评分值

274
00:09:34,840 --> 00:09:36,540
只要用户对某几部电影进行评分

275
00:09:37,350 --> 00:09:39,040
每个用户就都在帮助算法

276
00:09:39,300 --> 00:09:41,490
更好的学习出特征

277
00:09:42,900 --> 00:09:44,390
这样 通过自己

278
00:09:44,490 --> 00:09:46,690
对几部电影评分之后

279
00:09:47,810 --> 00:09:49,550
我就能帮助系统更好的学习到特征

280
00:09:49,680 --> 00:09:50,750
这些特征可以

281
00:09:50,930 --> 00:09:52,610
被系统运用 为其他人

282
00:09:52,890 --> 00:09:54,380
做出更准确的电影预测

283
00:09:54,640 --> 00:09:55,450
协同的另一层意思

284
00:09:55,530 --> 00:09:56,980
是说每位用户

285
00:09:57,370 --> 00:09:58,980
都在为了大家的利益

286
00:09:59,360 --> 00:10:00,740
学习出更好的特征

287
00:10:00,810 --> 00:10:03,450
这就是协同过滤

288
00:10:04,070 --> 00:10:04,990
在下一个视频中

289
00:10:05,140 --> 00:10:07,490
我们要把这些想法

290
00:10:07,740 --> 00:10:08,850
付诸实施

291
00:10:09,090 --> 00:10:09,910
尝试开发一种

292
00:10:10,170 --> 00:10:11,920
更完美的算法

293
00:10:12,180 --> 00:10:13,640
为协同过滤算法做出一点改进 【教育无边界字幕组】翻译人员不详 校对/审核: 所罗门捷列夫