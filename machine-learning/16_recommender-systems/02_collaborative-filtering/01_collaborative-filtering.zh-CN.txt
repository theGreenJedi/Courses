在这段视频中 我们要讲 一种构建推荐系统的方法 叫做协同过滤(collaborative filtering) 我们所讲的算法 有一个值得一提的 特点 那就是它能实现 对特征的学习 我的意思是 这种算法能够 自行学习所要使用的特征 我们建一个数据集 假定是为每一部电影准备的 对每一部电影 我们找一些人来 告诉我们这部电影 浪漫指数是多少 动作指数是多少 但想一下就知道 这样做难度很大 也很花费时间 你想想 要让每个人 看完每一部电影 告诉你你每一部电影有多浪漫 多动作 这是一件不容易的事情 而且通常 你还会希望得到除这两个特征之外的其他指数 那么你怎样才能得到这些特征呢？ 所以 让我们转移一下问题 假如我们 有某一个数据集 我们并不知道特征的值是多少 所以比如我们得到一些 关于电影的数据 不同用户对电影的评分 我们并不知道每部电影 到底有多少浪漫的成分 也不知道到底每部电影里面动作成分是多少 于是我把所有的问题都打上问号 现在我们稍稍改变一下这个假设 假设我们采访了每一位用户 而且每一位用户都告诉我们 他们是否喜欢 爱情电影 以及 他们是否喜欢动作电影 这样 Alice 就有了对应的参数 θ(1) Bob 的是 θ(2) Carol 的是 θ(3) Dave 的是 θ(4) 我们还有这样的假设 假如 Alice 告诉我们 她十分喜欢 爱情电影 于是 Alice 的特征 x1 对应的值就是5 假设 Alice 告诉我们 她非常不喜欢动作电影 于是这一个特征就是0 Bob 也有相似的喜好 所以也就有了 θ(2) 的数据 但 Carol 说 她非常喜欢动作电影 于是这个特征就被记录为5 也就是 x2 的值 别忘了 我们仍然有等于1的 x0 假设 Carol 告诉我们 她不喜欢爱情电影之类的 而且戴夫也是这样 于是 我们假定 某种程度上 我们就可以着眼于用户 看看任意的用户 j 对应的 θ(j) 是怎样的 这样就明确地告诉了我们 他们对不同题材电影的喜欢程度 如果我们能够从用户那里 得到这些 θ 参考值 那么我们理论上就能 推测出每部电影的 x1 以及 x2 的值 我们来看个例子 假如我们看电影1 于是电影1就对应于 表示特征的向量 x1 联系在一起了 这部电影的名字叫《爱到最后》 但这不重要 假设我们不知道 这部电影的主要内容 所以也不要在意电影的名字 我们知道的就是 Alice 喜欢这部电影 Bob 喜欢这部电影 Carol 和 Dave 不喜欢它 那么我们能推断出什么呢？ 好的 我们从 特征向量知道了 Alice 和 Bob 喜欢爱情电影 因为他们都在这里评了5分 然而 Carol 和 Dave 我们知道他们不喜欢 爱情电影 但喜欢动作电影 由于你知道这些 是可以从 第3和第4个参数看出来的 同时 由于我们知道 Alice 和 Bob 喜欢电影1 而 Carol 和 Dave 不喜欢它 我们可以推断 这可能是一部爱情片 而不太可能是动作片 这个例子在数学上 可能某种程度上简化了 但我们真正需要的是 特征向量 x(1) 应该是什么 才能让 θ(1) 的转置 乘以x(1) 约等于5 也就是 Alice 的评分值 然后 θ(2) 的转置乘以 x(1) 也近似于5 而 θ(3) 的转置 乘以 x(1) 约等于0 这是 Carol 的评分 而 θ(4) 的转置乘以 x(1) 也约等于0 由此可知 x(1) 应该用 [1 1.0 0.0] 这个向量表示 第一个1 是截距项 这样才能得出 Alice Bob Carol 和 Dave 四个人 对电影评分的结果 由此及之 我们可以 继续列举 试着 弄明白 其他电影的合理特征 让我们将这一学习问题标准化到任意特征 x(i) 假设我们的用户 告诉了我们的偏好 就是说用户们 已经给我们提供了 θ(1) 到 θ(nu) 的值 θ(1) 到 θ(nu) 的值 而我们想知道 电影 i 的 特征向量 x(i) 我们能做的 是列出以下的最优化的问题 所以 我们想要把 所有指数 j 相加 得到对电影 i 的评分 因为我们 想要求得电影 i 的特征 也就是向量 x(i) 所以现在我们 要做的是最小化这个平方误差 我们要选择 特征 x(i) 使得 我们预测的用户 j 对该电影 i 评分的预测值评分值 跟我们从用户 j 处 实际得到的评分值 不会相差太远 也就是这个差值 不要太大 所以 总结一下 这一阶段要做的 就是为所有 为电影评分的 用户 j 选择特征 x(i) 这一算法同样也预测出一个值 表示该用户将会如何评价某部电影 而这个预测值 在平方误差的形式中 与用户对该电影评分的实际值尽量接近 这就是那个平方误差项了 和之前一样 我们可以加上一个正则化项 来防止特征的数值 变得过大 这就是我们 如何从一部特定的电影中 学习到特征的方法 但我们要做的是 学习出所有电影的 所有特征 所以我现在要做的是 在此加上另外的一个求和 我要对所有的电影 nm 求和 n 下标 m 个电影 然后最小化整个这个目标函数 针对所有的电影 这样你就会得到如下的最优化的问题 如果你将这个最小化 就应该能得到所有电影的 一系列合理的特征 好的 把我们 前一个视频讨论的算法 以及我们刚刚 在这个视频中讲过的算法合在一起 上一个视频中 我们讲的是 如果你有一系列 对电影的评分 那么如果你 有r(i,j) 和 y(i,j) 也就是对电影的评分 于是 根据不同电影的特征 我们可以得到参数 θ 这样 如果你知道了特征 你就能学习出不同用户的 参数 θ 值 我们之前 这个视频中讲的是 如果用户愿意 为你提供参数 那么你就 可以为不同的电影估计特征 这有点像鸡和蛋的问题 到底先有鸡还是先有蛋？ 就是说 如果我们能知道 θ 就能学习到 x 如果我们知道 x 也会学出 θ 来 而这样一来 你能做的 就是 如果这真的可行的话 实际上你能做的就是 随机猜de θ 的值 基于你一开始随机 猜测出的 θ 的值 继你可以继续下去 运用我们刚刚讲到的 步骤 我们可以学习出 不同电影的特征 给出已有的一些电影的 原始特征 你可以运用 我们在上一个视频中讨论过的 第一种方法 可以得到 对参数 θ 的更好估计 这样就会为用户提供更好的参数 θ 集 我们就可以用这些 得到更好的 特征集或者其他数据 然后我们可以继续 迭代 不停重复 优化θ x θ x θ 这非常有效 如果你 这样做的话 你的算法将会收敛到 一组合理的电影的特征 以及一组对合理的 对不同用户参数的估计 这就是基本的协同过滤算法 这实际并不是最后 我们将要使用的算法 下一个视频中 我们将改进这个算法 让其在计算时更为高效 但是这节课希望能让你 基本了解如何 构建一个问题 在这个问题中 从不同的电影处学到参数以及特征 对于这个问题 对于推荐系统 可能就根据每个用户 对多部电影的评分 以及每部电影由 由不同用户的评分 这样你就可以反复进行这样的过程 来估计出 θ 和 x 总结一下 在这个视频中 我们了解了最基本的协同过滤算法 协同过滤算法指的是 当你执行这个算法时 你通过一大堆用户 得到的数据 这些用户实际上在高效地 进行了协同合作 来得到每个人 对电影的评分值 只要用户对某几部电影进行评分 每个用户就都在帮助算法 更好的学习出特征 这样 通过自己 对几部电影评分之后 我就能帮助系统更好的学习到特征 这些特征可以 被系统运用 为其他人 做出更准确的电影预测 协同的另一层意思 是说每位用户 都在为了大家的利益 学习出更好的特征 这就是协同过滤 在下一个视频中 我们要把这些想法 付诸实施 尝试开发一种 更完美的算法 为协同过滤算法做出一点改进 【教育无边界字幕组】翻译人员不详 校对/审核: 所罗门捷列夫