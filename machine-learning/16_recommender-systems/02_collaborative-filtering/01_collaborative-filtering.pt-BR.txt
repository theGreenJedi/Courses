Neste vídeo, falaremos sobre a uma abordagem para construir um sistema de recomendação que é chamado de filtragem colaborativa O algoritmo sobre o qual falaremos tem uma propriedade muito interessante, ele faz o que se chama aprendizagem de características. Quero dizer com isso que este algoritmo pode começar a aprender sozinho quais características usar. Aqui está o conjunto de dados que tinhamos, onde assumimos que, para cada filme, alguém nos contou quão romantico ele foi e quanta ação havia nele. Como você pode imaginar, pode ser muito difícil, demorado e custoso conseguir alguém para assistir cada filme e te contar o quão romântico e quanta ação existe em cada filme, além de que é comum querer muito mais características do que apenas estas duas. Então de onde você obtém essas características? Vamos mudar o problema um pouco e supor que nós temos um conjunto de dados onde nós não sabemos os valores dessas características. Então, temos um conjunto de dados de filmes e das avaliações dos usuários, mas nós não temos idéia do quão romântico cada filme é, e nem de quanta ação eles têm. Por isso, substituí todas estas coisas com interrogações. Agora, supomos outra coisa. Digamos que você perguntou para cada usuário, e cada um disse O quanto eles gostam de filmes românticos e o quanto eles gostam de filmes de ação. Alice está associada ao "θ⁽¹⁾", Bob a "θ⁽²⁾", Carol a "θ⁽³⁾", Dave a "θ⁽⁴⁾". Digamos, também, e que Alice nos diz que ela realmente gosta de filmes românticos, por isso temos um cinco aqui, que é o multiplicador associado a "x₁", e também nos diz que realmente não gosta de filmes de ação, por isso um 0 aqui. Bob nos diz algo similar, aqui está "θ⁽²⁾", enquanto Carol nos diz que ela realmente gosta de filmes de ação, por isso um 5 aqui, que é o multiplicador associado a "x₂". Não esqueçam que também há "x₀ = 1", e digamos que Carol nos diz que não gosta de filmes românticos, assim como Dave. Vamos assumir que podemos passar pelos usuários e cada usuário "j" nos diz qual o valor de "θ⁽ʲ⁾" correspondente. Nos especificam o quanto eles gostam de diferentes tipos de filmes. Se pudermos obter estes parâmetros "θ" dos nossos usuários, torna-se possível tentar inferir quais são os valores de "x₁" e "x₂" para cada filme. Vamos olhar para um exemplo. Vamos ver o filme 1, que está associado a um vetor de características "x₁". Este filme é chamado "Love at last", mas vamos ignorar isso. Vamos supor que não sabemos qual é, e ignoramos o título. Tudo o que sabemos é que Alice amou este filme, assim como Bob, e Carol and Dave odiaram este filme. O que podemos inferir? Bem, nós sabemos do vetor de características que Alice e Bob amam filmes românticos, porque eles nos disseram e por isso o 5 aqui. Já Carol e Dave, nós sabemos que eles odeiam filmes românticos e que eles amam os de ação. Estes são os vetores de parâmetros que os usuários 3 e 4, Carol e Dave, nos deram. Baseados no fato que o filme 1 é amado por Alice e Bob e odiado por Carol e Dave, nós podemos concluir, com motivo, que este é provavelmente um filme romântico. Além disso, também não tem muita ação. Este example está um pouco simplificado matematicamente, mas nós estamos perguntanto: "Qual vetor de características deveria ser "x₁", de modo que "(θ⁽¹⁾)ᵀ · x₁" é aproximadamente 5, que é a classificação de Alice, "(θ⁽²⁾)ᵀ · x₁" também é aproximadamente igual a 5, "(θ⁽³⁾)ᵀ · x₁" é aproximadamente 0, a classificação da Carol, e "(θ⁽⁴⁾)ᵀ · x₁" é aproximadamente 0. Assim, parece que "x₁" é igual a "[1; 1.0; 0]", o que faz sentido dado o que sabemos das preferências de Alice, Bob, Carol e Dave e da maneira que eles avaliaram este filme. De uma forma mais geral, podemos percorrer esta lista e tentar adivinhar quais seriam características razoáveis para estes outros filmes também. Vamos formalizar o problema de aprender as características "xᵢ". Digamos que nossos usuários nos disseram as suas preferências. Assim, eles já nos disseram todos os valores, desde "θ⁽¹⁾" a "θ⁽ⁿᵘ⁾" e nós queremos aprender o vetor de características "x⁽ⁱ⁾" para o filme número "i". Podemos propor o seguinte problema de otimização. Nós queremos somar sobre todos os índices "j" para os quais nós temos uma nota para o filme "i", porque nós estamos tentando aprender as características do filme "i", que é este vetor "xᵢ". O que nós queremos fazer é minimizar este erro ao quadrado, queremos escolher características "x⁽ⁱ⁾" de forma que valor estimado para a nota do usuário "j" para o filme "i" será próxima, não estará longe em erro quadrático do atual valor "y⁽ⁱʲ⁾" que nós realmente observamos na avaliação do usuário "j" ao filme "i". Resumindo, este termo tenta escolher características "xᵢ" de forma que, para todos os usuários "j" deram notas para o filme, o algoritmo prevê um valor valor para a avaliação daquele filme que não está muito distante, no sentido do erro quadrático, do valor real dado pelo usuário. Este é o erro quadrático. Como de costume, podemos adicionar este termo de regularização para evitar que as características fiquem muito grandes. É assim que aprenderíamos as características para um filme específico, mas queremos aprender todas as características para todos os filmes, então vou adicionar esta soma extra aqui. Somarei por todos os "nₘ" filmes, minimizando este objetivo aqui em cima, somado sobre todos filmes. Com isso, você obtém o um problema de otimização. Se você minimizar isto, você terá um conjunto de características razoável para todos os seus filmes. Agora vamos relacionar o algoritmo sobre o qual falamos no vídeo anterior e que o que vimos agora. No vídeo anterior, mostramos que, se você tem um conjunto de notas de filmes, tem os dados "r⁽ⁱʲ⁾" e os "y⁽ⁱʲ⁾", você tem as notas dos filmes. Então, dadas as características para os filmes, podemos aprender estes parâmetros "θ". Se você sabe as características,  pode aprender os parâmetros "θ" para seus usuários. Mostramos, antes neste vídeo é que, se seus usuários estão dispostos a informar parâmetros, então você pode estimar características para filmes diferentes. Este é um problema como o da galinha e o ovo. Qual vem primeiro? Se pudermos ter os "θ", podemos descobrir os "x", e se tivermos os "x", podemos aprender os "θ". O que você pode fazer é, e isso realmente funciona, é escolher aleatoriamente valores para os "θ". Baseado em seu chute inicial para os "θ", você pode usar o procedimento que acabamos de discutir, para aprender as características para diferentes filmes. Dado um conjunto inicial de características para os filmes, você pode usar o primeiro método, que discutimos no vídeo anterior, para tentar encontrar estimativas melhores para os parâmetros "θ". Agora que você tem uma configuração melhor para os parâmetros "θ" dos usuários, podemos usar isso para conseguir um conjunto melhor de características, e assim por diante, você pode iterar, indo para cá e para lá otimizando "θ", "x", "θ", "x", e isso realmente funciona. No fim, isso fará seu algoritmo convergir para um conjunto razoável de características para os filmes e um conjunto razoável de parâmetros para os diferentes usuários. Isso é um algoritmo de filtragem colaborativa básico. Na verdade, este não é o algoritmo final que vamos usar. No próximo vídeo, vamos melhorá-lo e torná-lo mais eficiente computacionalmente. Mas espero que isso tenha dado uma noção de como formular um problema no qual você pode simultaneamente aprender os parâmetros e as características de diferentes filmes. Para esse problema, do sistema de recomendação, Isso é possível pois cada usuário classifica múltiplos filmes e, com sorte, cada filme foi classificado por vários usuários. Assim, você pode fazer esse processo de ir e voltar para estimar "θ" e "x". Resumindo, neste vídeo vimos um algoritmo de filtragem colaborativa inicial. O termo "filtragem colaborativa" se refere à observação de que, quando você roda o algoritmo com um grande conjunto de usuários, os usuários colaboram, de certa forma. Colaboram para conseguir melhores classificações de filmes para todos, pois com cada usuário classificando um subconjunto de filmes, cada usuário está ajudando o algoritmo um pouco a aprender as características melhor. Ao ajudar, quando classifico alguns filmes, ajudo o sistema a aprender as características que podem ser usadas pelo sistema para fazer previsões melhores de filmes para todos os outros. Assim, existe uma colaboração, na qual cada usuário está ajudando o sistema a aprender as características para um benefício comum. Isso é filtragem colaborativa. No próximo vídeo, usaremos essas ideias que trabalhamos aqui para tentar desenvolver um algoritmo ainda melhor, uma técnica um pouco melhor para a filtragem coletiva.