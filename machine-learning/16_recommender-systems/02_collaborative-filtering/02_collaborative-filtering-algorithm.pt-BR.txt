Nos últimos vídeos, falamos sobre como, se você receber características determinadas para filmes, pode usá-las para aprender parâmetros para usuários. Também, se você receber parâmetros para os usuários, você pode usá-los para aprender características para os filmes. Neste vídeo, vamos pegar essas ideias e juntá-las para chegar a um algoritmo de filtragem colaborativa. Uma das coisas que descobrimos antes é que, se você tiver características para os filmes, pode resolver este problema de minimização para encontrar os parâmetros "θ" dos usuários. Também descobrimos que, se você receber os parâmetros "θ", você pode usá-los para estimar as características "x", resolvendo este problema de minimização. Uma coisa que você pode fazer é ir e voltar. Talvez inicializando aleatoriamente e solucionar em "θ", depois em "x", depois "θ", depois "x". Mas existe um algoritmo mais eficiente que não precisa ir e voltar entre os "x" e os "θ", mas consegue encontrar soluções para "θ" e "x" simultaneamente. Aqui está ele. Basicamente, pegamos ambos os objetivos de minimização e juntamos no mesmo objetivo. Definirei o novo objetivo de minimização "J", uma função custo, que é uma função das características "x" e dos parâmetros "θ". Assim, é basicamente a junção dos dois objetivos. Para explicar isso, primeiro preciso mostrar que este termo aqui, o termo de erro quadrático, é o mesmo termo que está aqui. As somas parece um pouco diferentes, mas vamos ver o que elas estão fazendo. A primeira soma é sobre todos os usuários "j", e a soma interna é sobre todos os filmes avaliados pelo usuário. Ou seja, uma soma por todos os pares "(i, j)" que correspondem a um filme avaliado por um usuário. A soma em "j" determina, para cada usuário, a soma de todos os filmes avaliados por ele. A soma aqui embaixo faz o mesmo, mas na ordem inversa. Ela determina, para cada filme "i", a soma por todos os usuários "j" que avaliaram o filme, portanto, ambas as somas são por todos os pares "(i, j)" para os quais "r(i, j) = 1". É uma soma por todos os pares "(i, j)" para os quais existe uma avaliação. Assim, os dois termos de cima são exatamente este primeiro termo, em que escrevi a soma explicitamente, por todos os pares "(i, j)" para os quais "r(i, j) = 1". Então, o que fazemos é definir um objetivo de otimização combinado que queremos minimizar para achar soluções em "x" e "θ" simulaneamente. Os outros termos no objetivo de minimização são: este, que é um termo de regularização para "θ", que veio aqui embaixo, e a última parte é esta, que está no objetivo de minimização para os "x", que veio para cá. Esse objetivo de otimização "J" tem uma propriedade interessante, onde, deixando os "x" constantes e minimizando em "θ", você estará resolvendo exatamente este problema, enquanto se fizer o contrário, deixando "θ" constante e minimizar "J" somente em relação aos "x", torna-se equivalente a isto. Isso porque este termo ou aquele será constante se minimizar somente em "x" ou somente em "θ". Então, este é um objetivo de otimização que junta as funções custo em termos de "x" e "θ". Para chegar ao problema de otimização único, o que faremos será tratar a função custo como uma função das características "x" e os parâmetros de usuário "θ" para minimizar isso tudo, como uma função tanto dos "x" quanto dos "θ". Na verdade, a única diferença entre este e o algoritmo anterior é que, em vez de ir e voltar, minimizando em "θ", depois minimizando em "x", depois em "θ", depois em "x", e assim por diante. Nesta nova versão, em vez de ir sequencialmente pelos dois conjuntos de parâmetros, "x" e "θ", o que faremos será simplesmente minimizar em ambos os conjuntos simultaneamente. Finalmente, um último detalhe é que, quando aprendemos assim, anteriomente tínhamos essa convenção de uma característica "x₀ = 1" que corresponde a um termo de intercepção. Quando usamos esse formalismo onde estamos aprendendo as características, vamos nos livrar dessa convenção. Assim, as características "x" que vamos aprender estão em "ℝⁿ", em comparação com as características em "ℝⁿ⁺¹" com o termo de intercepção. Nos livrando de "x₀", temos "x ∈ ℝⁿ". Da mesma forma, como os parâmetros "θ" têm a mesma dimensão, também temos "θ ∈ ℝⁿ", porque, se não existe "x₀", também não há necessidade para o "θ₀". Agora, estamos aprendendo todas as características, certo? Assim, não há necessidade de estabelecer uma característica sempre igual a 1. Isso porque, se o algoritmo realmente quiser uma característica igual a 1, pode aprender por conta própria. Assim, se ele escolher, pode colocar "x₁ = 1". Não há necessidade de forçar "x₀ = 1", o algoritmo agora tem a flexibilidade para aprender isso por conta própria. Juntando tudo, aqui está nosso algoritmo de filtragem colaborativa. Primeiro, inicializamos "x" e "θ" a valores aleatórios pequenos. Isso é um pouco como treinar redes neurais, onde também inicializamos todos os parâmetros a valores aleatórios pequenos. A seguir, vamos minimizar a função custo usando gradiente descendente ou um dos algoritmos de otimização avançados. Encontrando as derivadas, você descobre que as atualizações do gradiente descendente são estas, onde este termo é a derivada parcial da função custo, com respeito à característica "x⁽ⁱ⁾ₖ", e, similarmente, este termo aqui também é uma derivada parcial da função custo no parâmetro "θ" que estamos minimizando. Só como um lembrete, nesta fórmula não temos mais esse "x₀ = 1", ou seja, "x ∈ ℝⁿ" e "θ ∈ ℝⁿ". Neste novo formalismo, estamos regularizando todos os parâmetros "θ" e "x". Não existe mais o caso especial "θ₀", que era regularizado de forma diferente, ou que não era regularizado comparado aos parâmetros "θ₁" a "θₙ". Agora não existe mais o "θ₀", e é por isso que não separei um caso especial para "k = 0". Então, usamos gradiente descendente para minimizar a função custo "J" com respeito a "x" e "θ". E, finalmente, dado um usuário com parâmetros "θ", se existir um filme com características aprendidas "x", estimaríamos que o filme receberia uma nota igual a "θᵀ · x" do usuário. Ou seja, se o usuário "j" ainda não avaliou o filme "i" estimamos que o usuário "j" avaliará o filme "i" com a nota "(θ⁽ʲ⁾ᵀ) · (x⁽ⁱ⁾)". Esse é o algoritmo de filtragem colaborativa, e se você implementá-lo, obterá um algoritmo bem decente, que simultaneamente aprende boas características para todos os filmes, espero, além dos parâmetros para todos os usuários, e pode fornecer estimativas boas para as avaliações de usuários diferentes em filmes que ainda não viram.