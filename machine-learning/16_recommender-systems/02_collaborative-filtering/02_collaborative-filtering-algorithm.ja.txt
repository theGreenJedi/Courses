前回までのビデオで まずは映画のフィーチャーが与えられた時 それを用いて ユーザーのパラメータのデータを 学習する事が出来る、という話をした。 次に、ユーザーのパラメータを与えられたら、 それを使って映画のフィーチャーを学習する事が出来る、という話をした。 このビデオでは、これら二つのアイデアを 用いて、それらを合わせて 協調フィルタのアルゴリズムに たどり着く。 つまり以前やった事の 一つには 映画のフィーチャーがあれば、 最小化問題を解く事で ユーザーのパラメータである シータを見つける事が出来た。 そしてその次に、 パラメータであるシータがあれば、 それを用いて フィーチャーxを推計する事が 出来るのだった。 それは最小化問題を解く事で出来るのだった。 だから取りうる手段として一つ考えられるのは 行ったり来たりして実行する事だ。 ランダムに初期化されたパラメータで、 シータについて解き、 xについて解き、シータについて解き、 xについて解く。 だが、シータとxを 行ったり来たりしなくても良い もっと効率的なアルゴリズムがある事が 知られている、それは行ったり来たりする代わりに シータとxを同時に 解く事が出来る。 それはこんなだ。
我らがやる事は、基本的には これら二つの最適化の目的関数をとり、 それを一つの目的関数に突っ込む、という事だ。 つまり私は、新しい最適化の目的関数Jを 定義する、 それはフィーチャーxと パラメータのシータに関する 関数としての、 コスト関数だ。 そして基本的には上の所に 二つの最適化の目的関数があったが、それを一つにくっつけた。 これを説明する為に、 まず以下の二つの項が同じという事を指摘したい： この項、この二乗誤差の項と、 この二乗誤差の項、 これ。 和の取り方がちょっと違って見えるが、 この和が実際に何をやっているかを見てみよう。 最初の和は、 全てのユーザーjに渡ってとっている、 そして次にそのユーザーによってレーティングされた全ての映画について和を取る。 つまり、これは実際は、ユーザーにレーティングされた 全ての映画に対応した iとjのペアに渡って和を取っている。 jに渡って取る和は、各ユーザに対して、と言っていて そしてそのユーザーがレーティングした 全ての映画に渡って和を取る。 この下の和は、それを反対の順番でやるだけだ。 これが言っているのは、各映画iに対して その映画をレーティングした全てのユーザーj に渡って 和をとる、つまり、 これらの和は、これらは両方とも、 r i jがイコール1な 全てのi jのペアに渡って 和を取るだけ。 それはようするに、 レーティングを持っている全てのユーザーと映画の組に渡って和を取る。 つまりこれら二つの項は この最初の項と 完全に一致している。 そして私は和を明示的に書いた、 それはようするに、r i j がイコール1となる 全てのi jのペアに渡って 和を取る、と言っている。 我らがやりたい事は xとシータを同時に解く為に 最小化をする対象となる、 最適化の複合目的関数を 定義するという事だ。 そして最適化の目的関数に残ってる 他の項はこれだ。 これはシータの正規化項だ。 それはここに来る。 そして最後のピースとなるのは この項で、これは xの為の最適化の目的関数の中に残ってる物で それはここに来る。 そしてこの最適化の目的関数Jは 興味深い性質を持っている、それは xを定数に 固定してみて、 シータに関して最小化してみると、 するとまさにこの問題を解いている事になる。 一方、その反対をやると、 シータを仮に定数で 固定してみて、Jを xに関してだけ 最小化してみると、 この項か、またはこの項が xに関してかシータに関してのどちらかに関してだけ最小化するなら、 定数になるから。 だから、これが、xに関するコスト関数と シータに関するコスト関数を くっつけた最適化の目的関数だ。 そして一つの最適化問題に 帰着される為には、 我らがやるべき事は、 このコスト関数を フィーチャーxとユーザーのパラメータシータの 両方に関する 関数として 扱う事だ。 そして単純に全体を xとシータの関数として、 最小化すれば良い。 そして実際、これと 以前のアルゴリズムの 唯一の違いは、 行ったり来たりする代わりに、 以前のはシータに関して最小化した後 次にxについて最小化して、 その後シータについて最小化して、 xについて最小化して、、、などとやったのだったが、 この新しいバージョンでは、 xとシータという二つのパラメータのセットの間を 順番に行ったり来たりする代わりに たんに両方の パラメータに関して 同時に最小化する、という事をする。 最後に一つ詳細な話だが、 フィーチャーをこういう風に学ぶ場合、 以前はx0がイコール1となる コンベンションを使っていて、 これは切片項に 対応した物だった。 この種の定式化を用いる時には、 実際にはフィーチャーも学習する事になるので、 このコンベンション無しでいける。 だから我らの学習する事になるフィーチャーxはR nだ。 一方、以前はフィーチャーxは R n+1だった、切片項を含んでいたから。 そこからx0を取り除いたから、xはR nとなる。 そして同様に、 パラメータのシータは 同じ次元なので、 シータも R nとなる。 何故ならx0が無いなら、 シータ0も同様に 不要だからだ。 そしてこのコンベンション無しで いける理由としては、 いまや我らはフィーチャーを全て学習する事になった、よね？ だからいつも1と等しくなるフィーチャーを ハードコードする必要が無い。 何故ならもしアルゴリズムが いつも1となるフィーチャーを本当に必要としているなら、 それは自身で勝手にそう学習するはずだからだ。 だからもしアルゴリズムがそう選べば x1=1とセットされる。 だからフィーチャーx0を1と ハードコードする必要は無い。 アルゴリズムはそれを自分自身で学習する事が出来るだけの 柔軟性がある。 では全部を合わせると、 これが協調フィルタリングのアルゴリズムだ。 まず、xとシータを ある小さなランダムの値で 初期化する。 これはちょっと ニューラルネットワークのトレーニングに似てるね。 そこでもニューラルネットワークのパラメータを全て小さなランダムの数で初期化したんだった。 次に、コスト関数を、 最急降下法なりアドバンスドな最適化のアルゴリズムなりを使って 最小化する。 だから微分をとれば、 こんな感じの 最急降下法の更新ルールが得られる。 この項は、コスト関数を 偏微分した物。 全部書いたりはしないが、 それをフィーチャーx(i) kで 偏微分した物だ。 同様に、この項もまた、 コスト関数を偏微分した物で 今度はパラメータであるシータに関して 偏微分した物で、それに関して最小化する。 ちょっと注意を。 この式では、もはや x0イコール1が無い、 だからxはR nとなり、 シータもR nとなる。 この新しい定式化では、各パラメータ、シータも、 各パラメータx nも、正規化している。 もはやシータ0の特別扱いのケースも 存在しない。シータ0は異なる風に 正規化していたんだった。 それはシータ1からシータnのようには 正規化しないんだった。 もはやシータ0は存在しないので、 そんな訳だからこのアップデートでも k=0の特別なケースの 場合分けをしていない。 そして最急降下法を使って コスト関数Jを フィーチャーxとパラメータシータに関して 最小化していく。 そして最後に、あるユーザーに対して ユーザーがあるパラメータ、シータを 持っているなら、 そして映画にはある種の 学習されたフィーチャーxがあるなら、 そのユーザーが映画に 星いくつのレーティングをするかを シータjの転置と、、、 または、前の表記と 合わせると、 もしユーザーjがまだ 映画iをレーティング していなければ、 ユーザーjは映画iを シータjの転置 xi と レーティングすると 予測する。 以上が協調フィルタリングアルゴリズムだ。 もしこのアルゴリズムを 実装すれば、おそらく全ての映画の 良いフィーチャーと 全てのユーザーのパラメータを同時に 学習する、かなり良いアルゴリズムを 得る事が出来る。 そして別々のユーザーが別々の映画を どうレーティングするかの かなり良い予測を与える事も期待出来る。