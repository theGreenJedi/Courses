ここまでで、あなたは リコメンダーシステムのアルゴリズム、または 協調フィルリングのアルゴリズムの全ての主要な要素を見終わった事になる。 このビデオでは、 ちょっとした最後の実装の詳細を共有しておきたい。 それは平均標準化(mean normalize)と呼ばれる物で、 それはときどきアルゴリズムを ちょっと良く機能させる程度の物。 平均標準化のアイデアのモチベーションを理解する為、 なんの映画もレーティングしていない ユーザーの例を考えてみよう。 つまり、我らの四人のユーザー、 Alice, Bob, Carol, Daveに 加えて、さらに5番目のユーザー、 Eveを足したとしよう。彼女は一つの映画もレーティングしていないとする。 我らの協調フィルリングのアルゴリズムが このユーザーに何をするのか見てみよう。 n = 2としよう、 つまり学習するフィーチャーは2つ。 そしてパラメータベクトルの シータ5を学習したい。 それはR 2だ。 今このベクトルは R n+1じゃなくてR nとなったのを思い出そう。 ユーザー番号5のEve のパラメータベクトルを学習したい。 最適化の目的関数の 最初の項を 見てみると、 ユーザーEveはなんの映画もレーティングしていないので、 r ijが1となる 映画は、 Eve に関しては 一つも無い。 だからシータ5を決定するのに この最初の項はまったく寄与しない。 何故ならEveはなんの映画もレーティングしていないのだから。 だからシータ5に影響を与える 唯一の項はこの項だ。 つまり、我らは ベクトルシータ5 を、 最後の正規化項をなるべく小さくするように 選ぶ、と主張している。 言い換えると、我らが最小化しようとするのは この ラムダ/2  の シータ5下付き添字1の二乗 足すことの シータ5下付き添字2の二乗だ。 以上がユーザー5に関する 正規化項の要素だ。 そして当然、 あなたのゴールがこの項を 最小化するなら、 最終的に得られる シータ5は、イコール 0 0だ。 何故なら正規化項は パラメータを 0に近くなるように推奨する訳だが、 そこでもし パラメータを0から引き離す データが存在しなければ、 何故ならこの最初の項は シータ5には影響しないので、 結局シータ5としては 全ての要素が0のベクトルを得る事になる。 すると、ユーザー5が 映画をどうレーティングするかを 予測しようとすると、どんな映画に対しても、 シータ5の転置 xiは いかなるiに対しても、 イコール0となる。 シータ5はどのxに対しても0なので、 内積は0となる。 だから我らは結局、 Eveはどの動画も 0とレーティングする、と 予測する事になる。 でもこの予想はあんまり役に立たない、よね？ つまり別々の映画を見ていくと、 Love at Last、この最初の映画は、 何人かは星5とレーティングした。 そしてSwords vs. Karateですら、誰かは星5とレートしている。 だからある人々はある種の映画を好むのだ。 だからEveは全ての映画を 0と付けると予測するのは、あまり便利では無い。 さらに実際、もし我らが Eveは全てに星0のレーティングをする、と予測してしまうと、 彼女に推薦する映画を決める 良い方法も無くなってしまう。 何故ならこれら全ての 映画はEveの場合、 完全に同じ予測値となってしまうから。 どの映画も他より 高いレーティングとならないので、 彼女に進める映画が一つも無くなってしまう。それはあまり良くない。 平均標準化法のアイデアはこの問題を修正する。 それはこんな風に機能する。 前と同様、全ての映画のレーティングを この行列Yにグルーピングする。 つまりこれらのレーティングを 全て持ってきて、この行列Yに グルーピングする。 そしてこのここにある行の、 全部はてなマークなのは、 Eveがなんの映画もレーティングしていない事に対応している。 ここで平均標準化を実行する為には、 各映画の得たレーティングの 平均を計算する。 そして、それをミューというベクトルに 保存する。 つまり、最初の映画は二つの星5と二つの星0のレーティングを得たのだから、 その平均は星2.5だ。 二番目の映画の平均は 星2.5だ。などなど。 そして最後の映画は、0, 0, 5, 0だから 0, 0, 5, 0の平均は 平均をとると、 平均は1.25レーティング。 そして、全映画の レーティングを 見ていき、そこから 平均のレーティングを引いていく。 つまりこの最初の要素、5は、2.5を引くから、2.5となる。 二番目の要素5からは2.5を引くから 2.5となる。 そして次に0。 0引く2.5だから、-2.5。 -2.5。 言い換えると、私がやってる事は 映画のレーティングの行列を もってきて、 この幅の広い行列を持ってきて、 各列から、その映画の平均のレーティングを引く、という事。 つまり、私がやってるのは、 各映画を、平均が0になるように 標準化しているだけ。 そして最後に一つ例を見る。 この最後の列を見ると、0 0 5 0だ。 1.25を引くから、 結局ここの値と なる。 そして現在、もちろん このはてなマークは はてなマークのままだ。 だから、この新しい行列Yにある 各映画も 平均のレーティングは0となる。 そこで次にやる事としては、 このレーティングの集合を使って、 協調フィルタリングアルゴリズムを行う。 つまり、これをユーザーから取った データのフリをさせて、 言い換えると、これらを ユーザーから取った実際の レーティングのフリをさせて、 そしてこれを私のデータセットとして パラメータのシータjと フィーチャーのxiを 学習させる。 - これらの平均標準化された映画のレーティングから。 映画のレーティングの 予測をさせたくなったら、 以下のようにする: ユーザーjの映画iに関しては、 シータj転置 xi と 予測する。 ここでxとシータはこの、 平均標準化したデータセットから学習したパラメータ。 だが、このデータセットは 既に平均が引かれた物だから、 映画iに関して 予測を行いたいなら、 平均を足し戻す必要がある。 だからミューiを 足し戻す。 以上が私の 予測となる。そこでは、トレーニングデータから 平均を全て引いたのだから、 予測を行う時には、 これらの平均、ミューiを 映画iに対して 足し戻さなくてはならない。 特に、もしユーザー5、つまりEveに対して、 前のスライドの議論が いまだに適用出来て、 Eveはなんの映画も レーティングしてないので、 だからユーザー5について 学習したパラメータは まだイコール 0, 0だ。 だから得られる 物は、つまり、 特定の映画iについて Eveの結果を予測すると、 シータ5転置 xi 足すことの、 ミューiを足し戻す、のだから、 この最初の要素は シータ5が0なら0となる。 だから映画iに関しては、 ミューiになる、と予測する事になる。 これは納得出来る。 つまり、 映画1に関しては、 Eveが2.5とレーティングするだろう、と予測する訳だ。 映画2はEveは2.5とレーティングするだろう、 映画3はEveは2とレーティングすると 予測することになる、 などなど。 これは実際に筋が通っている、 何故ならEveがまだ 何もレーティングしていないとすると この新しいユーザーEveについては 我らは何も知らない事になる。
だから我らがする事といえば、 各映画に対して それらの映画のレーティングの平均と 予測する訳だ。 最後に、ちょっと補足。 このビデオでは、平均標準化について 議論した。そこでは、Y行列の 各列を、平均が0になるように 標準化した。 もし全くレーティングされていない 映画がある場合は、 それは何もレーティングしていないユーザーと似ているが、 レーティングの一切無い 映画がある場合、 各行の平均が 0になるようなバージョンの アルゴリズムを 使う事も出来る。 列を平均が0になるように標準化する代わりにだ。 でもこちらは比較的 重要では無いパターンかもしれない。何故なら、 実際にレーティングの無い映画があったら、 なんにせよその映画は 誰にも推薦すべきでは無いかもしれないから。 だから、何の映画もレーティングしていない ユーザーに対応するのは、 何のレーティングも得ていない映画に 対応するよりも、 より重要 かもしれない。 ではまとめだ。 以上が協調フィルタリングの前処理として 平均標準化を行う方法だ。 あなたのデータセットによっては、 この手法はあなたの実装を ちょっぴり良く振舞わせてくれるかもしれない。