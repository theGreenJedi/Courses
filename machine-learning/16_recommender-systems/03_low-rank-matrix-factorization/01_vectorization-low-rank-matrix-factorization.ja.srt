1
00:00:00,530 --> 00:00:01,650
ここ何回かのビデオで、

2
00:00:01,730 --> 00:00:03,890
協調的フィルタリングのアルゴリズムについて議論してきた。

3
00:00:04,830 --> 00:00:05,890
このビデオでは、このアルゴリズムの

4
00:00:05,970 --> 00:00:07,120
ベクトル化した実装について

5
00:00:07,490 --> 00:00:09,090
ちょこっと話しておきたい。

6
00:00:09,980 --> 00:00:12,670
またついでにこのアルゴリズムについて出来るその他の事についても話す。

7
00:00:13,340 --> 00:00:14,520
例えば、出来る事の一つに

8
00:00:14,600 --> 00:00:15,830
ある商品が

9
00:00:16,180 --> 00:00:17,390
与えられた時に、

10
00:00:17,770 --> 00:00:19,160
これに関連した商品を探す、

11
00:00:19,270 --> 00:00:20,210
というのがある。これは例えば

12
00:00:20,490 --> 00:00:23,140
ユーザーが最近ある商品を見たとすると、

13
00:00:23,650 --> 00:00:24,990
このユーザーに推薦する、別の関連した

14
00:00:25,520 --> 00:00:27,170
商品は無いか？という事。

15
00:00:27,620 --> 00:00:28,980
ではどうやってこれが出来るか見てみよう。

16
00:00:30,170 --> 00:00:31,190
ここでやろうとしているのは、

17
00:00:31,550 --> 00:00:33,520
協調的フィルタリングのアルゴリズムの予測を

18
00:00:33,740 --> 00:00:35,710
別のやり方で練習する、という物。

19
00:00:37,370 --> 00:00:38,590
はじめに、これが

20
00:00:38,960 --> 00:00:40,440
我々のデータセットで

21
00:00:40,750 --> 00:00:41,880
五つの映画がある。

22
00:00:42,160 --> 00:00:43,150
そして私がやる事は、

23
00:00:43,390 --> 00:00:44,520
ユーザーのレーティングを全て

24
00:00:44,850 --> 00:00:46,500
取ってきて、一つの行列に

25
00:00:47,080 --> 00:00:48,800
グループ化する。するとここでは、

26
00:00:49,200 --> 00:00:51,390
5つの映画と4人のユーザーがいるので、

27
00:00:51,670 --> 00:00:53,390
この行列yは

28
00:00:53,670 --> 00:00:54,550
5x4行列になる。

29
00:00:54,910 --> 00:00:57,110
これは単純に、

30
00:00:57,340 --> 00:00:58,770
これらの要素、これらのデータを全部とってきて、

31
00:00:59,820 --> 00:01:02,390
これははてなマークも全部含めて、それをこの行列にグループ化した物だ。

32
00:01:03,290 --> 00:01:04,470
もちろんこの行列の要素、

33
00:01:04,650 --> 00:01:06,400
この行列の要素 i jは、

34
00:01:06,500 --> 00:01:07,860
実際は、以前に

35
00:01:08,060 --> 00:01:09,710
yの上付き添字i jと

36
00:01:10,520 --> 00:01:12,090
書いていた物だ。

37
00:01:12,220 --> 00:01:13,480
それはユーザーjによる映画iのレーティング。

38
00:01:14,140 --> 00:01:15,640
我らの持つ全てのレーティングを含む

39
00:01:16,070 --> 00:01:17,290
この行列Yが与えられたとすると、

40
00:01:17,430 --> 00:01:18,520
レーティングを予測する

41
00:01:18,700 --> 00:01:20,500
アルゴリズムを書き下す

42
00:01:20,880 --> 00:01:23,340
代替的な方法がある。

43
00:01:24,320 --> 00:01:26,210
特に、もしあなたが

44
00:01:26,430 --> 00:01:27,540
あるユーザーのある映画に対する

45
00:01:27,920 --> 00:01:29,480
予測を調べたいなら、

46
00:01:29,690 --> 00:01:31,250
ユーザーjの映画iに対する予測の

47
00:01:31,950 --> 00:01:35,540
式はこうなる。

48
00:01:37,010 --> 00:01:38,570
だから、予測されたレーティングの

49
00:01:39,440 --> 00:01:40,330
行列があれば、

50
00:01:40,910 --> 00:01:42,000
それは以下のような

51
00:01:42,180 --> 00:01:43,600
行列だろう、

52
00:01:45,030 --> 00:01:48,140
i jエントリが

53
00:01:49,650 --> 00:01:51,440
これがユーザーjが映画iに

54
00:01:52,000 --> 00:01:54,020
与えるレーティングの

55
00:01:54,460 --> 00:01:55,690
予測値で、

56
00:01:57,130 --> 00:01:58,440
それは正確に

57
00:01:58,790 --> 00:02:00,680
シータjの転置 xi にイコールだ。

58
00:02:00,900 --> 00:02:01,940
つまり、この行列は、

59
00:02:02,520 --> 00:02:04,310
最初の要素、

60
00:02:04,750 --> 00:02:05,930
この要素 1 1は、

61
00:02:06,220 --> 00:02:07,450
ユーザー1の映画1に対するレーティングの

62
00:02:07,760 --> 00:02:09,360
予測値だ。

63
00:02:09,560 --> 00:02:11,070
そしてこの要素、要素 1 2は、

64
00:02:11,430 --> 00:02:12,680
ユーザー2の映画1に対する

65
00:02:13,470 --> 00:02:14,640
レーティングの予想値。

66
00:02:14,930 --> 00:02:16,070
などなど。

67
00:02:16,630 --> 00:02:18,670
そしてこれは、

68
00:02:19,000 --> 00:02:20,130
ユーザー1の最後の映画に対する

69
00:02:20,930 --> 00:02:23,380
レーティングの予想値。

70
00:02:23,640 --> 00:02:25,100
そしてこれは、

71
00:02:25,400 --> 00:02:26,870
このレーティングは

72
00:02:27,020 --> 00:02:28,050
この値を予想した物で、

73
00:02:29,050 --> 00:02:32,470
このレーティングは

74
00:02:32,650 --> 00:02:33,570
この値を予想した物で、、、

75
00:02:33,910 --> 00:02:35,080
などなど。

76
00:02:36,180 --> 00:02:37,480
いま、このレーティングの予想値の行列が

77
00:02:37,560 --> 00:02:39,290
与えられたとすると、これらを書きだす

78
00:02:39,610 --> 00:02:42,670
より簡単な、またはベクトル化した方法が存在する。

79
00:02:43,640 --> 00:02:44,640
まず、行列Xを

80
00:02:45,120 --> 00:02:46,850
定義する。これは、

81
00:02:46,970 --> 00:02:48,090
以前、線形回帰であった

82
00:02:48,370 --> 00:02:50,980
行列に似ている。

83
00:02:52,070 --> 00:02:53,820
x1の転置にx2の転置に、、、と

84
00:02:55,050 --> 00:02:57,060
xのn mの転置まで

85
00:02:58,530 --> 00:03:01,740
降りていく。

86
00:03:02,420 --> 00:03:03,320
つまり全ての映画の

87
00:03:04,210 --> 00:03:05,670
フィーチャーを持ってきて

88
00:03:06,140 --> 00:03:07,260
列として積んでいく。

89
00:03:07,950 --> 00:03:08,860
つまり各映画を

90
00:03:08,980 --> 00:03:09,810
一つの手本とみなして、

91
00:03:10,350 --> 00:03:11,200
それら別々の映画のフィーチャーを

92
00:03:11,670 --> 00:03:13,460
列として積んでいく訳だ。

93
00:03:14,290 --> 00:03:16,160
そしてまた、

94
00:03:16,280 --> 00:03:18,550
行列として大文字のシータも作りたい。

95
00:03:19,870 --> 00:03:20,840
その為には、

96
00:03:21,180 --> 00:03:22,490
ユーザー毎のパラメータベクトルを

97
00:03:22,750 --> 00:03:25,780
取ってきて、

98
00:03:26,280 --> 00:03:28,520
同様に列として積んでいく。

99
00:03:28,790 --> 00:03:29,690
つまり、これがシータ1で、

100
00:03:30,220 --> 00:03:31,880
これは最初のユーザーのパラメータベクトルだ。

101
00:03:33,430 --> 00:03:36,100
そしてシータ2、

102
00:03:37,040 --> 00:03:38,100
つまり、このように

103
00:03:38,360 --> 00:03:39,470
列として積んでいって

104
00:03:39,650 --> 00:03:41,530
大文字のシータの行列を定義する。

105
00:03:42,070 --> 00:03:43,830
するとこのように列として積み上がった

106
00:03:45,870 --> 00:03:48,410
n u個のパラメータベクトルを列に持った物を得る。

107
00:03:50,000 --> 00:03:51,390
さて、行列Xと行列シータが

108
00:03:52,080 --> 00:03:53,400
こう定義

109
00:03:53,590 --> 00:03:54,870
されたとして、

110
00:03:55,820 --> 00:03:56,970
全ての予測を計算する

111
00:03:57,290 --> 00:03:59,330
ベクトル化した方法を

112
00:03:59,420 --> 00:04:00,330
得るには、

113
00:04:01,060 --> 00:04:03,570
単純に X掛けるシータ転置 を

114
00:04:04,710 --> 00:04:07,050
計算するだけで良い。

115
00:04:07,160 --> 00:04:08,380
それがここにあるこの行列を計算する

116
00:04:08,570 --> 00:04:10,530
ベクトル化した方法となっている。

117
00:04:11,680 --> 00:04:12,460
協調的フィルタリングには、

118
00:04:12,480 --> 00:04:15,220
別の名前もある。

119
00:04:16,070 --> 00:04:17,190
我らの使っているこのアルゴリズムはまた、

120
00:04:17,660 --> 00:04:19,840
低ランク行列分解とも

121
00:04:21,240 --> 00:04:22,540
呼ばれている。

122
00:04:24,280 --> 00:04:25,410
つまりもし人々が

123
00:04:25,620 --> 00:04:26,760
低ランク行列分解について

124
00:04:27,210 --> 00:04:29,490
話しているのを耳にした時は、それは本質的には

125
00:04:30,390 --> 00:04:32,100
我らがここまで議論して来た物と同一の物だ。

126
00:04:32,590 --> 00:04:33,900
そしてこの用語は

127
00:04:33,990 --> 00:04:36,100
この行列 X 掛ける シータ転置 が持つ

128
00:04:36,770 --> 00:04:38,880
数学的特徴に、

129
00:04:39,110 --> 00:04:40,780
線形代数では

130
00:04:41,030 --> 00:04:42,410
この低ランク行列と

131
00:04:42,670 --> 00:04:43,820
呼ばれる物があって、

132
00:04:44,720 --> 00:04:45,800
だからこれらのアルゴリズムには

133
00:04:46,060 --> 00:04:47,190
低ランク行列分解という

134
00:04:47,340 --> 00:04:48,570
名前がついた。

135
00:04:48,930 --> 00:04:50,240
この行列 X シータ転置 の持つ低ランクという

136
00:04:50,410 --> 00:04:53,580
行列の特徴の為に。

137
00:04:54,830 --> 00:04:55,640
もし低ランクというのが

138
00:04:55,910 --> 00:04:57,310
なんなのか知らなくて、低ランク行列というのが

139
00:04:57,620 --> 00:04:59,770
何なのか知らなくても、まぁ気にすんな。

140
00:04:59,970 --> 00:05:02,820
このアルゴリズムを使うのに、そんな事を知ってる必要はまったく無い。

141
00:05:03,740 --> 00:05:04,790
だがもしあなたが線形代数のエキスパートなら、

142
00:05:04,890 --> 00:05:06,110
そんな理由でこのアルゴリズムに

143
00:05:06,320 --> 00:05:07,580
低ランク行列分解という

144
00:05:07,850 --> 00:05:12,370
別名がついた、というワケ。

145
00:05:12,620 --> 00:05:14,090
最後に、協調的フィルタリングのアルゴリズムを

146
00:05:14,300 --> 00:05:16,350
実行する時に、

147
00:05:17,310 --> 00:05:18,160
実行出来る別の事として、こんなのがある。

148
00:05:18,530 --> 00:05:20,060
それは関連する映画を探す為に

149
00:05:20,320 --> 00:05:23,510
学習したフィーチャーを用いる、という物。

150
00:05:25,060 --> 00:05:26,810
具体的には、各商品iに関して

151
00:05:27,050 --> 00:05:27,810
実際には各映画iに関して、

152
00:05:28,810 --> 00:05:30,970
フィーチャーベクトルxiを学習した。

153
00:05:31,740 --> 00:05:32,880
つまり、あるフィーチャー群を学習した時には、

154
00:05:32,930 --> 00:05:34,220
どんなフィーチャーがあるのかとかは

155
00:05:34,590 --> 00:05:35,420
前もっては

156
00:05:35,610 --> 00:05:37,850
知らなかった。

157
00:05:37,940 --> 00:05:39,550
だがアルゴリズムを実行すると、フィーチャーは

158
00:05:39,990 --> 00:05:41,690
これらの別々の映画の

159
00:05:41,930 --> 00:05:43,490
または別々の商品の、またはなんでも、

160
00:05:43,730 --> 00:05:45,340
これらの重要な性質は何か、を捕捉する傾向にある。

161
00:05:45,480 --> 00:05:47,120
何がある種のユーザー達がある映画たちを

162
00:05:47,610 --> 00:05:48,600
好きになる重要な

163
00:05:48,930 --> 00:05:49,830
特徴なのか、そしてあるユーザー達が

164
00:05:50,210 --> 00:05:51,670
異なる映画を好む、重要な特徴とは何か。

165
00:05:52,470 --> 00:05:53,380
だから例えば、最終的に

166
00:05:53,540 --> 00:05:55,050
あなたはフィーチャーx1としてロマンスを

167
00:05:55,260 --> 00:05:56,550
x2としてアクションを、これまでの例と同様に

168
00:05:57,060 --> 00:05:59,180
学習した上で、

169
00:05:59,460 --> 00:06:00,590
さらに別のフィーチャーx3として

170
00:06:00,710 --> 00:06:02,100
コメディー度合いを

171
00:06:02,210 --> 00:06:04,520
学習する事になるかもしれない。

172
00:06:05,330 --> 00:06:07,000
さらにx4として別の何かを学習するかも。

173
00:06:07,270 --> 00:06:09,750
そうやってn個のフィーチャーを

174
00:06:09,940 --> 00:06:11,600
得る事になったとして、

175
00:06:12,610 --> 00:06:14,420
実際はこれらのフィーチャーを

176
00:06:14,750 --> 00:06:16,030
見ていって、これらのフィーチャーが

177
00:06:16,420 --> 00:06:18,120
本当は何を意味しているのかを

178
00:06:18,390 --> 00:06:19,980
人間が理解するのは

179
00:06:20,810 --> 00:06:22,850
とても難しい事が多い。

180
00:06:22,950 --> 00:06:24,540
だが実践的には、

181
00:06:24,620 --> 00:06:27,480
これらのフィーチャーが、たとえ可視化する事すら大変でも、

182
00:06:28,100 --> 00:06:29,570
これらのフィーチャーが何なのかを突き止めるのは大変であっても、

183
00:06:31,070 --> 00:06:32,160
だいたいは、それが何にせよ

184
00:06:32,410 --> 00:06:33,400
あなたが映画を好いたり嫌ったりする

185
00:06:33,960 --> 00:06:35,250
もっとも特徴的でとても意義深い

186
00:06:35,870 --> 00:06:37,120
特徴を

187
00:06:37,880 --> 00:06:39,300
捕捉しているフィーチャーを

188
00:06:39,710 --> 00:06:41,800
学習する。

189
00:06:41,860 --> 00:06:44,950
では、以下のような問題に取り組むとしよう。

190
00:06:45,970 --> 00:06:47,410
あなたがある映画iを持ってたとする、

191
00:06:47,790 --> 00:06:48,980
そしてあなたはその映画に

192
00:06:49,120 --> 00:06:50,750
関連した別の映画jを

193
00:06:51,620 --> 00:06:52,680
探したい。

194
00:06:53,150 --> 00:06:54,770
ところで、いったいなんでそんな事したいのか？

195
00:06:54,920 --> 00:06:56,120
いいでしょう。例えば

196
00:06:56,320 --> 00:06:57,840
ユーザーが映画をブラウズしているとする、

197
00:06:58,360 --> 00:07:00,210
そして彼は今、映画jを観ているとする、

198
00:07:00,550 --> 00:07:01,820
その時、映画jを観終わった後に

199
00:07:02,350 --> 00:07:04,110
彼に視聴を推薦すべき、リーズナブルな映画はなんだろう？

200
00:07:04,530 --> 00:07:06,040
または誰かが映画jを購入したとすると、

201
00:07:06,330 --> 00:07:07,470
その時に彼らに購入を検討してもらう為に

202
00:07:07,730 --> 00:07:11,000
推薦する事がリーズナブルな別の映画はなんだろう？

203
00:07:12,190 --> 00:07:13,000
いまやあなたはこれらの学習した

204
00:07:13,080 --> 00:07:14,540
フィーチャーを持っているのだから、

205
00:07:14,640 --> 00:07:16,080
これを用いて二つの映画がどの位近いかを

206
00:07:16,250 --> 00:07:17,930
測るとても便利な方法がある。

207
00:07:18,670 --> 00:07:20,530
具体的には、映画iは

208
00:07:21,460 --> 00:07:22,340
フィーチャーベクトルxiを持つ訳だが、

209
00:07:23,290 --> 00:07:24,200
別の映画jを、

210
00:07:24,640 --> 00:07:27,500
フィーチャーベクトル xiとxjの

211
00:07:27,710 --> 00:07:29,300
距離が短い物として

212
00:07:29,780 --> 00:07:30,800
探す事が出来る。

213
00:07:33,080 --> 00:07:34,010
これは二つの映画、

214
00:07:34,430 --> 00:07:36,980
iとjが類似しているという

215
00:07:37,830 --> 00:07:41,360
極めて強い示唆を与える。

216
00:07:42,320 --> 00:07:44,080
少なくとも、映画iを好きな人は

217
00:07:44,200 --> 00:07:46,950
映画jも好むだろう、という意味において。

218
00:07:47,760 --> 00:07:49,940
ではまとめると、

219
00:07:50,590 --> 00:07:52,130
ユーザーが映画iを

220
00:07:52,510 --> 00:07:53,710
見ていたとする、

221
00:07:54,150 --> 00:07:55,060
そしてあなたはその映画にもっとも似た

222
00:07:55,310 --> 00:07:56,640
5つの新しい映画を彼らに

223
00:07:56,900 --> 00:07:57,860
リコメンド（推薦）

224
00:07:58,230 --> 00:07:59,590
したいとする。

225
00:07:59,690 --> 00:08:00,650
あなたがする事は、これら別々の映画間で

226
00:08:00,970 --> 00:08:02,260
フィーチャーの距離が一番小さい

227
00:08:02,340 --> 00:08:03,880
5つの映画を

228
00:08:04,190 --> 00:08:05,680
探してくる、という事。

229
00:08:06,550 --> 00:08:09,220
これであなたは勧めるべき幾つかの映画を得る事が出来る。

230
00:08:10,010 --> 00:08:11,500
以上で全てのユーザー、全ての映画の

231
00:08:11,680 --> 00:08:13,350
予測レーティングを

232
00:08:13,700 --> 00:08:15,930
ベクトル化して実装し計算する

233
00:08:16,560 --> 00:08:18,130
やり方を

234
00:08:18,210 --> 00:08:20,280
理解出来ただろう、

235
00:08:20,390 --> 00:08:21,720
そして学習したフィーチャーを

236
00:08:21,920 --> 00:08:23,300
どのように用いて、

237
00:08:23,930 --> 00:08:25,360
どの映画とか商品が

238
00:08:25,480 --> 00:08:27,490
関連しているのかを探す方法も。