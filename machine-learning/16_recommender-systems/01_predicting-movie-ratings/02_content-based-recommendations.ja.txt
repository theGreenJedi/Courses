前回のビデオでは、 リコメンダーシステムの問題について議論した。 そこでは例えば、 映画の集合があって、 ユーザーの集合があって、 それぞれのユーザーが 映画の部分集合をレーティングする。 映画を星一つから 星5までとか、または星0から星5まで のように。そしてやりたい事は これらのユーザーを見る事で、 彼らがまだレーティングしていない映画について どうレーティングするかを予測したい。 このビデオでは、 リコメンダーシステムを作り上げる 最初のアプローチについて議論する。 このアプローチはコンテントベースのリコメンデーションと言われる物だ。 前回から引き続き、これがデータセットで、 ちょっと記法を再度 説明しておくと、 私はn uで、ユーザーの数を 表す事にしていた。だからそれは イコール4だ。そしてn mで 映画の数を表していた。今回は5つの映画だ。 さて、どうやってこの欠けた値を 予測出来るか？ これらの映画に、 それぞれフィーチャーの集合が あると仮定しよう。 具体的に、今回は各映画に 二つのフィーチャーがあるとしよう。 それぞれx1とx2で表す事にする。 x1はその映画がどの位 ロマンティックな映画かの 指標として。x2はどの位アクションムービーかを 測る指標とする。 だからもしLove at lastの映画を 選ぶとすると、 ロマンスのスケールは 0.9レーティングとなっているので、 とてもロマンティックな映画だが、 アクションのスケールは0なので、 映画の中にはほとんどアクションシーンが無い。 Romance foreverは1.0で、 たくさんのロマンスがあって、アクションは0.01。 良く知らんが、映画の中に ちょっとだけ車の衝突とか そういうのがあるのかもね。だからわずかにアクションがあるのみ。 飛ばしてswords vs karate(ソードvs空手)を見てみると、 それはロマンスが0の レーティングとなっているので、 ロマンスはまったく無いが、 たくさんのアクションがある。
そしてnon-stop car crashesも ほんのちょっとだけロマンスが 映画の中にあるみたいだが、 ただだいたいはアクションだ。 そしてCute puppies of loveも だいたいロマンスの映画で アクションは全く無し。 つまりこれらのようなフィーチャーがあれば、 各映画をフィーチャーのベクトルで 表現出来る。 映画1を見てみよう。 これらの映画を単に映画1, 2, 3, 4そして5とだけ呼ぶ事にする。 最初の映画は、 Love at lastだが、 そこには二つのフィーチャー、0.9と0がある。 これらがフィーチャーx1とx2で、 そしてさらに いつも通り追加のフィーチャーを足そう、 切片項である フィーチャーx0だ。これはイコール1だ。 以上をあわせると、 フィーチャーx1が得られる、 ここでこの上付き添字の1は、 それが最初の映画のフィーチャーである事を 表していて、このフィーチャーベクトルは イコール、1と、、、 ここでこの最初の1は切片項だが、 そして二つのフィーチャー、0.9と0、となる。 などなど。 つまり、Love at lastに関しては、 フィーチャーベクトルx1があり、 映画、Romance Foreverに関しては 別個のフィーチャーベクトルであるx2がある、 などなど。 そして Swords vs. karateではまた、 別のフィーチャーベクトルであるxに上付き添字5という物が対応する。 また、以前の記法と 一貫させる為に nをフィーチャーの数と する、そしてこれは x0、つまり切片項は カウントしない。 つまり、n=2だ。何故なら、 フィーチャーは二つ、x1とx2で、 それが各映画の ロマンス度合いとアクション度合いを 捕捉しているのだから。
ここで、予測を行う為に 出来る事として、こんな事が考えられる。 それは各ユーザーのレーティングを 予測する事を、 独立した線形回帰の問題と扱う事だ。 具体的には、各ユーザーjに対し パラメータベクトルである シータjを学習する、 これはこの場合、Rの3だ。 より一般的には、シータのjは Rのn+1で、 ここでnはフィーチャーの数のうち、 切片項を考慮に入れない物だ。 そしてユーザーjが ムービーiをレーティングする事を、 単にパラメータベクトルであるシータと フィーチャーx(i)の内積で予測する事とする。 具体的に例を見てみよう。 ユーザー1をとる。 この場合はAliceだ。 そしてAliceはなんらかのパラメーターのベクトル、 シータ1に関連づけられている。 そして 二番目のユーザー、Bobは 別のパラメータベクトル、シータ2に 関連づけられている。 Carolはさらに別の パラメータベクトル、シータ3に、 そしてDaveも別のパラメータベクトルシータ4に 関連づけられている。 つまり、我らは例えば Aliceが映画、Cute Puppies of loveを どう思うかなどを 予測したい。 その映画は何らかのパラメータベクトル x3を持つ事になる。 ここでこのx3は イコール、 切片項の1と 0.99と0と等しい。 さらにこの例で、 どうにかして既に、 Aliceに関するパラメータ シータ1を得ているとしよう。 どうやって得るのかについては のちほど ちゃんと説明する。 ここでは 今は単に、何らかの学習アルゴリズムで パラメータベクトルのシータ1を 学習したとしよう。 そしてその結果は 0, 5, 0だったとする。 するとこのエントリの予測は シータ1 --これはAliceのパラメータベクトル-- これに、x3の転置 -- これはCute Puppies of Love、つまり映画3のフィーチャーベクトル-- と等しく なる。 これら二つのベクトルの 内積は、 5掛ける0.99となる。 それはイコール、4.95。 だからここの値の予測値は 4.95となる。 それはなかなか良さそうな値に 見える。これが本当に パラメータベクトルのシータ1ならね。 ここまでやってきた事は、 ようするに別々の、 本質的には線形回帰を、各ユーザーに適用してきた、 という事だ。そしてAliceは あるパラメータベクトル シータ1という物を持っている事にして、 それを使って、 彼女のレーティングを どれだけロマンティックか どれだけアクションか-- その映画が -- の関数として、予測した。 そしてBob、Carol、そしてDaveは それぞれ別の 映画に関しての、 ロマンティック度合いとアクション度合いに関する 別々の線形関数を 持つ事になる。 そしてそれをもって、彼らの星のレーティングを予測する。 より正式には、 これが我らの問題を書き下した物だ。 我らの記法では、r i jは もしユーザーjが映画iを レーティングしていたら1とする。 そしてy i jはその映画のレーティングが もし存在すればその値とする。 つまり、そのユーザーが、もし実際に その映画をレーティングしていたら。 そして前のスライドで、また我らは シータjを定義した。それは 各ユーザーのパラメータだった。 そしてxiは個々の映画のフィーチャーベクトルで、 そして各ユーザーの各映画ごとに レーティングを、以下のように 予測する事が出来る。 一時的にもう一つ、 追加の記法 m jを導入しよう。 m jを、映画jをレートした ユーザーの数を示すのに用いる事にする。 この記号はこのスライドだけでしか 使わない。
さて、パラメータベクトルのシータjを 学習する為に うーん、どうやったらいいかね？ これは基本的には線形回帰の問題だ。 だから可能な手段としては、 パラメータベクトルのシータjを、 予測された値が トレーニングセットで観測されている値に データとして観測されている値に なるべく近くなるように選ぶ、という事だ。 それを書き下してみよう。 パラメータベクトルのシータjを 学習する為には、 パラメータベクトルのシータjに関して、 最小化する事の、和で --ところで和は、 ユーザーjがレーティングした 映画全てに渡って取る--
つまり、和は、以下を満たす全てのiで、 そのiとはコロン、 r ij = 1となるi全てだ。 つまりこの和のインデックスの読み方は、 これはr ij = 1となるような 全てのiに渡って 和を取る、という事。 つまりこれは、ユーザーjがレーティングした 全ての映画に渡って和を取る事になる。 そして次に、 シータj転置 xiを 計算する、これは、 ユーザーjが映画iを どうレーティングするかの予測だ。 そこから引く事のy i j。 これは実際に観測されたレーティング。そして二乗。 そして次に、ユーザーjが 実際にレーティングした映画の数で 割っておく。 つまり1/2m(j)だ。 以上で、これは 単なる最小二乗法の回帰となった。 単なる線形回帰だよね。 パラメータベクトルのシータjを、 この種の二乗誤差項を最小化するように選ぶ、という。 そしてもしお望みなら、 正規化項を足しても良い。 つまり足す事の、 ラムダ / 2m。 これは実際は2m(j)だね。だって m(j)個の手本があるみたいな物だから。 何故ならユーザーjが 複数の映画をレーティングしたら、 それはパラメータシータjをフィットする データポイントがそれだけあるみたいな物だから。 そしてここに、通常の 正規化項である、シータj kの二乗を 足そう。 いつも通り、この和は k=1からnまでに渡って取る。 だからこのシータjは n+1次元の ベクトルとなり、 前の例だとnはイコール2だったが、 より一般的にはnは 各映画の持つフィーチャーの数だ。 そしていつも通り、シータ0は正規化しない。 バイアス項は正規化しない。 何故なら和はk=1からnに渡って とっているから。 もしこれをシータjの関数として 最小化すると、 良い解が得られる、 パラメータベクトルのシータjについてとても良い推計が得られて、 それを用いてユーザーjの 映画のレーティングを予測出来る。 リコメンダーシステムの場合、 この記法をちょっと変更する。 以降の計算を簡略化する為に このm j項を取り除く。 これは結局の所、単なる定数だ。でしょ？ だからシータjの値に影響を与えずに これを削除出来る。 シータjの値が最適化で取り出せる値だった。 想像してみよう、この式全体を 持ってきて、この式全体に mjを掛けてみる、 するとその定数は取り除かれる、 そしてそれを最小化した時、 得られるシータjは掛ける前と一緒のはずだ。 だから前のスライドに書いた事を 繰り返すと、 これが最適化の目的関数だ： シータjを学習する為に、 シータjはユーザーjのパラメータだが、 そのシータjを学習する為に、この最適化も目的関数を シータjに関して最小化する。 つまりこれは、通常の二乗誤差項で、 これが正規化項だ。 さて、もちろんリコメンダーシステムを 作るときには、一人のユーザーだけの パラメータを学習させたい、という事は 無い。我らは全てのユーザーの パラメータを学習させたい。 n下付き添字uのユーザーが居るのだった。 だからこれらのパラメータ全てを 学習させたい。 だから我らがやるのは、 この最適化の目的関数に対して、 単純に追加のシグマを足すだけ。 つまりこの、ここの式は 先頭にはまた1/2があるが、 これは上にあるのと、 完全に一致する、 ただし特定の一ユーザーの シータjについてだけ、これを行う代わりに、 ユーザー全員に渡って 目的関数を足して、 そしてこの最適化の目的関数全体を 最小化する。 このコスト関数全体を最小化する。 そしてこれを シータ1, シータ2、、、、と シータn uまでの 関数として最小化すると、 各ユーザーごとに別々の パラメータベクトルが得られ、 そしてそれを用いて ユーザー全員の、 全てのn下付き添字uのユーザーの 予測を行う事が出来る。 では全てをつなげると、 この上にあるのが、 最適化の目的関数だった、 これに名前をつけよう、 Jのシータ1, 点点点 シータn u。 つまりJはいつもどおりの 最適化の目的関数で、最小化しようとしている対象。 次に、実際に最小化を 実行する為に、 最急降下法のアップデートルールを 導出すると、 これらの等式が得られる。 つまりシータjのkをとって そこから引く事の アルファ、これはラーニングレートで、掛ける事のこれらの右にある項だ。 k=0の場合とkが0で無い場合で ちょっとだけ異なる場合分けが要る。 何故なら我らの正規化項は kが0で無い時の シータjのkにだけ 存在しているからだ。 つまりシータ0を正規化しないので、 k=0とkが0以外とで ちょっとだけ異なった更新の仕方をする。 そして、例えばこの項は 最適化の目的関数の パラメータに関する単なる 偏微分に 過ぎない。でしょ？ つまり、これは単なる 最急降下法で、すでに微分は 計算済みで、それをここに代入しただけ。 もしこれらの最急降下法の アップデートが、 線形回帰のそれととても似てると 思ったなら、それはこれらが本質的には 線形回帰と同じだからだろう。 唯一の小さな違いとしては、 線形回帰なら、これらの 1/mの項があった。 それは実際は1/m(j)だが、 でも、前に 最適化の目的関数を 導出した所で、 これを取り除いていた。だからこの1/mの項が無くなっている。 だがそれ以外は、ほんとうに トレーニング手本に渡って和をとる事の 誤差掛けるx kに、 足す事の正規化項の 微分への寄与だ。 だから最急降下法を 使うとするなら、これが コスト関数Jを最小化する やり方、つまりパラメータを全て 学習する方法だ。
そしてこれらの 微分の式を使って もしお望みなら、 よりアドバンスドな最適化アルゴリズムである クラスターグラディエントとかLBFGSとか その他なんでもお持ちのアルゴリズムに代入して、 同じようにコスト関数Jを最小化する事も出来る。 以上で、本質的には 線形回帰の一種の何かを使って 別々のユーザーの別々の映画へのレーティングを 予測するやり方が分かったかな。 このアルゴリズムは コンテントベースのリコメンデーション、または コンテントベースのアプローチと呼ばれている。 何故なら個々の映画の フィーチャーが使用可能だと仮定しているからだ。 つまり我らは、これらの映画のコンテンツ（内容）が なんなのか、という事を捕捉する フィーチャーがある、という事だ。
この映画はどれくらいロマンティックか？ どのくらいアクションな映画か？ そして映画のコンテンツに関するフィーチャーを 実際に用いて予測を行っている。 でも実際には、多くの映画について、 そんなフィーチャーなんて持ってない。 またはそんなフィーチャーを全部の 映画について取得するのは とても難しい。 売ろうとしている商品ならなんでも全てに渡って取るなんて。 だから次のビデオでは、 コンテントベースじゃないリコメンダーシステムの アプローチを議論する。 それはつまり、他の誰かが これらのフィーチャー全てを、 我らのデータセットの映画全てに 与えてくれている、と仮定しない物だ。