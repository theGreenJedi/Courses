1
00:00:01,370 --> 00:00:02,420
前回のビデオでは、

2
00:00:02,740 --> 00:00:04,200
リコメンダーシステムの問題について議論した。

3
00:00:05,030 --> 00:00:06,270
そこでは例えば、

4
00:00:06,380 --> 00:00:07,810
映画の集合があって、

5
00:00:07,940 --> 00:00:09,140
ユーザーの集合があって、

6
00:00:09,810 --> 00:00:10,960
それぞれのユーザーが

7
00:00:11,670 --> 00:00:13,170
映画の部分集合をレーティングする。

8
00:00:13,370 --> 00:00:14,340
映画を星一つから

9
00:00:14,500 --> 00:00:15,460
星5までとか、または星0から星5まで

10
00:00:15,630 --> 00:00:16,830
のように。そしてやりたい事は

11
00:00:17,200 --> 00:00:18,170
これらのユーザーを見る事で、

12
00:00:18,240 --> 00:00:19,720
彼らがまだレーティングしていない映画について

13
00:00:19,910 --> 00:00:22,540
どうレーティングするかを予測したい。

14
00:00:23,530 --> 00:00:24,540
このビデオでは、

15
00:00:24,600 --> 00:00:25,950
リコメンダーシステムを作り上げる

16
00:00:26,430 --> 00:00:28,190
最初のアプローチについて議論する。

17
00:00:28,360 --> 00:00:30,100
このアプローチはコンテントベースのリコメンデーションと言われる物だ。

18
00:00:31,460 --> 00:00:32,690
前回から引き続き、これがデータセットで、

19
00:00:33,310 --> 00:00:34,470
ちょっと記法を再度

20
00:00:34,550 --> 00:00:35,780
説明しておくと、

21
00:00:36,690 --> 00:00:37,870
私はn uで、ユーザーの数を

22
00:00:38,030 --> 00:00:39,110
表す事にしていた。だからそれは

23
00:00:39,290 --> 00:00:40,990
イコール4だ。そしてn mで

24
00:00:41,990 --> 00:00:44,780
映画の数を表していた。今回は5つの映画だ。

25
00:00:47,230 --> 00:00:48,140
さて、どうやってこの欠けた値を

26
00:00:48,960 --> 00:00:50,950
予測出来るか？

27
00:00:52,490 --> 00:00:53,520
これらの映画に、

28
00:00:53,700 --> 00:00:55,500
それぞれフィーチャーの集合が

29
00:00:55,540 --> 00:00:57,460
あると仮定しよう。

30
00:00:57,910 --> 00:00:58,990
具体的に、今回は各映画に

31
00:00:59,690 --> 00:01:00,850
二つのフィーチャーがあるとしよう。

32
00:01:01,920 --> 00:01:03,500
それぞれx1とx2で表す事にする。

33
00:01:04,080 --> 00:01:05,700
x1はその映画がどの位

34
00:01:06,130 --> 00:01:07,450
ロマンティックな映画かの

35
00:01:07,650 --> 00:01:09,270
指標として。x2はどの位アクションムービーかを

36
00:01:09,810 --> 00:01:12,080
測る指標とする。

37
00:01:12,840 --> 00:01:13,700
だからもしLove at lastの映画を

38
00:01:14,470 --> 00:01:16,490
選ぶとすると、

39
00:01:16,800 --> 00:01:17,960
ロマンスのスケールは

40
00:01:18,030 --> 00:01:19,190
0.9レーティングとなっているので、

41
00:01:19,260 --> 00:01:20,850
とてもロマンティックな映画だが、

42
00:01:20,920 --> 00:01:22,400
アクションのスケールは0なので、

43
00:01:22,520 --> 00:01:24,390
映画の中にはほとんどアクションシーンが無い。

44
00:01:24,540 --> 00:01:25,860
Romance foreverは1.0で、

45
00:01:26,230 --> 00:01:27,610
たくさんのロマンスがあって、アクションは0.01。

46
00:01:27,860 --> 00:01:29,790
良く知らんが、映画の中に

47
00:01:30,700 --> 00:01:32,650
ちょっとだけ車の衝突とか

48
00:01:33,630 --> 00:01:35,580
そういうのがあるのかもね。だからわずかにアクションがあるのみ。

49
00:01:35,610 --> 00:01:36,760
飛ばしてswords vs karate(ソードvs空手)を見てみると、

50
00:01:37,860 --> 00:01:39,630
それはロマンスが0の

51
00:01:39,870 --> 00:01:41,110
レーティングとなっているので、

52
00:01:41,520 --> 00:01:42,780
ロマンスはまったく無いが、

53
00:01:43,250 --> 00:01:46,040
たくさんのアクションがある。
そしてnon-stop car crashesも

54
00:01:46,300 --> 00:01:47,120
ほんのちょっとだけロマンスが

55
00:01:47,220 --> 00:01:48,390
映画の中にあるみたいだが、

56
00:01:48,500 --> 00:01:49,800
ただだいたいはアクションだ。

57
00:01:50,460 --> 00:01:51,560
そしてCute puppies of loveも

58
00:01:51,680 --> 00:01:52,730
だいたいロマンスの映画で

59
00:01:53,510 --> 00:01:54,410
アクションは全く無し。

60
00:01:55,990 --> 00:01:57,150
つまりこれらのようなフィーチャーがあれば、

61
00:01:57,550 --> 00:01:59,220
各映画をフィーチャーのベクトルで

62
00:01:59,800 --> 00:02:01,510
表現出来る。

63
00:02:02,380 --> 00:02:03,810
映画1を見てみよう。

64
00:02:04,020 --> 00:02:06,210
これらの映画を単に映画1, 2, 3, 4そして5とだけ呼ぶ事にする。

65
00:02:06,630 --> 00:02:08,180
最初の映画は、

66
00:02:08,520 --> 00:02:09,810
Love at lastだが、

67
00:02:10,170 --> 00:02:11,710
そこには二つのフィーチャー、0.9と0がある。

68
00:02:12,180 --> 00:02:12,950
これらがフィーチャーx1とx2で、

69
00:02:13,380 --> 00:02:16,170
そしてさらに

70
00:02:16,340 --> 00:02:17,270
いつも通り追加のフィーチャーを足そう、

71
00:02:17,790 --> 00:02:18,780
切片項である

72
00:02:19,350 --> 00:02:21,640
フィーチャーx0だ。これはイコール1だ。

73
00:02:22,680 --> 00:02:23,810
以上をあわせると、

74
00:02:24,700 --> 00:02:26,150
フィーチャーx1が得られる、

75
00:02:26,970 --> 00:02:28,420
ここでこの上付き添字の1は、

76
00:02:28,510 --> 00:02:29,430
それが最初の映画のフィーチャーである事を

77
00:02:29,770 --> 00:02:30,720
表していて、このフィーチャーベクトルは

78
00:02:30,980 --> 00:02:32,520
イコール、1と、、、

79
00:02:33,190 --> 00:02:34,880
ここでこの最初の1は切片項だが、

80
00:02:35,740 --> 00:02:37,010
そして二つのフィーチャー、0.9と0、となる。

81
00:02:37,260 --> 00:02:39,330
などなど。

82
00:02:40,370 --> 00:02:41,360
つまり、Love at lastに関しては、

83
00:02:41,550 --> 00:02:43,470
フィーチャーベクトルx1があり、

84
00:02:44,480 --> 00:02:46,220
映画、Romance Foreverに関しては

85
00:02:46,340 --> 00:02:47,510
別個のフィーチャーベクトルであるx2がある、

86
00:02:47,800 --> 00:02:49,310
などなど。

87
00:02:49,380 --> 00:02:50,780
そして Swords vs. karateではまた、

88
00:02:51,510 --> 00:02:54,050
別のフィーチャーベクトルであるxに上付き添字5という物が対応する。

89
00:02:56,150 --> 00:02:57,460
また、以前の記法と

90
00:02:57,680 --> 00:02:59,090
一貫させる為に

91
00:02:59,300 --> 00:03:00,220
nをフィーチャーの数と

92
00:03:00,490 --> 00:03:02,130
する、そしてこれは

93
00:03:02,360 --> 00:03:03,530
x0、つまり切片項は

94
00:03:03,810 --> 00:03:05,320
カウントしない。

95
00:03:05,420 --> 00:03:06,600
つまり、n=2だ。何故なら、

96
00:03:06,790 --> 00:03:08,180
フィーチャーは二つ、x1とx2で、

97
00:03:08,890 --> 00:03:10,140
それが各映画の

98
00:03:10,640 --> 00:03:11,980
ロマンス度合いとアクション度合いを

99
00:03:12,630 --> 00:03:14,270
捕捉しているのだから。
ここで、予測を行う為に

100
00:03:14,560 --> 00:03:17,930
出来る事として、こんな事が考えられる。

101
00:03:19,230 --> 00:03:20,980
それは各ユーザーのレーティングを

102
00:03:21,160 --> 00:03:22,340
予測する事を、

103
00:03:23,250 --> 00:03:26,210
独立した線形回帰の問題と扱う事だ。

104
00:03:26,440 --> 00:03:27,660
具体的には、各ユーザーjに対し

105
00:03:27,920 --> 00:03:29,170
パラメータベクトルである

106
00:03:29,270 --> 00:03:30,860
シータjを学習する、

107
00:03:31,340 --> 00:03:33,030
これはこの場合、Rの3だ。

108
00:03:33,540 --> 00:03:35,730
より一般的には、シータのjは

109
00:03:35,950 --> 00:03:37,960
Rのn+1で、

110
00:03:38,340 --> 00:03:39,460
ここでnはフィーチャーの数のうち、

111
00:03:39,700 --> 00:03:42,170
切片項を考慮に入れない物だ。

112
00:03:42,440 --> 00:03:43,880
そしてユーザーjが

113
00:03:44,050 --> 00:03:45,780
ムービーiをレーティングする事を、

114
00:03:46,000 --> 00:03:47,390
単にパラメータベクトルであるシータと

115
00:03:47,860 --> 00:03:50,590
フィーチャーx(i)の内積で予測する事とする。

116
00:03:51,830 --> 00:03:53,680
具体的に例を見てみよう。

117
00:03:55,130 --> 00:03:56,700
ユーザー1をとる。

118
00:03:59,600 --> 00:04:01,120
この場合はAliceだ。

119
00:04:01,380 --> 00:04:02,700
そしてAliceはなんらかのパラメーターのベクトル、

120
00:04:02,830 --> 00:04:03,990
シータ1に関連づけられている。

121
00:04:04,810 --> 00:04:06,210
そして

122
00:04:06,520 --> 00:04:07,610
二番目のユーザー、Bobは

123
00:04:07,720 --> 00:04:08,600
別のパラメータベクトル、シータ2に

124
00:04:08,970 --> 00:04:10,290
関連づけられている。

125
00:04:10,800 --> 00:04:12,190
Carolはさらに別の

126
00:04:12,300 --> 00:04:13,360
パラメータベクトル、シータ3に、

127
00:04:13,660 --> 00:04:14,790
そしてDaveも別のパラメータベクトルシータ4に

128
00:04:15,750 --> 00:04:17,670
関連づけられている。

129
00:04:18,090 --> 00:04:18,990
つまり、我らは例えば

130
00:04:19,320 --> 00:04:21,040
Aliceが映画、Cute Puppies of loveを

131
00:04:21,240 --> 00:04:22,450
どう思うかなどを

132
00:04:22,690 --> 00:04:24,640
予測したい。

133
00:04:24,810 --> 00:04:25,670
その映画は何らかのパラメータベクトル

134
00:04:26,810 --> 00:04:29,180
x3を持つ事になる。

135
00:04:29,410 --> 00:04:30,400
ここでこのx3は

136
00:04:30,430 --> 00:04:32,460
イコール、

137
00:04:32,650 --> 00:04:34,580
切片項の1と

138
00:04:34,800 --> 00:04:37,220
0.99と0と等しい。

139
00:04:38,560 --> 00:04:39,680
さらにこの例で、

140
00:04:39,810 --> 00:04:41,040
どうにかして既に、

141
00:04:41,190 --> 00:04:42,890
Aliceに関するパラメータ

142
00:04:43,290 --> 00:04:44,600
シータ1を得ているとしよう。

143
00:04:44,830 --> 00:04:45,700
どうやって得るのかについては

144
00:04:45,850 --> 00:04:47,560
のちほど

145
00:04:47,800 --> 00:04:48,520
ちゃんと説明する。

146
00:04:48,600 --> 00:04:50,530
ここでは

147
00:04:50,710 --> 00:04:52,000
今は単に、何らかの学習アルゴリズムで

148
00:04:52,150 --> 00:04:53,560
パラメータベクトルのシータ1を

149
00:04:54,040 --> 00:04:55,040
学習したとしよう。

150
00:04:55,180 --> 00:04:56,970
そしてその結果は

151
00:04:57,120 --> 00:04:59,260
0, 5, 0だったとする。

152
00:05:00,150 --> 00:05:02,010
するとこのエントリの予測は

153
00:05:02,270 --> 00:05:04,130
シータ1

154
00:05:04,260 --> 00:05:06,930
--これはAliceのパラメータベクトル--

155
00:05:07,440 --> 00:05:08,760
これに、x3の転置

156
00:05:09,620 --> 00:05:11,450
-- これはCute Puppies of Love、つまり映画3のフィーチャーベクトル--

157
00:05:11,620 --> 00:05:13,730
と等しく

158
00:05:14,170 --> 00:05:16,050
なる。

159
00:05:16,250 --> 00:05:17,200
これら二つのベクトルの

160
00:05:17,470 --> 00:05:18,470
内積は、

161
00:05:19,910 --> 00:05:21,780
5掛ける0.99となる。

162
00:05:23,980 --> 00:05:26,340
それはイコール、4.95。

163
00:05:27,360 --> 00:05:28,940
だからここの値の予測値は

164
00:05:29,130 --> 00:05:30,930
4.95となる。

165
00:05:31,970 --> 00:05:33,110
それはなかなか良さそうな値に

166
00:05:33,230 --> 00:05:34,660
見える。これが本当に

167
00:05:36,130 --> 00:05:37,830
パラメータベクトルのシータ1ならね。

168
00:05:38,950 --> 00:05:40,290
ここまでやってきた事は、

169
00:05:40,520 --> 00:05:42,710
ようするに別々の、

170
00:05:42,930 --> 00:05:44,480
本質的には線形回帰を、各ユーザーに適用してきた、

171
00:05:44,760 --> 00:05:46,020
という事だ。そしてAliceは

172
00:05:46,230 --> 00:05:47,610
あるパラメータベクトル

173
00:05:47,820 --> 00:05:48,880
シータ1という物を持っている事にして、

174
00:05:49,160 --> 00:05:50,400
それを使って、

175
00:05:51,410 --> 00:05:52,380
彼女のレーティングを

176
00:05:53,310 --> 00:05:54,770
どれだけロマンティックか

177
00:05:54,950 --> 00:05:56,190
どれだけアクションか-- その映画が --

178
00:05:56,470 --> 00:05:57,540
の関数として、予測した。

179
00:05:58,210 --> 00:05:59,600
そしてBob、Carol、そしてDaveは

180
00:05:59,740 --> 00:06:01,010
それぞれ別の

181
00:06:01,220 --> 00:06:03,170
映画に関しての、

182
00:06:03,330 --> 00:06:04,700
ロマンティック度合いとアクション度合いに関する

183
00:06:05,220 --> 00:06:06,510
別々の線形関数を

184
00:06:07,580 --> 00:06:08,030
持つ事になる。

185
00:06:08,820 --> 00:06:11,300
そしてそれをもって、彼らの星のレーティングを予測する。

186
00:06:14,820 --> 00:06:16,330
より正式には、

187
00:06:16,610 --> 00:06:17,920
これが我らの問題を書き下した物だ。

188
00:06:19,260 --> 00:06:20,320
我らの記法では、r i jは

189
00:06:20,690 --> 00:06:21,600
もしユーザーjが映画iを

190
00:06:21,680 --> 00:06:22,910
レーティングしていたら1とする。

191
00:06:23,380 --> 00:06:24,630
そしてy i jはその映画のレーティングが

192
00:06:25,850 --> 00:06:28,010
もし存在すればその値とする。

193
00:06:29,540 --> 00:06:30,520
つまり、そのユーザーが、もし実際に

194
00:06:31,030 --> 00:06:32,830
その映画をレーティングしていたら。

195
00:06:33,330 --> 00:06:34,360
そして前のスライドで、また我らは

196
00:06:34,650 --> 00:06:36,540
シータjを定義した。それは

197
00:06:36,740 --> 00:06:38,790
各ユーザーのパラメータだった。

198
00:06:39,150 --> 00:06:40,830
そしてxiは個々の映画のフィーチャーベクトルで、

199
00:06:41,220 --> 00:06:42,370
そして各ユーザーの各映画ごとに

200
00:06:42,850 --> 00:06:43,780
レーティングを、以下のように

201
00:06:44,300 --> 00:06:45,620
予測する事が出来る。

202
00:06:47,230 --> 00:06:49,560
一時的にもう一つ、

203
00:06:49,650 --> 00:06:51,600
追加の記法

204
00:06:51,860 --> 00:06:53,530
m jを導入しよう。

205
00:06:53,760 --> 00:06:54,980
m jを、映画jをレートした

206
00:06:55,070 --> 00:06:56,140
ユーザーの数を示すのに用いる事にする。

207
00:06:56,400 --> 00:06:57,350
この記号はこのスライドだけでしか

208
00:06:57,580 --> 00:06:59,890
使わない。
さて、パラメータベクトルのシータjを

209
00:07:00,160 --> 00:07:01,700
学習する為に

210
00:07:01,760 --> 00:07:03,720
うーん、どうやったらいいかね？

211
00:07:04,410 --> 00:07:06,380
これは基本的には線形回帰の問題だ。

212
00:07:06,930 --> 00:07:07,980
だから可能な手段としては、

213
00:07:08,290 --> 00:07:09,810
パラメータベクトルのシータjを、

214
00:07:10,520 --> 00:07:12,100
予測された値が

215
00:07:12,570 --> 00:07:13,620
トレーニングセットで観測されている値に

216
00:07:13,980 --> 00:07:15,280
データとして観測されている値に

217
00:07:15,800 --> 00:07:18,760
なるべく近くなるように選ぶ、という事だ。

218
00:07:19,900 --> 00:07:21,390
それを書き下してみよう。

219
00:07:22,290 --> 00:07:24,320
パラメータベクトルのシータjを

220
00:07:24,380 --> 00:07:26,960
学習する為には、

221
00:07:27,170 --> 00:07:28,510
パラメータベクトルのシータjに関して、

222
00:07:29,400 --> 00:07:30,360
最小化する事の、和で

223
00:07:31,920 --> 00:07:32,860
--ところで和は、

224
00:07:33,290 --> 00:07:34,900
ユーザーjがレーティングした

225
00:07:35,240 --> 00:07:36,930
映画全てに渡って取る--
つまり、和は、以下を満たす全てのiで、

226
00:07:37,270 --> 00:07:38,290
そのiとはコロン、

227
00:07:39,100 --> 00:07:42,000
r ij = 1となるi全てだ。

228
00:07:43,870 --> 00:07:45,970
つまりこの和のインデックスの読み方は、

229
00:07:46,370 --> 00:07:48,280
これはr ij = 1となるような

230
00:07:48,470 --> 00:07:49,550
全てのiに渡って

231
00:07:49,780 --> 00:07:51,180
和を取る、という事。

232
00:07:51,210 --> 00:07:52,470
つまりこれは、ユーザーjがレーティングした

233
00:07:52,560 --> 00:07:54,670
全ての映画に渡って和を取る事になる。

234
00:07:56,230 --> 00:07:57,000
そして次に、

235
00:07:58,150 --> 00:07:59,910
シータj転置 xiを

236
00:08:01,810 --> 00:08:04,450
計算する、これは、

237
00:08:04,610 --> 00:08:06,740
ユーザーjが映画iを

238
00:08:07,030 --> 00:08:08,390
どうレーティングするかの予測だ。

239
00:08:09,230 --> 00:08:10,960
そこから引く事のy i j。

240
00:08:11,700 --> 00:08:13,700
これは実際に観測されたレーティング。そして二乗。

241
00:08:15,190 --> 00:08:16,790
そして次に、ユーザーjが

242
00:08:17,260 --> 00:08:18,650
実際にレーティングした映画の数で

243
00:08:19,040 --> 00:08:20,990
割っておく。

244
00:08:21,380 --> 00:08:23,910
つまり1/2m(j)だ。

245
00:08:24,000 --> 00:08:25,460
以上で、これは

246
00:08:25,690 --> 00:08:27,620
単なる最小二乗法の回帰となった。

247
00:08:28,210 --> 00:08:29,550
単なる線形回帰だよね。

248
00:08:30,170 --> 00:08:31,170
パラメータベクトルのシータjを、

249
00:08:31,320 --> 00:08:34,480
この種の二乗誤差項を最小化するように選ぶ、という。

250
00:08:34,510 --> 00:08:35,090
そしてもしお望みなら、

251
00:08:36,330 --> 00:08:39,580
正規化項を足しても良い。

252
00:08:39,980 --> 00:08:41,870
つまり足す事の、 ラムダ / 2m。

253
00:08:43,780 --> 00:08:44,930
これは実際は2m(j)だね。だって

254
00:08:45,420 --> 00:08:47,760
m(j)個の手本があるみたいな物だから。

255
00:08:47,920 --> 00:08:49,330
何故ならユーザーjが

256
00:08:49,650 --> 00:08:50,910
複数の映画をレーティングしたら、

257
00:08:51,050 --> 00:08:53,340
それはパラメータシータjをフィットする

258
00:08:53,680 --> 00:08:55,790
データポイントがそれだけあるみたいな物だから。

259
00:08:56,650 --> 00:08:57,390
そしてここに、通常の

260
00:08:58,340 --> 00:09:00,260
正規化項である、シータj kの二乗を

261
00:09:00,460 --> 00:09:02,530
足そう。

262
00:09:03,110 --> 00:09:04,270
いつも通り、この和は

263
00:09:04,840 --> 00:09:05,980
k=1からnまでに渡って取る。

264
00:09:06,330 --> 00:09:08,670
だからこのシータjは

265
00:09:08,880 --> 00:09:10,050
n+1次元の

266
00:09:10,520 --> 00:09:12,400
ベクトルとなり、

267
00:09:12,620 --> 00:09:14,630
前の例だとnはイコール2だったが、

268
00:09:15,320 --> 00:09:17,090
より一般的にはnは

269
00:09:17,260 --> 00:09:20,980
各映画の持つフィーチャーの数だ。

270
00:09:21,730 --> 00:09:22,270
そしていつも通り、シータ0は正規化しない。

271
00:09:22,390 --> 00:09:23,710
バイアス項は正規化しない。

272
00:09:23,910 --> 00:09:24,750
何故なら和はk=1からnに渡って

273
00:09:24,930 --> 00:09:28,590
とっているから。

274
00:09:28,760 --> 00:09:30,430
もしこれをシータjの関数として

275
00:09:30,570 --> 00:09:31,780
最小化すると、

276
00:09:31,900 --> 00:09:33,010
良い解が得られる、

277
00:09:33,180 --> 00:09:35,330
パラメータベクトルのシータjについてとても良い推計が得られて、

278
00:09:36,490 --> 00:09:37,200
それを用いてユーザーjの

279
00:09:37,940 --> 00:09:39,460
映画のレーティングを予測出来る。

280
00:09:40,820 --> 00:09:42,250
リコメンダーシステムの場合、

281
00:09:42,520 --> 00:09:44,140
この記法をちょっと変更する。

282
00:09:44,500 --> 00:09:46,130
以降の計算を簡略化する為に

283
00:09:46,690 --> 00:09:48,440
このm j項を取り除く。

284
00:09:49,570 --> 00:09:50,720
これは結局の所、単なる定数だ。でしょ？

285
00:09:50,970 --> 00:09:52,140
だからシータjの値に影響を与えずに

286
00:09:53,000 --> 00:09:54,310
これを削除出来る。

287
00:09:54,430 --> 00:09:55,840
シータjの値が最適化で取り出せる値だった。

288
00:09:56,010 --> 00:09:57,030
想像してみよう、この式全体を

289
00:09:57,220 --> 00:09:58,850
持ってきて、この式全体に

290
00:09:59,010 --> 00:10:00,290
mjを掛けてみる、

291
00:10:00,870 --> 00:10:02,540
するとその定数は取り除かれる、

292
00:10:02,950 --> 00:10:04,110
そしてそれを最小化した時、

293
00:10:04,200 --> 00:10:06,590
得られるシータjは掛ける前と一緒のはずだ。

294
00:10:06,710 --> 00:10:07,780
だから前のスライドに書いた事を

295
00:10:08,440 --> 00:10:10,060
繰り返すと、

296
00:10:10,340 --> 00:10:12,250
これが最適化の目的関数だ：

297
00:10:12,580 --> 00:10:13,620
シータjを学習する為に、

298
00:10:13,990 --> 00:10:15,080
シータjはユーザーjのパラメータだが、

299
00:10:15,790 --> 00:10:17,570
そのシータjを学習する為に、この最適化も目的関数を

300
00:10:17,770 --> 00:10:19,820
シータjに関して最小化する。

301
00:10:20,100 --> 00:10:21,360
つまりこれは、通常の二乗誤差項で、

302
00:10:21,720 --> 00:10:24,830
これが正規化項だ。

303
00:10:26,050 --> 00:10:27,410
さて、もちろんリコメンダーシステムを

304
00:10:27,690 --> 00:10:28,790
作るときには、一人のユーザーだけの

305
00:10:29,030 --> 00:10:29,800
パラメータを学習させたい、という事は

306
00:10:30,420 --> 00:10:31,500
無い。我らは全てのユーザーの

307
00:10:31,650 --> 00:10:33,140
パラメータを学習させたい。

308
00:10:33,490 --> 00:10:35,640
n下付き添字uのユーザーが居るのだった。

309
00:10:35,760 --> 00:10:36,730
だからこれらのパラメータ全てを

310
00:10:36,950 --> 00:10:38,920
学習させたい。

311
00:10:39,060 --> 00:10:39,830
だから我らがやるのは、

312
00:10:40,140 --> 00:10:42,320
この最適化の目的関数に対して、

313
00:10:42,500 --> 00:10:45,480
単純に追加のシグマを足すだけ。

314
00:10:45,800 --> 00:10:47,610
つまりこの、ここの式は

315
00:10:48,410 --> 00:10:49,200
先頭にはまた1/2があるが、

316
00:10:49,240 --> 00:10:50,510
これは上にあるのと、

317
00:10:50,780 --> 00:10:52,520
完全に一致する、

318
00:10:52,950 --> 00:10:53,980
ただし特定の一ユーザーの

319
00:10:54,090 --> 00:10:55,670
シータjについてだけ、これを行う代わりに、

320
00:10:55,960 --> 00:10:57,270
ユーザー全員に渡って

321
00:10:57,680 --> 00:10:59,340
目的関数を足して、

322
00:10:59,490 --> 00:11:00,940
そしてこの最適化の目的関数全体を

323
00:11:01,260 --> 00:11:03,700
最小化する。

324
00:11:04,320 --> 00:11:05,570
このコスト関数全体を最小化する。

325
00:11:06,730 --> 00:11:09,200
そしてこれを

326
00:11:09,380 --> 00:11:10,560
シータ1, シータ2、、、、と

327
00:11:11,360 --> 00:11:12,400
シータn uまでの

328
00:11:12,600 --> 00:11:14,130
関数として最小化すると、

329
00:11:14,270 --> 00:11:15,750
各ユーザーごとに別々の

330
00:11:16,030 --> 00:11:17,340
パラメータベクトルが得られ、

331
00:11:17,450 --> 00:11:18,720
そしてそれを用いて

332
00:11:19,090 --> 00:11:20,460
ユーザー全員の、

333
00:11:20,530 --> 00:11:21,610
全てのn下付き添字uのユーザーの

334
00:11:21,720 --> 00:11:23,150
予測を行う事が出来る。

335
00:11:24,520 --> 00:11:26,560
では全てをつなげると、

336
00:11:27,180 --> 00:11:28,730
この上にあるのが、

337
00:11:28,880 --> 00:11:29,940
最適化の目的関数だった、

338
00:11:30,170 --> 00:11:31,070
これに名前をつけよう、

339
00:11:31,930 --> 00:11:33,480
Jのシータ1, 点点点

340
00:11:33,630 --> 00:11:35,520
シータn u。

341
00:11:36,050 --> 00:11:37,280
つまりJはいつもどおりの

342
00:11:37,590 --> 00:11:39,830
最適化の目的関数で、最小化しようとしている対象。

343
00:11:41,330 --> 00:11:42,500
次に、実際に最小化を

344
00:11:42,880 --> 00:11:44,310
実行する為に、

345
00:11:44,500 --> 00:11:45,840
最急降下法のアップデートルールを

346
00:11:46,150 --> 00:11:47,410
導出すると、

347
00:11:47,530 --> 00:11:48,720
これらの等式が得られる。

348
00:11:49,900 --> 00:11:51,300
つまりシータjのkをとって

349
00:11:51,750 --> 00:11:53,310
そこから引く事の

350
00:11:53,430 --> 00:11:56,190
アルファ、これはラーニングレートで、掛ける事のこれらの右にある項だ。

351
00:11:56,280 --> 00:11:57,540
k=0の場合とkが0で無い場合で

352
00:11:58,160 --> 00:11:59,660
ちょっとだけ異なる場合分けが要る。

353
00:11:59,840 --> 00:12:01,460
何故なら我らの正規化項は

354
00:12:01,960 --> 00:12:04,380
kが0で無い時の

355
00:12:04,910 --> 00:12:06,430
シータjのkにだけ

356
00:12:06,610 --> 00:12:07,690
存在しているからだ。

357
00:12:07,830 --> 00:12:09,470
つまりシータ0を正規化しないので、

358
00:12:10,090 --> 00:12:11,610
k=0とkが0以外とで

359
00:12:12,270 --> 00:12:13,580
ちょっとだけ異なった更新の仕方をする。

360
00:12:14,680 --> 00:12:16,080
そして、例えばこの項は

361
00:12:16,250 --> 00:12:18,090
最適化の目的関数の

362
00:12:18,520 --> 00:12:20,790
パラメータに関する単なる

363
00:12:21,090 --> 00:12:24,300
偏微分に

364
00:12:25,350 --> 00:12:28,270
過ぎない。でしょ？

365
00:12:28,790 --> 00:12:30,280
つまり、これは単なる

366
00:12:30,680 --> 00:12:33,000
最急降下法で、すでに微分は

367
00:12:33,230 --> 00:12:35,440
計算済みで、それをここに代入しただけ。

368
00:12:36,560 --> 00:12:39,580
もしこれらの最急降下法の

369
00:12:40,570 --> 00:12:41,810
アップデートが、

370
00:12:41,980 --> 00:12:42,870
線形回帰のそれととても似てると

371
00:12:43,050 --> 00:12:44,700
思ったなら、それはこれらが本質的には

372
00:12:44,880 --> 00:12:47,250
線形回帰と同じだからだろう。

373
00:12:48,190 --> 00:12:49,510
唯一の小さな違いとしては、

374
00:12:49,780 --> 00:12:51,120
線形回帰なら、これらの

375
00:12:51,580 --> 00:12:52,600
1/mの項があった。

376
00:12:52,990 --> 00:12:54,710
それは実際は1/m(j)だが、

377
00:12:54,810 --> 00:12:56,770
でも、前に

378
00:12:57,550 --> 00:12:59,230
最適化の目的関数を

379
00:12:59,370 --> 00:13:00,780
導出した所で、

380
00:13:01,270 --> 00:13:03,540
これを取り除いていた。だからこの1/mの項が無くなっている。

381
00:13:04,440 --> 00:13:05,880
だがそれ以外は、ほんとうに

382
00:13:06,080 --> 00:13:08,350
トレーニング手本に渡って和をとる事の

383
00:13:08,530 --> 00:13:09,890
誤差掛けるx kに、

384
00:13:10,230 --> 00:13:13,390
足す事の正規化項の

385
00:13:14,900 --> 00:13:16,550
微分への寄与だ。

386
00:13:18,120 --> 00:13:19,040
だから最急降下法を

387
00:13:19,200 --> 00:13:20,360
使うとするなら、これが

388
00:13:20,680 --> 00:13:22,140
コスト関数Jを最小化する

389
00:13:22,440 --> 00:13:23,880
やり方、つまりパラメータを全て

390
00:13:24,110 --> 00:13:25,490
学習する方法だ。
そしてこれらの

391
00:13:25,640 --> 00:13:26,980
微分の式を使って

392
00:13:27,090 --> 00:13:28,240
もしお望みなら、

393
00:13:28,440 --> 00:13:29,710
よりアドバンスドな最適化アルゴリズムである

394
00:13:30,290 --> 00:13:31,710
クラスターグラディエントとかLBFGSとか

395
00:13:31,810 --> 00:13:33,730
その他なんでもお持ちのアルゴリズムに代入して、

396
00:13:33,940 --> 00:13:35,930
同じようにコスト関数Jを最小化する事も出来る。

397
00:13:37,360 --> 00:13:38,450
以上で、本質的には

398
00:13:38,750 --> 00:13:40,510
線形回帰の一種の何かを使って

399
00:13:41,000 --> 00:13:42,820
別々のユーザーの別々の映画へのレーティングを

400
00:13:42,950 --> 00:13:45,460
予測するやり方が分かったかな。

401
00:13:46,350 --> 00:13:47,510
このアルゴリズムは

402
00:13:48,030 --> 00:13:49,930
コンテントベースのリコメンデーション、または

403
00:13:50,040 --> 00:13:51,980
コンテントベースのアプローチと呼ばれている。

404
00:13:52,130 --> 00:13:53,200
何故なら個々の映画の

405
00:13:53,650 --> 00:13:55,430
フィーチャーが使用可能だと仮定しているからだ。

406
00:13:56,150 --> 00:13:57,330
つまり我らは、これらの映画のコンテンツ（内容）が

407
00:13:57,490 --> 00:13:58,610
なんなのか、という事を捕捉する

408
00:13:58,700 --> 00:14:00,260
フィーチャーがある、という事だ。
この映画はどれくらいロマンティックか？

409
00:14:01,280 --> 00:14:03,050
どのくらいアクションな映画か？

410
00:14:03,430 --> 00:14:04,690
そして映画のコンテンツに関するフィーチャーを

411
00:14:04,780 --> 00:14:06,910
実際に用いて予測を行っている。

412
00:14:08,350 --> 00:14:09,770
でも実際には、多くの映画について、

413
00:14:09,920 --> 00:14:11,300
そんなフィーチャーなんて持ってない。

414
00:14:11,820 --> 00:14:13,630
またはそんなフィーチャーを全部の

415
00:14:13,850 --> 00:14:14,970
映画について取得するのは

416
00:14:15,050 --> 00:14:16,160
とても難しい。

417
00:14:16,460 --> 00:14:17,800
売ろうとしている商品ならなんでも全てに渡って取るなんて。

418
00:14:18,880 --> 00:14:20,430
だから次のビデオでは、

419
00:14:20,590 --> 00:14:21,530
コンテントベースじゃないリコメンダーシステムの

420
00:14:22,010 --> 00:14:23,290
アプローチを議論する。

421
00:14:23,570 --> 00:14:24,710
それはつまり、他の誰かが

422
00:14:24,980 --> 00:14:26,090
これらのフィーチャー全てを、

423
00:14:26,670 --> 00:14:28,420
我らのデータセットの映画全てに

424
00:14:28,880 --> 00:14:30,300
与えてくれている、と仮定しない物だ。