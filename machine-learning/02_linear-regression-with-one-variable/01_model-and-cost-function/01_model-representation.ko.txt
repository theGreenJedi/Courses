우리의 첫번째 학습 알고리즘인 선형 회귀에 대해서
배울 것입니다. 여러분은 이 비디오에서 모델의 구성에 대해 배우고 더 중요한 지도 학습의 전체적인 과정에 대해 볼 것입니다. 흥미로운 예제로 집세에 대한 예측을 해 봅시다. Oregon과 Portland 도시의 주택 가격 데이터를 이용할 것입니다. 주택 자료를 표시해보도록 하겠습니다 그리고 제가 다른 크기, 다른 가격 범위의 
자료를 표시해보도록 하겠습니다 집을 파려고 하는 친구에게 
이 자료를 준다고 가정하고, 친구의 집 사이즈가 
1250 평방피트라고 했을 때, 당신이 얼마에 팔 수 있는지를 
친구에게 알려준다고 가정해봅시다. 당신이 할 수 있는 한가지 일은 모형에 맞춰보는 것 입니다.
자료에 일직선을 맞춰볼 수 있습니다. 그리고 이 선에 근거해서 
당신은 친구에게 집을 220,000달러에 팔 수 있다고 
말해줄 수 있습니다. 그래서 이 것이 지도 학습 알고리즘의 예시입니다. 
그리고 이 것이 ‘지도 학습’이라고 불리는 이유는 당신의 예시에 “적합한 답”을 주기 때문입니다.
다시 말해, 어떤 것이 실제의 집인지, 어떤 것이 우리의 자료에서 
각각의 집이 어떤 가격에 팔렸는지에 대해 말하고 있고, 게다가, 
이 것은 실제 수치의 결과, 다시 말해 가격을 예측하는 회귀라는 의미의 
회기 문제의 예시입니다. 그리고 다른 대부분의 감독학습의 형태는 분류문제로 불리는데 예를들면 암종양을 찾을때 그게 악성인지 아닌지에 대한 결정을 내리는 것과 같은 이산값을 예측하는 문제같은 것입니다. 그래서 이것은 0-1의 이산값입니다. 공식적으로, 감독학습에서 우리는 데이터셋을 갖고 있고 이 데이터셋을 우리는 학습셋이라고 부릅니다. 주택 가격의 예제에서 우리는 서로 다른 주택 가격의 학습셋을 가지고 있고, 우리가 할 일은 이 데이터로부터 어떻게 주택 가격을 예측할 지 학습시키는 것입니다. 이번 강의내내 사용할 표기법을 정의해봅시다. 우리는 꽤 많은 기호를 정의할 겁니다. 당장 모든 기호를 외울 필요는 없지만 강의 진행과정에서 유용하고 편리한 표기법이 될 것입니다. 저는 이번 강좌 전체에서 소문자 m을 학습예제의 수를 나타내는데 사용할 것입니다. 만약 제가 가지고 있는 이 데이터셋에서, 47줄의 이 테이블이 있다고합시다. 저는 47개의 학습 예제를 가지고 있고 따라서 m은 47입니다. 소문자 x는 종종 특징(feature)이라고 부르는 입력 변수를 표시하기 위해 사용합니다. x는 여기가 될 것이고, 그것이 입력 feature일 것입니다. 그리고 y는 출력값이나 예측하려하는 목표변수를 표기하는데 사용할 것이며 여기 두 번째 열이 그것입니다. (x, y)는 하나의 학습예제를 표기하는데 사용할 것입니다. 이 표에서 한 줄은 특정한 하나의 학습예제와 대응되며 (x(i), y(i))는 i번째 학습예제를 의미하도록 할 것입니다. 여기 써져있는 위첨자 i는 지수가 아닙니다. 이 (x(i), y(i))의 괄호에서 위첨자 i는 그냥 예제셋에서 몇번째인지, 표에서 몇 번째 줄인지를 말하는 것일 뿐입니다. 그래서 이것은 x의 i제곱, y의 i제곱이 아닙니다. 대신에 (x(i), y(i))는 표의 i번째를 말합니다. 예를 들면, x(1)은 첫 번째 학습예제의 입력값을 말하며 그것은 2104입니다. 첫 번째 행에서 x는 이것입니다. x(2)는 1416입니다. 그게 두 번째고, y(1)은 460이 될 것입니다. 제 첫 번째 훈련예시의 y값이고 이 말은 (1)이 나타내는 의미와 같습니다. 
언급한대로, 때때로 저는 당신에게 이와 같은 질문으로 
이해하고 있는지를 체크할 것이고, 이 비디오에서 몇 초 정도 객관식의 문제가 
화면에 뜰 것입니다. 그럴 때는 마우스를 사용해서 
적합한 답을 선택해주세요. 훈련집합을 통해 배우게 될 것은, 
이 지도 학습 알고리즘이 어떻게 돌아가느냐에 대한 것 입니다. 우리는 지금까지 주택 가격 같은 
훈련집합에 대해 배웠고, 우리의 지도 알고리즘에 사용할 것입니다. 
지도 알고리즘은 결과 값으로 가는데 보통 이 값은 소문자h로 나타나며 h는 가설을 의미합니다.
그래서 가설이 하는 일은 당신의 친구가 팔려고 하는 
새로운 집의 사이즈를 x에 입력 값으로 받고 
결과 값으로 추측되는 값을 그 적당한 집의 y에 받는 것입니다.
그래서 h는 x에서부터 y까지의 지도입니다. 사람들은 주로 저에게 묻는데, 
당신도 알다시피 이것이 사전적이든 과학적이든 뭐든 
가설이라는 용어의 의미입니다. 기계학습에서도, 기계학습 초기부터 사용되던 용어이지만 
약간 애매합니다. 왜냐하면 아마도 이런 종류의 함수에서 
좋은 이름은 아니고 집 크기를 이용해 예측한 것을 
도표화 한다 던지, 아시다시피.. 저는 가설이라는 단어가 
가장 적합한 단어는 아니라고 생각하지만, 이 단어는 기계학습에서 사용되는 전문용어입니다. 
그러니까 사람들이 왜 이렇게 부르는가에 대해서는 너무 걱정하지는 마세요. 지도알고리즘을 디자인할 때, 
그 다음으로 우리가 결정해야 할 것은 우리가 가설 h를 어떻게 표현할 것인지에 대해서 
입니다. 이것과 다음 비디오를 통해, 저는 가설을 표현하기 위해 
한가지 선택을 할 것입니다. 우리는 h를 다음과 같이 표현할 것입니다. 
h <u>세타(x)<u>는 세타0 + 세타1</u>x</u>라고 하겠습니다. 세타1<u>x라고 하겠습니다. 
이 것을 약칭하자면</u> h Θx라고 쓰는 것 대신에, 
hx라고 쓰겠습니다. 그러나 세타를 포함한 것을 
더 자주 사용하게 됩니다 그리고 이것을 그림에 나타내보자면, 
이 모든 것의 의미는, 우리가 x의 선형함수인 y를 예측하는 것입니다. 
그래서, 자료와 함수가 하는 것은 x의 몇몇 직선함수인 y를 예측하는 것 입니다. 
그리고 이 직선함수는 h Θx 는 Θ0 h Θx 는 Θ0 + Θ1x입니다, 아시겠죠? 
왜 선형함수를 사용하냐고요? 음, 가끔 우리는 비선형함수 같은 
좀 더 복잡한 것을 사용하기도 합니다. 하지만 이 선형 유형은 간단한 빌딩블록으로, 
우리는 선형 함수 유형에서부터 시작할 것입니다. 그리고 우리는 결과적으로 
더 복잡한 모형들, 그리고 더 복잡한 
학습 알고리즘으로 갈 것입니다. 특정한 모형에도 이름을 줘 봅시다. 
이 모형은 선형회귀라고 불리고, 예를 들자면 실제로 
선형회귀의 값은 하나이며, 이 값은 x입니다. 
하나의 값 x로 모든 가격들을 예측합니다. 그리고 이 모형의 다른 이름은 
단일변량 선형 회귀입니다. 그리고 단일변량이라는 말은 하나의 값이라는 
말을 멋있게 이야기한 것입니다. 그래서, 이것이 선형회귀입니다. 다음에는
우리는 이 모형을 어떻게 실행할 것인지에 대해 이야기해보겠습니다.