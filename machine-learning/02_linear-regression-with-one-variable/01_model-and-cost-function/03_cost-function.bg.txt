В това видео ще дефинираме нещо, 
ценова функция. Това ще ни позволи да решим как да посторим възможно най-добрата
права линя през данните ни. В линейната регресия имаме тренировъчно множество като 
това, показано тук. Спомнете си означението М беше броя тренировъчни примери. 
Така че може би М=47. И формата на хипотезата, която използваме за да правим 
предположения, е линейна функция. За да представим още малко терминолгия,
тези тета 0 и тета 1, тези тета i наричам параметрите на
модела. Това, което ще направим в това видео, е да си поговорим за
това как да изберем тези две стойности на параметрите, тета 0 и тета 1.
С различен избор на параметрите тета 0 и тета 1 получаваме различни
хипотези, различни хипотетични функции. Знам, че някои от вас може би
вече са запознати с това, което ще направя на този слайд, но само за да
преговорим, ето няколко примера. Ако тета нула е 1.5 и тета едно е 0, тогава
хипотетичната функция ще изглежда ето така. Нали, защото хипотетичната
ви функция ще бъде h( x) = 1.5 + 0 по x, което е функция на константна
стойност, тоест права през 1.5. Ако тета нула е равна на 0 и тета едно е равна
на 0.5, тогава хипотезата ще изглежда ето така. И трябва да минава през тази
точка (2, 1), защото сега имаме h(x) или всъщност някаква h<u>theta(x), но
понякога просто ще пропускам тета</u> за съкращение. Така, h(x) ще е равно просто на
0.5 по x, което изглежда ето така. И накрая, ако тета нула е равно на 1 и тета
едно е равно на 0.5, значи ще имаме хипотеза, която изглежда ето така. Да видим,
трябва да минава през точка (2, 2) ето така. И това е новата ми h(x) или новата 
ми h<u>theta(x). Нали? Добре,</u> помните, че това е h<u>theta(x),
но за по-кратко</u> понякога просто го пиша като h(x). В линейната
регресия имаме тренировъчно множество, като може би това, което съм отбелязал с кръстчета 
тук. Искаме да намерим стойности за параметрите тета нула и тета едно. Така че
правата линия, която получаваме от това, да отговаря на правата линия, която
някак си минава добре през данните. Като може би тази права ето тук. Как да 
намерим стойности за тета нула и тета едно, които отговарят на добро построение
през данните? Идеята е да изберем параметрите тета нула, тета едно, така че
h(x), тоест стойността, която предвиждаме при вход x, да е поне близо до 
стойностите y за примерите в тренировъчното ни множество, или тренировъчните
ни стойности. Така, в тренировъчното множество са ни дадени няколко прмера, в които знам че x 
определя къщата, и знаем истинската цена, на която е била продадена. Хайде да се опитаме
да изберем стойности за параметрите, такива че поне в тренировъчното множество, при дадени
х-ове в тренировъчното множество, да можем да предвидим сравнително точно стойностите на
y. Да го направим формално. Линейната регресия, за да я приложа, ще искам 
да реша задача за минимизация. Ще искам да получа стойности при тета 
нула и тета едно, като искам това да бъде малко, нали, искам разликата 
между h(x) и y да бъде малка. Едно нещо, което мога да направя, е да се опитам да 
минимизирам квадрата от разстоянията между полученото от хипотезата и истинската цена на къщата. 
Добре? Хайде да запълним някои подробности. Спомнете си, че използвах
означението (x(i), y(i)), за да представя i-тия поред тренировъчен пример. Това, което
наистина искам, е сума в тренировъчното ми множество. Сумата от i=1 до М
от квадрата от разликата между това, е предположението на моята хипотеза, 
когато ѝ е зададен вход размера на къща номер i, нали, минус истинската цена, за която
тази къща ще бъде продадена, и искам да минимизирам сумата в тренировъчното 
ми множество, сумата от i = 1 до М, от разликата, от тази грешка на квадрат,
разликата на квадрат между предвидената цена на къщата и цената, за която 
наистина ще бъде продадена. И само да напомня, че означавам с М тук големината
на тренировъчното ми множество, нали, така че М тук е броя тренировъчни 
примери. Нали? Символа # е съкращение за "броя" тренировъчни
примери. Добре? И за да направим смятането малко по-лесно, ще 
разглеждам всъщност, 1 върху М, умножено по това. Така че ще се опитаме да 
минимизираме средно аритметично от грешката, което ще направи 1 върху 2М минимално.
Като сложим двойката, константата 1/2 отпред, прост смятането става малко
по-лесно. Така че минимума на половината от нещо ще даде същите стойности 
за параметрите тета нула и тета едно, като минимума на тази функция.
И само за да се уверим, че това уравнение е ясно... Този израз тук, 
h<u>theta(x), това е</u> обичайното, нали? Равно е на това
плюс тета едно x(i). И този запис минимизираме по тета нула и тета едно,
означава, намери ми стойностите на тета нула и тета едно, такива че този
израз е с минимална стойност. И този израз зависи от тета нула и тета едно. Нали?
Сега за да преговорим, поставяме тази задача: намери ми стойностите на 
тета нула и тета едно, така че средното аритметично, 1/М умножено 
по сумата от квадратните грешки между предположенията за тренировъчното множество,
минус истинските стойности на къщите за тренировъчното множество, е с минимална стойност.
Така че това ще бъде функцията, към която се стремим при линейната регресия. И просто,
за да го препишем малко по начисто, по конвенция обикновено
дефинираме ценова функция. Която ще е точно това. Тази
формула, която имам тук горе. Искам да минимизирам по тета нула и тета 
едно функцията ми J от тета нула запетайка тета едно. Написано 
така, това е ценова функция. Ценовата функция също се нарича функция 
на квадратните грешки, или понякога ценова функция с квадратни грешки,
и излиза, че... Защо взимаме грешките на квадрат? Излиза че ценовата 
функция с квадратни грешки е разумен избор, и ще работи за повечето
задачи, за повечето задачи за регресия. Има други ценови функции, които
работят доста добре, но ценовата функция с квадратни грешки е може би
най-често използвана за задачи с регресия. По-късно в този курс ще говорим също и
за други ценови функции, но този избор който направихме, би трябвало да
е доста разумен за опитване върху повечето задачи с линейна регресия. Добре.
Това е ценовата функция. До момента видяхме математическа дефиниция на
ценовата функция, и в случай че тази функция J от тета нула 
изглежда малко абстрактна и още нямате добра представа какво
прави, в следващото видео, в следващите няколко видеа ще отидем
малко по надълбоко, във това какво прави ценовата функция J, и ще се опитам да ви
дам по-добра интуция за това какво пресмята и защо искаме да я ползваме.