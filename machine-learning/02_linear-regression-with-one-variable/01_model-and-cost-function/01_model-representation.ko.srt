1
00:00:02,338 --> 00:00:04,677
우리의 첫번째 학습 알고리즘인 선형 회귀에 대해서
배울 것입니다. 여러분은 이 비디오에서

2
00:00:06,956 --> 00:00:09,234
모델의 구성에 대해 배우고 더 중요한

3
00:00:09,234 --> 00:00:14,801
지도 학습의 전체적인 과정에 대해 볼 것입니다. 흥미로운 예제로 집세에 대한 예측을 해 봅시다.

4
00:00:14,801 --> 00:00:20,036
Oregon과 Portland 도시의 주택 가격 데이터를 이용할 것입니다.

5
00:00:20,036 --> 00:00:25,205
주택 자료를 표시해보도록 하겠습니다

6
00:00:25,205 --> 00:00:30,833
그리고 제가 다른 크기, 다른 가격 범위의 
자료를 표시해보도록 하겠습니다

7
00:00:30,833 --> 00:00:35,872
집을 파려고 하는 친구에게 
이 자료를 준다고 가정하고,

8
00:00:35,872 --> 00:00:41,238
친구의 집 사이즈가 
1250 평방피트라고 했을 때,

9
00:00:41,238 --> 00:00:46,459
당신이 얼마에 팔 수 있는지를 
친구에게 알려준다고 가정해봅시다.

10
00:00:46,648 --> 00:00:53,039
당신이 할 수 있는 한가지 일은 모형에 맞춰보는 것 입니다.
자료에 일직선을 맞춰볼 수 있습니다.

11
00:00:53,039 --> 00:00:59,168
그리고 이 선에 근거해서 
당신은 친구에게

12
00:00:59,168 --> 00:01:03,575
집을 220,000달러에 팔 수 있다고 
말해줄 수 있습니다.

13
00:01:03,575 --> 00:01:08,834
그래서 이 것이 지도 학습 알고리즘의 예시입니다. 
그리고 이 것이 ‘지도 학습’이라고 불리는 이유는

14
00:01:08,834 --> 00:01:14,287
당신의 예시에 “적합한 답”을 주기 때문입니다.
다시 말해, 어떤 것이

15
00:01:14,287 --> 00:01:19,351
실제의 집인지, 어떤 것이 우리의 자료에서 
각각의 집이 어떤 가격에 팔렸는지에 대해 말하고 있고,

16
00:01:19,351 --> 00:01:24,441
게다가, 
이 것은 실제 수치의 결과,

17
00:01:24,441 --> 00:01:29,545
다시 말해 가격을 예측하는 회귀라는 의미의 
회기 문제의 예시입니다.

18
00:01:29,545 --> 00:01:34,586
그리고 다른 대부분의 감독학습의 형태는

19
00:01:34,586 --> 00:01:39,006
분류문제로 불리는데 예를들면 암종양을

20
00:01:39,006 --> 00:01:45,202
찾을때 그게 악성인지 아닌지에 대한 결정을 내리는 것과 같은

21
00:01:45,202 --> 00:01:52,032
이산값을 예측하는 문제같은 것입니다. 그래서 이것은 0-1의 이산값입니다.

22
00:01:52,032 --> 00:01:57,087
공식적으로, 감독학습에서 우리는 데이터셋을 갖고 있고 이 데이터셋을 우리는 학습셋이라고 부릅니다.

23
00:01:57,087 --> 00:02:02,018
주택 가격의 예제에서 우리는 서로 다른 주택 가격의 학습셋을 가지고 있고,

24
00:02:02,018 --> 00:02:07,386
우리가 할 일은 이 데이터로부터 어떻게 주택 가격을 예측할 지 학습시키는 것입니다.

25
00:02:07,386 --> 00:02:11,907
이번 강의내내 사용할 표기법을 정의해봅시다.

26
00:02:11,907 --> 00:02:16,100
우리는 꽤 많은 기호를 정의할 겁니다. 당장 모든 기호를 외울 필요는 없지만

27
00:02:16,100 --> 00:02:20,075
강의 진행과정에서 유용하고 편리한 표기법이 될 것입니다.

28
00:02:20,075 --> 00:02:24,267
저는 이번 강좌 전체에서 소문자 m을 학습예제의 수를 나타내는데

29
00:02:24,267 --> 00:02:28,897
사용할 것입니다. 만약 제가 가지고 있는 이 데이터셋에서,

30
00:02:28,897 --> 00:02:34,366
47줄의 이 테이블이 있다고합시다. 저는 47개의 학습 예제를 가지고 있고 따라서 m은 47입니다.

31
00:02:34,366 --> 00:02:39,497
소문자 x는 종종 특징(feature)이라고 부르는 입력 변수를 표시하기 위해 사용합니다.

32
00:02:39,497 --> 00:02:44,290
x는 여기가 될 것이고, 그것이 입력 feature일 것입니다.

33
00:02:44,290 --> 00:02:49,556
그리고 y는 출력값이나 예측하려하는 목표변수를 표기하는데 사용할 것이며

34
00:02:49,556 --> 00:02:54,552
여기 두 번째 열이 그것입니다.

35
00:02:54,552 --> 00:03:05,749
(x, y)는 하나의 학습예제를 표기하는데 사용할 것입니다. 이 표에서 한 줄은

36
00:03:05,749 --> 00:03:12,068
특정한 하나의 학습예제와 대응되며

37
00:03:12,068 --> 00:03:19,708
(x(i), y(i))는 i번째 학습예제를 의미하도록 할 것입니다.

38
00:03:25,322 --> 00:03:30,935
여기 써져있는 위첨자 i는

39
00:03:30,935 --> 00:03:37,864
지수가 아닙니다. 이 (x(i), y(i))의 괄호에서

40
00:03:37,864 --> 00:03:44,873
위첨자 i는 그냥 예제셋에서 몇번째인지, 표에서 몇 번째 줄인지를 말하는 것일 뿐입니다.

41
00:03:44,873 --> 00:03:51,629
그래서 이것은 x의 i제곱, y의 i제곱이 아닙니다.

42
00:03:51,629 --> 00:03:58,216
대신에 (x(i), y(i))는 표의 i번째를 말합니다. 예를 들면, x(1)은

43
00:03:58,216 --> 00:04:04,972
첫 번째 학습예제의 입력값을 말하며 그것은 2104입니다.

44
00:04:04,972 --> 00:04:11,685
첫 번째 행에서 x는 이것입니다. x(2)는 1416입니다.

45
00:04:11,685 --> 00:04:17,385
그게 두 번째고, y(1)은 460이 될 것입니다.

46
00:04:17,385 --> 00:04:24,526
제 첫 번째 훈련예시의 y값이고 이 말은 (1)이 나타내는 의미와 같습니다. 
언급한대로, 때때로

47
00:04:24,526 --> 00:04:28,345
저는 당신에게 이와 같은 질문으로 
이해하고 있는지를 체크할 것이고,

48
00:04:28,345 --> 00:04:34,044
이 비디오에서 몇 초 정도 객관식의 문제가 
화면에 뜰 것입니다.

49
00:04:34,044 --> 00:04:40,362
그럴 때는 마우스를 사용해서 
적합한 답을 선택해주세요.

50
00:04:40,362 --> 00:04:45,124
훈련집합을 통해 배우게 될 것은, 
이 지도 학습 알고리즘이 어떻게 돌아가느냐에 대한 것 입니다.

51
00:04:45,124 --> 00:04:50,513
우리는 지금까지 주택 가격 같은 
훈련집합에 대해 배웠고,

52
00:04:50,513 --> 00:04:55,715
우리의 지도 알고리즘에 사용할 것입니다. 
지도 알고리즘은 결과 값으로 가는데

53
00:04:55,715 --> 00:05:00,101
보통 이 값은 소문자h로 나타나며

54
00:05:00,101 --> 00:05:06,574
h는 가설을 의미합니다.
그래서 가설이 하는 일은

55
00:05:06,574 --> 00:05:12,471
당신의 친구가 팔려고 하는 
새로운 집의 사이즈를

56
00:05:12,471 --> 00:05:18,368
x에 입력 값으로 받고 
결과 값으로 추측되는 값을

57
00:05:18,368 --> 00:05:31,630
그 적당한 집의 y에 받는 것입니다.
그래서 h는 x에서부터 y까지의 지도입니다.

58
00:05:31,630 --> 00:05:37,729
사람들은 주로 저에게 묻는데, 
당신도 알다시피

59
00:05:37,729 --> 00:05:42,121
이것이 사전적이든 과학적이든 뭐든 
가설이라는 용어의 의미입니다.

60
00:05:42,121 --> 00:05:46,744
기계학습에서도,

61
00:05:46,744 --> 00:05:51,310
기계학습 초기부터 사용되던 용어이지만 
약간 애매합니다.

62
00:05:51,310 --> 00:05:55,239
왜냐하면 아마도 이런 종류의 함수에서 
좋은 이름은 아니고

63
00:05:55,239 --> 00:05:59,978
집 크기를 이용해 예측한 것을 
도표화 한다 던지,

64
00:05:59,978 --> 00:06:04,543
아시다시피.. 저는 가설이라는 단어가 
가장 적합한 단어는 아니라고 생각하지만,

65
00:06:04,543 --> 00:06:09,362
이 단어는 기계학습에서 사용되는 전문용어입니다. 
그러니까 사람들이 왜 이렇게 부르는가에 대해서는 너무 걱정하지는 마세요.

66
00:06:09,362 --> 00:06:14,332
지도알고리즘을 디자인할 때, 
그 다음으로 우리가 결정해야 할 것은

67
00:06:14,332 --> 00:06:20,540
우리가 가설 h를 어떻게 표현할 것인지에 대해서 
입니다. 이것과 다음 비디오를 통해,

68
00:06:20,540 --> 00:06:26,978
저는 가설을 표현하기 위해 
한가지 선택을 할 것입니다.

69
00:06:26,978 --> 00:06:33,009
우리는 h를 다음과 같이 표현할 것입니다. 
h <u>세타(x)<u>는 세타0 + 세타1</u>x</u>라고 하겠습니다.

70
00:06:33,009 --> 00:06:39,254
세타1<u>x라고 하겠습니다. 
이 것을 약칭하자면</u>

71
00:06:39,254 --> 00:06:45,441
h Θx라고 쓰는 것 대신에, 
hx라고 쓰겠습니다.

72
00:06:45,441 --> 00:06:51,627
그러나 세타를 포함한 것을 
더 자주 사용하게 됩니다

73
00:06:51,627 --> 00:06:58,210
그리고 이것을 그림에 나타내보자면, 
이 모든 것의 의미는,

74
00:06:58,210 --> 00:07:04,634
우리가 x의 선형함수인 y를 예측하는 것입니다. 
그래서, 자료와 함수가 하는 것은

75
00:07:04,634 --> 00:07:11,698
x의 몇몇 직선함수인 y를 예측하는 것 입니다. 
그리고 이 직선함수는 h Θx 는 Θ0

76
00:07:11,698 --> 00:07:18,450
h Θx 는 Θ0 + Θ1x입니다, 아시겠죠? 
왜 선형함수를 사용하냐고요?

77
00:07:18,450 --> 00:07:23,405
음, 가끔 우리는 비선형함수 같은 
좀 더 복잡한 것을 사용하기도 합니다.

78
00:07:23,405 --> 00:07:28,298
하지만 이 선형 유형은 간단한 빌딩블록으로, 
우리는 선형 함수 유형에서부터 시작할 것입니다.

79
00:07:28,298 --> 00:07:32,943
그리고 우리는 결과적으로 
더 복잡한 모형들,

80
00:07:32,943 --> 00:07:37,403
그리고 더 복잡한 
학습 알고리즘으로 갈 것입니다.

81
00:07:37,403 --> 00:07:42,628
특정한 모형에도 이름을 줘 봅시다. 
이 모형은 선형회귀라고 불리고,

82
00:07:42,628 --> 00:07:48,271
예를 들자면 실제로 
선형회귀의 값은 하나이며,

83
00:07:48,271 --> 00:07:53,914
이 값은 x입니다. 
하나의 값 x로 모든 가격들을 예측합니다.

84
00:07:53,914 --> 00:07:58,852
그리고 이 모형의 다른 이름은 
단일변량 선형 회귀입니다.

85
00:07:58,852 --> 00:08:04,400
그리고 단일변량이라는 말은 하나의 값이라는 
말을 멋있게 이야기한 것입니다.

86
00:08:04,400 --> 00:08:09,760
그래서, 이것이 선형회귀입니다. 다음에는
우리는 이 모형을 어떻게 실행할 것인지에 대해 이야기해보겠습니다.