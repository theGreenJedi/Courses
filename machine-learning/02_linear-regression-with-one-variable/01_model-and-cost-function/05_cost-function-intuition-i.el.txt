Στο προηγούμενο βίντεο, δώσαμε τον 
μαθηματικό ορισμό της συνάρτησης κόστους Σε αυτό το βίντεο, ας δούμε μερικά παραδείγματα 
για να καταλάβουμε διαισθητικά τι κάνει η συνάρτηση κόστους και γιατί 
την χρησιμοποιούμε. Ανακεφαλαιώνοντας, να τι είχαμε την τελευταία φορά. Θέλουμε να προσαρμόσουμε 
μια ευθεία γραμμή στα δεδομένα μας, κι έτσι φτιάξαμε την υπόθεση με τις 
παραμέτρους θ0 και θ1 , και με διαφορετικές επιλογές παραμέτρων, παίρνουμε 
διαφορετικές προσαρμοσμένες ευθείες Άρα τα δεδομένα που προσαρμόζονται έτσι,
και υπάρχει κι η συνάρτηση κόστους, και αυτός ήταν ο σκοπός βελτιστοποίησης. Για []
αυτό το βίντεο, προκειμένου να απεικονίσουμε καλύτερα την συνάρτηση J, θα δουλέψω 
με μία απλοποιημένη συνάρτηση υπόθεσης, όπως αυτή που φαίνεται στα δεξιά. Έτσι,
θα χρησιμοποιήσω την απλοποιημένη υπόθεση, που είναι απλώς θ1*Χ. Μπορούμε, αν θέλετε, 
να το σκεφτούμε σαν να θέτουμε την παράμετρο θ0 ίση με 0. Έτσι έχω μόνο 
μία παράμετρο θ1 και η συνάρτηση κόστους μου είναι παρόμοια 
με πρίν, μόνο που τώρα h του x είναι ίσο με μόνο το θ1*x. Και έχω μόνο μια παράμετρο και έτσι ο σκοπός της βελτιστοποίησης είναι να 
ελαχιστοποιήσω την J του θ1. Σε εικόνες, αυτό σημαίνει ότι αν το θ0 είναι ίσο με 0, αυτό αντιστοιχίζεται 
με το να επιλέγεις μόνο συναρτήσεις υπόθεσης που περνούν από την αρχή των αξόνων, 
που περνούν από το σημείο (0,0). Χρησιμοποιώντας έναν απλοποιημένο ορισμό της συνάρτησης 
κόστους της υπόθεσης, ας προσπαθήσουμε να κατανοήσουμε την ιδέα της συνάρτησης κόστους καλύτερα. Καταλήγουμε ότι
υπάρχουν 2 συναρτήσεις-κλειδιά που θέλουμε να καταλάβουμε. Η πρώτη είναι η συνάρτηση υπόθεσης και η 
δεύτερη είναι η συνάρτηση κόστους. Παρατηρήστε ότι η υπόθεση h του x, για 
συγκεκριμένη τιμή του θ1, είναι μία συνάρτηση του x. Έτσι, η υπόθεση είναι μία 
συνάρτηση του μεγέθους του σπιτιού Χ. Αντίθετα, η συνάρτηση κόστους J, είναι
μία συνάρτηση της παραμέτρου θ1, που ελέγχει την κλίση της ευθείας. Ας 
αναπαραστήσουμε αυτές τις συναρτήσεις και να προσπαθήσουμε να τις καταλάβουμε καλύτερα. 
Ας αρχίσουμε με την υπόθεση. Στ' αριστερά, ας πούμε ότι έχω το σύνολο εκπαίδευσης με 3
σημεία (1,1), (2,2) και (3,3). Ας διαλέξουμε μία τιμή θ1, τέτοια ώστε όταν θ1=1 τότε η υπόθεση μου θα μοιάζει με 
αυτή την ευθεία γραμμή εδώ πέρα. Και δείχνω όταν αναπαριστώ την συνάρτηση
υπόθεσης, στον άξονα x, ο οριζόντιος άξονας είναι ο x, επισημαίνονται
τα μεγέθη των σπιτιών εδώ πέρα. Τώρα, προσωρινά, ορίζω θ1=1, 
αυτό που θέλω να κάνω είναι να βρω πόσο είναι το J του θ1,
όταν θ1 ισούται με 1. Ας συνεχίσουμε και να υπολογίσουμε τι θα δώσει
η συνάρτηση κόστους για την τιμή 1. Ως συνήθως, η συνάρτηση κόστους ορίζεται
ως ακολούθως, ωραία; Κάποια από αυτά είναι σύνολα εκπαίδευσης του συνηθισμένου τετραγωνικού 
σφάλματος. Και άρα αυτό είναι ίσο με "αυτό". θ1*xi μείον yi και αν το απλοποιήσουμε, 
καταλήγουμε σε αυτό: 0^2 + 0^2 + 0^2 που φυσικά είναι ίσο με 0. Τώρα, μέσα στην συνάρτηση κόστους, καταλήγουμε ότι
κάθε ένας από αυτούς τους όρους είναι 0. Επειδή για το συγκεκριμένο σύνολο εκπαίδευσης έχω 3
δείγματα εκπαίδευσης (1,1), (2,2), (3,3). Αν θ1 είναι ίσο με 1, τότε h του xi είναι ίσο με yi ακριβώς. 
Επιτρέψτε μου να το γράψω καλύτερα. Και έτσι, h του x μείον y, κάθε ένας από 
αυτούς  τους όρους είναι ίσος με 0, κι έτσι βρίσκω ότι J του 1 είναι ίσο με 0. 
Πλέον ξέρουμε ότι το J του 1 είναι ίσο με 0. Ας το αναπαραστήσουμε γραφικά. Αυτό που 
θα κάνω στα δεξιά είναι να αναπαραστήσω την συνάρτηση κόστους J. Και παρατηρήστε ότι, επειδή η 
συνάρτηση κόστους είναι μία συνάρτηση με παράμετρο θ1, όταν αναπαριστώ την συνάρτηση κόστους, ο 
οριζόντιος άξονας επισημαίνεται ως θ1. Έχω λοιπόν J του 1 ίσο με 0, οπότε 
ας το αναπαραστήσουμε. Καταλήγουμε με ένα x εκεί πέρα. Τώρα ας δούμε κάποια 
άλλα παραδείγματα. Το θ-1 μπορεί να πάρει ένα εύρος τιμών. Άρα το θ-1 μπορεί 
να πάρει αρνητικές τιμές, μηδέν και θετικές τιμές. Τι γίνεται αν το θ-1 
είναι ίσο με 0.5; Ας το αναπαραστήσουμε. Θα ορίσω το θ-1 ίσο με 0.5
και σε αυτή την περίπτωση, η υπόθεση μου μοιάζει κάπως έτσι. Μία ευθεία 
με κλίση ίση με 0.5 και ας υπολογίσουμε το J για 0.5. Θα είναι 1 δια 2*m
της συνηθισμένης συνάρτησης κόστους. Καταλήγουμε ότι η συνάρτηση κόστους θα
είναι το άθροισμα των τετραγωνικών τιμών του ύψους αυτής της γραμμής συν το άθροισμα των 
τετραγώνων του ύψους εκείνης της γραμμής συν το άθροισμα των τετραγώνων του ύψους 
εκείνης της γραμμής, σωστά; Επειδή η κάθετη απόσταση είναι η διαφορά μεταξύ του
Υi και της προβλεπόμενης τιμής, h του Xi. Άρα το 1ο παράδειγμα θα είναι 0.5 - 1^2 επειδή η υπόθεση προέβλεψε 0.5 ενώ η 
πραγματική τιμή ήταν 1. Για το δεύτερο παράδειγμα, έχω 1 - 2^2, επειδή
η υπόθεσή μου προέβλεψε 1, αλλά η πραγματική τιμή του σπιτιού ήταν 2. Και
το τελευταίο είναι 1.5 - 3^2. Και αυτό είναι ίσο με 1 δια 2*3 επειδή
το m, το μέγεθος του συνόλου εκπαίδευσης, έχει 3 δείγματα εκπαίδευσης. 
. Απλοποιώντας τις παρενθέσεις είναι 3.5
Άρα έχω 3.5 / 6 που είναι περίπου 0.68 . Τώρα ξέρουμε ότι το J του 0.5 
είναι περίπου 0.68 . Ας το αναπαραστήσουμε. Ωπ, συγχωρήστε με, μαθηματικό λάθος. Είναι 0.58 . 
Άρα το αναπαριστούμε και είναι περίπου εκεί. Εντάξει; Τώρα, ας κάνουμε άλλο ένα. Τι συμβαίνει 
αν το θ1 είναι ίσο με 0; Με τι ισούται το J του 0; Καταλήγουμε ότι αν το 
θ1 είναι ίσο με 0, τότε το h του x είναι ίσο με αυτή την επίπεδη γραμμή, 
που απλώς πηγαίνει οριζόντια, κάπως έτσι. Και μετρώντας τα σφάλματα,
έχουμε ότι το J του 0 είναι ίσο με 1 δια 2*m επί 1^2 + 2^2 + 3^2 που είναι 1/6 επί 14, περίπου 2.3 . Ας το
αναπαραστήσουμε και αυτό. Καταλήξαμε με μια τιμή περίπου 2.3
και φυσικά μπορούμε να συνεχίσουμε να το κάνουμε αυτό με άλλες τιμές του θ1.
Καταλήγουμε ότι μπορείτε να έχετε αρνητικές τιμές του θ1. Άρα αν το θ1 είναι αρνητικό,
τότε το h του x θα είναι ίσο με -0.5 επί x, τότε το θ1 είναι -0.5 
και αυτό αντιστοιχεί σε μία υπόθεση με αρνητική κλίση 0.5.
Μπορείτε να συνεχίσετε να υπολογίζετε αυτά τα σφάλματα. 
Καταλήγει να είναι, ξέρετε, για 0.5 καταλήγει να έχει πολύ μεγάλο σφάλμα.
Βγαίνει κάτι περίπου στο 5.25 Για διάφορες τιμές του θ1, μπορείτε
να τα υπολογίσετε αυτά, σωστά; Και καταλήγετε να έχετε υπολογίσει
αυτό το εύρος τιμών. Και υπολογίζοντας το εύρος τιμών, 
μπορείτε να χαράξετε την συνάρτηση J του θ. Αυτό λοιπόν είναι η J του θ.
Ανακεφαλαιώνοντας, για κάθε τιμή του θ1 αντιστοιχίζεται μια διαφορετική υπόθεση ή μια διαφορετική ευθεία 
προσαρμογής. Και για κάθε τιμή του θ1, θα μπορούσαμε να παραγωγίσουμε
μια διαφορετική τιμή του J του θ1. Και για παράδειγμα, το θ1=1 αντιστοιχίζεται
με την ευθεία γραμμή ανάμεσα στα δεδομένα, ενώ η θ=0.5 σε αυτό το μωβ σημείο αντιστοιχεί ίσως σε αυτή την γραμμή, και το
θ1=0 που φαίνεται με μπλε αντιστοιχεί στην οριζόντια γραμμή. Άρα, για κάθε τιμή 
του θ1 θα καταλήγουμε με μία διαφορετική τιμή του J του θ1 και θα μπορούσαμε 
να το χρησιμοποιήσουμε για να χαράξουμε αυτή την γραφική στα δεξιά. Τώρα, θυμάστε ότι ο σκοπός 
βελτιστοποίησης του αλγόριθμου μάθησης μας είναι ότι θέλουμε να διαλέξουμε 
τιμή του θ1 που ελαχιστοποιεί το J του θ1. Σωστά; Αυτή ήταν η αντικειμενική συνάρτηση 
για την γραμμική παλινδρόμηση. Κοιτώντας την καμπύλη, η τιμή που ελαχιστοποιεί την J του θ1
είναι, ξέρετε, θ1 ίσο με 1 . Και ιδού, αυτή είναι όντως η καλύτερη
δυνατή ευθεία προσαρμογής στα δεδομένα μας, θέτωντας θ1=1. 
Και μόνο για το συγκεκριμένο σύνολο εκπαίδευσης, προσαρμόζεται τέλεια. Και 
γι' αυτό ελαχιστοποιώντας το J του u1 ανταποκρίνεται στην εύρεση μιας ευθείας που
προσαρμόζεται στα δεδομένα τόσο καλα. Κλείνοντας, σε αυτό το βίντεο, είδαμε κάποιες 
γραφικές παραστάσεις για να καταλάβουμε την συνάρτηση κόστους. Για να το κάνουμε αυτό, 
απλοποιήσαμε τον αλγόριθμο ώστε να έχει μόνο μία παράμετρο θ1. Ορίσαμε την παράμετρο θ0 να 
είναι μόνο 0. Στο επόμενο βίντεο , θα επιστρέψουμε στην αρχική διατύπωση του
προβλήματος και θα δούμε μερικές απεικονίσεις που περιλαμβάνουν και 
το θ0 και το θ1. Αυτό χωρίς να ορίσουμε το θ0 ίσο με 0. Και ελπίζω να σας δώσει μία
καλύτερη αίσθηση του τι κάνει η συνάρτηση κόστους J στην αρχική διατύπωση
του προβλήματος της γραμμικής παλινδρόμησης.