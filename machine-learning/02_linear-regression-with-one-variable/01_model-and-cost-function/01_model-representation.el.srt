1
00:00:02,338 --> 00:00:04,677
Our first learning algorithm will be
linear regression. In this video, you'll see

2
00:00:06,956 --> 00:00:09,234
πώς μοιάζει το μοντέλο και το πιο σημαντικό,
θα δείτε πως η γενική

3
00:00:09,234 --> 00:00:14,801
διαδικασία της επιβλεπόμενης μάθησης μοιάζει.
Ας δούμε ένα ενθαρρυντικό παράδειγμα πρόβλεψης

4
00:00:14,801 --> 00:00:20,036
της αξίας σπιτιών. Θα χρησιμοποιήσουμε ένα σύνολο
δεδομένων με τιμές σπιτιών στην πόλη

5
00:00:20,036 --> 00:00:25,205
Portland του Oregon. Θα απεικονίσω γραφικά
τα δεδομένα ενός αριθμού σπιτιών

6
00:00:25,205 --> 00:00:30,833
διαφορετικού μεγέθους που πουλήθηκαν για
ένα εύρος τιμών. Έστω ότι με  

7
00:00:30,833 --> 00:00:35,872
αυτά τα δεδομένα, ένας φίλος σας
προσπαθεί να πουλήσει ένα σπίτι.

8
00:00:35,872 --> 00:00:41,238
Έστω ότι το σπίτι είναι 1250 τετραγωνικά 
πόδια και θέλετε να του πείτε 

9
00:00:41,238 --> 00:00:46,459
πόσο θα μπορούσε να το πουλήσει. Ένα πράγμα 
που θα μπορούσατε να κάνετε είναι να

10
00:00:46,648 --> 00:00:53,039
προσαρμόσετε ένα μοντέλο. Ίσως μια ευθεία γραμμή
για αυτά τα δεδομένα να μοιάζει κάπως έτσι και

11
00:00:53,039 --> 00:00:59,168
βασιζόμενοι σε αυτό, θα μπορούσατε να πείτε
στον φίλο σας ότι ίσως μπορεί να πουλήσει 

12
00:00:59,168 --> 00:01:03,575
το σπίτι περίπου $220,000.
Λοιπόν, αυτό είναι ένα παράδειγμα

13
00:01:03,575 --> 00:01:08,834
ενός αλγόριθμου επιβλεπόμενης μάθησης. Και είναι
επιβλεπόμενη μάθηση επειδή μας δίνεται

14
00:01:08,834 --> 00:01:14,287
η "σωστή απάντηση" για κάθε δείγμα.
Δηλαδή, μας έχουν πει ποιο είναι 

15
00:01:14,287 --> 00:01:19,351
το σπίτι, ποια είναι η τιμή για 
κάθε σπίτι στο σύνολο δεδομένων

16
00:01:19,351 --> 00:01:24,441
που πουλήθηκε και επιπλέον, αυτό είναι ένα
παράδειγμα προβλήματος παλινδρόμησης όπου

17
00:01:24,441 --> 00:01:29,545
ο όρος "παλινδρόμηση" αναφέρεται στο γεγονός
ότι προβλέπουμε μια πραγματικών τιμών έξοδο,

18
00:01:29,545 --> 00:01:34,586
δηλαδή την τιμή. Και υπενθυμίζω ότι ο 
άλλος πιο κοινός τύπος προβλήματος

19
00:01:34,586 --> 00:01:39,006
επιβλεπόμενης μάθησης ονομάζεται
πρόβλημα ταξινόμησης, όπου προβλέπουμε

20
00:01:39,006 --> 00:01:45,202
εξόδους διακριτών τιμών όπως αν κοιτούσαμε 
καρκινικούς όγκους και προσπαθούσαμε να

21
00:01:45,202 --> 00:01:52,032
αποφασίσουμε αν ένας όγκος είναι κακοήθης ή
καλοήθης. Άρα είναι μια διακριτή έξοδος
με τιμές 0 ή 1

22
00:01:52,032 --> 00:01:57,087
Πιο επίσημα, στην επιβλεπόμενη μάθηση, έχουμε
ένα σύνολο δεδομένων και ονομάζεται

23
00:01:57,087 --> 00:02:02,018
σύνολο εκπαίδευσης. Για το παράδειγμα με τις
τιμές σπιτιών, έχουμε ένα σύνολο εκπαίδευσης

24
00:02:02,018 --> 00:02:07,386
με διαφορετικές τιμές και η δουλειά μας είναι
από αυτά τα δεδομένα να προβλέψουμε τιμές

25
00:02:07,386 --> 00:02:11,907
των σπιτιών. Ας ορίσουμε μερικές σημειογραφίες
που χρησιμοποιούμε στο μάθημα.

26
00:02:11,907 --> 00:02:16,100
Θα ορίσουμε αρκετά σύμβολα. 
Δεν πειράζει αν δεν θυμάστε

27
00:02:16,100 --> 00:02:20,075
όλα τα σύμβολα, αλλά όσο το μάθημα
προχωράει, θα ήταν χρήσιμο

28
00:02:20,075 --> 00:02:24,267
[] να γνωρίζετε τις σημειογραφίες. Θα 
χρησιμοποιήσω το μικρό m σε όλο το μάθημα

29
00:02:24,267 --> 00:02:28,897
για να υποδηλώσω τον αριθμό δειγμάτων εκπαίδευσης.
Σε αυτό το σύνολο δεδομένων, αν έχω,

30
00:02:28,897 --> 00:02:34,366
ας πούμε 47 γραμμές σε αυτό τον πίνακα. Τότε
έχω 47 δείγματα εκπαίδευσης και m = 47

31
00:02:34,366 --> 00:02:39,497
Επιτρέψτε μου να χρησιμοποιήσω το μικρό x για
να υποδηλώσω μεταβλητές εισόδου, που επίσης

32
00:02:39,497 --> 00:02:44,290
λέγονται χαρακτηριστικά. Τα x εδώ, θα είναι 
τα χαρακτηριστικά εισόδου. Και θα

33
00:02:44,290 --> 00:02:49,556
χρησιμοποιήσω το y για να υποδηλώνω τις μεταβλητές 
εξόδου ή την στοχευμένη μεταβλητή που θα

34
00:02:49,556 --> 00:02:54,552
προβλέψω και είναι η δεύτερη στήλη εδώ.
[] Περαιτέρω σημειογραφία, θα 

35
00:02:54,552 --> 00:03:05,749
χρησιμοποιήσω το (x,y) για να υποδηλώνω
ένα δείγμα εκπαίδευσης. Άρα, μια γραμμή σε

36
00:03:05,749 --> 00:03:12,068
αυτόν τον πίνακα αντιστοιχεί σε ένα δείγμα
εκπαίδευσης και αναφέρεται σε ένα συγκεκριμένο

37
00:03:12,068 --> 00:03:19,708
δείγμα εκπαίδευσης. Θα χρησιμοποιήσω αυτή την 
σημειογραφία, το x(i) μου δίνει y(i). Και θα  

38
00:03:25,322 --> 00:03:30,935
το χρησιμοποιήσουμε για να αναφερόμαστε στο 
i-οστό δείγμα. Άρα αυτός ο εκθέτης i εδώ,

39
00:03:30,935 --> 00:03:37,864
δεν είναι δύναμη, ωραία; Στο (x(i),y(i)) ο εκθέτης στις

40
00:03:37,864 --> 00:03:44,873
παρενθέσεις είναι ένας δείκτης στο σύνολο εκπαίδευσης
και αναφέρεται στην i-οστή γραμμή στον

41
00:03:44,873 --> 00:03:51,629
πίνακα, εντάξει; Λοιπόν, δεν είναι x^i , y^i. 
Αντ' αυτού το

42
00:03:51,629 --> 00:03:58,216
(x(i),y(i)) αναφέρεται στην i-οστή γραμμή
του πίνακα. Για παράδειγμα, το x(1) αναφέρεται

43
00:03:58,216 --> 00:04:04,972
στην τιμή εισόδου για το 1ο δείγμα εκπαίδευσης
άρα είναι 2104. Είναι το x στην 1η γραμμή

44
00:04:04,972 --> 00:04:11,685
Το x(2) θα είναι ίσο με 1416, σωστά;
Αυτό είναι το 2ο  x και 

45
00:04:11,685 --> 00:04:17,385
το y(1) θα είναι ίσο με 460. 
Η 1η, η y τιμή για το 1ο 

46
00:04:17,385 --> 00:04:24,526
δείγμα εκπαίδευσης, εκεί αναφέρεται το (1).
Όπως ειπώθηκε, περιστασιακά θα σας κάνω

47
00:04:24,526 --> 00:04:28,345
μια ερώτηση για να ελέγξετε την αντίληψη σας 
και σε μερικά δευτερόλεπτα

48
00:04:28,345 --> 00:04:34,044
μια ερώτηση πολλαπλής επιλογής θα εμφανιστεί.
Όταν γίνει αυτό, παρακαλώ

49
00:04:34,044 --> 00:04:40,362
χρησιμοποιήστε το ποντίκι σας για να επιλέξετε
την απάντηση που θεωρείτε σωστή. 

50
00:04:40,362 --> 00:04:45,124
Ορίστε λοιπόν πως δουλεύει αυτός ο 
αλγόριθμος επιβλεπόμενης μάθησης

51
00:04:45,124 --> 00:04:50,513
Παίρνουμε το σύνολο εκπαίδευσης, όπως το σύνολο 
εκπαίδευσης με τις τιμές σπιτιών και το τροφοδοτούμε

52
00:04:50,513 --> 00:04:55,715
στον αλγόριθμο μάθησης. Είναι δουλειά του 
αλγόριθμου να δώσει στη έξοδο μια συνάρτηση

53
00:04:55,715 --> 00:05:00,101
η οποία, κατά σύμβαση, συνήθως υποδηλώνεται
με το μικρό h από το  "hypothesis"

54
00:05:00,101 --> 00:05:06,574
Και η δουλειά της υπόθεσης 
είναι μια συνάρτηση που 

55
00:05:06,574 --> 00:05:12,471
παίρνει ως είσοδο το μέγεθος ενός σπιτιού, όπως 
το μέγεθος του νέου σπιτιού που ο φίλος σας

56
00:05:12,471 --> 00:05:18,368
προσπαθεί να πουλήσει. Άρα παίρνει την τιμή του x 
και προσπαθεί να εκτιμήσει την 

57
00:05:18,368 --> 00:05:31,630
τιμή της εξόδου y για το αντίστοιχο σπίτι.  To h είναι
μία συνάρτηση που καθορίζει από τα x προς τα y

58
00:05:31,630 --> 00:05:37,729
Συχνά με ρωτάνε, γιατί αυτή η 
συνάρτηση ονομάζεται υπόθεση.

59
00:05:37,729 --> 00:05:42,121
Κάποιοι από εσάς ίσως ξέρουν την 
έννοια του όρου "υπόθεση", από το

60
00:05:42,121 --> 00:05:46,744
λεξικό ή από την επιστήμη ή απ' οπουδήποτε. 
Καταλήγουμε ότι στην μηχανική μάθηση, αυτό

61
00:05:46,744 --> 00:05:51,310
το όνομα χρησιμοποιούταν στις αρχές τής 
μηχανικής μάθησης και έμεινε. Επειδή 

62
00:05:51,310 --> 00:05:55,239
ίσως δεν είναι καλό όνομα για αυτό το είδος συνάρτησης, 
για να καθορίζεις από τα μεγέθη των

63
00:05:55,239 --> 00:05:59,978
σπιτιών προς τις προβλέψεις, καταλαβαίνετε...
Νομίζω ότι ο όρος "υπόθεση", ίσως δεν είναι

64
00:05:59,978 --> 00:06:04,543
το καλύτερο όνομα για αυτό, αλλά είναι η
καθιερωμένη ορολογία που χρησιμοποιείται 

65
00:06:04,543 --> 00:06:09,362
στην μηχανική μάθηση. Μην νοιάζεστε πολύ 
γιατί το ονομάζουν έτσι. Όταν

66
00:06:09,362 --> 00:06:14,332
σχεδιάζετε έναν αλγόριθμο μάθησης, το επόμενο 
πράγμα που πρέπει να αποφασίσουμε είναι πως

67
00:06:14,332 --> 00:06:20,540
να αναπαραστήσουμε την υπόθεση h. Για αυτό και
τα επόμενα βίντεο, θα επιλέξω την

68
00:06:20,540 --> 00:06:26,978
αρχική επιλογή μας, για να αναπαραστήσω την 
υπόθεση. Θα το αναπαραστήσουμε  

69
00:06:26,978 --> 00:06:33,009
με τον ακόλουθο τρόπο. Και θα το γράψουμε ως
            hθ(x)  =  θ0 + 

70
00:06:33,009 --> 00:06:39,254
θ1 του x. Ως συντομογραφία, 
κάποιες φορές, αντί να γράφω 

71
00:06:39,254 --> 00:06:45,441
hθ του x , απλά θα γράφω h του x

72
00:06:45,441 --> 00:06:51,627
Αλλά πιο συχνά θα το γράφω όπως εδώ.
Και σχεδιάζοντας το

73
00:06:51,627 --> 00:06:58,210
στις εικόνες, σημαίνει ότι θα
προβλέψουμε ότι το y είναι γραμμική

74
00:06:58,210 --> 00:07:04,634
συνάρτηση του x. Ωραία, αυτό είναι το σύνολο 
δεδομένων και αυτό που κάνει η συνάρτηση,   

75
00:07:04,634 --> 00:07:11,698
είναι να προβλέψει ότι το y είναι μια συνάρτηση 
ευθείας γραμμής. Αυτό είναι h του x ίσον με θ0 

76
00:07:11,698 --> 00:07:18,450
συν θ1 του x, εντάξει; Και γιατί γραμμική
συνάρτηση; Κάποιες φορές θα θέλουμε να 

77
00:07:18,450 --> 00:07:23,405
προσαρμόσουμε πιο περίπλοκες, πιθανόν 
μη-γραμμικές συναρτήσεις. Αλλά αφού η γραμμική

78
00:07:23,405 --> 00:07:28,298
είναι αυτό το απλό block, θα ξεκινήσουμε 
το πρώτο παράδειγμα προσαρμόζοντας

79
00:07:28,298 --> 00:07:32,943
γραμμικές συναρτήσεις, και αργότερα 
θα κατασκευάσουμε πάνω του πιο περίπλοκα

80
00:07:32,943 --> 00:07:37,403
μοντέλα και πιο περίπλοκους αλγόριθμους μάθησης.
Ας ονομάσω το συγκεκριμένο μοντέλο.

81
00:07:37,403 --> 00:07:42,628
Αυτό το μοντέλο λέγεται γραμμική παλινδρόμηση 
και αυτό για παράδειγμα είναι

82
00:07:42,628 --> 00:07:48,271
γραμμική παλινδρόμηση με μία μεταβλητή,
με την μεταβλητή να είναι το x.

83
00:07:48,271 --> 00:07:53,914
Προβλέποντας όλες τις τιμές ως συναρτήσεις 
μίας μεταβλητής x. Και ένα άλλο όνομα για

84
00:07:53,914 --> 00:07:58,852
αυτό το μοντέλο είναι "μονοπαραγοντική
γραμμική παλινδρόμηση". Και μονοπαραγοντική είναι

85
00:07:58,852 --> 00:08:04,400
απλώς ένας ευφάνταστος τρόπος να πεις μία μεταβλητή.
Αυτή λοιπόν είναι η γραμμική παλινδρόμηση. Στο επόμενο

86
00:08:04,400 --> 00:08:09,760
βίντεο, θα ξεκινήσουμε να μιλάμε σχετικά με
το πως θα υλοποιούμε αυτό το μοντέλο.