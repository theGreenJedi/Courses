1
00:00:00,000 --> 00:00:04,100
Στο προηγούμενο βίντεο, δώσαμε τον 
μαθηματικό ορισμό της συνάρτησης κόστους

2
00:00:04,100 --> 00:00:08,616
Σε αυτό το βίντεο, ας δούμε μερικά παραδείγματα 
για να καταλάβουμε διαισθητικά

3
00:00:08,616 --> 00:00:14,466
τι κάνει η συνάρτηση κόστους και γιατί 
την χρησιμοποιούμε. Ανακεφαλαιώνοντας, να

4
00:00:14,466 --> 00:00:19,396
τι είχαμε την τελευταία φορά. Θέλουμε να προσαρμόσουμε 
μια ευθεία γραμμή στα δεδομένα μας, κι έτσι

5
00:00:19,396 --> 00:00:23,958
φτιάξαμε την υπόθεση με τις 
παραμέτρους θ0 και θ1 , και

6
00:00:23,958 --> 00:00:28,888
με διαφορετικές επιλογές παραμέτρων, παίρνουμε 
διαφορετικές προσαρμοσμένες ευθείες

7
00:00:31,323 --> 00:00:33,758
Άρα τα δεδομένα που προσαρμόζονται έτσι,
και υπάρχει κι η συνάρτηση κόστους, και

8
00:00:33,758 --> 00:00:38,554
αυτός ήταν ο σκοπός βελτιστοποίησης. Για []
αυτό το βίντεο, προκειμένου να απεικονίσουμε

9
00:00:38,554 --> 00:00:43,293
καλύτερα την συνάρτηση J, θα δουλέψω 
με μία απλοποιημένη συνάρτηση υπόθεσης,

10
00:00:43,293 --> 00:00:48,220
όπως αυτή που φαίνεται στα δεξιά. Έτσι,
θα χρησιμοποιήσω την απλοποιημένη υπόθεση,

11
00:00:48,220 --> 00:00:53,275
που είναι απλώς θ1*Χ. Μπορούμε, αν θέλετε, 
να το σκεφτούμε σαν να θέτουμε την

12
00:00:53,275 --> 00:00:58,721
παράμετρο θ0 ίση με 0. Έτσι έχω μόνο 
μία παράμετρο θ1 και

13
00:00:58,721 --> 00:01:04,372
η συνάρτηση κόστους μου είναι παρόμοια 
με πρίν, μόνο που τώρα h του x είναι ίσο με

14
00:01:04,372 --> 00:01:10,309
μόνο το θ1*x. Και έχω μόνο μια παράμετρο και έτσι

15
00:01:10,309 --> 00:01:16,246
ο σκοπός της βελτιστοποίησης είναι να 
ελαχιστοποιήσω την J του θ1. Σε εικόνες, αυτό σημαίνει

16
00:01:16,246 --> 00:01:21,611
ότι αν το θ0 είναι ίσο με 0, αυτό αντιστοιχίζεται 
με το να επιλέγεις μόνο συναρτήσεις υπόθεσης

17
00:01:21,611 --> 00:01:27,176
που περνούν από την αρχή των αξόνων, 
που περνούν από το σημείο (0,0).

18
00:01:27,176 --> 00:01:33,415
Χρησιμοποιώντας έναν απλοποιημένο ορισμό της συνάρτησης 
κόστους της υπόθεσης, ας προσπαθήσουμε να κατανοήσουμε την

19
00:01:33,415 --> 00:01:40,178
ιδέα της συνάρτησης κόστους καλύτερα. Καταλήγουμε ότι
υπάρχουν 2 συναρτήσεις-κλειδιά που θέλουμε να καταλάβουμε.

20
00:01:40,178 --> 00:01:46,432
Η πρώτη είναι η συνάρτηση υπόθεσης και η 
δεύτερη είναι η συνάρτηση κόστους. Παρατηρήστε

21
00:01:46,432 --> 00:01:52,068
ότι η υπόθεση h του x, για 
συγκεκριμένη τιμή του θ1, είναι μία

22
00:01:52,068 --> 00:01:58,168
συνάρτηση του x. Έτσι, η υπόθεση είναι μία 
συνάρτηση του μεγέθους του σπιτιού Χ.

23
00:01:58,168 --> 00:02:03,959
Αντίθετα, η συνάρτηση κόστους J, είναι
μία συνάρτηση της παραμέτρου θ1,

24
00:02:03,959 --> 00:02:09,993
που ελέγχει την κλίση της ευθείας. Ας 
αναπαραστήσουμε αυτές τις συναρτήσεις

25
00:02:09,993 --> 00:02:15,481
και να προσπαθήσουμε να τις καταλάβουμε καλύτερα. 
Ας αρχίσουμε με την υπόθεση. Στ' αριστερά, ας πούμε

26
00:02:15,481 --> 00:02:20,283
ότι έχω το σύνολο εκπαίδευσης με 3
σημεία (1,1), (2,2) και (3,3). Ας διαλέξουμε

27
00:02:20,283 --> 00:02:25,338
μία τιμή θ1, τέτοια ώστε όταν θ1=1

28
00:02:25,338 --> 00:02:30,392
τότε η υπόθεση μου θα μοιάζει με 
αυτή την ευθεία γραμμή εδώ πέρα.

29
00:02:30,392 --> 00:02:35,234
Και δείχνω όταν αναπαριστώ την συνάρτηση
υπόθεσης, στον άξονα x, ο οριζόντιος

30
00:02:35,234 --> 00:02:40,525
άξονας είναι ο x, επισημαίνονται
τα μεγέθη των σπιτιών εδώ πέρα.

31
00:02:40,525 --> 00:02:46,551
Τώρα, προσωρινά, ορίζω θ1=1, 
αυτό που θέλω να κάνω είναι

32
00:02:46,551 --> 00:02:52,430
να βρω πόσο είναι το J του θ1,
όταν θ1 ισούται με 1. Ας συνεχίσουμε

33
00:02:52,430 --> 00:02:58,781
και να υπολογίσουμε τι θα δώσει
η συνάρτηση κόστους για την τιμή 1.

34
00:02:58,781 --> 00:03:05,761
Ως συνήθως, η συνάρτηση κόστους ορίζεται
ως ακολούθως, ωραία; Κάποια από αυτά είναι

35
00:03:05,761 --> 00:03:13,840
σύνολα εκπαίδευσης του συνηθισμένου τετραγωνικού 
σφάλματος. Και άρα αυτό είναι ίσο με "αυτό".

36
00:03:14,740 --> 00:03:25,066
θ1*xi μείον yi και αν το απλοποιήσουμε, 
καταλήγουμε σε αυτό:

37
00:03:25,066 --> 00:03:31,995
0^2 + 0^2 + 0^2 που φυσικά είναι ίσο με 0. Τώρα,

38
00:03:31,995 --> 00:03:39,098
μέσα στην συνάρτηση κόστους, καταλήγουμε ότι
κάθε ένας από αυτούς τους όρους είναι 0. Επειδή

39
00:03:39,098 --> 00:03:46,288
για το συγκεκριμένο σύνολο εκπαίδευσης έχω 3
δείγματα εκπαίδευσης (1,1), (2,2), (3,3). Αν θ1

40
00:03:46,288 --> 00:03:54,667
είναι ίσο με 1, τότε h του xi είναι ίσο με yi ακριβώς. 
Επιτρέψτε μου να το γράψω

41
00:03:54,667 --> 00:04:04,164
καλύτερα. Και έτσι, h του x μείον y, κάθε ένας από 
αυτούς  τους όρους είναι ίσος με 0,

42
00:04:04,164 --> 00:04:14,821
κι έτσι βρίσκω ότι J του 1 είναι ίσο με 0. 
Πλέον ξέρουμε ότι το J του 1 είναι ίσο

43
00:04:14,821 --> 00:04:20,504
με 0. Ας το αναπαραστήσουμε γραφικά. Αυτό που 
θα κάνω στα δεξιά είναι να αναπαραστήσω την

44
00:04:20,504 --> 00:04:26,187
συνάρτηση κόστους J. Και παρατηρήστε ότι, επειδή η 
συνάρτηση κόστους είναι μία συνάρτηση με παράμετρο

45
00:04:26,187 --> 00:04:32,017
θ1, όταν αναπαριστώ την συνάρτηση κόστους, ο 
οριζόντιος άξονας επισημαίνεται ως θ1.

46
00:04:32,017 --> 00:04:38,069
Έχω λοιπόν J του 1 ίσο με 0, οπότε 
ας το αναπαραστήσουμε. Καταλήγουμε

47
00:04:38,069 --> 00:04:46,464
με ένα x εκεί πέρα. Τώρα ας δούμε κάποια 
άλλα παραδείγματα. Το θ-1 μπορεί να πάρει

48
00:04:46,464 --> 00:04:52,470
ένα εύρος τιμών. Άρα το θ-1 μπορεί 
να πάρει αρνητικές τιμές, μηδέν και

49
00:04:52,470 --> 00:04:58,876
θετικές τιμές. Τι γίνεται αν το θ-1 
είναι ίσο με 0.5; Ας το

50
00:04:58,876 --> 00:05:05,442
αναπαραστήσουμε. Θα ορίσω το θ-1 ίσο με 0.5
και σε αυτή την περίπτωση, η υπόθεση μου

51
00:05:05,442 --> 00:05:11,688
μοιάζει κάπως έτσι. Μία ευθεία 
με κλίση ίση με 0.5 και ας

52
00:05:11,688 --> 00:05:17,855
υπολογίσουμε το J για 0.5. Θα είναι 1 δια 2*m
της συνηθισμένης συνάρτησης κόστους.

53
00:05:17,855 --> 00:05:23,769
Καταλήγουμε ότι η συνάρτηση κόστους θα
είναι το άθροισμα των τετραγωνικών τιμών του

54
00:05:23,769 --> 00:05:29,609
ύψους αυτής της γραμμής συν το άθροισμα των 
τετραγώνων του ύψους εκείνης της γραμμής

55
00:05:29,609 --> 00:05:34,783
συν το άθροισμα των τετραγώνων του ύψους 
εκείνης της γραμμής, σωστά; Επειδή η κάθετη

56
00:05:34,783 --> 00:05:42,854
απόσταση είναι η διαφορά μεταξύ του
Υi και της προβλεπόμενης τιμής, h του Xi.

57
00:05:42,854 --> 00:05:48,772
Άρα το 1ο παράδειγμα θα είναι 0.5 - 1^2 επειδή

58
00:05:49,033 --> 00:05:55,647
η υπόθεση προέβλεψε 0.5 ενώ η 
πραγματική τιμή ήταν 1. Για το

59
00:05:55,647 --> 00:06:02,436
δεύτερο παράδειγμα, έχω 1 - 2^2, επειδή
η υπόθεσή μου προέβλεψε 1, αλλά

60
00:06:02,436 --> 00:06:09,663
η πραγματική τιμή του σπιτιού ήταν 2. Και
το τελευταίο είναι 1.5 - 3^2.

61
00:06:09,663 --> 00:06:17,263
Και αυτό είναι ίσο με 1 δια 2*3 επειδή
το m, το μέγεθος του συνόλου εκπαίδευσης,

62
00:06:17,263 --> 00:06:24,274
έχει 3 δείγματα εκπαίδευσης. 
.

63
00:06:24,274 --> 00:06:33,011
Απλοποιώντας τις παρενθέσεις είναι 3.5
Άρα έχω 3.5 / 6 που είναι περίπου 0.68 .

64
00:06:33,011 --> 00:06:41,085
Τώρα ξέρουμε ότι το J του 0.5 
είναι περίπου 0.68 . Ας το αναπαραστήσουμε.

65
00:06:41,085 --> 00:06:50,308
Ωπ, συγχωρήστε με, μαθηματικό λάθος. Είναι 0.58 . 
Άρα το αναπαριστούμε και είναι περίπου εκεί. Εντάξει;

66
00:06:50,308 --> 00:07:00,293
Τώρα, ας κάνουμε άλλο ένα. Τι συμβαίνει 
αν το θ1 είναι ίσο με 0; Με τι

67
00:07:00,293 --> 00:07:08,975
ισούται το J του 0; Καταλήγουμε ότι αν το 
θ1 είναι ίσο με 0, τότε το h του x είναι

68
00:07:08,975 --> 00:07:16,916
ίσο με αυτή την επίπεδη γραμμή, 
που απλώς πηγαίνει οριζόντια,

69
00:07:16,916 --> 00:07:26,882
κάπως έτσι. Και μετρώντας τα σφάλματα,
έχουμε ότι το J του 0 είναι ίσο με 1 δια 2*m

70
00:07:26,882 --> 00:07:34,659
επί 1^2 + 2^2 + 3^2 που είναι

71
00:07:34,659 --> 00:07:41,555
1/6 επί 14, περίπου 2.3 . Ας το
αναπαραστήσουμε και αυτό.

72
00:07:41,555 --> 00:07:47,622
Καταλήξαμε με μια τιμή περίπου 2.3
και φυσικά μπορούμε να συνεχίσουμε να

73
00:07:47,622 --> 00:07:53,335
το κάνουμε αυτό με άλλες τιμές του θ1.
Καταλήγουμε ότι μπορείτε να έχετε αρνητικές

74
00:07:53,335 --> 00:07:59,327
τιμές του θ1. Άρα αν το θ1 είναι αρνητικό,
τότε το h του x θα είναι ίσο με

75
00:07:59,327 --> 00:08:05,179
-0.5 επί x, τότε το θ1 είναι -0.5 
και αυτό αντιστοιχεί σε

76
00:08:05,179 --> 00:08:10,188
μία υπόθεση με αρνητική κλίση 0.5.
Μπορείτε να συνεχίσετε

77
00:08:10,188 --> 00:08:15,694
να υπολογίζετε αυτά τα σφάλματα. 
Καταλήγει να είναι, ξέρετε, για 0.5

78
00:08:15,694 --> 00:08:21,520
καταλήγει να έχει πολύ μεγάλο σφάλμα.
Βγαίνει κάτι περίπου στο 5.25

79
00:08:21,520 --> 00:08:28,087
Για διάφορες τιμές του θ1, μπορείτε
να τα υπολογίσετε αυτά, σωστά;

80
00:08:28,087 --> 00:08:34,413
Και καταλήγετε να έχετε υπολογίσει
αυτό το εύρος τιμών.

81
00:08:34,413 --> 00:08:40,499
Και υπολογίζοντας το εύρος τιμών, 
μπορείτε να χαράξετε την

82
00:08:40,499 --> 00:08:50,999
συνάρτηση J του θ. Αυτό λοιπόν είναι η J του θ.
Ανακεφαλαιώνοντας, για κάθε

83
00:08:50,999 --> 00:08:57,851
τιμή του θ1 αντιστοιχίζεται μια διαφορετική

84
00:08:57,851 --> 00:09:04,448
υπόθεση ή μια διαφορετική ευθεία 
προσαρμογής. Και για κάθε τιμή

85
00:09:04,448 --> 00:09:11,723
του θ1, θα μπορούσαμε να παραγωγίσουμε
μια διαφορετική τιμή του J του θ1. Και για

86
00:09:11,723 --> 00:09:19,354
παράδειγμα, το θ1=1 αντιστοιχίζεται
με την ευθεία γραμμή ανάμεσα

87
00:09:19,354 --> 00:09:27,846
στα δεδομένα, ενώ η θ=0.5 σε αυτό το μωβ σημείο

88
00:09:27,846 --> 00:09:35,340
αντιστοιχεί ίσως σε αυτή την γραμμή, και το
θ1=0 που φαίνεται με μπλε αντιστοιχεί

89
00:09:35,340 --> 00:09:41,527
στην οριζόντια γραμμή. Άρα, για κάθε τιμή 
του θ1 θα καταλήγουμε με μία

90
00:09:41,527 --> 00:09:48,516
διαφορετική τιμή του J του θ1 και θα μπορούσαμε 
να το χρησιμοποιήσουμε για να χαράξουμε αυτή την γραφική

91
00:09:48,516 --> 00:09:54,461
στα δεξιά. Τώρα, θυμάστε ότι ο σκοπός 
βελτιστοποίησης του αλγόριθμου

92
00:09:54,461 --> 00:10:01,963
μάθησης μας είναι ότι θέλουμε να διαλέξουμε 
τιμή του θ1 που ελαχιστοποιεί το J του θ1.

93
00:10:01,963 --> 00:10:08,076
Σωστά; Αυτή ήταν η αντικειμενική συνάρτηση 
για την γραμμική παλινδρόμηση. Κοιτώντας

94
00:10:08,076 --> 00:10:13,710
την καμπύλη, η τιμή που ελαχιστοποιεί την J του θ1
είναι, ξέρετε, θ1 ίσο με 1 .

95
00:10:13,710 --> 00:10:19,132
Και ιδού, αυτή είναι όντως η καλύτερη
δυνατή ευθεία προσαρμογής

96
00:10:19,132 --> 00:10:24,624
στα δεδομένα μας, θέτωντας θ1=1. 
Και μόνο για το συγκεκριμένο

97
00:10:24,624 --> 00:10:30,328
σύνολο εκπαίδευσης, προσαρμόζεται τέλεια. Και 
γι' αυτό ελαχιστοποιώντας το J του u1

98
00:10:30,328 --> 00:10:36,447
ανταποκρίνεται στην εύρεση μιας ευθείας που
προσαρμόζεται στα δεδομένα τόσο καλα.

99
00:10:36,447 --> 00:10:40,884
Κλείνοντας, σε αυτό το βίντεο, είδαμε κάποιες 
γραφικές παραστάσεις για να καταλάβουμε την

100
00:10:40,884 --> 00:10:45,259
συνάρτηση κόστους. Για να το κάνουμε αυτό, 
απλοποιήσαμε τον αλγόριθμο ώστε να έχει μόνο

101
00:10:45,259 --> 00:10:50,258
μία παράμετρο θ1. Ορίσαμε την παράμετρο θ0 να 
είναι μόνο 0. Στο επόμενο βίντεο , θα επιστρέψουμε

102
00:10:50,258 --> 00:10:54,445
στην αρχική διατύπωση του
προβλήματος και θα δούμε μερικές

103
00:10:54,445 --> 00:10:59,570
απεικονίσεις που περιλαμβάνουν και 
το θ0 και το θ1. Αυτό χωρίς να ορίσουμε

104
00:10:59,570 --> 00:11:04,757
το θ0 ίσο με 0. Και ελπίζω να σας δώσει μία
καλύτερη αίσθηση του τι κάνει

105
00:11:04,757 --> 00:11:09,257
η συνάρτηση κόστους J στην αρχική διατύπωση
του προβλήματος της γραμμικής παλινδρόμησης.