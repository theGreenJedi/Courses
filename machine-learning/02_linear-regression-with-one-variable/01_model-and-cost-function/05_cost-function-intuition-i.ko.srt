1
00:00:00,000 --> 00:00:04,100
전 비디오에서, 우리는 비용함수의 수학적 정의에 
대해 알아봤습니다.

2
00:00:04,100 --> 00:00:08,616
이번 비디오에서는, 몇몇 예제를 살펴보고,

3
00:00:08,616 --> 00:00:14,466
비용함수가 무슨 일을 하고, 
왜 우리가 사용해야 하는지에 대한 직감으로 돌아가보겠습니다.

4
00:00:14,466 --> 00:00:19,396
요약하자면, 이 것이 우리가 저번 시간에 했던 것들입니다. 
우리는 자료에 일직선을 맞추고 싶고,

5
00:00:19,396 --> 00:00:23,958
그래서 우리는 이런 형태의 가설과 
이런 파라메터 Θ0과 Θ1,

6
00:00:23,958 --> 00:00:28,888
그리고 다른 파라메터 값은 
다른 직선으로 표현된다는 것을 배웠습니다.

7
00:00:31,323 --> 00:00:33,758
그래서 자료는 이런 식으로 되고, 
이것은 비용함수

8
00:00:33,758 --> 00:00:38,554
그리고 이것이 최적화된 목표입니다. 
[sound] 이 비디오에서

9
00:00:38,554 --> 00:00:43,293
비디오에서 비용 함수 j를 더 시각화하기 위해서,

10
00:00:43,293 --> 00:00:48,220
저는 오른쪽에 보이는 간소화 한,

11
00:00:48,220 --> 00:00:53,275
Θ1에 x를 곱한 가설 함수를 사용하겠습니다. 
만약 원한다면,

12
00:00:53,275 --> 00:00:58,721
Θ0값은 0과 같다고 둘 수 있습니다. 
그래서 저는 파라메터 Θ1만 가진 상태이고,

13
00:00:58,721 --> 00:01:04,372
제 비용함수는 hΘxi값이 
Θ1xi라는 것만 빼고 비슷합니다.

14
00:01:04,372 --> 00:01:10,309
그리고 하나의 파라메터 Θ1만 
가진 상태이기 때문에,

15
00:01:10,309 --> 00:01:16,246
저의 최적화된 목표는 jΘ1의 최소값입니다.

16
00:01:16,246 --> 00:01:21,611
그림에서 의미하는 바를 보자면, 
Θ0가 0일 때

17
00:01:21,611 --> 00:01:27,176
선택된 하나의 가설함수는 원점을 지나고, 
(0, 0) 점을 지나게 됩니다.

18
00:01:27,176 --> 00:01:33,415
이 간소화 한 가설 비용 함수를 이용하면, 
비용 함수 개념을 더 잘 이해할 수 있습니다

19
00:01:33,415 --> 00:01:40,178
두개의 중요한 함수를 이해해야 합니다.

20
00:01:40,178 --> 00:01:46,432
첫번째는 가설 함수이고, 
두번째는 비용 함수입니다.

21
00:01:46,432 --> 00:01:52,068
가설함수를 보시면, 오른쪽에 hΘx가 있습니다.

22
00:01:52,068 --> 00:01:58,168
액면가로는 Θ1, 이것은 x의 함수입니다. 
그래서 가설은 함수로서, 집 x의 크기를 말합니다.

23
00:01:58,168 --> 00:02:03,959
반대로, 비용 함수 J는, 
직선의 경사를 좌지우지하는

24
00:02:03,959 --> 00:02:09,993
파라메터 Θ1의 함수입니다. 
이 함수들에 표시를 해보고

25
00:02:09,993 --> 00:02:15,481
이 둘을 더 잘 이해해봅시다. 
가설부터 시작합시다. 왼쪽에,

26
00:02:15,481 --> 00:02:20,283
제 훈련집합이 (1, 1), (2, 2), (3, 3), 
세가지 점으로 이루어져 있다고 가정해봅시다.

27
00:02:20,283 --> 00:02:25,338
Θ1의 값을 구해보면, Θ1은 1과 같고, 
만약 제 선택이 Θ1이라면,

28
00:02:25,338 --> 00:02:30,392
제 가설은 여기에 있는 
직선처럼 보여질 것입니다.

29
00:02:30,392 --> 00:02:35,234
만약 제 가설 함수가 그래프에 
그려진다고 해보겠습니다

30
00:02:35,234 --> 00:02:40,525
x라고 이름 붙여진 수평의 축, 
즉 x축은 여기 써 있는 대로 주택의 크기입니다.

31
00:02:40,525 --> 00:02:46,551
이제, 일시적으로, Θ1이 1과 같다고 하면,

32
00:02:46,551 --> 00:02:52,430
Θ1이 1과 같을 때, 
jΘ1 값이 무엇인지를 알아내야 합니다.

33
00:02:52,430 --> 00:02:58,781
자, 비용함수가 어떤 값인지 계산해봅시다. 
당신은 1을 절하할 것입니다. 음

34
00:02:58,781 --> 00:03:05,761
보통 비용함수는 다음과 같이 표현합니다, 맞죠?

35
00:03:05,761 --> 00:03:13,840
보통의 오차 제곱의 훈련 집합이고,

36
00:03:14,740 --> 00:03:25,066
이 식은 이 식, Θ1xi – yi와 같습니다.

37
00:03:25,066 --> 00:03:31,995
만약 이걸 간소화한다면 
0의 제곱 더하기 0의 제곱 더하기 0의 제곱이고,

38
00:03:31,995 --> 00:03:39,098
당연히 이 값은 0의 제곱과 같습니다. 
이제 비용함수 안을 봅시다. 이 식들은 0과 같습니다.

39
00:03:39,098 --> 00:03:46,288
왜냐하면 제가 가지고있는 특별한 훈련집합, 
3개의 훈련 예시가 (1, 1), (2, 2), (3, 3)이기 때문입니다.

40
00:03:46,288 --> 00:03:54,667
만약 Θ1이 1과 같다면, 
hΘxi 값은 yi와 같습니다.

41
00:03:54,667 --> 00:04:04,164
더 잘 설명해보겠습니다. 
그래서 hΘxi – yi 등 이 식들은 0과 같고,

42
00:04:04,164 --> 00:04:14,821
그 이유는 제가 j함수가 0이라는 것을 
알았기 때문입니다.

43
00:04:14,821 --> 00:04:20,504
그래서 이제 우리는 j1은 0임을 알게 되었습니다. 
이것을 도표로 그려봅시다.

44
00:04:20,504 --> 00:04:26,187
오른쪽에 비용 함수 그래프 j를 그려보겠습니다. 
말씀드린 것처럼, 비용함수는 파라메터 Θ1의 함수와 같기 때문에,

45
00:04:26,187 --> 00:04:32,017
비용함수를 그렸을 때, 
수평축은 이제 Θ1이 됩니다.

46
00:04:32,017 --> 00:04:38,069
j1은 0이고, 
이제 그것을 그래프에 그려보겠습니다.

47
00:04:38,069 --> 00:04:46,464
여기 엑스 표시에서 끝나게 됩니다. 
다른 예시들도 같이 봅시다.

48
00:04:46,464 --> 00:04:52,470
그래서 Θ-1은 다른 범위의 값들을 가지게 됩니다, 맞죠? 
Θ1은 음수 값, 0, 그리고 양수 값을 가지게 됩니다.

49
00:04:52,470 --> 00:04:58,876
그래서 만약 Θ-1이 0,5와 같다면. 어떻게 될까요?

50
00:04:58,876 --> 00:05:05,442
한번 그래프에 그려봅시다. 
저는 Θ-1이 0.5와 같다고 두고,

51
00:05:05,442 --> 00:05:11,688
이 상황에서 가설은 이런 식으로 보이게 됩니다. 
경사는 0.5가 되고,

52
00:05:11,688 --> 00:05:17,855
j0.5를 계산해봅시다. 1/2m을 곱하고요, 
계속 썼던 비용 함수입니다.

53
00:05:17,855 --> 00:05:23,769
비용 함수는, 
이 선들을 제곱한 것의 합계가 될 것입니다.

54
00:05:23,769 --> 00:05:29,609
이 선의 길이의 제곱을 더하고, 
이 선의 길이를 제곱한 것을 더하고,

55
00:05:29,609 --> 00:05:34,783
이 선의 길이를 제곱한 것을 더하겠습니다, 맞죠?
왜냐하면 이 수직의 길이는,

56
00:05:34,783 --> 00:05:42,854
이 둘의 차이는, 아시다시피, yi값과, 예측 값인 hΘxi의 차입니다.

57
00:05:42,854 --> 00:05:48,772
그래서 첫번째 예시는 
0.5 빼기 1의 제곱이 됩니다.

58
00:05:49,033 --> 00:05:55,647
가설이 0.5로 예측되기 때문에, 
실제 값은 1이 됩니다.

59
00:05:55,647 --> 00:06:02,436
두번째 예시로는, 
1에서 2를 제곱한 것을 빼 주는데,

60
00:06:02,436 --> 00:06:09,663
가설이 1로 예측되지만, 그러나 실제 집의 가격은 2입니다. 
그리고 마지막으로 1.5 – 3의 제곱 값을 더해줍니다.

61
00:06:09,663 --> 00:06:17,263
그래서 이 값은 1/2 곱하기 1/3과 같아집니다. 
왜냐면 m읜 집합의 개수이고,

62
00:06:17,263 --> 00:06:24,274
우리는 3가지의 훈련 집합을 
가지고 있기 때문입니다.

63
00:06:24,274 --> 00:06:33,011
그래서, 괄호안의 값은 간단하게 3.5로 정리할 수 있습니다. 
그래서 3.5 곱하기

64
00:06:33,011 --> 00:06:41,085
3.5 곱하기 1/6은 0.68이 됩니다. 
그래서 이제 우리는 j0.5값은 0.68이라는 것을 알게 되었습니다.

65
00:06:41,085 --> 00:06:50,308
이것을 그래프에 그려보겠습니다. 
아, 계산 실수를 했네요, 사실은 0.58입니다.

66
00:06:50,308 --> 00:07:00,293
그래서 그래프에 그려보겠습니다. 
한가지 더 해봅시다. 만약 Θ1이 1과 같다면,

67
00:07:00,293 --> 00:07:08,975
j0도 같을까요? 
Θ1이 0과 같다고 두고, hx도 이 납작한 선처럼,

68
00:07:08,975 --> 00:07:16,916
이런 식으로 수평으로 간다고 해봅시다.

69
00:07:16,916 --> 00:07:26,882
그 다음에 오차를 계산해봅시다. j0값은

70
00:07:26,882 --> 00:07:34,659
값은 1/2m을 곱하고 
1의 제곱에 2의 제곱과 3의 제곱을 더한 값입니다.

71
00:07:34,659 --> 00:07:41,555
이 값은, 1/6에 2.3을 곱한 값이 되며. 
2.3정도가 됩니다.

72
00:07:41,555 --> 00:07:47,622
이제 이것도 그래프에 그려봅시다. 
그래서 2.3 값에서 끝나게 되고,

73
00:07:47,622 --> 00:07:53,335
우리는 Θ1의 다른 값도 구할 수 있습니다.

74
00:07:53,335 --> 00:07:59,327
Θ1의 값이 음수라면,

75
00:07:59,327 --> 00:08:05,179
hx의 값은 -0.5에 x를 곱한 값이 되며,

76
00:08:05,179 --> 00:08:10,188
Θ1은 -0.5가 해서, 
-0.5의 경사와 가설이 일치하게 됩니다.

77
00:08:10,188 --> 00:08:15,694
그리고 당신은 이 차를 계산할 수 있습니다. 
당신도 아시다시피 0.5값이 되는데,

78
00:08:15,694 --> 00:08:21,520
아주 큰 차가 됩니다. 
이 값은 5.25가 되고요.

79
00:08:21,520 --> 00:08:28,087
계속해서 당신의 범위 안의 값을 계산하면, 
이런 점들을 갖게 됩니다.

80
00:08:28,087 --> 00:08:34,413
그리고 많은 범위의 값들을 계산 하다 보면,

81
00:08:34,413 --> 00:08:40,499
실제로는 천천히 이런 식으로 
그래프가 만들어집니다.

82
00:08:40,499 --> 00:08:50,999
J에 Θ를 넣으면 어떻게 될까요? 
이게 바로 j에 Θ를 넣은 값입니다.

83
00:08:50,999 --> 00:08:57,851
요약하자면, 
Θ1값, 각각의 Θ1값은 1을 지나게 되고,

84
00:08:57,851 --> 00:09:04,448
다른 가설 또는 왼쪽에 있는 
다른 직선과 일치하게 됩니다.

85
00:09:04,448 --> 00:09:11,723
그리고 Θ1의 각각의 값은,
다른 jΘ1의 값을 이끌어 내게 됩니다.

86
00:09:11,723 --> 00:09:19,354
예를 들자면, Θ1이 1일 때 
자료는 이런 직선과 일치하게 되고,

87
00:09:19,354 --> 00:09:27,846
Θ1이 0.5일때는. 
그럴 때는 지금 분홍색으로 표시하고 있는

88
00:09:27,846 --> 00:09:35,340
이 점과 이 선이 일치하게 되고, 
Θ1이 0일때는 이 파란색 점이

89
00:09:35,340 --> 00:09:41,527
이 수평선과 일치하게 됩니다. 
그래서 각각의 Θ1의 값을 jΘ1의

90
00:09:41,527 --> 00:09:48,516
다른 값들과 처리했고, 
우리는 오른쪽에 있는 이 그래프를

91
00:09:48,516 --> 00:09:54,461
그릴 수 있었습니다. 
이제 기억하시는 것처럼, 우리가 배우는

92
00:09:54,461 --> 00:10:01,963
지도 알고리즘의 최선의 목표는 Θ1입니다. 
jΘ1값을 최소화 하는 것입니다, 맞죠?

93
00:10:01,963 --> 00:10:08,076
이것은 선형 회귀를 배울 때 목적 함수였습니다.

94
00:10:08,076 --> 00:10:13,710
이 곡선을 보시면, jΘ1의 최소값은, 
Θ1이 1일 때 입니다.

95
00:10:13,710 --> 00:10:19,132
보시게 되면, 당연히 가장 최선의 직선은

96
00:10:19,132 --> 00:10:24,624
자료와 잘 맞고, 
Θ1이 1과 같다고 두면서,
우리는 실제로 완벽하게 일치하게 됩니다.

97
00:10:24,624 --> 00:10:30,328
그리고 이것이 왜 jΘ1을 최소화한 값이

98
00:10:30,328 --> 00:10:36,447
자료에 잘 맞는 직선을 찾는 것과 
일치하는 이유입니다.

99
00:10:36,447 --> 00:10:40,884
정리해보자면요. 
이 비디오에서는 우리는 몇 개의 그래프를 봤습니다.

100
00:10:40,884 --> 00:10:45,259
비용함수에 대해 이해하기 위해서요.
그렇게 하기 위해서, 우리는 알고리즘을 간소화했죠.

101
00:10:45,259 --> 00:10:50,258
그래서 1개의 파라메터 Θ1만이 가지고 있었습니다. 
그리고 파라메터 Θ0는 0밖에 될 수 없었죠.

102
00:10:50,258 --> 00:10:54,445
다음 비디오에서는, 
우리는 우리는 다시 공식 문제로 돌아가서

103
00:10:54,445 --> 00:10:59,570
Θ0과 Θ1이 포함된 시각적 자료를 보도록 하겠습니다.

104
00:10:59,570 --> 00:11:04,757
Θ0를 0으로 설정하지 않고요. 
그렇게 한다면,

105
00:11:04,757 --> 00:11:09,257
선형 회귀 공식을 배우면서 
비용함수 j에 대해 더 나은 이해를 할 수 있을 것입니다