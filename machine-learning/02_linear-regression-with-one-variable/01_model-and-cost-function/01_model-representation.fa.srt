1
00:00:02,338 --> 00:00:04,677
اولین الگوریتم یادگیری مون رگرسیون خطی
خواهد بود . توی این ویدیو ، خواهید دید

2
00:00:06,956 --> 00:00:09,234
مدلش چه شکلی هست و مهمتر
از همه خواهید دید که درکل

3
00:00:09,234 --> 00:00:14,801
فرآیند یادگیری نظارت شده چگونه است .
بزارین چند تا نمونه مهیج پیش بینی

4
00:00:14,801 --> 00:00:20,036
قیمت خونه بزنم . میخوایم مجموعه داده ایی 
از قیمت های خونه استفاده کنیم از شهر

5
00:00:20,036 --> 00:00:25,205
پورتلند ،اوریگون . و اینجا میخوام مجموعه داده ام
رو چاپ کنم که از تعدادی خونه های

6
00:00:25,205 --> 00:00:30,833
با اندازه های مختلف هست که با قیمت های
متفاوتی به فروش رفته . بزارین بگیم

7
00:00:30,833 --> 00:00:35,872
که مجموعه داده دراختیار گذاشته شده ، 
دوستی دارین که سعی داره خونه اش رو بفروشه و

8
00:00:35,872 --> 00:00:41,238
بزارین ببینیم اگه خونه دوستتون اندازش 
1250 اسکوئر فیت باشه و بخواین بهش بگین

9
00:00:41,238 --> 00:00:46,459
چه مقدار اونا قادر خواهند بود که خونه رو 
براش بفروشن .خب یه چیزی که میتونین انجام بدین

10
00:00:46,648 --> 00:00:53,039
اینه مدلی براش تطبیق بدین . شاید انطباق 
خطی مستقیم به این داده ها . یه چیزی شبیه آن و بر اساس

11
00:00:53,039 --> 00:00:59,168
اون ، شاید بتونین به دوستتون بگین که 
احتمالا بتونه خونش رو بفروشه به

12
00:00:59,168 --> 00:01:03,575
حدود 220.000 دلار . خب این 
نمونه ایی از یک

13
00:01:03,575 --> 00:01:08,834
الگوریتم یادگیری نظارت شده هست . و 
یادگیری نظارت شده هست ، چون بهش

14
00:01:08,834 --> 00:01:14,287
به قولی ، "جواب صحیح" رو دادیم برای هر یک
از نمونه هامون . یعنی ما بهش گفتیم که

15
00:01:14,287 --> 00:01:19,351
قیمت واقعی خونه چقدر هست ، قیمت واقعی
هر خونه چقدر بوده توی مجموعه داده هامون

16
00:01:19,351 --> 00:01:24,441
که فروخته شدن و بیشتر از اون ، این
نمونه ایی از یه مساله رگرسیون هست که

17
00:01:24,441 --> 00:01:29,545
اصطلاح رگرسیون اشاره داره به عاملی
که مقادیر حقیقی خروجی رو داریم پیش بینی میکنیم

18
00:01:29,545 --> 00:01:34,586
به نام قیمت . و فقط یادتون باشه 
نوع مرسوم دیگه ای از مساله یادگیری

19
00:01:34,586 --> 00:01:39,006
نظارت شده اسمش مساله طبقه بندی هست
که پیش بینی میکنیم

20
00:01:39,006 --> 00:01:45,202
مقادیر گسسته خروجی رو مثل اینکه 
اگر به تومور سرطانی نگاهی بندازیم و سعی کنیم به

21
00:01:45,202 --> 00:01:52,032
تصمیم گیری که آیا تومور بدخیم هست یا 
خوش خیم . خب اون خروجی گسسته با مقدار صفر-یک  هست .

22
00:01:52,032 --> 00:01:57,087
به شکلی رسمی تر ، در یادگیری نظارت شده ، 
مجموعه داده ایی داریم و این مجموعه داده به نام یک

23
00:01:57,087 --> 00:02:02,018
مجموعه آموزشی نامیده میشه . پس برای 
نمونه قیمت های خونه ، مجموعه ایی آموزشی داریم از

24
00:02:02,018 --> 00:02:07,386
قیمت خونه های مختلف و کار مون یادگیری
از این داده هاست که چطور پیش بینی کنیم قیمت

25
00:02:07,386 --> 00:02:11,907
خونه هارو . بزارین چند تا علامت رو بگم 
که توی این دوره ازشون استفاده میکنیم .

26
00:02:11,907 --> 00:02:16,100
میخوایم نمادهای زیادی رو به شکل کامل 
تعریف کنیم . مشکلی نیست اگر یادتون نباشه

27
00:02:16,100 --> 00:02:20,075
همه ی نماد ها رو بدرستی حالا ، ولی 
همینطور که دوره جلو میره مفید خواهد بود

28
00:02:20,075 --> 00:02:24,267
دونستن نماد مناسب . پس از حرف ام کوچیک 
توی این دوره برای

29
00:02:24,267 --> 00:02:28,897
اختصاص تعداد نمونه های آموزشی استفاده میکنم .
پس توی این مجموعه داده ، اگر داشته باشم ، میدونین ،

30
00:02:28,897 --> 00:02:34,366
بزارین بگم 47 سطر توی این جدول . بنابراین 
47 نمونه آموزشی دارم و ام برابر با 47 هست .

31
00:02:34,366 --> 00:02:39,497
بزارین از حرف ایکس کوچیک برای اختصاص به 
متغییر های ورودی استفاده کنم که اغلب به نام

32
00:02:39,497 --> 00:02:44,290
ویژگی نامیده شده . ایکس اینجا خواهد بود ، 
این ویژگی ورودی خواهد بود . و میخوام

33
00:02:44,290 --> 00:02:49,556
حرف ایگرگ رو اختصاص بدم به متغیر های خروجی
یا متغیر هدف که میخوام

34
00:02:49,556 --> 00:02:54,552
پیش بینی کنم و خب اون دومین ستون اینجاست .
سومین علامت ، میخوام

35
00:02:54,552 --> 00:03:05,749
از پرانتز ایکس و ایگرگ برای اختصاص به یه
نمونه آزمایشی استفاده کنم . خب یک سطر تکی تو این

36
00:03:05,749 --> 00:03:12,068
جدول مرتبط به تک نمونه آموزشی
و اشاره به نمونه آموزشی خاصی داره،

37
00:03:12,068 --> 00:03:19,708
میخوام این علامت ایکس پرانتز آی رو استفاده کنم 
بهم ایگرگ پرانتز آی رو میده و ، میخوایم

38
00:03:25,322 --> 00:03:30,935
این رو برای اشاره به آی امین نمونه آموزشی مون
بکار بگیریم . پس این سوپر اسکریپت آی

39
00:03:30,935 --> 00:03:37,864
توی اینجاست ، این به توان رسوندن نیست درست ؟
این ایکس آی ام ، ایگرگ آی ام ، سوپر اسکرییپت آی توی

40
00:03:37,864 --> 00:03:44,873
پرانتز ها که فقط اندیس داخل مجموعه
داده آموزشی ام هستن و اشاره به سطر آی ام توی

41
00:03:44,873 --> 00:03:51,629
این جدول داره ، باشه ؟ خب این ایکس به توان آی 
نیست ، و ایگرگ به توان آی نیست .بجای اون

42
00:03:51,629 --> 00:03:58,216
ایکس آی و ایگرگ آی فقط اشاره به آی امین سطر
این جدول دارن . پس برای نمونه ، ایکس 1 اشاره داره به

43
00:03:58,216 --> 00:04:04,972
مقدار ورودی برای اولین نمونه آموزشی ، خب 
اون 2104 هست . اون این ایکسه توی اولین

44
00:04:04,972 --> 00:04:11,685
سطر . ایکس 2 برابر با 1416 خواهد بود درسته ؟
اون دومین ایکس هست

45
00:04:11,685 --> 00:04:17,385
و ایگرگ 1 برابر با 460 خواهد بود .
اولی ، مقدار ایگرگ برای اولین

46
00:04:17,385 --> 00:04:24,526
نمونه آموزشی ام ، اون چه که هست به 1 اشاره داره . 
پس همونطور که ذکر کردم ، بعضی وقتا ازتون

47
00:04:24,526 --> 00:04:28,345
پرسشی میکنم برای بررسی درک شما 
و چند ثانیه توی این

48
00:04:28,345 --> 00:04:34,044
ویدیو یک پرسش چند انتخابی بر روی
ویدیو نشون داده میشه . وقتیکه اومد

49
00:04:34,044 --> 00:04:40,362
لطفا ماوس تون رو برای انتخاب چیزی که 
فکر میکنین پاسخ صحیح هست استفاده کنین . چیزیکه تعریف شده

50
00:04:40,362 --> 00:04:45,124
مجموعه آموزشی هست . خب اینجا 
نحوه کار کردن این الگوریتم یادگیری نظارت شده هست .

51
00:04:45,124 --> 00:04:50,513
اون رو با مجموعه آموزشی ایی شبیه مجموعه 
آموزشی قیمت خونه هامون دیدیم و خوراک

52
00:04:50,513 --> 00:04:55,715
الگوریتم یادیگیری مون میکنیمش . یه کار 
یه الگوریتم یادگیری هست که بعدش یک

53
00:04:55,715 --> 00:05:00,101
تابع ازش خارج میشه که طبق قرارداد
معمولا با حرف اچ کوچیک نشونش میدن و اچ

54
00:05:00,101 --> 00:05:06,574
سرنام فرضیه هست و کار فرضیه اینه که ،
یه تابعی هست که

55
00:05:06,574 --> 00:05:12,471
اندازه خونه ای رو مثل شاید اندازه خونه جدید 
دوستتون به عنوان اندازه ورودی میگیره

56
00:05:12,471 --> 00:05:18,368
که سعی داره اون رو بفروشه ، پس اونو توی
مقداری از ایکس میگیره و سعی بر برآورد

57
00:05:18,368 --> 00:05:31,630
مقداری از ایگرگ برای خونه مورد نظرمون میکنه .
پس اچ تابعی هست برای نگاشت ایکس ها

58
00:05:31,630 --> 00:05:37,729
به ایگرگ ها . مردم اغلب از من میپرسن ، میدونین
میگن چرا نام تابع شده

59
00:05:37,729 --> 00:05:42,121
فرضیه . تعدادی از شما ها ممکنه معنی 
اصطلاح فرضیه رو بدونین ، از

60
00:05:42,121 --> 00:05:46,744
لغتنامه یا از علوم پایه یا هر چیز دیگه ای .
پیداست که توی یادگیری ماشین ، این

61
00:05:46,744 --> 00:05:51,310
نامی هست که در روزگار اولیه یادگیری ماشین 
استفاده شده و کمی تردید توش داره . چون

62
00:05:51,310 --> 00:05:55,239
احتمالا اسم عالی ایی برای این نوع تابع 
نیست ، برای نگاشت اندازه

63
00:05:55,239 --> 00:05:59,978
خونه ها به پیش بینی ها ، که میدونین ... 
فکر میکنم اصطلاح فرضیه ، شاید

64
00:05:59,978 --> 00:06:04,543
بهترین نام ممکن برای این نباشه ، ولی 
اصطلاحی استاندارد هست که مردم استفاده میکنن توی

65
00:06:04,543 --> 00:06:09,362
یادگیری ماشین . پس زیاد نگران این نباشین که
مردم اونو چی صدا میزنن . وقتی

66
00:06:09,362 --> 00:06:14,332
الگوریتم یادگیری ایی رو طراحی میکنیم ، چیز
بعدی ایی که لازم داریم تصمیم گیری اینه که چطور

67
00:06:14,332 --> 00:06:20,540
این فرضیه اچ رو بیان کنیم . برای این ویدیو و 
چندتای بعدی ، میخوام انتخاب کنم

68
00:06:20,540 --> 00:06:26,978
انتخاب اولیه مون رو ، برای بیان فرضیه ها
در ادامه خواهد بود . میخوایم

69
00:06:26,978 --> 00:06:33,009
اچ رو به صورت زیر معرفی کنیم . و مثل اونو اینجوری مینویسیم 
h<u>theta(x) equals theta<u>0</u></u>

70
00:06:33,009 --> 00:06:39,254
plus theta<u>1 of x. And as a shorthand,
sometimes instead of writing, you</u>

71
00:06:39,254 --> 00:06:45,441
میدونین ، اچ زیر تتا ایکس ، بعضی وقتا 
کاربردی تره ، فقط مینویسم اچ یا ایکس .

72
00:06:45,441 --> 00:06:51,627
ولی اکثر وقتا به صورت زیر تتا توی اونجا
مینویسم . و چاپ میکنم

73
00:06:51,627 --> 00:06:58,210
این و توی تصاویر ، همه اینا به این معناست که
میخوایم ایگرگی رو پیش بینی که تابعی خطی از

74
00:06:58,210 --> 00:07:04,634
ایکس هست . درست . پس اون مجموعه داده 
هست و کاری که این تابع انجام میده ،

75
00:07:04,634 --> 00:07:11,698
پیش بینی اینه که ایگرگ تابع خطی مستقیمی 
از ایکس هست . که هست اچ ایکس برابر تتا 0

76
00:07:11,698 --> 00:07:18,450
به علاوه تتا 1 ایکس ، باشه ؟ و چرا تابعی خطی ؟
خب ، بعضی مواقع میخوایم

77
00:07:18,450 --> 00:07:23,405
پیچیده تری بیشتری تطبیق داده بشه ، شاید 
تابعی غیر خطی . ولی از اونجا که این مورد خطی

78
00:07:23,405 --> 00:07:28,298
بلاک ساختمونی ساده ایی هست ، با این
نمونه شروع میکنیم اول منطبق کنیم

79
00:07:28,298 --> 00:07:32,943
تابعی خطی ، و بر طبق این درنهایت 
نمونه هایی با پیچیدگی بیشتری رو ایجاد میکنیم

80
00:07:32,943 --> 00:07:37,403
و الگوریتم های یادگیری پیچیده تری رو . 
بزارین همچنین به این

81
00:07:37,403 --> 00:07:42,628
مدل خاص اسمی بدم . نام این مدل
رگرسیون خطی هست یا این برای

82
00:07:42,628 --> 00:07:48,271
مثال ، در واقع رگرسیون خطی ایی با
یک متغییر هست ، با متغییری که ایکس هست .

83
00:07:48,271 --> 00:07:53,914
پیش بینی کلیه قیمت ها به عنوان تابعی 
از متغیر ایکس . و اسم دیگه ای برای

84
00:07:53,914 --> 00:07:58,852
این مدل ، رگرسیون خطی تک متغیره هست .
و تک متغیره فقط برای

85
00:07:58,852 --> 00:08:04,400
اینه که بگیم یه متغیر داره . پس 
رگرسیون خطی هست . توی

86
00:08:04,400 --> 00:08:09,760
ویدیو بعدی شروع میکنیم به صحبت 
درباره اینکه چطور این مدل رو پیاده سازی کنیم .