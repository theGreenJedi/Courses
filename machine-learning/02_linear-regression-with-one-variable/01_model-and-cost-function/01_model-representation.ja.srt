1
00:00:02,338 --> 00:00:04,677
最初に学ぶ学習アルゴリズムは線形回帰です。このビデオでは、

2
00:00:06,956 --> 00:00:09,234
そのモデルがどのようなもので、さらに重要なのは、総合的に

3
00:00:09,234 --> 00:00:14,801
教師あり学習のプロセスがどのようなものかを見ていきます。では、動機付けをする例として、

4
00:00:14,801 --> 00:00:20,036
住宅の価格を予測する例を使いましょう。ここで使うデータセットは、

5
00:00:20,036 --> 00:00:25,205
オレゴン州ポートランド市の住宅価格のものです。ここにデータセットをプロットします。いくつかの家の

6
00:00:25,205 --> 00:00:30,833
それぞれのサイズと、それらが売れたそれぞれの価格の範囲です。

7
00:00:30,833 --> 00:00:35,872
このデータセットを元に、家を売ろうとしている友人がいたとして、

8
00:00:35,872 --> 00:00:41,238
そうですね、その人の家のサイズが 1250 平行フィートで、

9
00:00:41,238 --> 00:00:46,459
幾らで家を売ることが出来るか教えたいとします。さて、できることの一つは、

10
00:00:46,648 --> 00:00:53,039
モデルを当てはめることです。例えば、このデータに直線を当てはめるとします。こんな感じに。そして

11
00:00:53,039 --> 00:00:59,168
それに基づき、友人に言えることは、そうですね、例えば

12
00:00:59,168 --> 00:01:03,575
その家をだいたい 22万ドルぐらいで売れるだろうということです。これは

13
00:01:03,575 --> 00:01:08,834
教師あり学習アルゴリズムの一例です。これが教師あり学習だという理由は

14
00:01:08,834 --> 00:01:14,287
それぞれのサンプルに対して「正解」が与えられているからです。つまり、

15
00:01:14,287 --> 00:01:19,351
実際の家が、データセット内のそれぞれの家が実際に

16
00:01:19,351 --> 00:01:24,441
いくらで売れたのかです。さらに、これは回帰問題の一例です。

17
00:01:24,441 --> 00:01:29,545
回帰という言葉は、私たちが予測しようとしているのが実数値の出力であるという事実を指しています。

18
00:01:29,545 --> 00:01:34,586
つまり価格です。そして思い返して頂きたいのは、もう一つの最も一般的なタイプの

19
00:01:34,586 --> 00:01:39,006
教師あり学習問題は分類問題と呼ばれ、それは

20
00:01:39,006 --> 00:01:45,202
離散値出力を予測するものでした。例えば、癌腫瘍を見て

21
00:01:45,202 --> 00:01:52,032
どれが悪性でどれが良性かを判別する場合です。それは 0 か 1 の値で、つまり離散値です。もっと

22
00:01:52,032 --> 00:01:57,087
形式的に言うと、教師あり学習ではデータセットがあり、そしてこのデータセットは

23
00:01:57,087 --> 00:02:02,018
訓練セットと呼ばれます。ですから住宅の価格の例では、訓練セットとして

24
00:02:02,018 --> 00:02:07,386
それぞれの家の価格があり、課題は、このデータから住宅の価格を

25
00:02:07,386 --> 00:02:11,907
予測するよう学習することです。では、このコースを通して使ういくつかの表記方法を定義します。

26
00:02:11,907 --> 00:02:16,100
かなりの数のシンボルを定義していきます。全てのシンボルを

27
00:02:16,100 --> 00:02:20,075
今すぐ覚えなくても構いません。しかし、コースが進行するにつれて、こうした表記方法を

28
00:02:20,075 --> 00:02:24,267
覚えていくと便利です。では、このコースを通して小文字の m を使って

29
00:02:24,267 --> 00:02:28,897
訓練サンプルの数を表します。ですからの、このデータセットでは

30
00:02:28,897 --> 00:02:34,366
この表には 47 行あるとします。ということは 47 件の訓練サンプルがあるということで、m = 47 となります。

31
00:02:34,366 --> 00:02:39,497
小文字の x を使って、入力変数を表します。これはよく

32
00:02:39,497 --> 00:02:44,290
特徴とも言われます。これはここの x です。 この下に並ぶのが入力する特徴です。そして

33
00:02:44,290 --> 00:02:49,556
y を使って予測する出力変数、目標変数を表します。

34
00:02:49,556 --> 00:02:54,552
そしてそれはこの二番目の列です。もう少し表記方法について。

35
00:02:54,552 --> 00:03:05,749
(x, y) と表記して一件の訓練サンプルを表します。ですから、この表の各行が

36
00:03:05,749 --> 00:03:12,068
一件の訓練サンプルに対応します。そして、特定の

37
00:03:12,068 --> 00:03:19,708
訓練サンプルを指すときには、この表記方法 (x(i), y(i)) を使い、

38
00:03:25,322 --> 00:03:30,935
これを使って i 番目の訓練サンプルを指します。ですから、この添え字 i は

39
00:03:30,935 --> 00:03:37,864
ここにありますが、これは指数ではありません。よいですか。この (x(i), y(i)) では、添え字の i は

40
00:03:37,864 --> 00:03:44,873
括弧で囲まれており、それは単に訓練セットへのインデックスで、

41
00:03:44,873 --> 00:03:51,629
このテーブルの i 行目を示します。いいですね。ですから、これは x の i 乗、y の i 乗という意味ではありません。

42
00:03:51,629 --> 00:03:58,216
(x(i), y(i)) は単にこの表の i 番目の列を示すだけです。つまり、例えば、x(1) は

43
00:03:58,216 --> 00:04:04,972
最初の訓練サンプルの入力値を指しますので、それは 2104 です。それは、この 最初の行の x の

44
00:04:04,972 --> 00:04:11,685
値です。x(2) は = 1416、ですね。これが二番目の

45
00:04:11,685 --> 00:04:17,385
x の値です。そして y(1) は = 460、最初の y の値、

46
00:04:17,385 --> 00:04:24,526
最初の訓練サンプルです。それが(1) の示す意味です。前にも触れた通り、時々、

47
00:04:24,526 --> 00:04:28,345
質問をして、皆さんが自分の理解を確認できるようにします。数秒後にこの

48
00:04:28,345 --> 00:04:34,044
ビデオに選択問題がビデオに表示されます。そうしたら、

49
00:04:34,044 --> 00:04:40,362
マウスを使って、あなたが正しいと思う答えを選択してください。

50
00:04:40,362 --> 00:04:45,124
訓練セットによって定義されるのは何か。これが教師あり学習アルゴリズムの仕組みです。

51
00:04:45,124 --> 00:04:50,513
開始点に住宅価格の訓練セットような訓練セットがあります。そして

52
00:04:50,513 --> 00:04:55,715
それを学習アルゴリズムに読み込ませます。学習アルゴリズムの仕事は、

53
00:04:55,715 --> 00:05:00,101
ある関数を出力することで、慣習的にこれは小文字の h で表記されます。

54
00:05:00,101 --> 00:05:06,574
h は 仮説（hypothesis）の略です。そして仮説の仕事は、関数として

55
00:05:06,574 --> 00:05:12,471
入力として家のサイズを受け取り、例えば、友人が売ろうとしている

56
00:05:12,471 --> 00:05:18,368
新しい家のサイズなど、そして 与えられた x の値に対して

57
00:05:18,368 --> 00:05:31,630
それに相当する家の推定価格 y を出力しようとします。つまり、h は x から

58
00:05:31,630 --> 00:05:37,729
y に対応付けする関数です。よく人から聞かれるのは、なぜこの関数が

59
00:05:37,729 --> 00:05:42,121
仮説と呼ばれるかです。皆さんの中には仮説という言葉の意味をご存知の方もいると思います。

60
00:05:42,121 --> 00:05:46,744
辞書からとか、あるいは科学からとか何とか。実は、機械学習では、これは

61
00:05:46,744 --> 00:05:51,310
機械学習の初期に使われた名前で、それがなんとなく定着してしまったのです。

62
00:05:51,310 --> 00:05:55,239
このような関数にはそれほどふさわしい名前ではないかもしれません。家のサイズを

63
00:05:55,239 --> 00:05:59,978
予測価格に対応付けするような場合には。仮説という用語は多分

64
00:05:59,978 --> 00:06:04,543
一番適切な名前ではないでしょう。しかし、人々が使う標準的な用語として、

65
00:06:04,543 --> 00:06:09,362
機械学習では使われています。ですから、なぜ人々がそのように呼ぶのかは、あまり気にしないで下さい。

66
00:06:09,362 --> 00:06:14,332
学習アルゴリズムを設計する際に、次に決めなければいけないことは、

67
00:06:14,332 --> 00:06:20,540
どのようにこの仮説 h を表現するかです。今回以降の数回のビデオでは

68
00:06:20,540 --> 00:06:26,978
初期の選択として、仮説の表現を以下のようにします。

69
00:06:26,978 --> 00:06:33,009
h を以下のように表現します。そしてこれをこのように書きます。h_theta(x) = theta_0 +

70
00:06:33,009 --> 00:06:39,254
theta_1 掛ける x。そして簡略表記として、

71
00:06:39,254 --> 00:06:45,441
h_theta(x) と書く代わりに、h(x) と簡略して書くことがあります。

72
00:06:45,441 --> 00:06:51,627
しかし、たいていの場合は、添え字のthetaをそこに書きます。そしてこれを図としてプロットすると、

73
00:06:51,627 --> 00:06:58,210
これの意味は y を x の線形

74
00:06:58,210 --> 00:07:04,634
関数として予測するということです。これがデータセットで、この関数が行っているのは、

75
00:07:04,634 --> 00:07:11,698
y がなんらかの x の直線の関数だと予測しているわけです。h(x) = theta_0

76
00:07:11,698 --> 00:07:18,450
+ theta_1 * x。分かりますか。ではなぜ線形関数なのか。時には、

77
00:07:18,450 --> 00:07:23,405
もっと複雑な、例えば非線形関数を当てはめたいこともあります。しかし、この線形のケースは

78
00:07:23,405 --> 00:07:28,298
簡単な基本となるケースですので、まずはこの例では最初に

79
00:07:28,298 --> 00:07:32,943
線形関数に当てはめ、いずれはこれを発展させてもっと複雑な

80
00:07:32,943 --> 00:07:37,403
モデル、もっと複雑な学習アルゴリズムにしていきます。また、

81
00:07:37,403 --> 00:07:42,628
このモデルを特に指す名前をつけたいと思います。このモデルは線形回帰といい、

82
00:07:42,628 --> 00:07:48,271
この例は、実は変数が一つの場合の線形回帰で、その変数は x です。

83
00:07:48,271 --> 00:07:53,914
全ての価格を一つの変数 x で予測するものです。そして

84
00:07:53,914 --> 00:07:58,852
このモデルのもう一つの名前は単回帰です。そして単回帰の単は

85
00:07:58,852 --> 00:08:04,400
変数が一つであるということを意味しています。これが線形回帰です。次の

86
00:08:04,400 --> 00:08:09,760
ビデオでは、このモデルをどのように実装していくかをお話します。