1
00:00:00,960 --> 00:00:05,684
这节课中 我们将更深入地学习代价函数的作用

2
00:00:05,684 --> 00:00:10,523
这段视频的内容假设你已经认识轮廓图

3
00:00:10,523 --> 00:00:15,189
如果你对轮廓图不太熟悉的话

4
00:00:15,189 --> 00:00:20,144
这段视频中的某些内容你可能会听不懂 但不要紧

5
00:00:20,144 --> 00:00:24,522
如果你跳过这段视频的话 也没什么关系

6
00:00:24,522 --> 00:00:29,246
不听这节课对后续课程理解影响不大

7
00:00:29,246 --> 00:00:34,935
和之前一样 这是我们的几个重要公式

8
00:00:34,935 --> 00:00:39,882
包括了假设h、参数θ、代价函数J 以及优化目标

9
00:00:39,882 --> 00:00:45,163
跟前一节视频不同的是 我还是把θ写成θ0、θ1的形式

10
00:00:45,163 --> 00:00:50,573
便于这里我们要对代价函数进行的可视化

11
00:00:50,573 --> 00:00:57,204
和上次一样 首先来理解假设h和代价函数J

12
00:00:57,204 --> 00:01:04,167
这是房价数据组成的训练集数据 让我们来构建某种假设

13
00:01:04,167 --> 00:01:10,219
就像这条线一样 很显然这不是一个很好的假设

14
00:01:10,219 --> 00:01:16,270
但不管怎样 如果我假设θ0等于50 θ1等于0.06的话

15
00:01:16,270 --> 00:01:22,190
那么我将得到这样一个假设函数 对应于这条直线

16
00:01:22,190 --> 00:01:27,511
给出θ0和θ1的值 我们要在右边画出代价函数的图像

17
00:01:27,511 --> 00:01:33,150
上一次 我们是只有一个θ1 也就是说

18
00:01:33,150 --> 00:01:37,814
画出的代价函数是关于θ1的函数 但现在我们有两个参数

19
00:01:37,814 --> 00:01:42,340
θ0和θ1 因此图像就会复杂一些了

20
00:01:42,340 --> 00:01:47,699
当只有一个参数θ1的时候 我们画出来是这样一个弓形函数

21
00:01:47,699 --> 00:01:52,925
而现在我们有了两个参数 那么代价函数

22
00:01:52,925 --> 00:01:58,218
仍然呈现类似的某种弓形 实际上这取决于训练样本

23
00:01:58,218 --> 00:02:03,511
你可能会得到这样的图形

24
00:02:03,511 --> 00:02:09,404
因此这是一个三维曲面图 两个轴分别表示θ0和θ1

25
00:02:09,404 --> 00:02:15,326
随着你改变θ0和θ1的大小 你便会得到不同的代价函数

26
00:02:15,326 --> 00:02:20,964
J(θ0,θ1) 对于某个特定的点 (θ0,θ1)

27
00:02:20,964 --> 00:02:26,347
这个曲面的高度 也就是竖直方向的高度

28
00:02:26,347 --> 00:02:31,200
就表示代价函数 J(θ0,θ1) 的值

29
00:02:31,200 --> 00:02:36,471
不难发现这是一个弓形曲面 我们来看看三维图

30
00:02:36,471 --> 00:02:46,351
这是这个曲面的三维图 水平轴是θ0、θ1

31
00:02:46,351 --> 00:02:52,122
竖直方向表示 J(θ0,θ1) 旋转一下这个图

32
00:02:52,122 --> 00:02:57,608
你就更能理解这个弓形曲面所表示的代价函数了

33
00:02:57,608 --> 00:03:03,592
在这段视频的后半部分 为了描述方便

34
00:03:03,592 --> 00:03:09,077
我将不再像这样给你用三维曲面图的方式解释代价函数J

35
00:03:09,077 --> 00:03:16,475
而还是用轮廓图来表示

36
00:03:16,475 --> 00:03:24,748
contour plot 或 contour figure 意思一样

37
00:03:24,748 --> 00:03:31,135
右边就是一个轮廓图 两个轴分别表示 θ0 和 θ1

38
00:03:31,135 --> 00:03:37,602
而这些一圈一圈的椭圆形 每一个圈就表示

39
00:03:37,602 --> 00:03:43,757
J(θ0,θ1) 相同的所有点的集合

40
00:03:43,757 --> 00:03:50,514
具体举例来说 我们选三个点出来

41
00:03:50,514 --> 00:03:55,583
这三个桃红色的点 都表示相同的

42
00:03:55,583 --> 00:03:59,730
J(θ0,θ1) 的值 对吧 横纵坐标分别是θ0 θ1

43
00:03:59,730 --> 00:04:04,774
这三个点的 J(θ0,θ1) 值是相同的

44
00:04:04,774 --> 00:04:10,218
如果你之前没怎么接触轮廓图的话 你就这么想

45
00:04:10,218 --> 00:04:14,992
你就想象一个弓形的函数从屏幕里冒出来

46
00:04:14,992 --> 00:04:19,668
因此最小值 也就是这个弓形的最低点就是这个点 对吧

47
00:04:19,668 --> 00:04:24,285
也就是这一系列同心椭圆的中心点 想象一下这个弓形从屏幕里冒出来

48
00:04:24,285 --> 00:04:28,786
所以这些椭圆形 都从我的屏幕上冒出相同的高度

49
00:04:28,786 --> 00:04:33,345
弓形的最小值点是这个位置

50
00:04:33,345 --> 00:04:37,787
因此轮廓图是一种很方便的方法 能够直观地观察

51
00:04:37,787 --> 00:04:45,185
代价函数J 接下来让我们看几个例子

52
00:04:45,185 --> 00:04:53,275
在这里有一点 这个点表示θ0等于800

53
00:04:53,275 --> 00:05:01,964
θ1大概等于-0.15 那么这个红色的点

54
00:05:01,964 --> 00:05:07,322
代表了某个 (θ0,θ1) 组成的数值组

55
00:05:07,322 --> 00:05:12,092
而这个点也对应于左边这样一条线 对吧

56
00:05:12,092 --> 00:05:17,189
θ0等于800 也就是跟纵轴相交于大约800

57
00:05:17,189 --> 00:05:21,763
斜率大概是-0.15 当然 这条线并不能很好地拟合数据

58
00:05:21,763 --> 00:05:26,859
对吧 以这组 θ0 θ1 为参数的这个假设 h(x)

59
00:05:26,859 --> 00:05:32,283
并不是数据的较好拟合 并且你也发现了

60
00:05:32,283 --> 00:05:37,531
这个代价值 就是这里的这个值 距离最小值点还很远

61
00:05:37,531 --> 00:05:42,901
也就是说这个代价值还是算比较大的

62
00:05:42,901 --> 00:05:47,247
因此不能很好拟合数据 让我们再来看几个例子

63
00:05:47,247 --> 00:05:52,489
这是另一个假设 你不难发现 这依然不是一个好的拟合

64
00:05:52,489 --> 00:05:57,986
但比刚才稍微好一点 这是我的 θ0  θ1 点

65
00:05:57,986 --> 00:06:07,387
这是 θ0 的值 大约为360

66
00:06:07,387 --> 00:06:14,047
θ1 的值为0 我们把它写下来

67
00:06:14,047 --> 00:06:20,063
θ0=360  θ1=0 因此这组θ值对应的假设是

68
00:06:20,063 --> 00:06:26,161
这条水平的直线 也就是h(x) = 360 + 0 × x

69
00:06:26,161 --> 00:06:32,421
这就是假设 这个假设同样也有某个代价值

70
00:06:32,421 --> 00:06:38,600
而这个代价值就对应于这个代价函数在这一点的高度

71
00:06:38,791 --> 00:06:44,886
让我们再来看一些例子 这是另一个例子

72
00:06:44,886 --> 00:06:52,231
这个点这组 θ0 和 θ1  对应这样一条假设h(x)

73
00:06:52,231 --> 00:06:58,599
同样地 还是对数据拟合不好 离最小值更远了

74
00:06:58,599 --> 00:07:03,450
最后一个例子 这个点其实不是最小值 但已经非常靠近最小值点了

75
00:07:03,450 --> 00:07:08,486
这个点对数据的拟合就很不错

76
00:07:08,486 --> 00:07:13,337
它对应这样两个θ0 和  θ1 的值

77
00:07:13,337 --> 00:07:18,004
同时也对应这样一个 h(x) 这个点虽然不在最小值点 但非常接近了

78
00:07:18,004 --> 00:07:23,039
因此误差平方和 或者说 训练样本和假设的距离的平方和

79
00:07:23,039 --> 00:07:28,259
这个距离值的平方和

80
00:07:28,259 --> 00:07:32,548
非常接近于最小值 尽管它还不是最小值

81
00:07:32,548 --> 00:07:37,096
好的 通过这些图形 我希望你能更好地

82
00:07:37,096 --> 00:07:41,869
理解这些代价函数 J 所表达的值 它们是什么样的

83
00:07:41,869 --> 00:07:47,324
它们对应的假设是什么样的 以及什么样的假设对应的点

84
00:07:47,324 --> 00:07:52,983
更接近于代价函数J的最小值

85
00:07:52,983 --> 00:07:57,619
当然 我们真正需要的是一种有效的算法

86
00:07:57,619 --> 00:08:02,218
能够自动地找出这些使代价函数J取最小值的参数θ0和θ1来

87
00:08:02,218 --> 00:08:06,566
对吧 我想我们也不希望编个程序

88
00:08:06,566 --> 00:08:10,697
把这些点画出来 然后人工的方法来读出这些点的数值

89
00:08:10,697 --> 00:08:15,263
这很明显不是一个好办法 事实上 我们后面就会学到

90
00:08:15,426 --> 00:08:19,938
我们会遇到更复杂、更高维度、更多参数的情况

91
00:08:19,938 --> 00:08:23,906
这在我们在后面的视频中很快就会遇到

92
00:08:23,906 --> 00:08:28,091
而这些情况是很难画出图的

93
00:08:28,091 --> 00:08:33,664
因此更无法将其可视化 因此我们真正需要的

94
00:08:33,664 --> 00:08:37,729
是编写程序来找出这些最小化代价函数的θ0和θ1的值

95
00:08:37,916 --> 00:08:42,914
在下一节视频中 我们将介绍一种算法 能够自动地找出能使代价函数 J

96
00:08:42,914 --> 00:08:47,600
最小化的参数θ0和θ1的值 【教育无边界字幕组】翻译:所罗门捷列夫 校对:御姐sama 审核:Naplessss