1
00:00:00,520 --> 00:00:04,480
前回のビデオで、

2
00:00:04,480 --> 00:00:09,540
最急降下法のアルゴリズムについて話し、

3
00:00:09,540 --> 00:00:14,280
線形回帰のモデルと

4
00:00:14,280 --> 00:00:17,400
二乗誤差のコスト関数についても話した。

5
00:00:17,400 --> 00:00:18,730
このビデオでは、

6
00:00:20,800 --> 00:00:24,950
最急降下法とコスト関数を

7
00:00:24,950 --> 00:00:28,920
両方合わせて、

8
00:00:28,920 --> 00:00:34,210
そこから直線を我らのデータにフィッティングする

9
00:00:34,210 --> 00:00:36,540
線形回帰のアルゴリズムを作ろう。

10
00:00:36,540 --> 00:00:42,312
これは前回のビデオで

11
00:00:42,312 --> 00:00:47,820
我らが作った物だ。

12
00:00:47,820 --> 00:00:51,275
これが我らの最急降下法アルゴリズムで

13
00:00:51,275 --> 00:00:59,810
もはやお馴染みとなっただろう。

14
00:00:59,810 --> 00:01:04,060
そしてあなたは、線形回帰のモデルと

15
00:01:04,060 --> 00:01:07,710
線形の仮説、そして二乗誤差のコスト関数も分かってるはず。

16
00:01:07,710 --> 00:01:11,670
今回やろうとしているのは、

17
00:01:13,020 --> 00:01:15,550
最急降下法を、二乗誤差のコスト関数を

18
00:01:15,550 --> 00:01:21,400
最小化するために適用する、という事。

19
00:01:21,400 --> 00:01:23,520
最急降下法を

20
00:01:23,520 --> 00:01:26,190
適用する為には、

21
00:01:27,290 --> 00:01:34,820
このコード片を書く為には、

22
00:01:34,820 --> 00:01:43,280
我らが必要とするキーとなる項は

23
00:01:43,280 --> 00:01:47,830
この微分の項だ。

24
00:01:47,830 --> 00:01:50,782
つまり、我らはこの偏微分の項が

25
00:01:50,782 --> 00:01:53,190
何になるのかを知る必要がある。

26
00:01:53,190 --> 00:01:56,570
その為には

27
00:01:56,570 --> 00:02:00,310
コスト関数Jの定義を

28
00:02:00,310 --> 00:02:04,170
代入して、

29
00:02:04,170 --> 00:02:06,940
結局、これに、

30
00:02:06,940 --> 00:02:12,064
1からmまでの和を取る事の

31
00:02:12,064 --> 00:02:18,354
この二乗誤差の

32
00:02:18,354 --> 00:02:24,294
コスト関数の項。

33
00:02:24,294 --> 00:02:27,114
ここでやった事は単に、

34
00:02:27,114 --> 00:02:34,008
コスト関数の定義を

35
00:02:34,008 --> 00:02:37,440
ここに代入しただけ。

36
00:02:37,440 --> 00:02:41,720
そしてさらに単純化して、

37
00:02:41,720 --> 00:02:46,000
結局イコール、

38
00:02:46,000 --> 00:02:51,020
これに、1からmまでの和をとる事の、

39
00:02:51,020 --> 00:02:54,930
シータ0 足す シータ1 xi

40
00:02:54,930 --> 00:02:59,510
マイナス yi の二乗。

41
00:02:59,510 --> 00:03:04,050
ここでやったのは

42
00:03:04,050 --> 00:03:08,100
仮説の定義を

43
00:03:08,100 --> 00:03:11,350
ここに代入した。

44
00:03:11,350 --> 00:03:13,390
結局、我らは

45
00:03:14,750 --> 00:03:18,490
2つのケースについての

46
00:03:18,490 --> 00:03:22,310
偏微分がどうなるかを知る必要がある訳だ。

47
00:03:23,310 --> 00:03:27,160
j=0のケースと、

48
00:03:27,160 --> 00:03:28,640
j=1のケース。

49
00:03:28,640 --> 00:03:32,728
つまり、シータ0と

50
00:03:32,728 --> 00:03:38,380
シータ1についての偏微分の

51
00:03:39,390 --> 00:03:41,070
両方が知りたい。

52
00:03:43,080 --> 00:03:46,050
そして直接答えを書いてしまう事にする。

53
00:03:47,160 --> 00:03:48,628
この最初の項は整理すると

54
00:03:52,529 --> 00:03:56,804
1/m 和を取ることの

55
00:03:56,804 --> 00:03:59,790
トレーニングセット全体で、

56
00:03:59,790 --> 00:04:05,730
このx(i)、、、引くことの y(i)。

57
00:04:05,730 --> 00:04:11,420
そしてこの項は、シータ1による

58
00:04:11,420 --> 00:04:15,230
偏微分は、結局

59
00:04:15,230 --> 00:04:19,265
この項となる。、、、y(i)と、掛けるx(i)。

60
00:04:19,265 --> 00:04:22,250
オーケー。

61
00:04:24,290 --> 00:04:25,570
これらの偏微分を計算するには

62
00:04:25,570 --> 00:04:28,120
つまり、この式から

63
00:04:28,120 --> 00:04:31,862
これらの式を導くには

64
00:04:31,862 --> 00:04:32,700
偏微分の項を計算するのに

65
00:04:32,700 --> 00:04:36,780
多変数の解析学がいくらか必要だ。

66
00:04:36,780 --> 00:04:40,900
もし解析学を知ってるなら

67
00:04:40,900 --> 00:04:43,014
どうぞご自由に導出してみて、

68
00:04:43,014 --> 00:04:45,480
実際に微分してみて、

69
00:04:45,480 --> 00:04:50,390
さきに挙げた答えと一致するかチェックしてみてくれ。

70
00:04:50,390 --> 00:04:55,220
だが、もしあなたが

71
00:04:55,220 --> 00:05:00,190
あんま解析学詳しくないとしても、

72
00:05:03,230 --> 00:05:07,800
気にしないでよろしい。

73
00:05:07,800 --> 00:05:09,490
単にこれらの式を受け入れてもらえば

74
00:05:09,490 --> 00:05:16,620
なんの問題も無い。

75
00:05:16,620 --> 00:05:22,295
そうすれば解析学とか、

76
00:05:22,295 --> 00:05:26,465
そういう事を一切知らなくても、

77
00:05:26,465 --> 00:05:30,445
宿題は出来るし、最急降下法も実装出来るし、それを活用する事も出来る。

78
00:05:30,445 --> 00:05:33,155
だがこれらの定義に従えば

79
00:05:33,155 --> 00:05:36,615
まあは微分とは何か、という事に

80
00:05:38,250 --> 00:05:45,910
立ち戻ってみれば、

81
00:05:45,910 --> 00:05:50,020
それはコスト関数Jの

82
00:05:50,020 --> 00:05:54,220
単なる勾配に過ぎない。

83
00:05:54,220 --> 00:05:56,370
さて、今や、それら全てを

84
00:05:56,370 --> 00:06:01,354
最急降下法のアルゴリズムに代入する事が出来る。

85
00:06:01,354 --> 00:06:07,619
これが最急降下法、

86
00:06:07,619 --> 00:06:12,644
または回帰で、

87
00:06:12,644 --> 00:06:16,547
これを収束するまで繰り返す。

88
00:06:16,547 --> 00:06:21,060
シータ0とシータ1を

89
00:06:21,060 --> 00:06:26,845
同じ マイナス アルファ 掛ける

90
00:06:26,845 --> 00:06:31,510
微分の項。

91
00:06:31,510 --> 00:06:35,450
つまりこの項。

92
00:06:35,450 --> 00:06:39,780
これが線形回帰のアルゴリズムだ。

93
00:06:41,230 --> 00:06:42,380
といいことでこのような行列が作成されます。

94
00:06:42,380 --> 00:06:46,370
もちろん

95
00:06:47,670 --> 00:06:52,760
対応するシータ0による偏微分の項だ。

96
00:06:52,760 --> 00:06:56,190
前のスライドで見た。

97
00:06:57,340 --> 00:07:02,430
そしてこの二番目の項のこれ、

98
00:07:02,430 --> 00:07:06,520
この項は

99
00:07:08,200 --> 00:07:14,660
シータ1による偏微分の項で、

100
00:07:14,660 --> 00:07:20,090
これも前のスライドで既に出した。

101
00:07:21,400 --> 00:07:25,800
ここでちょっと注意を。

102
00:07:25,800 --> 00:07:31,230
最急降下法を実装する時は

103
00:07:31,230 --> 00:07:34,490
実装の詳細な話だが、

104
00:07:34,490 --> 00:07:38,900
シータ0とシータ1を同時に更新するように

105
00:07:38,900 --> 00:07:43,350
実装しなくてはならない。

106
00:07:43,350 --> 00:07:48,720
では最急降下法がどう機能するか見てみよう。

107
00:07:48,720 --> 00:07:52,620
最急降下法で解く場合に疑われる問題としては

108
00:07:52,620 --> 00:07:57,510
局所最適に落ち着いてしまう、という事がある。

109
00:07:57,510 --> 00:08:00,730
最初に最急降下法を説明した時に

110
00:08:00,730 --> 00:08:04,310
あなたにこの図を見せた、

111
00:08:04,310 --> 00:08:08,880
これは表面の丘を

112
00:08:08,880 --> 00:08:13,850
下っていくもの。

113
00:08:13,850 --> 00:08:17,760
そしてどこから始めるかによって

114
00:08:17,760 --> 00:08:21,400
異なる局所最適解に落ち着きうるのだった。

115
00:08:21,400 --> 00:08:25,660
つまり、ここに行き着く場合もあればここに行き着く場合もありうる。

116
00:08:25,660 --> 00:08:30,620
だけど、線形回帰の場合の

117
00:08:30,620 --> 00:08:34,175
コスト関数のgradientは、

118
00:08:34,175 --> 00:08:36,365
いつも弓形の関数で

119
00:08:36,365 --> 00:08:39,585
こんな形に

120
00:08:39,585 --> 00:08:43,715
必ずなる。

121
00:08:43,715 --> 00:08:46,247
これを表す専門用語があって、

122
00:08:46,247 --> 00:08:48,837
それは凸型関数と呼ばれる。

123
00:08:48,837 --> 00:08:51,247
私はわざわざ

124
00:08:51,247 --> 00:08:55,207
凸関数の正式な定義を

125
00:08:55,207 --> 00:08:58,357
説明する気は無い。

126
00:08:58,357 --> 00:09:03,497
だが直感的には、凸関数は

127
00:09:05,980 --> 00:09:09,550
弓形の関数という事だ。

128
00:09:09,550 --> 00:09:12,260
そしてつまり、この関数は

129
00:09:12,260 --> 00:09:15,510
グローバル最適な解以外の

130
00:09:15,510 --> 00:09:19,410
局所最適解は持たない。

131
00:09:19,410 --> 00:09:22,270
そしてこの種類のコスト関数、

132
00:09:22,270 --> 00:09:25,870
それは線形回帰を適用する時はいつもそうだが、

133
00:09:25,870 --> 00:09:29,730
この種のコスト関数に最急降下法を適用すると、

134
00:09:29,730 --> 00:09:33,020
いつもグローバル最適な結果を返す、

135
00:09:33,020 --> 00:09:34,520
何故ならグローバル最適以外の局所最適が存在しないから。

136
00:09:34,520 --> 00:09:37,020
では次に、実際のアルゴリズムの動作を見てみよう。

137
00:09:37,020 --> 00:09:41,000
いつも通り、ここに仮説関数の

138
00:09:41,000 --> 00:09:46,420
プロットがある。

139
00:09:46,420 --> 00:09:50,140
そしてコスト関数Jも。

140
00:09:50,140 --> 00:09:51,400
そしてパラメータの初期値を

141
00:09:51,400 --> 00:09:53,910
ここに初期化するとしよう。

142
00:09:55,340 --> 00:10:00,430
普通はパラメータは

143
00:10:00,430 --> 00:10:04,990
0、 0で初期化するものだ、

144
00:10:04,990 --> 00:10:07,480
シータ0 = シータ1 = 0 で。

145
00:10:07,480 --> 00:10:11,460
でもこのプレゼンでは

146
00:10:11,460 --> 00:10:14,510
例示の為、

147
00:10:14,510 --> 00:10:17,900
シータ0をだいたい

148
00:10:17,900 --> 00:10:20,420
900に、シータ1をだいたい-0.1とした。