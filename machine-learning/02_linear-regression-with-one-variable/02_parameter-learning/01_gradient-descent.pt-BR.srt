1
00:00:00,370 --> 00:00:02,420
Definimos anteriormente a função de custo J.

2
00:00:02,420 --> 00:00:06,960
Neste vídeo gostaria de falar sobre um algoritmo 
denominado Gradiente Descendente (ou Descida de Gradiente) para

3
00:00:06,960 --> 00:00:09,360
minimizar a função de custo J.

4
00:00:09,360 --> 00:00:12,860
O fato é que o Gradiente Descendente 
é um algoritmo mais amplo e

5
00:00:12,860 --> 00:00:15,000
não é usado apenas a regressão linear.

6
00:00:15,000 --> 00:00:17,910
Ele também é utilizado onde quer
 que haja aprendizagem de máquina

7
00:00:17,910 --> 00:00:21,010
Mais adiante, nesta aula, 
usaremos Gradiente Descendente para minimizar

8
00:00:21,010 --> 00:00:25,110
não apenas a função de custo J 
para regressão linear, como outras funções também.

9
00:00:26,150 --> 00:00:30,163
Neste vídeo falaremos sobre Gradiente Descendente
 para minimizar uma

10
00:00:30,163 --> 00:00:34,434
função J arbitrária e então, 
nos vídeos subsequentes, falaremos sobre este algoritmo e

11
00:00:34,434 --> 00:00:38,122
o aplicaremos especificamente à função
 de custo J que definimos.

12
00:00:38,122 --> 00:00:39,306
Regressão Linear. 

13
00:00:41,848 --> 00:00:43,849
Eis o problema:

14
00:00:43,849 --> 00:00:46,748
Vamos assumir que temos 
uma função J(theta0,

15
00:00:46,748 --> 00:00:50,202
theta1) como função de custo
 para uma regressão linear

16
00:00:50,202 --> 00:00:53,340
e que talvez haja alguma outra função
 que queiramos minimizar.

17
00:00:53,340 --> 00:00:55,919
Além disso, queremos um algoritmo para

18
00:00:55,919 --> 00:00:59,617
minimizar isso como uma função 
de J(theta0, theta1).

19
00:00:59,617 --> 00:01:04,324
Apenas a título de informação, observa-se 
que o Gradiente Descendente é aplicado a

20
00:01:04,324 --> 00:01:05,800
funções mais gerais.

21
00:01:05,800 --> 00:01:09,530
Imagine portanto, uma função 
que é uma função de J e os parâmetros theta0, theta1,

22
00:01:09,530 --> 00:01:16,360
theta2, até theta n, e queira minimizar theta0.

23
00:01:16,360 --> 00:01:23,880
Você minimiza θ0 ...até θn 
desta função J(θ0, ... até o θn).

24
00:01:23,880 --> 00:01:25,690
De fato, o Gradiente Descendente é um algoritmo

25
00:01:25,690 --> 00:01:27,740
para resolver este problema mais amplo.

26
00:01:27,740 --> 00:01:30,520
Por questões de brevidade e

27
00:01:30,520 --> 00:01:34,840
concisão da notação, farei 
de conta que tenho apenas

28
00:01:34,840 --> 00:01:37,470
dois parâmetros ao longo 
do restante deste vídeo.

29
00:01:37,470 --> 00:01:40,420
Aqui está a ideia do Gradiente Descendente.

30
00:01:40,420 --> 00:01:45,240
O que faremos a seguir é atribuir
 estimativas iniciais para os valores de

31
00:01:45,240 --> 00:01:47,180
theta0 e theta1.

32
00:01:47,180 --> 00:01:51,916
Não importa realmente o que são esses parâmetros,
 mas uma escolha comum seria estabelecermos theta0 = 0

33
00:01:51,916 --> 00:01:55,600
e theta1 = 0. Apenas os inicializamos com 0.

34
00:01:55,600 --> 00:02:00,372
O que nós vamos fazer no Gradiente Descendente 
é que mudaremos os valores de theta0 e

35
00:02:00,372 --> 00:02:05,359
theta1 um pouco para tentar reduzir
 J(theta0, theta1) até que,

36
00:02:05,359 --> 00:02:08,420
com sorte, cheguemos a um valor mínimo 
ou talvez a um valor mínimo local.

37
00:02:09,880 --> 00:02:13,588
Vejamos então nas figuras o que o 
Gradiente Descendente faz.

38
00:02:13,588 --> 00:02:16,269
Digamos que você esteja tentando 
minimizar esta função.

39
00:02:16,269 --> 00:02:18,812
Observe os eixos, este é theta0,

40
00:02:18,812 --> 00:02:22,784
theta1 no eixo horizontal
 e J no eixo vertical, e

41
00:02:22,784 --> 00:02:27,730
a altura da superfície mostra J e 
queremos minimizar esta função.

42
00:02:27,730 --> 00:02:31,840
Vamos iniciar com theta0, 
theta1 em algum ponto.

43
00:02:31,840 --> 00:02:35,450
Imagine escolher algum valor para theta0 e theta1

44
00:02:35,450 --> 00:02:40,160
que corresponda ao ponto inicial do algoritmo 
em algum lugar na superfície desta função.

45
00:02:40,160 --> 00:02:43,130
Portanto, suponha um valor de theta0, 
theta1 que resulte em algum ponto aqui.

46
00:02:43,130 --> 00:02:44,917
Eu os inicializei com 0, mas

47
00:02:44,917 --> 00:02:47,700
às vezes, pode-se inicializá-los
 com outros valores também.

48
00:02:49,280 --> 00:02:54,290
Imagine agora que esta 
figura mostre um buraco.

49
00:02:54,290 --> 00:02:57,930
Imagine isto como a paisagem de 
um parque gramado

50
00:02:57,930 --> 00:03:02,710
com dois montes assim, e imagine 
que você esteja fisicamente

51
00:03:02,710 --> 00:03:08,030
situado neste ponto no monte, 
neste pequeno monte vermelho no parque.

52
00:03:08,030 --> 00:03:12,270
No Gradiente Descendente, o que
 vamos fazer é girar 360 graus

53
00:03:12,270 --> 00:03:17,260
ao redor, apenas para olhar ao nosso redor,
 e perguntar, se eu fosse dar um pequeno passo em

54
00:03:17,260 --> 00:03:22,290
alguma direção, e eu quero ir para o ponto 
mais baixo o mais rapidamente possível,

55
00:03:22,290 --> 00:03:25,060
qual direção eu devo tomar em relação 
a este pequeno passo?

56
00:03:25,060 --> 00:03:26,790
Se eu quero ir para baixo, então

57
00:03:26,790 --> 00:03:30,300
eu quero andar fisicamente para baixo 
deste monte o mais rapidamente possível.

58
00:03:31,370 --> 00:03:35,060
Acontece que, se você estiver neste ponto do monte,
 você olha ao redor e

59
00:03:35,060 --> 00:03:38,820
descobre que a melhor direção é dar 
um pequeno passo ladeira abaixo

60
00:03:38,820 --> 00:03:40,930
mais ou menos nesta direção.

61
00:03:40,930 --> 00:03:44,530
Ok, e agora você está neste
 novo ponto no monte.

62
00:03:44,530 --> 00:03:46,750
Você vai, novamente, olhar ao redor

63
00:03:46,750 --> 00:03:52,230
dizer: qual direção devo tomar para dar um
 pequeno passo ladeira abaixo?

64
00:03:52,230 --> 00:03:56,050
E se você fizer isto e der outro passo,
 você dá um passo nesta direção.

65
00:03:57,220 --> 00:03:58,446
E então continua.

66
00:03:58,446 --> 00:04:00,293
A partir deste novo ponto você olha ao redor,

67
00:04:00,293 --> 00:04:04,020
decide qual direção tomar 
ladeira abaixo mais rapidamente.

68
00:04:04,020 --> 00:04:06,190
Dá outro passo, outro passo, e então

69
00:04:06,190 --> 00:04:10,660
vai até convergir neste
 mínimo local bem aqui.

70
00:04:11,920 --> 00:04:13,690
O Gradiente Descendente possui 
uma propriedade interessante.

71
00:04:14,810 --> 00:04:18,500
A primeira vez que rodamos o Gradiente Descendente 
nós estávamos iniciando neste ponto

72
00:04:18,500 --> 00:04:20,130
aqui, certo?

73
00:04:20,130 --> 00:04:22,290
Começamos naquele ponto ali.

74
00:04:22,290 --> 00:04:26,940
Imagine agora que inicializamos o Gradiente
 Descendente apenas a alguns passos à direita.

75
00:04:26,940 --> 00:04:31,000
Imagine que tínhamos iniciado o Gradiente
 Descendente neste ponto à direita, um pouco mais acima.

76
00:04:31,000 --> 00:04:35,064
Se você repetir o processo, iniciando deste ponto, 
olhando ao redor,

77
00:04:35,064 --> 00:04:38,961
dando um pequeno passo nesta direção 
de descida mais íngreme, você faria isso.

78
00:04:38,961 --> 00:04:42,120
Então, olhando ao redor, dando outro pequeno passo, e assim em diante.

79
00:04:43,960 --> 00:04:47,910
E se você iniciasse apenas a alguns passos à direita, o Gradiente Descendente teria

80
00:04:47,910 --> 00:04:52,860
levado você a este segundo local ótimo do lado direito.

81
00:04:54,250 --> 00:04:58,005
Então, se você tivesse iniciado neste ponto,
 você teria chegado a este local

82
00:04:58,005 --> 00:05:02,090
ótimo, mas se você iniciou em um local um pouco diferente,

83
00:05:02,090 --> 00:05:06,050
você teria chegado a um local
 ótimo muito diferente.

84
00:05:06,050 --> 00:05:08,810
E esta é a propriedade do Gradiente 
Descendente que nós

85
00:05:08,810 --> 00:05:10,780
iremos abordar um pouco posteriormente.

86
00:05:10,780 --> 00:05:14,970
Isso é a explicação baseada nas imagens.

87
00:05:14,970 --> 00:05:18,070
Vejamos a matemática.

88
00:05:18,070 --> 00:05:21,130
Esta é a definição do algoritmo
 Gradiente Descendente.

89
00:05:21,130 --> 00:05:26,540
Devemos realizar isto repetidamente
 até a convergência,

90
00:05:26,540 --> 00:05:31,950
iremos atualizar meu parâmetro
 theta j pegando theta j e

91
00:05:31,950 --> 00:05:36,560
subtraindo seu valor de alfa vezes 
este termo aqui, ok?

92
00:05:36,560 --> 00:05:40,920
Então vejamos, há uma série de detalhes 
nesta equação, então deixe-me destrinchar alguns deles.

93
00:05:40,920 --> 00:05:45,715
Em primeiro lugar, esta notação aqui, 
:=, usa-se := para

94
00:05:45,715 --> 00:05:50,847
denotar atribuição, este é 
o operador de atribuição.

95
00:05:50,847 --> 00:05:56,965
Resumidamente, se eu escrever a := b, 
o que isso significa é que, em um computador,

96
00:05:56,965 --> 00:06:02,650
ele pega o valor em b e usa-o para sobrepor
 o valor que estiver em a.

97
00:06:02,650 --> 00:06:07,025
Isso significa que define-se um valor em a igual
 ao valor contido em b, que é a atribuição.

98
00:06:07,025 --> 00:06:10,515
E eu também posso fazer a := a + 1.

99
00:06:10,515 --> 00:06:13,020
Isso significa que eu pego a e incremento 
seu valor em uma unidade.

100
00:06:13,020 --> 00:06:17,489
Em contrapartida, se eu usar o sinal de igual

101
00:06:17,489 --> 00:06:22,308
eu escrevo a igual a b, 
então isso é uma assertiva.

102
00:06:24,854 --> 00:06:26,542
Ok? Então se eu escrever a igual a b,

103
00:06:26,542 --> 00:06:31,160
então estarei afirmando que o valor de a 
é igual ao valor de b, correto?

104
00:06:31,160 --> 00:06:34,136
Portanto, aqui do lado esquerdo, temos a operação do computador

105
00:06:34,136 --> 00:06:36,450
onde definimos um novo valor para a.

106
00:06:36,450 --> 00:06:40,480
E isso aqui, do lado direito, é uma assertiva, estou afirmando que os valores de

107
00:06:40,480 --> 00:06:45,620
a e b são os mesmos, e desta forma você pode escrever a := a + 1, que significa o incremento de

108
00:06:45,620 --> 00:06:50,810
a por 1, porém, jamais escreva a = a + 1 porque isso é errado,

109
00:06:50,810 --> 00:06:54,100
'a' e 'a + 1' nunca serão iguais, não são mesmos valores.

110
00:06:54,100 --> 00:06:55,020
OK?

111
00:06:55,020 --> 00:06:59,404
Portanto, esta é a primeira parte da definição.

112
00:06:59,404 --> 00:07:06,640
Este alfa aqui é um número conhecido como taxa de aprendizagem.

113
00:07:08,760 --> 00:07:12,310
E o que alfa faz é basicamente controlar

114
00:07:12,310 --> 00:07:15,280
o quão grande será o passo tomado 
ladeira abaixo no Gradiente Descendente.

115
00:07:15,280 --> 00:07:19,750
Se alfa for muito grande, então isso 
corresponde a uma descida de gradiente muito agressiva,

116
00:07:19,750 --> 00:07:22,880
onde nós tentaremos realizar passos muito grandes ladeira abaixo e,

117
00:07:22,880 --> 00:07:26,730
se alfa for muito pequeno, então nós tentaremos
 passos extremamente pequenos ladeira abaixo.

118
00:07:26,730 --> 00:07:30,980
Voltarei a falar mais sobre isso posteriormente,
 sobre como estabelecer alfa entre outras coisas.

119
00:07:32,090 --> 00:07:37,320
E finalmente, este termo aqui, é uma derivada.

120
00:07:37,320 --> 00:07:42,400
Não quero falar sobre isso agora, mas 
 farei o cálculo deste termo derivado e

121
00:07:42,400 --> 00:07:45,360
direi a você exatamente o que é posteriormente, ok?

122
00:07:45,360 --> 00:07:49,100
Alguns de vocês estão mais familiarizados com Cálculo do que outros, mas

123
00:07:49,100 --> 00:07:51,550
até mesmo se você não tiver muita familiaridade
 com Cálculo, não se preocupe.

124
00:07:51,550 --> 00:07:54,010
Eu direi o que você precisa saber
 sobre esse termo aqui.

125
00:07:55,450 --> 00:08:00,260
Agora, há mais uma sutileza sobre o Gradiente Descendente que está nos

126
00:08:00,260 --> 00:08:04,230
valores de gradiente que iremos atualizar, você sabe, theta0 e theta1, certo?

127
00:08:04,230 --> 00:08:07,809
Essa atualização acontece para j = 0 e j = 1, então

128
00:08:07,809 --> 00:08:12,260
você atualizará theta0 e theta1.

129
00:08:12,260 --> 00:08:19,593
E a sutileza de como você implementa o Gradiente Descendente

130
00:08:19,593 --> 00:08:25,201
nesta expressão, nesta equação de atualização,

131
00:08:25,201 --> 00:08:32,127
você precisa atualizar simultaneamente theta0 e theta1.

132
00:08:32,127 --> 00:08:36,304
O que eu quero dizer com isso é que 
nesta equação iremos atualizar theta0 :=

133
00:08:36,304 --> 00:08:40,569
theta0 menos algo, e atualizar 
theta1 := theta1 menos alguma coisa.

134
00:08:40,569 --> 00:08:46,552
E a maneira de implementar é que você deve calcular o lado direito, correto?

135
00:08:46,552 --> 00:08:51,661
Calcular aquele termo para theta0 e 
theta1 e então simultaneamente,

136
00:08:51,661 --> 00:08:55,654
ou seja, ao mesmo tempo, 
atualizar theta0 e theta1, ok?

137
00:08:55,654 --> 00:08:58,175
Então, deixe-me falar o que isso significa.

138
00:08:58,175 --> 00:09:02,387
Esta é uma implementação correta do Gradiente Descendente de maneira simultânea.

139
00:09:02,387 --> 00:09:02,960
simultânea.

140
00:09:02,960 --> 00:09:05,928
Então eu vou definir temp0 igual a isso,
 definir temp1 igual a isso,

141
00:09:05,928 --> 00:09:09,736
realizar os cálculos básicos do lado direito e, 
ter o lado direito calculado

142
00:09:09,736 --> 00:09:13,824
e armazenado nas variáveis temp0 e temp1, e irei atualizar theta0 e

143
00:09:13,824 --> 00:09:17,240
theta1 simultaneamente porque 
é a implementação correta.

144
00:09:18,550 --> 00:09:19,460
Em contraste,Em contraste,

145
00:09:19,460 --> 00:09:24,140
Aqui está uma implementação incorreta 
que não realiza uma atualização simultânea.

146
00:09:24,140 --> 00:09:28,274
Portanto, nesta implementação incorreta,
 calculamos temp0,

147
00:09:28,274 --> 00:09:33,580
atualizamos theta0, calculamos temp1, e então atualizamos temp1.

148
00:09:34,780 --> 00:09:37,010
A diferença entre as implementações 
do lado direito e

149
00:09:37,010 --> 00:09:40,510
do lado esquerdo é que, se você 
olhar aqui embaixo,

150
00:09:40,510 --> 00:09:45,260
observando este passo, se neste momento 
você já tiver atualizado theta0,

151
00:09:45,260 --> 00:09:52,130
então você estaria utilizando o novo valor de theta0 para calcular este termo derivado.

152
00:09:52,130 --> 00:09:58,366
E isso lhe dará um valor diferente de temp1 
em relação ao procedimento do lado esquerdo, certo?

153
00:09:58,366 --> 00:10:02,700
Porque agora você conectou o novo valor de theta0 a esta equação.

154
00:10:02,700 --> 00:10:05,750
E assim, este procedimento do lado direito
 não é uma implementação correta

155
00:10:05,750 --> 00:10:07,720
do Gradiente Descendente, ok?

156
00:10:07,720 --> 00:10:10,710
Não quero dizer o motivo da necessidade
 em fazer as atualizações simultâneas.

157
00:10:10,710 --> 00:10:15,670
Acontece que essa é a forma como o Gradiente Descendente é normalmente implementado,

158
00:10:15,670 --> 00:10:17,680
eu falarei mais sobre isso posteriormente

159
00:10:17,680 --> 00:10:21,990
ele realmente torna-se mais natural
 implementando atualizações simultâneas.

160
00:10:21,990 --> 00:10:23,765
E quando as pessoas falam sobre Gradiente Descendente,

161
00:10:23,765 --> 00:10:26,020
eles sempre referem-se à atualização simultânea.

162
00:10:26,020 --> 00:10:28,470
Se você implementar a atualização não-simultânea

163
00:10:28,470 --> 00:10:31,210
ele ainda assim provavelmente deverá funcionar.

164
00:10:31,210 --> 00:10:32,690
Mas esse algoritmo não estava correto.

165
00:10:32,690 --> 00:10:35,010
E não é o que as pessoas referem-se ao Gradiente Descendente, e

166
00:10:35,010 --> 00:10:37,423
esse é algum outro algoritmo
 com propriedades diferentes.

167
00:10:37,423 --> 00:10:42,234
E por várias razões isso pode se comportar 
de formas ligeiramente estranhas, e portanto

168
00:10:42,234 --> 00:10:48,010
o que você deve fazer é realmente implementar a atualização simultânea do Gradiente Descendente.

169
00:10:48,010 --> 00:10:51,420
Então, esse é o perfil do 
algoritmo Gradiente Descendente.

170
00:10:51,420 --> 00:10:56,080
No próximo vídeo, entraremos nos detalhes do termo derivado,

171
00:10:56,080 --> 00:10:58,660
que eu escrevi acima, mas realmente não o defini.

172
00:10:58,660 --> 00:11:02,620
Se você teve aulas de Cálculo antes e está familiarizado com derivadas

173
00:11:02,620 --> 00:11:06,970
e derivadas parciais, observará o 
que é esse termo derivado

174
00:11:06,970 --> 00:11:11,870
mas no caso de você não estar familiarizado 
com cálculo, não se preocupe.

175
00:11:11,870 --> 00:11:14,010
No próximo vídeo darei todos os esclarecimentos e

176
00:11:14,010 --> 00:11:18,260
direi tudo o que você precisa saber
 para calcular o termo derivado, até mesmo se

177
00:11:18,260 --> 00:11:23,050
você nunca viu cálculo, ou se ainda
 não viu derivadas parciais antes.

178
00:11:23,050 --> 00:11:25,860
E com isso, no nosso próximo vídeo, espero

179
00:11:25,860 --> 00:11:29,280
que tenhamos condições de dar a você todas 
as observações necessárias para aplicar o Gradiente Descendente.