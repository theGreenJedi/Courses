1
00:00:00,190 --> 00:00:01,190
בסרטון הקודם,

2
00:00:01,190 --> 00:00:04,960
נתנו הגדרה מתמטית לירידה בכיוון הגרדיאנט.

3
00:00:04,960 --> 00:00:08,830
בואו נצלול בסרט הזה עמוק יותר,  בכדי לקבל אינטואיציה טובה יותר על מה

4
00:00:08,830 --> 00:00:12,580
עושה האלגוריתם ומדוע הצעדים שמבצע האלגוריתם הם הגיוניים.

5
00:00:15,430 --> 00:00:19,580
הנה אלגוריתם הירידה בכיוון הגרדיאנט, כפי שראינו בפעם שעברה,

6
00:00:19,580 --> 00:00:25,800
ורק להזכיר, הפרמטר הזה או הגורם אלפא נקרא קצב הלימוד.

7
00:00:25,800 --> 00:00:30,620
והוא שולט בגודל הצעד שאנו עושים בכל עדכון של הפרמטר תטא-j.

8
00:00:31,660 --> 00:00:36,406
והגורם השני כאן הוא הנגזרת

9
00:00:39,147 --> 00:00:43,904
ומה שאני רוצה לעשות בהרצאה זו  הוא לתת לכם אינטואיציה לגבי מה עושה כל אחד

10
00:00:43,904 --> 00:00:49,281
משני הגורמים האלה, ומדוע כאשר מרכיבים אותם, כל העדכון הגיוני.

11
00:00:49,281 --> 00:00:55,054
כדי להעביר את האינטואיציות האלה, מה שאני רוצה לעשות הוא להשתמש

12
00:00:55,054 --> 00:01:00,403
בדוגמא קצת יותר פשוטה, בה אנחנו רוצים למזער פונקציה של פרמטר אחד בלבד.

13
00:01:00,403 --> 00:01:03,930
נניח שיש לנו פונקצית מחיר, j של פרמטר אחד בלבד,

14
00:01:03,930 --> 00:01:09,410
תטא-1, כמו שעשינו לפני כמה קטעי הרצאות, ותטא-1 הוא מספר ממשי.

15
00:01:09,410 --> 00:01:14,410
אז יש לנו גרף דו-ממדי, שקצת יותר פשוט לשרטט אותו.

16
00:01:14,410 --> 00:01:17,360
בואו ננסה להבין מה תעשה הירידה בכיוון הגרדיאנט לפונקציה הזו.

17
00:01:20,850 --> 00:01:26,980
אז בואו נאמר שזו הפונקציה שלי, J של תטא-1.

18
00:01:26,980 --> 00:01:28,550
זו הפונקציה שלי.

19
00:01:28,550 --> 00:01:31,505
ותטא-1 הוא מספר ממשי.

20
00:01:32,635 --> 00:01:33,755
בסדר?

21
00:01:33,755 --> 00:01:39,605
עתה, בואו נשים בשקופית את הירידה בכיוון הגרדיאנט עם תטא-1 כאן.

22
00:01:39,605 --> 00:01:43,085
דמיינו שאנחנו מתחילים בנקודה הזו על הפונקציה שלי.

23
00:01:44,495 --> 00:01:48,105
מה שהירידה בכיוון הגרדיאנט תעשה הוא לעדכן

24
00:01:49,570 --> 00:01:54,719
את תטא-1 , שייתעדכן לערך לתטא-1 פחות אלפא כפול

25
00:01:54,719 --> 00:02:01,940
נגרזת לפי תטא-1 של J של תטא-1, נכון?

26
00:02:01,940 --> 00:02:09,140
ואגב, הגורם הזה, הנגזרת, אם אתם

27
00:02:09,140 --> 00:02:13,170
תוהים מדוע שיניתי את הסמל הקודם של נגזרת חלקית לזה.

28
00:02:13,170 --> 00:02:16,280
אם אינכם יודעים מה ההבדל בין הסימון של נגזרת

29
00:02:16,280 --> 00:02:18,490
ונגזרת חלקית, תתעלמו מזה.

30
00:02:18,490 --> 00:02:22,000
מבחינה טכנית במתמטיקה קוראים לאחד נגזרת חלקית

31
00:02:22,000 --> 00:02:27,170
ולשני נגזרת, בהתאם למספר הפרמטרים בפונקציה j.

32
00:02:27,170 --> 00:02:28,690
אבל זה עניין טכני מתמטי.

33
00:02:28,690 --> 00:02:32,000
לצורך הרצאה זו

34
00:02:32,000 --> 00:02:36,430
חישבו על הסמלים של נגזרת חלקית ושל נגזרת כאילו הם אותו דבר בדיוק.

35
00:02:36,430 --> 00:02:38,650
ואל תדאגו לגבי ההבדל ביניהם.

36
00:02:38,650 --> 00:02:42,340
אני אנסה להשתמש בסימון מתמטי מדויק, אבל

37
00:02:42,340 --> 00:02:46,550
לענייננו שני הסימונים האלה הם בעצם אותו הדבר.

38
00:02:46,550 --> 00:02:48,890
אז בואו נראה מה תעשה המשוואה הזאת.

39
00:02:48,890 --> 00:02:53,470
עכשיו נחשב את הנגזרת הזו, אינני יודע כמה אתם

40
00:02:53,470 --> 00:02:57,460
מכירים נגזרות, אבל בעצם הנגזרת היא פשוט

41
00:02:57,460 --> 00:03:02,380
הישר המשיק לאותה נקודה, קו ישר כזה, הקו האדום,

42
00:03:02,380 --> 00:03:06,480
שבדיוק נוגע בפונקציה הזו, בואו נראה מה השיפוע של הישר האדום הזה.

43
00:03:06,480 --> 00:03:07,870
זהו מה שהנגזרת אומרת,

44
00:03:07,870 --> 00:03:11,890
מה השיפוע של הישר הזה שבדיוק משיק לפונקציה.

45
00:03:11,890 --> 00:03:17,278
אוקיי, השיפוע של ישר הוא הגובה הזה חלקי האורך האופקי הזה.

46
00:03:17,278 --> 00:03:22,780
עכשיו, לישר הזה יש שיפוע חיובי,

47
00:03:22,780 --> 00:03:26,690
ולכן הנגזרת היא חיובית.

48
00:03:26,690 --> 00:03:30,370
אז העדכון של תטא יהיה תטא-1 מקבל את תטא-1

49
00:03:30,370 --> 00:03:35,813
פחות אלפא כפול איזשהו מספר חיובי.

50
00:03:39,296 --> 00:03:40,271
בסדר.

51
00:03:40,271 --> 00:03:43,300
אלפא, המשתנה שמגדיר את קצב הלמידה, הוא תמיד מספר חיובי.

52
00:03:43,300 --> 00:03:47,220
אז מה שיוצא זה שאנחנו נעדכן את תטא-1 לערך תטא-1 מינוס משהו חיובי.

53
00:03:47,220 --> 00:03:49,910
אז בסופו של דבר תטא-1 נע שמאלה.

54
00:03:49,910 --> 00:03:53,350
תטא-1 פוחת והולך, ואנחנו יכולים לראות שזה הדבר הנכון לעשות

55
00:03:53,350 --> 00:03:55,810
כי אנחנו רוצים לנוע בכיוון הזה.

56
00:03:55,810 --> 00:03:59,490
אתם רואים, להתקרב למינימום שנמצא שם.

57
00:04:00,810 --> 00:04:04,060
אז עד עכשיו, לפי הירידה בכיוון הגדריאנט אנחנו עושים את הדבר הנכון.

58
00:04:04,060 --> 00:04:06,120
בואו נראה עוד דוגמא.

59
00:04:06,120 --> 00:04:10,330
אז בואו ניקח את אותה פונקציה j, בואו ננסה להשתמש באותה פונקציה,

60
00:04:10,330 --> 00:04:11,530
J של תטא-1.

61
00:04:11,530 --> 00:04:16,140
ועכשיו, נניח שאתחלנו את הפרמטר שם משמאל.

62
00:04:16,140 --> 00:04:17,740
אז תטא-1 הוא כאן.

63
00:04:17,740 --> 00:04:19,240
אני מתבונן בנקודה הזו על המשטח.

64
00:04:20,650 --> 00:04:25,680
עכשיו הנגזרת לפי תטא-1 של J של תטא-1 כשמחשבים אותה

65
00:04:25,680 --> 00:04:31,420
בנקודה הזו, אנחנו מסתכלים על השיפוע של הישר הזה,

66
00:04:31,420 --> 00:04:34,580
אז הנגזרת היא השיפוע של הקו הזה.

67
00:04:34,580 --> 00:04:37,644
אבל הישר הזה הוא יורד, ולכן לישר הזה יש שיפוע שלילי.

68
00:04:41,021 --> 00:04:41,990
בסדר.

69
00:04:41,990 --> 00:04:45,880
או במילים אחרות זה אומר שלפונקציה הזו יש נגזרת שלילית,

70
00:04:45,880 --> 00:04:48,220
זו המשמעות של שיפוע שלילי בנקודה זו.

71
00:04:48,220 --> 00:04:54,690
אז החלק הזה קטן  או שווה ל-0, וכאשר נעדכן את תטא-1, יהיה לנו...

72
00:04:54,690 --> 00:04:59,100
תטא-1 פחות אלפא כפול מספר שלילי.

73
00:05:02,380 --> 00:05:07,460
את התוצאה היא תטא-1 פחות מספר שלילי כלומר בעצם

74
00:05:07,460 --> 00:05:11,210
תטא-1 תגדל, כי חיסור מספר שלילי

75
00:05:11,210 --> 00:05:12,840
פירושו תוספת של משהו חיובי לתטא-1.

76
00:05:12,840 --> 00:05:16,640
ופירוש הדבר הוא שאנחנו מגדילים את תטא-1

77
00:05:16,640 --> 00:05:21,110
עד שהוא זז הנה, וזה אכן שוב נראה כמו

78
00:05:21,110 --> 00:05:24,270
הדבר הנכון לעשות כדי לנסות ולהתקרב למינימום.

79
00:05:26,430 --> 00:05:31,600
אז זו כל התיאוריה הזאת או האינטואיציה מאחורי מה שעושה גורם הנגזרת.

80
00:05:31,600 --> 00:05:36,250
עכשיו בואו נעיף מבט על אלפא, קצב הלימוד, ונראה מה הוא עושה.

81
00:05:38,090 --> 00:05:42,330
אז הנה הירידה בכיוון הגרדיאנט עם המשוואה הזו.

82
00:05:43,890 --> 00:05:48,440
בואו נסתכל מה קורה אם אלפא הוא או קטן מדי

83
00:05:48,440 --> 00:05:50,740
או גדול מדי.

84
00:05:50,740 --> 00:05:54,200
אז קודם כל מה קורה אם אלפא קטן מדי?

85
00:05:54,200 --> 00:05:59,228
אז הנה הפונקציה J שלי, J של תטא-1.

86
00:05:59,228 --> 00:06:02,460
בואו נתחיל כאן.

87
00:06:02,460 --> 00:06:06,920
אם אלפא קטן מדי, אז מה שנעשה הוא להכפיל

88
00:06:06,920 --> 00:06:11,220
את הנגזרת במספר קטן, מה שיגרום שתטא-1 ישתנה בכמות מאד קטנה.

89
00:06:11,220 --> 00:06:13,350
אוקיי, אז זה היה הצעד הראשון.

90
00:06:13,350 --> 00:06:16,520
מהנקודה החדשה הזה, נצטרך לעשות צעד נוסף.

91
00:06:16,520 --> 00:06:19,690
אבל אם אלפא קטן מדי, גם הצעד הבא יהיה קטן.

92
00:06:19,690 --> 00:06:26,530
אז אם קצב הלימוד הוא קטן מדי אנחנו

93
00:06:26,530 --> 00:06:31,770
פוסעים בצעדי תינוק קטנטנים בדרך למינימום.

94
00:06:31,770 --> 00:06:35,380
ונצטרך הרבה שלבים כדי להגיע למינימום

95
00:06:35,380 --> 00:06:38,980
ולכן אם אלפא הוא קטן מדי אז הירידה במדרון תהיה מאד איטית כי

96
00:06:38,980 --> 00:06:40,880
אנחנו צועדים צעדי תינוק קטנטנים

97
00:06:40,880 --> 00:06:44,830
ולכן נצטרך הרבה שלבים לפני שנגיע לאיזה שהוא מקום קרוב למינימום הגלובלי.

98
00:06:46,750 --> 00:06:49,460
מצד שני, מה קורה אם אלפא הוא גדול מדי?

99
00:06:49,460 --> 00:06:54,880
אז הנה הפונקציה j של תטא-1, ואם אלפא מדי גדול,

100
00:06:54,880 --> 00:06:59,180
אז הירידה במדרון עלולה להחטיא את המינימום ועלולה אפילו לא להצליח להתכנס,

101
00:06:59,180 --> 00:07:00,910
ואולי היא אפילו תתבדר, הנה מה שאני מתכוון.

102
00:07:00,910 --> 00:07:04,170
נניח שהנקודה הנוכחית שלנו היא שם, קרובה למדי למינימום.

103
00:07:04,170 --> 00:07:07,430
אז הנגזרת פונה ימינה, אבל אם אלפא הוא גדול מדי,

104
00:07:07,430 --> 00:07:09,060
אנחנו נעשה צעד ענק.

105
00:07:09,060 --> 00:07:10,820
נעשה צעד ענק כזה.

106
00:07:10,820 --> 00:07:14,980
אז אנחנו נעשה צעד ענק, ועכשיו הפונקציה שלנו מתחילה להתבדר.

107
00:07:14,980 --> 00:07:19,390
כי היא התחילה עם הערך הזה, ועכשיו, הערכים שלה מתחילים לעלות.

108
00:07:19,390 --> 00:07:22,872
עכשיו הנגזרת מצביעה שמאלה, מה שאומר שאני צריך להקטין את תטא-1.

109
00:07:22,872 --> 00:07:25,070
אבל אם אלפא, הלמידה, גדולה מדי,

110
00:07:25,070 --> 00:07:27,930
אנחנו עלולים לעשות צעד ענק שיוצא מכאן ועולה שמאלה הרבה.

111
00:07:27,930 --> 00:07:31,560
אז הגענו לכאן, נכון?

112
00:07:31,560 --> 00:07:35,020
ואם אלפא קצת גדול מדי, אנחנו יכולים לעשות עוד צעד ענק ולעלות עוד יותר

113
00:07:35,020 --> 00:07:39,950
לגובה ולהחטיא את המטרה שוב ושוב, עד שאתם כבר שמים לב

114
00:07:39,950 --> 00:07:44,170
שאני בעצם מתרחק יותר ויותר מהמינימום.

115
00:07:44,170 --> 00:07:49,530
אז אם אלפא גדולה מדי, התהליך עלול לא להתכנס או אפילו להתבדר.

116
00:07:49,530 --> 00:07:52,170
עכשיו, יש לי עוד שאלה בשבילכם.

117
00:07:52,170 --> 00:07:55,870
זה קצת מסובך וכשלמדתי את זה לראשונה באמת זה לקח לי

118
00:07:55,870 --> 00:07:57,020
הרבה זמן להבין את זה.

119
00:07:57,020 --> 00:08:00,740
מה אם הפרמטר תטא-1 כבר נמצא במינימום מקומי,

120
00:08:00,740 --> 00:08:03,420
מה אתה חושב שיעשה הצעד הבא של הירידה במדרון?

121
00:08:06,520 --> 00:08:10,260
בואו נניח שאתחלנו את תטא-1 למינימום מקומי.

122
00:08:10,260 --> 00:08:15,580
נניח שהערך הראשוני של תטא-1 הוא

123
00:08:15,580 --> 00:08:18,630
כבר באופטימום המקומי או במינימום המקומי.

124
00:08:19,960 --> 00:08:23,280
אז מה שקורה הוא שבאופטימום המקומי, הנגזרת תהיה שווה לאפס.

125
00:08:23,280 --> 00:08:29,070
אז בשביל המדרון הזה, זו נקודת המשיק, ולכן השיפוע של הקו הזה

126
00:08:29,070 --> 00:08:36,370
יהיה שווה לאפס ולכן הנגזרת הזו שווה לאפס.

127
00:08:36,370 --> 00:08:38,430
אז שלב העדכון בירידה בכיוון הגרדיאנט

128
00:08:38,430 --> 00:08:43,970
תשאיר את תטא-1 כמו שהוא כי אנחנו מפחיתים ממנו אלפא כפול אפס.

129
00:08:43,970 --> 00:08:48,780
אז מה שזה אומר הוא שאם אתה כבר נמצא במינימום המקומי תטא-1 יישאר

130
00:08:48,780 --> 00:08:54,680
ללא שינוי בשלב העדכון, תטא-1 שווה תטא-1.

131
00:08:54,680 --> 00:08:57,830
אז אם הפרמטרים שלך כבר במינימום מקומי

132
00:08:57,830 --> 00:09:00,980
אז הירידה בכיוון הגרדיאנט לא תעשה דבר לפרמטרים

133
00:09:00,980 --> 00:09:04,830
וזה מה שאנחנו רוצים, כי הוא משאיר את הפתרון במינימום המקומי.

134
00:09:05,970 --> 00:09:09,860
וזה גם מסביר מדוע הירידה בכיוון הגרדיאנט מתכנסת למינימום המקומי

135
00:09:09,860 --> 00:09:13,110
למרות שאלפא, קצב הלימוד, קבוע.

136
00:09:13,110 --> 00:09:15,570
הנה מה שאני מתכוון, בואו נסתכל בדוגמא.

137
00:09:15,570 --> 00:09:20,570
אז הנה פונקצית העלות j של תטא

138
00:09:20,570 --> 00:09:24,750
שאותה אני רוצה למזער ובואו נניח שאתחלתי את האלגוריתם שלי,

139
00:09:24,750 --> 00:09:29,040
אלגוריתם הירידה בכיוון הגרדיאנט, שם בנקודה בצבע מגנטה.

140
00:09:29,040 --> 00:09:33,060
אם אני עושה צעד אחד של ירידה בכיוון הגרדיאנט, אולי זה יביא אותי לנקודה הזו,

141
00:09:33,060 --> 00:09:34,770
כי הנגזרת באזור הזה כאן היא די תלולה.

142
00:09:34,770 --> 00:09:36,020
נכון?

143
00:09:36,020 --> 00:09:41,130
עכשיו, אני בנקודה הירוקה הזו, ואם אני עושה עוד צעד בירידה בכיוון הגרדיאנט,

144
00:09:41,130 --> 00:09:45,740
אתם יכולים לראות שהנגזרת, או המדרון, הוא פחות תלול

145
00:09:45,740 --> 00:09:49,470
בנקודה הירוקה לעומת הנקודה החיצונית בסגול.

146
00:09:49,470 --> 00:09:54,060
ככל שאני מתקרב למינימום, הנגזרת מתקרבת יותר ויותר לאפס,

147
00:09:54,060 --> 00:09:57,570
כשאני מתקרב למינימום.

148
00:09:57,570 --> 00:10:02,350
אז אחרי צעד אחד במדרון, הנגזרת החדשה שלי קצת יותר קטנה.

149
00:10:02,350 --> 00:10:04,890
וכשאעשה את הצעד הבא,

150
00:10:04,890 --> 00:10:08,910
הצעד שאעשה יהיה קצת

151
00:10:08,910 --> 00:10:11,290
יותר קטן מהקודם.

152
00:10:11,290 --> 00:10:15,030
עכשיו יש לנו עוד נקודה, נקודה אדומה, קרוב אפילו יותר למינימום הגלובלי

153
00:10:15,030 --> 00:10:19,390
והנגזרת כאן תהיה עוד יותר קטנה מאשר בנקודה הירוקה.

154
00:10:19,390 --> 00:10:21,050
אז בצעד הבא בירידה בכיוון הגרדיאנט

155
00:10:22,280 --> 00:10:26,560
הנגזרת עוד יותר קטנה ולכן גודל העדכון

156
00:10:26,560 --> 00:10:31,700
של תטא-1 יהיה עוד יותר קטן, ולכן הצעד יהיה יותר קטן.

157
00:10:31,700 --> 00:10:36,630
ותוך כדי התהליך של הירידה בכיוון הגרדיאנט,

158
00:10:36,630 --> 00:10:40,870
הצעדים באופן אוטומטי יהפכו לצעדים קטנים יותר.

159
00:10:41,880 --> 00:10:45,230
עד שבסופו של דבר הצעדים יהיו קטנים מאוד

160
00:10:45,230 --> 00:10:48,990
ובסוף התהליך יתכנס למינימום המקומי.

161
00:10:50,270 --> 00:10:55,580
אז לסיכום, בירידה בכיוון הגרדיאנט, ככל שאנו מתקרבים למינימום מקומי,

162
00:10:55,580 --> 00:10:58,290
הירידה תתקדם בצעדים קטנים יותר באופן אוטומטי.

163
00:10:58,290 --> 00:11:01,060
וזה משום שככל שאנו מתקרבים למינימום המקומי,

164
00:11:01,060 --> 00:11:06,110
ההגדרה של המינימום המקומי היא שהנגזרת בו משתווה לאפס.

165
00:11:06,110 --> 00:11:10,450
ככל שאנו מתקרבים למינימום מקומי, הביטוי הזה של הנגזרת

166
00:11:10,450 --> 00:11:16,720
ילך ויקטן באופן אוטומטי, ולכן הירידה תיעשה בצעדים קטנים יותר.

167
00:11:16,720 --> 00:11:21,140
כך שאין צורך להקטין את אלפא כל הזמן.

168
00:11:22,810 --> 00:11:27,840
אז זהו אלגוריתם הירידה בכיוון הגרדיאנט, ואפשר להשתמש בו כדי לנסות ולמזער

169
00:11:27,840 --> 00:11:32,940
כל פונקציית עלות J, לאו דווקא פונקצית העלות J שהגדרנו עבור רגרסיה ליניארית.

170
00:11:32,940 --> 00:11:35,720
בסרטון הבא, אנחנו הולכים לחזור לפונקצית העלות j

171
00:11:35,720 --> 00:11:39,350
שבה השתמשנו כפונקצית העלות של רגרסיה ליניארית,

172
00:11:39,350 --> 00:11:42,140
פונקצית העלות של ריבועי השגיאות בה השתמשנו קודם.

173
00:11:42,140 --> 00:11:46,210
ניקח את הירידה בכיוון הגרדיאנט ואת פונקצית העלות הריבועית הזו ונשלב אותן.

174
00:11:46,210 --> 00:11:48,830
וזה ייתן לנו את אלגוריתם הלמידה הראשון שלנו,

175
00:11:48,830 --> 00:11:50,750
אלגוריתם הרגרסיה הליניארית.