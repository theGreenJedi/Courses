1
00:00:00,000 --> 00:00:04,934
前に目的関数 J を定義しました。このビデオでは、

2
00:00:04,934 --> 00:00:09,634
目的関数 J を最小化する、最急降下法というアルゴリズムについてお話ししたいと思います。実は

3
00:00:09,634 --> 00:00:14,275
最急降下法はより汎用的なアルゴリズムで、線形回帰

4
00:00:14,275 --> 00:00:18,916
以外でも使われます。実際には機械学習では至るところで使われています。そして後ほどこのクラスでは

5
00:00:18,916 --> 00:00:23,791
最急降下法を使って他の関数も最小化します。線形回帰の目的関数 J

6
00:00:23,791 --> 00:00:27,845
だけではなく。ですから、このビデオでは、

7
00:00:27,845 --> 00:00:32,558
最急降下法の説明に、任意の関数 J を使います。そして

8
00:00:32,558 --> 00:00:37,406
後のビデオで、このアルゴリズムを使って、それを特に線形回帰で使った

9
00:00:37,406 --> 00:00:43,332
目的関数 J に適用します。では、これが問題の設定です。

10
00:00:43,332 --> 00:00:48,112
ある関数 J(theta 0, theta 1) があります。

11
00:00:48,112 --> 00:00:52,773
これは線形回帰の目的関数かもしれません。最小化したいそれ以外のなんらかの関数かもしれません。

12
00:00:52,773 --> 00:00:56,801
そして、それを J(theta 0, theta1) の関数として

13
00:00:56,801 --> 00:01:01,174
最小化するアルゴリズムを見つけたいと思います。余談ですが、実は

14
00:01:01,174 --> 00:01:05,793
最急降下法は実はもっと一般的な関数にも適用されます。

15
00:01:05,793 --> 00:01:10,994
ですから、ある関数が、 J(theta 0, theta 1, theta 2,

16
00:01:10,994 --> 00:01:16,194
と theta n まで続く ) に対する関数であると想像してください。そして

17
00:01:16,405 --> 00:01:21,795
この J(theta 0 から theta n) を theta 0 から theta n にかけて

18
00:01:21,795 --> 00:01:26,580
最小化したいとします。実は最急降下法はこのような

19
00:01:26,580 --> 00:01:31,368
もっと一般的な問題を解くためのアルゴリズムですが、簡潔さのために、そして

20
00:01:31,368 --> 00:01:35,935
表記の簡明さのために、これ以降ビデオでは二つのパラメータだけを

21
00:01:36,113 --> 00:01:41,097
表記して行きます。これが最急降下法の考え方です。何を行うかというと、

22
00:01:41,097 --> 00:01:45,882
最初になんらかの初期値を theta 0 と theta 1 に対し推定します。

23
00:01:45,882 --> 00:01:50,788
それはなんでも構いません。しかし、一般的な選択は、

24
00:01:50,788 --> 00:01:55,452
theta 0 = 0、theta 1 = 0 と設定することです。単に 0 に初期化するのです。

25
00:01:55,452 --> 00:02:00,322
最急降下法で行うのは、theta 0 と

26
00:02:00,322 --> 00:02:05,258
theta 1 の値を少しずつ変え続けて、J(theta 0, theta 1) を減少させられないか試していくことです。

27
00:02:05,258 --> 00:02:10,571
するといずれ最小値、あるいは、もしかして局所的最小値に到達します。では、

28
00:02:10,796 --> 00:02:16,106
最急降下法が何をするのか、図解を見てみましょう。例えば、この関数を最小化しようとしている

29
00:02:16,106 --> 00:02:20,849
とします。座標軸をご覧下さい。これは、theta 0、theta 1 が横軸に、

30
00:02:20,849 --> 00:02:25,774
J は縦軸に取られています。よって、表面の高さが J を示しており、

31
00:02:25,774 --> 00:02:30,582
そしてこの関数を最小化したいのです。まず始めに、(theta 0, theta 1) を

32
00:02:30,582 --> 00:02:35,375
どこかの点に設定します。ですから、なんらかの値を (theta 0, theta 1) に取ると想像してください。

33
00:02:35,375 --> 00:02:39,934
そしてそれはこの関数の表面のどこかの点に対応します。ですから

34
00:02:39,934 --> 00:02:44,201
(theta 0, theta 1) の値が何であれ、それはこの上のどこかの点となります。今回は

35
00:02:44,201 --> 00:02:48,819
(0, 0) としませんでしたが、時には他の値に初期化することがあります。

36
00:02:48,819 --> 00:02:53,942
さて、この図が丘を表示していると想像してください。

37
00:02:53,942 --> 00:02:59,178
これが二つ丘がある緑の草の生えた公園の風景であると想像してください。

38
00:02:59,178 --> 00:03:04,618
そして、自分が実際に丘のその地点に立っていると想像してください。

39
00:03:04,618 --> 00:03:09,990
この公園の小さな赤い丘の上です。最急降下法で行うのは、

40
00:03:09,990 --> 00:03:15,770
ここで360度回転し、周囲を見渡して自問します「もし、なんらかの方向に

41
00:03:15,770 --> 00:03:20,423
小さく一歩踏み出すとしたら、そしてなるべく急いで斜面を

42
00:03:20,423 --> 00:03:25,320
降りたいとしたら、どの方向にその一歩を踏み出すべきか、もし

43
00:03:25,320 --> 00:03:29,686
降りたければ、もしなるべく急いで実際に丘を下っていくには」と。

44
00:03:29,686 --> 00:03:34,465
丘のその地点に立ち、周りを見渡して、

45
00:03:34,465 --> 00:03:39,185
下るための小さな一歩を踏み出すのに最良の方向は、

46
00:03:39,185 --> 00:03:44,035
ほぼこちらだと見極めました。これで丘の上の新しい地点に移動しました。

47
00:03:44,035 --> 00:03:49,430
また、周囲を見渡して自問します。「下るための小さな一歩を踏み

48
00:03:49,430 --> 00:03:54,695
出すのに最良の方向はどれか」と。そうして、もう一歩踏み出すと、

49
00:03:54,695 --> 00:03:59,700
その方向に一歩移動します。そして、これを続けます。この新しい地点で周囲を見渡し、

50
00:03:59,700 --> 00:04:04,835
どの方向なら最も速く下に降りられるか決め、また一歩

51
00:04:04,835 --> 00:04:09,775
また一歩、と続け、やがてこの局所的

52
00:04:09,970 --> 00:04:15,059
最小値に収束します。最急降下法には興味深い特性があります。この

53
00:04:15,059 --> 00:04:19,682
最初に最急降下法を実行した時、この地点から始めましたよね。

54
00:04:19,682 --> 00:04:24,183
この地点から始めました。さて、最急降下法を実行する時に、

55
00:04:24,183 --> 00:04:29,232
ほんの数歩ほど右の地点から始めたと想像してください。最急降下法の初期値が

56
00:04:29,232 --> 00:04:34,159
その右上の地点だと想像してください。このプロセスを繰り返して、その地点で立ち止まって、周りを見渡し、

57
00:04:34,159 --> 00:04:39,207
最も急な下り方面に一歩踏み出すとします。移動して、周囲を

58
00:04:39,207 --> 00:04:44,772
見渡します。また一歩移動し、これを繰り返します。

59
00:04:44,772 --> 00:04:50,570
もしほんの二歩ほど右から開始すると、最急降下法はこの右の二番目の

60
00:04:50,570 --> 00:04:56,236
局所的最適解に導きます。ですから、この最初の地点から

61
00:04:56,236 --> 00:05:01,602
開始すると、この局所的最適解に落ち着きます。しかし、もし少しだけ

62
00:05:01,602 --> 00:05:06,762
やや別の場所から始めると、全く別の局所的最適解に落ち着きます。

63
00:05:06,762 --> 00:05:12,197
そしてこれが最急降下法の特性で、後でまた少しお話します。さて、

64
00:05:12,197 --> 00:05:17,425
これが図解による説明です。では、数学的に見てみましょう。

65
00:05:17,425 --> 00:05:22,929
これが最急降下法アルゴリズムの定義です。単に繰り返し

66
00:05:22,929 --> 00:05:28,240
これを実行し、収束するまで続けます。

67
00:05:28,240 --> 00:05:33,543
パラメータ theta j から alpha 掛けるこの項を引いて theta j を

68
00:05:33,543 --> 00:05:39,129
更新します。さて、この式には色々なポイントがありますので

69
00:05:39,129 --> 00:05:45,030
それを少し分解しましょう。まず、この表記、:=

70
00:05:45,030 --> 00:05:51,643
この := は代入を表記するために使いますので、これは代入演算子です。

71
00:05:51,643 --> 00:05:57,790
ですから、具体的には、もし a := b と書いたら、それは

72
00:05:57,790 --> 00:06:02,878
コンピュータでは、これは b の値を取って、それを使って

73
00:06:02,878 --> 00:06:08,517
a の値を上書きするということです。つまり、a を b の値と同じにするということです。これは代入です。

74
00:06:08,517 --> 00:06:13,674
また a := a+1 と書くことも出来ます。これは a の値を 1 インクリメントするということです。

75
00:06:13,674 --> 00:06:18,969
一方、対照的に、もし 等号を使って a = b と書いたら、

76
00:06:18,969 --> 00:06:26,067
これは真理表明です。ですから、もし

77
00:06:26,067 --> 00:06:31,006
a = b と書いたら、私は a の値が b の値に等しいと表明していることになります。

78
00:06:31,006 --> 00:06:36,331
ですから左側は、これはコンピュータ演算で、a の値をなんらかに設定します。

79
00:06:36,331 --> 00:06:41,399
右側は、これは表明で、a と b の値が同じであると主張しているわけです。

80
00:06:41,399 --> 00:06:46,274
a := a + 1 と書くことができ、それが、a を 1 インクリメントすることを意味するのに対し、

81
00:06:46,274 --> 00:06:50,764
願わくば a = a + 1 とは決して書かないはずです。間違いですので。

82
00:06:50,764 --> 00:06:55,704
a と a + 1 は絶対に同じ値にはなれません。これは、定義の最初の

83
00:06:55,704 --> 00:07:05,733
部分です。この alpha は、学習率という

84
00:07:05,733 --> 00:07:12,360
数字です。alpha の役割は、基本的にどれだけ大きな降下ステップを

85
00:07:12,360 --> 00:07:17,113
最急降下法で取るかを制御します。もし alpha が非常に大きい場合、それが対応するのは、

86
00:07:17,113 --> 00:07:21,925
非常に積極的な最急降下法のやり方となり、大きなステップで降下します。

87
00:07:21,925 --> 00:07:26,322
もし alpha が非常に小さければ、小刻みなステップで降下していくことになります。

88
00:07:26,322 --> 00:07:31,194
そして、これについては後ほど戻ってもう少しお話します。どうやって alpha を設定するかなどについて。

89
00:07:31,194 --> 00:07:35,660
そして最後に、この項。これは

90
00:07:35,660 --> 00:07:40,582
導関数項です。これについては今はお話したくありませんが、

91
00:07:40,582 --> 00:07:45,564
後でこの導関数を導出し、それが一体何かを説明します。皆さんの中には

92
00:07:45,564 --> 00:07:50,547
他の人より微分積分をご存知の方もいると思いますが、もし微分積分をよく知らなくても

93
00:07:50,547 --> 00:07:55,469
心配しないでください。この項について知る必要のあることは説明します。

94
00:07:55,469 --> 00:08:00,580
さて、もう一つ 最急降下法について大事なポイントがあります。それは、

95
00:08:00,580 --> 00:08:05,837
最急降下法では、theta 0 と theta 1 を更新します。ですから、

96
00:08:05,837 --> 00:08:10,699
この更新は j = 0 と j = 1 に対して実行されます。よって theta 0 を更新し、theta 1

97
00:08:10,699 --> 00:08:15,955
を更新します。そして 最急降下法を実装する方法のポイントは、

98
00:08:15,955 --> 00:08:21,562
この式では、この更新の式では、

99
00:08:21,562 --> 00:08:31,384
同時に theta 0 と theta 1 を更新すべきだという点です。

100
00:08:31,384 --> 00:08:36,432
私が言いたいのは、この式では、

101
00:08:36,432 --> 00:08:40,975
theta 0 := theta 0 - 何か、を更新し、theta 1 := theta 1 - 何か、を更新します。

102
00:08:40,975 --> 00:08:45,834
これを実装する方法は、右辺を計算することです。

103
00:08:45,834 --> 00:08:52,677
これを計算します。theta 0 と theta 1 の両方に対して。そして
同時に

104
00:08:52,677 --> 00:08:57,469
同時に theta 0 と theta 1 を更新します。では、その意味を

105
00:08:57,469 --> 00:09:02,024
説明します。これが、最急降下法の正しい実装方法、つまり同時

106
00:09:02,024 --> 00:09:06,461
更新です。temp 0 = それ、と設定し、temp 1 = それ、

107
00:09:06,461 --> 00:09:11,430
と設定します。 つまり基本的に右辺を計算するわけです。そして右辺を計算して、変数

108
00:09:11,430 --> 00:09:15,926
temp 0 と temp 1 に代入した後で、theta 0 と theta 1 を同時に更新します。

109
00:09:15,926 --> 00:09:20,245
それが正しい実装です。それと対照的に、これが間違った実装方法です。

110
00:09:20,245 --> 00:09:25,533
同時更新を行わないものです。では、この間違った

111
00:09:25,533 --> 00:09:31,666
実装方法では、temp 0 を計算し、次に theta 0 を更新します。

112
00:09:31,666 --> 00:09:36,644
そして temp 1 を計算し、次に theta 1 を更新します。そして、右側と左側の

113
00:09:36,644 --> 00:09:41,877
実装方法の違いは、ここを見ると、このステップを見ると

114
00:09:41,877 --> 00:09:46,791
この時点では、既に theta 0 を更新してしまっているので、

115
00:09:46,791 --> 00:09:51,897
theta 0 の新しい値を使ってこの導関数項を計算することになり、

116
00:09:51,897 --> 00:09:57,340
結果的に左側と比べて temp 1 の値が異なることになります。

117
00:09:57,340 --> 00:10:01,565
この式に theta 0 の新しい値を使ってしまっているからです。

118
00:10:01,565 --> 00:10:05,852
ですから、この右側のものは正しい最急降下法の

119
00:10:05,852 --> 00:10:09,916
実装方法ではありません。なぜ同時更新が必要なのかについては

120
00:10:09,916 --> 00:10:14,617
説明したくありません。単にこれが最急降下法

121
00:10:14,617 --> 00:10:18,735
を通常実装するやり方なのです。後でこれについてはさらにお話します。実は、

122
00:10:18,735 --> 00:10:22,496
同時更新を実装する方がより自然なのです。人々が

123
00:10:22,496 --> 00:10:26,665
最急降下法について話す時は、常に同時更新という意味で使っています。もし

124
00:10:26,665 --> 00:10:30,630
非同時更新を実装しても、おそらく動作はすると思います。

125
00:10:30,630 --> 00:10:34,747
しかし、右側のアルゴリズムは人々が最急降下法として言及するものではなく、

126
00:10:34,747 --> 00:10:38,356
それは何か異なる特性をもつ別のアルゴリズムです。色々な

127
00:10:38,356 --> 00:10:42,220
理由で、これは少し変わった動作をする可能性があります。そして

128
00:10:42,220 --> 00:10:46,626
皆さんがすべきなのは、最急降下法の同時更新を実装することです。

129
00:10:46,626 --> 00:10:52,313
さて、これが最急降下法アルゴリズムの概要です。次のビデオでは、

130
00:10:52,313 --> 00:10:56,998
導関数項の詳細について説明します。書き出しはしましたが定義しません

131
00:10:56,998 --> 00:11:01,799
でしたので。もし以前に微分積分の授業を受けたことがあり、

132
00:11:01,799 --> 00:11:06,367
導関数や偏導関数をご存知の方は、導関数項がまさにそれと

133
00:11:06,367 --> 00:11:11,425
同じものだと分かります。しかしたとえ微分積分に詳しくなくても

134
00:11:11,425 --> 00:11:15,680
心配しないでください。次のビデオで全ての直感的理解が得られ、

135
00:11:15,680 --> 00:11:19,883
導関数項を計算するのに必要なことは全て説明します。たとえ

136
00:11:19,883 --> 00:11:24,296
微分積分を見たことがなくても、偏導関数を見たことがなくても。

137
00:11:24,296 --> 00:11:28,288
以上です。次のビデオでは、十分に直感的理解が得られ

138
00:11:28,288 --> 00:11:30,180
最急降下法を応用できるようになると思います。