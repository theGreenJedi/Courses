पिछले वीडियो में, हमने बात की ग्रेडीयंट डिसेंट अल्गोरिद्म की और हमने बात की लिनीअर रेग्रेशन मॉडल की और स्क्वेर्ड एरर कॉस्ट फ़ंक्शन की. इस वीडियो में हम एक साथ रखेंगे ग्रेडीयंट डिसेंट और हमारा कॉस्ट फ़ंक्शन, और वह देगा हमें एक अल्गोरिद्म लिनीअर रेग्रेशन के लिए या डालना / रखना एक सीधी रेखा हमारे डेटा में. तो यह है जो हम पिछले वीडियो में किया था. यह ग्रेडीयंट डिसेंट अल्गोरिद्म जिससे आप परिचित होने चाहिए और यहाँ है लिनीअर रेग्रेशन मॉडल हमारी लिनीअर हायपॉथिसस के साथ और हमारा स्क्वेर्ड एरर कोस्ट फ़ंक्शन. हम क्या करेंगे कि अप्लाई करेंगे ग्रेडीयंट डिसेंट न्यूनतम करने के लिए हमारा स्क्वेर्ड एरर कोस्ट फ़ंक्शन. अब अप्लाई करने के लिए ग्रेडीयंट डिसेंट, आप जानते हैं लिखने के लिए यह कोड का हिस्सा, कीई टर्म जो हमें चाहिए वह है यह डेरिवेटिव टर्म यहाँ. तो आपको यह समझना है कि क्या है यह पर्शियल डेरिवेटिव टर्म और प्लग करना है इसे परिभाषा में कोस्ट फ़ंक्शन जे की. परिणाम यह निकलता है. सम वाय बराबर एक से एम तक. इस स्क्वेर्ड एरर कॉस्ट फ़ंक्शन टर्म की. और मैंने सिर्फ़ यहाँ क्या किया कि मैंने सिर्फ़ आप जानते हैं प्लग किया परिभाषा में कॉस्ट फ़ंक्शन की वहाँ. और थोड़ा और अधिक सरल बनाने के लिए, यह निकलता है इसके बराबर. सिग्मा आइ बराबर एक से एम तक थीटा 0 प्लस थीटा वन एक्स 1 माईनस वाय आइ स्क्वेर्ड. मैंने सिर्फ़ क्या किया कि ली परिभाषा मेरी हायपॉथिसस की और प्लग किया इसे वहाँ. और ऐसा है कि हमें समझना है कि क्या है यह पर्शियल डेरिवेटिव दो केस के लिए J बराबर 0 और जे बराबर 1. तो हम चाहते हैं समझना कि क्या है यह पर्शियल डेरिवेटिव दोनो थीटा 0 केस के लिए और थीटा 1 केस के लिए. और अब मैं सिर्फ़ लिखूँगा उत्तर. यह पहली टर्म है, सरलीकृत 1/M सम मेरे ट्रेनिंग सेट पर केवल X(i)-Y(i) और इस पर्शियल डेरिवेटिव टर्म के लिए चलो लिखते हैं थीटा 1, मुझे मिलती है यह टर्म. माइनस Y (i) टाइम्ज़ X(i). ठीक है और कम्प्यूट करने के लिए ये पर्शियल डेरिवेटिव, तो हम जा रहे हैं इस इक्वेज़न से. ठीक है जा रहे हैं इस इक्वेज़न से इनमें से एक इक्वेज़न पर नीचे वहाँ. कम्प्यूट करने के लिए वे पर्शियल डेरिवेटिव आवश्यकता है कुछ मल्टी-वेरियेट कैल्क्युलस की. यदि आप जानते हैं कैल्क्युलस, आप अपने आप कर सकते हैं डेरिवेशनज़ और चेक कर सकते हैं कि यदि आप लेते हैं डेरिवेटिव्स, आपको वास्तव में मिलते हैं वही जवाब जो मुझे मिले हैं. लेकिन यदि आप कम परिचित है कैल्क्युलस से, चिंता न करें उसकी और यह ठीक है ले लेना इन इक्वेज़न्स को जो हल की गई हैं और आपको नहीं होगी आवश्यकता जानने की कैल्क्युलस या वैसा कुछ, करने के लिए होमवर्क तो चलो इम्प्लमेंट करते हैं ग्रेडीयंट डिसेंट और काम पर लगते हैं. तो इन परिभाषाओं के साथ या जो हमने निकाले डेरिवेटिव्स जो है वास्तव में सिर्फ़ स्लोप कॉस्ट फ़ंक्शन जे की हम अब प्लग कर सकते हैं वापिस उन्हें हमारे ग्रेडीयंट डिसेंट अल्गोरिद्म में. तो यहाँ है ग्रेडीयंट डिसेंट लिनीअर रेग्रेशन के लिए जो बार बार चलेगा जब तक कन्वर्जेन्स नहीं हो जाता, थीटा 0 और थीटा 1 होंगे अपडेट जैसे आप जानते हैं यह माइनस अल्फ़ा टाइम्ज़ डेरिवेटिव टर्म. तो यह टर्म यहाँ. तो यहाँ है हमारा लिनीअर रेग्रेशन अल्गोरिद्म. यह पहली टर्म यहाँ. वह टर्म है निश्चय ही सिर्फ़ पर्शियल डेरिवेटिव विद रिस्पेक्ट टु थीटा ज़ीरो, जो हमने पिछली स्लाइड में किया था. और यह दूसरी टर्म यहाँ, वह टर्म है सिर्फ़ पर्शियल डेरिवेटिव विद रिस्पेक्ट टु थीटा 1, जो हमने पिछली स्लाइड में किया था. और सिर्फ़ एक छोटी चेतावनी, आप, जब कर रहे हैं इम्प्लमेंट ग्रेडीयंट डिसेंट. यह विस्तृत जानकारी कि आपको इम्प्लमेंट करना चाहिए इसे ताकि थीटा 0 और थीटा 1 अपडेट हों एक साथ. अतः. तो चलिए देखते हैं ग्रेडीयंट डिसेंट कैसे काम करता है. एक मुद्दा जो हमने ग्रेडीयंट डिसेंट के साथ देखा कि यह संवेदनशील हो सकता है लोकल ऑप्टिमा को. तो जब मैंने पहली बार ग्रेडीयंट डिसेंट समझाया मैंने दिखाई इस की यह तस्वीर आपको नीचे जाते हुए सतह पर, और हमने देखा कि कैसे निर्भर करते हुए कि कहाँ आप ईनिशीयलाइज करते हैं इसे, आप पहुँच सकते हो भिन्न लोकल ऑप्टिमा पर. आप पहुँच सकते हैं यहाँ या यहाँ. लेकिन, ऐसा होता है कि वह कॉस्ट फ़ंक्शन लिनीअर रेग्रेशन का हमेशा होगा एक धनुष के आकार का फ़ंक्शन ऐसा. इस के लिए तकनीकी शब्द है कि इसे कहते हैं एक कान्वेक्स फ़ंक्शन, और मैं नहीं दूँगा विधिवत परिभाषा कि क्या है कान्वेक्स फ़ंक्शन, सी,ओ,एन,वी,ई,एक्स. लेकिन अनौपचारिक रूप से एक कान्वेक्स फ़ंक्शन का मतलब है एक धनुष के आकार का फ़ंक्शन और इसलिए इस फ़ंक्शन का नहीं है कोई लोकल ऑप्टिमा एक ग्लोबल ऑप्टिमा के अतिरिक्त. और ग्रेडीयंट डिसेंट इस तरह के कॉस्ट फ़ंक्शन पर जो आपको मिलता है जब भी आप करते हैं लिनीअर रेग्रेशन यह होगा हमेश कन्वर्ज ग्लोबल ओप्टिमम पर. क्योंकि वहाँ कोई लोकल ओप्टिमम नहीं है, सिर्फ़ ग्लोबल ओप्टिमम है. तो अब देखते हैं यह अल्गोरिद्म काम करते हुए. हमेशा की तरह, यहां हैं प्लॉट्स हायपॉथिसस फ़ंक्शन के और मेरे कॉस्ट फ़ंक्शन जे के. और इसलिए मान लो मैंने ईनिशीयलाइज किए हैं मेरे पेरमिटर्स इस वैल्यू पर. मान लो, आम तौर पर आप ईनिशीयलाइज करते हैं आपके पेरमिटर्स ज़ीरो, ज़ीरो पर. थीटा ज़ीरो और थीटा वन बराबर हैं ज़ीरो. लेकिन समझाने के लिए, इस केस में मैंने ईनिशीयलाइज किया है, आप जानते हैं, थीटा ज़ीरो को 900 और थीटा एक को -0.1 ठीक है. और इसलिए यह बनता है एच(एक्स)=900-0.1 एक्स, है यह लाइन, यहाँ कॉस्ट फ़ंक्शन पर. अब, यदि मैं लेता हूँ एक स्टेप ग्रेडीयंट डिसेंट में, मैं पहुँचूँगा इस पोईँट यहाँ पर से नीचे और बाईं तरफ़, उस दूसरे पोईँट पर और आप ध्यान दें कि मेरी लाइन बदल गई थोड़ी, और जैसे मैं लेता हूँ एक और स्टेप ग्रेडीयंट डिसेंट में, मेरी लाइन बाईं तरफ़ की बदल जाएगी. ठीक? और मैं पहुँच गया एक नए पोईँट पर मेरे कॉस्ट फ़ंक्शन में. जैसे मैं लेता हूँ और स्टेप्स ग्रेडीयंट डिसेंट में, मैं जाता हूँ नीचे कॉस्ट में. तो मेरे पेरमिटर्स ले रहे हैं यह रास्ता. और अगर आप बाईं तरफ देखें, यह कॉरेस्पॉंड करता है हायपॉथिसस से. वह प्रतीत होता है बेहतर और बेहतर फ़िट होता हुआ डेटा को जब तक अंत में में पहुँचता हूँ ग्लोबल मिनिमम पास यह ग्लोबल मिनिमम कॉरेस्पॉंड करता है इस हायपॉथिसस को जो देती है मुझे एक अच्छा फ़िट डेटा को. और इसलिए वह है ग्रेडीयंट डिसेंट, और हम सिर्फ़ इसे रन करते हैं और पाते हैं एक अच्छा फ़िट मेरे डेटा सेट के लिए घरों की क़ीमतों के. और अब आप इसे उपयोग कर सकते हैं प्रिडिक्ट करने के लिए, आप जानते हैं, यदि अपने दोस्त के पास है एक घर जिसका साइज़ है 1250 वर्ग फुट, अब आप पढ़ सकते हैं वैल्यू और बता सकते हैं उन्हें कि मैं नहीं जानता शायद उन्हें मिल सकते हैं $ 250,000 उनके घर के लिए. अंत में सिर्फ़ देने के लिए इसे एक और नाम ऐसा होता है कि अल्गोरिद्म जो हमने अभी समझा कभी कभी कहलाता है बैच ग्रेडीयंट डिसेंट. और ऐसा होता है मशीन लर्निंग में मैं नहीं जानता मुझे लगता है हम मशीन लर्निंग के लोग नहीं थे हमेशा महान नाम देने में अल्गोरिद्म्स को. लेकिन टर्म बैच ग्रेडीयंट डिसेंट सम्बोधित करती है तथ्य को कि ग्रेडीयंट डिसेंट के प्रत्येक स्टेप में, हम देख रहे हैं सारे ट्रेनिंग इग्ज़ाम्पल्ज़. तो ग्रेडीयंट डिसेंट में, जब कम्प्यूट करते हैं डेरिवेटिव्स, हम कम्प्यूट कर रहे हैं सम [ सुनाई नहीं दिया]. तो ग्रेडीयंट डिसेंट के प्रत्येक स्टेप में हम करते हैं कम्प्यूट कुछ ऐसे कि सम करें हमारे एम ट्रेनिंग इग्ज़ाम्पल्ज़ पर और इसलिए टर्म बैच ग्रेडीयंट डिसेंट बताती है कि हम देख रहे हैं पूरे बैच पर ट्रेनिंग इग्ज़ाम्पल्ज़ के. और फिर, यह वास्तव में नहीं है एक बढ़िया नाम, लेकिन यह है जो मशीन लर्निंग के लोग कहते हैं इसे. और यह होता है, कि कभी कभी हैं दूसरे वर्ज़न ग्रेडीयंट डिसेंट के जो नहीं है बैच वर्ज़न, लेकिन वे हैं इसके बजाय. वे नहीं देखते पूरे ट्रेनिंग सेट बल्कि देखते हैं एक छोटे सब सेट को ट्रेनिंग सेट के एक समय में. और हम बात करेंगे उन वर्ज़न्स की भी बाद में इस कोर्स में. लेकिन अभी के लिए इस्तेमला करेंगे अल्गोरिद्म जो हमने अभी सीखा या इस्तेमाल करेंगे बैच ग्रेडीयंट डिसेंट आप अब जानते हैं कैसे इम्प्लमेंट करना है ग्रेडीयंट डिसेंट लिनीअर रेग्रेशन के लिए. तो वह है लिनीअर रेग्रेशन ग्रेडीयंट डिसेंट के साथ. यदि अपने देखा है एडवान्सड लिनीअर ऐल्जेब्रा पहले, तो आप में से कुछ ने शायद ली हो एक क्लास एडवांसड लिनीअर ऐल्जेब्रा की. आप शायद जानते होंगे कि एक हल मौजूद है नूमेरिक्ली निकालने के लिए न्यूनतम कॉस्ट फ़ंक्शन जे का बिना इस्तेमाल किए एक आइटरेटिव अल्गोरिद्म ग्रेडीयंट डिसेंट जैसा. बाद में इस कोर्स में हम बात करेंगे उस विधि की भी जो सिर्फ़ हल करता है न्यूनतम के लिए कॉस्ट फ़ंक्शन जे के, बिना करे ये बहुत स्टेप ग्रेडीयंट डिसेंट के. उस दूसरी विधि को कहते हैं नोर्मल इक्वेज़नज़ विधि. लेकिन यदि अपने सुना है पहले उस विधि के बारे में तो ऐसा होता है कि ग्रेडीयंट डिसेंट बेहतर काम करता है बड़े डेटा सेट्स के लिए तुलना में नोर्मल इक्वेज़न विधि के. और अब जब हम जानते हैं ग्रेडीयंट डिसेंट के बारे में हम इस्तेमाल कर पाएँगे इसे बहुत से विभिन्न संदर्भों में और हम इस्तेमाल करेंगे इसे बहुत सी मशीन लर्निंग प्राब्लम्ज़ में भी. तो आपको पहला मशीन लर्निंग एल्गोरिद्म के बारे में सीखने पर बधाई. बाद में हमारे पास अभ्यास है जिसमें हम आपको ग्रेडीयंट डिसेंट करने के लिए कहेंगे और उम्मीद है कि देख पाएँगे इन अल्गोरिद्म्स को अपने आप. लेकिन उससे पहले मैं पहले बताना चाहता हूँ आपको अगले सेट के वीडियोंज़ में. पहला जो आपको बताना चाहता हूँ एक जनरलाइज़ेशन के बारे में ग्रेडीयंट डिसेंट के जो बनाएगा इसे और ताक़तवर. और मैं सोचता हूँ मैं बताऊँगा उसके बारे में अगले वीडियो में.