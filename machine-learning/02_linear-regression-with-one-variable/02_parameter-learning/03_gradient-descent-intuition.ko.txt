이전 강의에서 여러분에게 기울기 하강에 대한 수학적인 정의를 드렸습니다. 이번에는 알고리즘의 개념에 대해서 
더 깊게 이해해보기 위해 몇가지를 더 배워보겠습니다. 저번시간에 봤던 기울기 하강알고리즘입니다. 다시한번 기억시켜드리자면,
여기에 있는 α는 훈련비율입니다. 얼마나 많은 값이 변하는가에 대한 변수이며,
파라메터 j값이 영향을 받습니다. 그리고 여기에 있는 두번째 용어는 
미분계수입니다. 그래서 이번 시간에 배울 것은,
이 두 용어에 대한 개념을 설명하고 같이 사용됐을 때, 어떤 변화가 있는지
설명해드리겠습니다. 이 개념을 잘 설명해 드리기 위해서, 
약간 간단한 예제를 사용해보겠습니다. 하나의 파라메터를 가지고
함수를 최소화해보겠습니다. 비용함수 j와 하나의 파라메터가 있다고 합시다. 이전 비디오에서 많이 사용했던 Θ1을 쓰겠습니다.
Θ1은 실제 정수입니다. 그래서 하나의 그래프를 그릴수 있게되는데요,
더 간단하게 표현해보겠습니다. 이 함수에서 기울기 하강이
어떤 일을 하는지 봅시다. 여기에 j Θ1 함수가 있습니다. 이런식으로 생겼고요. Θ1은 실제 정수입니다. 아시겠죠? Θ1의 위치를 그래프에서
표시해보도록 합시다. Θ1값이 함수와 만나는 지점을 표시해봅시다. 함수가 어떤 값이 될까요? Θ1은 Θ1 - α 의 값으로
변할 것입니다. d/dΘ1, 맞죠? 이게 바로 미분계수입니다. 왜 갑자기 미분계수의 부분의 기호를 바꿨는지, 두 기호간의 차이는 무엇인지, 그리고 d는 무엇인지 모르셔도 괜찮습니다. 수학 기술적으로, 이것을 부분 미분계수나 미분계수라고 부르는데, 
함수j의 파라메터의 개수에 따라 달라집니다. 그렇지만 이것은 수학 기술적인 의미입니다. 이 강의에서 의미하는 바는, 부분기호와 d, dΘ1은 같은 것입니다. 실제로 뭐가 다른지에 대해 고민하지마세요. 정확한 수학 표기법을 사용하려고 하겠지만, 두 표기법이 의도하는 바는
정확히 같은 것입니다. 이제 공식이 뭘 하는지를 봅시다. 이 미분계수를 계산하려고하는데, 계산하기 전에, 이 점에서 미분계수가 하는 일은 그 점의 탄젠트값을 구하는 것입니다.
여기의 빨간 선처럼요. 이 함수와 맞닿기만 하고요, 
이 빨간 선의 기울기를 봅시다. 이 기울기 값이 바로 함수의 탄젠트값이 바로
미분계수입니다. 좋아요, 이 선의 기울기를 이정도 길이의
수직선으로 나눠봅시다. 기울기가 양수값임을 알 수 있습니다. 그 말은 미분계수가 양수라는 겁니다. 이제 Θ1값은 변하게 되겠죠. Θ1 - α 값에 양수값을 곱한 값이 됩니다. 좋아요. 이제 α값은 항상 양수라는 것을 알았습니다. 이제 우리가 해야할 일은 Θ1값에서
특정 값을 빼는겁니다. Θ1을 왼쪽으로 옮겨보겠습니다. 그리고 Θ1값을 줄여보겠습니다. 값이 줄어든다는 것은
이 방향으로 Θ1값이 이동하는 것을 말합니다. 아시다시피, 최소값은 이 지점이니까요. 그래서 지금까지 얘기한 것이
기울기하강입니다. 다른 예제를 보시죠. 같은 함수 j를 사용해보도록 하겠습니다. j Θ1 함수를 말입니다. 그리고 저 왼쪽으로 파라메터를 
초기화해보겠습니다. Θ1은 여기에 있고요. 함수의 표면과 만나는 점을 표시하겠습니다. 이제 미분계수인 d/dΘ1 의 값을 구하기위해 이 선의 기울기에 대해 보도록하죠. 그러니까 이 선의 기울기가 
즉, 미분계수가 되는겁니다. 그러나 이런 기울기는 음수값입니다. 좋아요. 이 함수를 음수 미분계수라고 하겠습니다. 이 점의 기울기가 음수라는 뜻입니다. 이 말은 값이 0과 같거나 작다는 것입니다. 이제 Θ값은 Θ - α값에 음수를 곱한값이 됩니다. 그래서 Θ1에 음수 값을 뺀다는 말은, Θ값이 증가한다는 말입니다.
왜냐하면 음수값을 빼주기 때문이죠. Θ값에 어떤 값을 더해준다는 말입니다. 그 뜻은 바로 Θ값이 증가하면 이제 이점에 있는 것이아니라 최소값과 가까운 쪽으로 이동하게됩니다. 이것이 바로 미분계수의 모든 개념적 이론입니다. 이제 α가 의미하는 비율의 값을 보도록 합시다. 여기에 기울기 하강 공식이 있습니다. 이제부터 α값이 매우 작거나, 크다면 어떻게 되는지 보도록합시다. 첫번째 예시로는, 
α값이 매우 작다면 어떻게될까요? 함수 j, j Θ가 있습니다. 여기서부터 시작하도록 하죠. 만약 α값이 매우 작다면, 여기에 작은 숫자를 곱하게 될 겁니다.
그리고 매우 작게 이동할 겁니다. 좋아요, 첫번째 점의 이동입니다. 이제 새로운 점에서,
다른 이동을 해보도록 합시다. 그러나 α값이 매우 작기때문에,
조금만 움직이도록 하겠습니다. 그래서 만약 훈련 비율이 너무 작다면 최소값에 도달하기위해 조금씩만 움직여야  할 겁니다. 그리고 최소값에 이동하기위해 많은 이동이 필요하게 됩니다. α가 너무 작다면, 하강은 매우 느려집니다. 많은 이동이 필요하기 때문이죠. 전역적 최소값에 도달하기 위해서는
많은 이동이 필요합니다. 이제 만약에 α값이 매우 크다면 어떻게 될까요? 여기에 함수 j를 그려보도록 하겠습니다. 그리고 α값이 너무 크다면 최소값보다 더 가거나, 값을 바꾸거나 방향을 바꾸는 것도 어려워질 수 있습니다. 우리의 자료가 이 지점에 있다고 해봅시다.
실제로 최소값과 매우 가깝습니다. 그리고 방향은 오른쪽으로 이동해야합니다.
그러나 α값이 너무 큽니다. 큰 거리를 이동을 해야합니다. 기억하세요, 매우 큰 거리입니다. 그래서 큰 거리를 이동했습니다.
그리고 비용함수의 반대편으로 가게됩니다. 이 지점에서 시작했기때문이죠.
이제 제 값은 큰 반대값이 됩니다. 이제 미분계수는 왼쪽에 있습니다.
자료값이 감소하게 되죠. 하지만 훈련값이 너무 크기때문에. 저기에 있는 지점으로 이동하게 됩니다. 이 지점에서 끝나게 됩니다. 맞죠? 그리고 α값이 크기때문에, 
또 다른 값으로 크게 이동합니다. 계속해서 더 이동하고, 더 이동합니다. 계속해서 최소값으로부터
멀어지게되죠. 그래서 α값이 너무 크게되면, 
방향을 전환하는 것 조차 실패합니다. 한가지 다른 질문을  해보겠습니다. 약간 꼰 문제이며,
제가 처음에 이 문제를 풀기위해 꽤 많은 시간을 썼습니다. 만약 파라메터 Θ1이 이미 최소값이라면, 어떤 각도로 하강해야할까요? Θ1이 지역최소값이라고 가정해봅시다. 그리고 Θ1인 지역최소값은
이 지점이라고 해봅시다. 이미 지역적 최적, 최소값입니다. 지역 최적값이라면, 
미분계수는 0이됩니다. 그래서 이 선의 기울기, 탄젠트값은 0과 같아질거고, 미분계수는 0이됩니다. 그래서 하강 기울기를 찾아봅시다. Θ1 값은 Θ - α값에 0을 곱한 값이됩니다. 이 의미는 만약 이미 지역최적값이라면, Θ1값은 변하지 않게되고,
Θ1 = Θ1이 됩니다. 그래서 만약 파라메터가 지역최소값이라면, 하강 기울기는 파라메터에 
아무런 영향도 끼치지않습니다. 이렇게 되면 지역최적값이 유지가 됩니다. 그리고 만약 훈련 비율인 α가 고정되어있다면, 하강 기울기는 최소값에 영향을 미치지못합니다. 이 예제를 보시면서 이해해봅시다. Θ에 대한 비용함수 j가 있습니다. 저는 최소화하고싶고,
알고리즘을 초기화해봅시다. 하강 기울기 또한 초기화해봅시다.
이 분홍색으로 표시한 점으로 말입니다. 하강 기울기에서 이동하게 된다면, 
저는 이 지점으로 이동하게 될 것입니다. 왜냐면 미분계수가 매우 가파르기때문입니다. 그렇지 않습니까? 저는 이제 이 초록색 지점에 있게되고,
하강 기울기에서 또 이동해봅시다. 미분계수가 기울기를 의미한다는 것을 기억하실겁니다. 분홍색지점보다 초록색지점이
기울기가 덜 가파릅니다. 왜냐하면 최소값에 가까워지고 있고,
제 미분계수는 0에 가까워지고 있으니까요. 최소값에 가까워질수록 말입니다. 좀 더 하강해본다면, 
제 미분계수는 더 작아질겁니다. 하강 기울기에서 더 내려가보겠습니다. 분홍색 점에서 초록색 점으로 이동한 거리보다 더 적게 이동해보도록 하겠습니다. 새로운 지점에서,
전역적 최소값에 더 가까워졌습니다. 그리고 미분계수는 초록색 점보다 더 작아집니다. 하강 기울기에서 또 이동했습니다. 이렇게 적은 거리를 이동거리를 이동하게 되더라도 미분계수는 더 작아지고, Θ1의 값도 더 작아집니다. 하강 기울기를 계속 진행하면서, 자연스럽게 더 조금씩 움직일 겁니다. 결국에 조금씩 이동하다보면, 지역 최소값에 도달하게 될겁니다. 요약하자면, 하강 기울기는 지역 최소값에 가까워질수록, 더 작은 거리를 이동하게 됩니다. 왜냐하면, 최소값에 가까워진다는 것은 지역 최소값의 정의는, 미분계수가 0이 되는 것이기 때문입니다. 지역 최소값에 가까워질수록, 미분계수값은 작아지게 되고,
하강 기울기는 더 조금씩 이동하게 됩니다. 그렇기 때문에 α값을 감소할 필요가 없는겁니다. 이게 바로 기울기 하강 알고리즘이였습니다. 선형회귀에서 어떤 비용함수 j나 비용함수가 아니더라도 
최소값을 구할 때 사용할 수 있습니다. 다음시간에서는 비용함수 j를 사용해서 선형회귀에서 사용되는 비용함수로 돌아가보도록 하겠습니다. 우리가 했던 비용함수의 제곱말입니다. 그리고 이 함수와 기울기 하강 알고리즘을 
함께
사용해보도록 하겠습니다. 지도 알고리즘을 이해하고, 선형 회귀 알고리즘을 이해하게 해 줄겁니다.