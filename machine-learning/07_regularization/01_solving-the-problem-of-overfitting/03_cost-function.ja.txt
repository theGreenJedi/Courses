このビデオでは 正規化がどう機能するか、の背後にある 主要な直感をお伝えしたい。 そして、我らが正規化を用いる時に 使うコスト関数を書き下していく。 これらのスライドに描いた 手書きの例で、 その直感の一部をお伝え出来ると思う。 だが、より良い方法としては、 自分自身で見てみる事だろう、 正規化がどう機能するかを、 自分で実装してみて、自分の所で機能するかを見てみる事で。 そしてこの後に 適切な課題を解けば、 正規化が実際には ちゃんと動くかが自分で確かめる事が出来る。 では、直感とはこうだ。 前回のビデオでは、 このデータに二次関数を フィッティングさせると、 データにかなり良くフィットする事を見た。 一方でもし、とても高次の 多項式でフィッティングすると、 結局、トレーニングセットには とても良くフィットした 曲線を得られるかもしれないが、 だが実際には、 データにオーバーフィットしてしまっていて、 あまりうまく一般化出来ないだろう事も見た。 以下を考えてみよう。 パラメータのシータ3とシータ4に ペナルティを与えて、とても小さくしてみよう。 それはつまりこういう事だ。 これが最適化の目的関数だ。 あるいは最適化問題だ、それは 通常の、二乗誤差の コスト関数を最小化するという物だ。 この目的関数を 変更して、これに 1000 シータ3の二乗 を加えて、 さらに1000シータ4の二乗を加えよう。 1000というのは適当な大きな数字を書いただけ。 いま、この関数を 最小化すると、 この新しいコスト関数を小さくする 唯一の方法は、 シータ3とシータ4を 小さくする事だ。 何故なら、さもないと1000掛けるシータ3の 項があるから、 この新しいコスト関数も大きくなってしまう。 だからこの新しいコスト関数を 最小化する時には、 結局シータ3を0に近づけ、 シータ4を0に近づけ、 そしてここの、これら二つの項を 取り除くしか 無い。 そうすると、 シータ3とシータ4が0に近いなら、 残った物は 二次関数だ。 つまり結局は、 二次関数に、足す事の 小さな項による寄与、の関数で、 データにフィッティングする事になる。 小さな項とはシータ3, シータ4の項で、これはとても0に近い。 つまり結局、 本質的には二次関数となり、それは良い。 何故ならこれはより良い 仮説だから。 この具体例では、二つのパラメータに とても大きな値でのペナルティを与えた場合の 効果を見てきた。 より一般的には、正規化の背後にあるアイデアはこういう物だ。 そのアイデアとは、 パラメータとして小さな値だったらその時は、 パラメータが 小さな値だったら、 それは通常、いくらかよりシンプルな仮説に 対応している。 つまり、さっきの例では、 シータ3とシータ4だけにペナルティを与えた。 そしてこれら二つが 0に近づけば それはよりシンプルな仮説である、ようするにほとんど 二次関数となる。 だがより広く、全てのパラメータに ペナルティを与えると、 それもまた、よりシンプルな仮説を 与えようとする試みと みなす事が出来る。何故なら、、、 これらのパラメータが 0に行く時は、 二次関数を与えた訳だから。 より一般の場合でも、 より小さいパラメータの値は よりスムースな関数に対応する、という事を 示す事が出来る。つまり よりシンプルになる、という事を。 そしてそれ故に、よりオーバーフィットしづらくなるという事を。 何故全てのパラメータを 小さく保つ事が、どうして よりシンプルな仮説に対応するのか、 その理由がいまいち良く分からないかもしれないのは、 私の方でも分かっている。 それは自分で実際に実装してみないで 理解するのは、なかなかに 難しい。 だが、シータ3とシータ4を 小さくする、という例が どのようによりシンプルな仮説を 与えるかを見た事で、 なにがしか納得出来るような、 少なくともなんとなくそう思える事を、 期待している。 具体的な例を見ていこう。 住居の価格の予測では、 100個ものフィーチャーがありえる、 という話をした。例えば、 x1はサイズ、 x2は寝室の数、 x3は何階建てか、などなど。 そんな風に、何百ものフィーチャーを持ちうる。 そして多項式の例と違って、 我らは知らないのだーー 我らはシータ3やシータ4が 高次の項だとか知らないのだ。 だから、我らは単にカバンの中に たくさんのフィーチャーが 入っている、というだけなので、 前もってどのフィーチャーがあまり関係なさそうかを 選び出すのは難しい。 つまり我らには100個とか101個のパラメータがある訳だ。 そしてどれを選ぶべきか 知らない、 どのパラメータを縮めるべきか 分からない。 だから正規化において我らがやる事は、 コスト関数に対して、 これが線形回帰のコスト関数だ。 そして私がやる事は、 このコスト関数を修正して、 全てのパラメータを縮める。 何故なら、 どれを縮めたらいいのか 知らないから。 つまり、私はコスト関数を修正して 最後に項を追加する。 こんな感じ。だから大カッコも足しておく。 おのおののパラメータを 縮める為に 正規化項を 末尾に足す。 つまりこの項は、我らの全てのパラメータ シータ1, シータ2、シータ3、と シータ100までの全てのパラメータを 縮めるように機能する。 ところで、慣例により、ここでの和は 1から始まっている。 つまりパラメータのシータ0が大きくなる事は ペナルティを与えていない。 iが0からnまでじゃなく、 iが１からnまでであるという 慣習は、 実際には、とても小さな 効果しかない。 だからシータ0を 含めようが含めなかろうが、 現実的には結果にはほとんど違いを生まない。 だが慣例により、通常は、 我らはシータの1からシータ100までだけを 正規化する。 我らの正規化した最適化の目的関数を、 我らの正規化したコスト関数をもう一度書き下そう。 それはこんな風になる。 Jのシータは、 この右側の項は正規化項で、 そしてここのラムダは 正規化パラメータと呼ばれる物で、 ラムダのやる事は、 二つの異なるゴールのトレードオフを コントロールする事だ。 最初のゴールは、最初のゴールの目的関数で 捉えられている物だが、 トレーニングデータに うまくフィットするようにトレーニングしたい、という物。 我らはトレーニングセットにうまくフィットさせたい。 そして二番目のゴールは、 パラメータを小さく保っておきたい。 これは二番目の項で捉えられている、 正規化の目的関数で、正規化の項で。 そしてラムダ、正規化のパラメータがやる事は、 これら二つのゴールの間の トレードオフを制御する事、 トレーニングセットにうまくフィットさせるというゴールと そしてもう一つの パラメータシータを小さく保ちたい、 ゆえに仮説を比較的シンプルに保ちたい、オーバーフィットを避ける為に というゴールの。 我らの住居の価格の予測の例では、 前に、とても高次の多項式で フィッティングすれば、 とても、いわゆるうねった関数、 こんな感じ、 こういう感じになるかもしれないのだった。 もし高次の多項式で、 全ての多項式の項のフィーチャーを 含めておいたら。 だが代わりに、確かにこれらの 正規化された目的関数を使えば そこから得られる物は、 それは実際には完全に二次関数という 訳では無いが、だが もっとスムースでもっとシンプルな物となる。 そしてマゼンタ色のカーブが得られるだろう。 これはたぶん、このデータには より良い仮説と言える。 ここでも私は自覚してるが、 何故パラメータを縮める事が、この効果を生むのかを理解するのは ちょっと難しいかもしれない。 だが正規化を自分で 実装すれば、 この効果を直接 見る事が出来るだろう。 正規化された線形回帰では、 正規化のパラメータラムダが とても大きい値にセットされると、 起こる事は、 パラメータのシータ1, シータ2, シータ3, シータ4を とても大きく ペナルティを課す訳だ。 つまり、我らの仮説がこの下にあるような物だとして、 最終的にシータ1, シータ2, シータ3, シータ4にとても重く ペナルティを課すと、 結局、これらのパラメータは全て0に近づく訳です。 シータ1が0に近づき、シータ2が0に近づき、 シータ3とシータ4も 結局は0に近づく。 そうすると、それはまるで 仮説のこれらの項を 取り除いたような物で、 つまり我らはこの残った物だけの仮説を持っているような物で、 その残った物はつまり、 住居の価格は、イコール、 シータ0と等しい、と言っているような物だ。 それは水平な直線をデータに フィッティングしているような物だ。 そしてこれは、アンダーフィッティングの 例でもある。 具体的にはこの仮説では、 この直線で、これでは、 トレーニングセットにうまくフィッティングする事は出来ない。 これは単なる平坦な直線だから。 だからトレーニング手本の大半が近くにあるようなどこかには 行くことが出来ない。 別の言い方をすると、 この仮説は、あまりにも強い 前提を置いている、あるいは あまりにも高いバイアスを置いている、と言える、 住居の価格が単純にシータ0とイコールである、という。 データとは明らかに 矛盾しているにも関わらず。 平坦な直線に フィッティングする事を選んでいる、 水平な直線に。あまりうまく描けなかったが。 こんな水平の、直線を データに。 だから正規化がうまく行く為には、 ある程度の注意が必要だ、 正規化項のラムダを ちょうど良く選んでやる為には。 そしてこのコースの後半で マルチセレクションの話をする時には、 正規化のパラメータラムダを 自動的に選ぶ、 様々な方法も議論する。 さて、以上が高正規化のアイデアと、 そして正規化で用いるコスト関数が どんな物かについてだ。 続く2つのビデオで、 これらのアイデアを用いて 線形回帰とロジスティック回帰に 適用することで、 オーバーフィッティングを 回避してみよう。