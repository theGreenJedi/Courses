1
00:00:00,260 --> 00:00:01,490
線形回帰に関しては

2
00:00:01,680 --> 00:00:03,130
我らは以前、2つの学習アルゴリズムを

3
00:00:03,490 --> 00:00:05,010
扱った。一つは最急降下法に基づくもの、

4
00:00:05,180 --> 00:00:07,650
もう一つは正規方程式(normal equation)に基づく物。

5
00:00:08,750 --> 00:00:09,740
この動画では、これら2つのアルゴリズムを

6
00:00:09,890 --> 00:00:11,640
正規化した線形回帰へと

7
00:00:12,290 --> 00:00:13,380
一般化する。

8
00:00:14,330 --> 00:00:17,640
これが最適化の目的関数で

9
00:00:18,100 --> 00:00:19,540
前回得た正規化した

10
00:00:20,200 --> 00:00:22,380
線形回帰の物だ。

11
00:00:23,360 --> 00:00:24,580
この最初の部分は、いつも通りの

12
00:00:24,980 --> 00:00:27,240
線形回帰の目的関数だ。

13
00:00:28,170 --> 00:00:29,300
そしてそこに、この追加の

14
00:00:30,200 --> 00:00:31,750
正規化項がある。

15
00:00:32,450 --> 00:00:34,960
ここでラムダは正規化パラメータ。

16
00:00:35,220 --> 00:00:36,690
そしてこのコスト関数を最小化するような

17
00:00:37,160 --> 00:00:38,550
パラメータシータを見つけたい。

18
00:00:39,030 --> 00:00:41,280
この正規化されたコスト関数、Jのシータを。

19
00:00:41,840 --> 00:00:43,030
以前に、元のコスト関数に対して

20
00:00:43,440 --> 00:00:45,180
最急降下法を適用した、

21
00:00:46,620 --> 00:00:48,060
正規化項無しのコスト関数に。

22
00:00:48,770 --> 00:00:49,820
そして以下のようなアルゴリズムを

23
00:00:50,060 --> 00:00:51,990
通常の正規化無しの

24
00:00:52,370 --> 00:00:53,620
線形回帰に関しては得た。

25
00:00:54,660 --> 00:00:56,260
繰り返し、以下のように

26
00:00:56,330 --> 00:00:57,670
パラメータのシータjをアップデートしていく、

27
00:00:58,270 --> 00:01:00,030
j=0、1、2、、、とnまで。

28
00:01:00,400 --> 00:01:02,110
これを、シータ0だけを

29
00:01:02,530 --> 00:01:03,960
分けて書くように

30
00:01:04,240 --> 00:01:06,580
直してみよう。

31
00:01:07,210 --> 00:01:08,400
つまり、シータ0の

32
00:01:08,720 --> 00:01:09,900
アップデートルールだけは

33
00:01:10,160 --> 00:01:12,500
別に書く、

34
00:01:12,680 --> 00:01:14,380
パラメータの1、2、3、、、

35
00:01:14,780 --> 00:01:17,090
とnまでについては。

36
00:01:17,370 --> 00:01:19,760
つまりまだ何も変えてない。

37
00:01:19,970 --> 00:01:21,070
ここまでは単に、シータ0に関する

38
00:01:21,300 --> 00:01:23,300
アップデートを、

39
00:01:23,550 --> 00:01:25,240
シータ1、シータ2、シータ3、、、と

40
00:01:25,510 --> 00:01:26,980
シータnまでとを分けて書いただけ。

41
00:01:27,040 --> 00:01:27,900
こうした理由は、

42
00:01:28,230 --> 00:01:29,320
覚えてるかもしれないが、

43
00:01:29,880 --> 00:01:31,260
正規化した線形回帰では

44
00:01:32,620 --> 00:01:33,970
我らはパラメータのシータ1、シータ2、などとシータnまでに

45
00:01:34,440 --> 00:01:35,540
ペナルティを課した。

46
00:01:35,860 --> 00:01:38,360
だがシータ0にはペナルティを課していない。

47
00:01:38,820 --> 00:01:40,250
だから、このアルゴリズムを

48
00:01:40,410 --> 00:01:42,400
正規化した線形回帰へと

49
00:01:42,750 --> 00:01:44,050
修正する時には、

50
00:01:44,710 --> 00:01:46,870
シータ0をちょっとだけ異なる形で扱う事になる。

51
00:01:48,560 --> 00:01:50,360
具体的には、

52
00:01:50,500 --> 00:01:52,170
このアルゴリズムに対して

53
00:01:52,300 --> 00:01:53,780
正規化の目的関数を使うように

54
00:01:53,870 --> 00:01:55,630
修正したい時には

55
00:01:55,740 --> 00:01:57,170
この一番下の項を

56
00:01:57,350 --> 00:02:00,010
以下のように修正すれば良い。

57
00:02:00,460 --> 00:02:01,860
この項に、-ラムダ/m の

58
00:02:02,670 --> 00:02:05,310
シータj を

59
00:02:06,330 --> 00:02:08,920
追加する。

60
00:02:09,100 --> 00:02:10,850
これを実装すると、

61
00:02:11,000 --> 00:02:13,230
正規化されたコスト関数

62
00:02:13,960 --> 00:02:15,920
Jのシータを最小化する

63
00:02:16,160 --> 00:02:18,200
最急降下法が得られる。具体的には

64
00:02:19,520 --> 00:02:20,570
ここで証明の為に

65
00:02:20,680 --> 00:02:22,260
計算する事はしないが、

66
00:02:22,390 --> 00:02:23,480
この項を見ると、

67
00:02:23,690 --> 00:02:26,580
この、ここの大カッコでくくられた所を見ると、

68
00:02:27,730 --> 00:02:28,930
解析学をおさめていたら、

69
00:02:29,380 --> 00:02:31,150
この項はJのシータの

70
00:02:31,370 --> 00:02:33,150
シータjによる偏微分である事が、

71
00:02:33,980 --> 00:02:35,400
正規化の項の入ったJのシータの

72
00:02:35,660 --> 00:02:37,520
偏微分である事が

73
00:02:38,140 --> 00:02:39,330
示せる。

74
00:02:39,510 --> 00:02:42,490
同様に、この上の項は、

75
00:02:42,760 --> 00:02:43,960
これは

76
00:02:44,750 --> 00:02:45,570
青緑の箱で

77
00:02:45,680 --> 00:02:47,240
描いていたと思うが、

78
00:02:48,000 --> 00:02:49,270
これもまた、シータ0による

79
00:02:49,940 --> 00:02:52,700
Jのシータの偏微分である事が分かる。

80
00:02:53,680 --> 00:02:54,900
シータjのアップデートを見ると、

81
00:02:55,600 --> 00:02:56,710
なかなか面白い事が

82
00:02:56,910 --> 00:02:59,190
分かる。つまり

83
00:02:59,860 --> 00:03:01,100
シータjは

84
00:03:01,280 --> 00:03:03,400
シータj マイナスの アルファ掛けることの

85
00:03:04,090 --> 00:03:05,010
このもう一つシータjに依存する項があり、

86
00:03:05,380 --> 00:03:06,730
これでシータj をアップデートする。

87
00:03:06,910 --> 00:03:08,310
だからこの

88
00:03:08,420 --> 00:03:09,410
シータjに依存する項を

89
00:03:10,030 --> 00:03:11,690
一箇所にまとめると、

90
00:03:11,780 --> 00:03:13,190
このアップデートは

91
00:03:13,670 --> 00:03:15,100
以下のように書く事が出来る。

92
00:03:15,200 --> 00:03:16,160
ここで私がやった事は

93
00:03:16,470 --> 00:03:17,620
ここのシータjは

94
00:03:18,310 --> 00:03:20,100
シータj掛ける1と、

95
00:03:20,450 --> 00:03:21,950
そしてこの項は

96
00:03:22,910 --> 00:03:24,830
ラムダ/m  と、ここにアルファがあるから

97
00:03:25,140 --> 00:03:25,990
結局は、

98
00:03:26,180 --> 00:03:27,650
アルファ ラムダ/mとなり、

99
00:03:27,970 --> 00:03:31,450
それにシータjを

100
00:03:31,820 --> 00:03:33,660
掛ける。そしてここでこの

101
00:03:34,230 --> 00:03:36,300
1マイナス アルファ掛けるラムダ/mという項は

102
00:03:36,600 --> 00:03:39,470
なかなか興味深い項だ。これはとても面白い効果を与える。

103
00:03:42,310 --> 00:03:43,710
つまり、この項、

104
00:03:43,890 --> 00:03:45,320
1 引く アルファの ラムダ/m

105
00:03:45,730 --> 00:03:46,780
というのは

106
00:03:46,870 --> 00:03:48,740
通常、1より小さい、、、

107
00:03:48,800 --> 00:03:50,390
1より小さい数となる。

108
00:03:50,610 --> 00:03:51,670
何故なら

109
00:03:51,920 --> 00:03:53,580
アルファ掛けるラムダ/m

110
00:03:54,070 --> 00:03:55,920
は通常正で、普通ラーニングレートは小さい値で、mは大きい。

111
00:03:58,650 --> 00:03:58,860
だから普通は凄く小さい。

112
00:03:59,650 --> 00:04:00,680
だからこのここの項は

113
00:04:00,740 --> 00:04:03,060
普通は1よりもちょっとだけ小さいような数となる。

114
00:04:03,340 --> 00:04:04,150
だから例えばその数は

115
00:04:04,330 --> 00:04:05,860
0.99とかそういう感じの数だと思っておけばよい。

116
00:04:07,380 --> 00:04:08,800
そうすると、シータjの

117
00:04:09,120 --> 00:04:10,550
アップデートに対する影響としては

118
00:04:10,690 --> 00:04:11,950
シータjを、シータj掛ける0.99で

119
00:04:12,410 --> 00:04:15,420
置き換える、と言ってる事になる。

120
00:04:15,770 --> 00:04:17,500
ふむ、シータj掛ける0.99というのは

121
00:04:18,490 --> 00:04:20,940
シータjをちょっとだけ

122
00:04:21,280 --> 00:04:23,560
0の方に向かって縮める効果を与える。

123
00:04:23,670 --> 00:04:25,690
だからこれは、シータjをちょっと小さくする。

124
00:04:26,220 --> 00:04:28,080
よりフォーマルに言うと、

125
00:04:28,420 --> 00:04:29,750
このシータjの二乗が

126
00:04:29,870 --> 00:04:31,580
小さくなる。

127
00:04:31,720 --> 00:04:33,430
そこに、その後ろにある

128
00:04:33,910 --> 00:04:35,400
この二番目の項は、それは

129
00:04:35,980 --> 00:04:37,930
元の最急降下法のアップデートの時と

130
00:04:38,050 --> 00:04:40,270
同じ物だ。

131
00:04:40,750 --> 00:04:42,840
この正規化に関する物を追加する前の。

132
00:04:44,270 --> 00:04:46,920
以上でこの最急降下法は

133
00:04:47,380 --> 00:04:48,630
このアップデートは納得出来たかな。

134
00:04:48,880 --> 00:04:51,350
正規化線形回帰を使う時には

135
00:04:51,550 --> 00:04:52,920
我らがやる事は

136
00:04:53,320 --> 00:04:55,210
各イテレーションごとにシータjに

137
00:04:55,420 --> 00:04:56,310
ちょっとだけ1より小さい数を

138
00:04:56,400 --> 00:04:57,300
掛ける事だ。

139
00:04:57,400 --> 00:04:58,900
つまりパラメータをちょっとだけ

140
00:04:59,230 --> 00:05:00,340
縮める。そしてそこに

141
00:05:00,500 --> 00:05:03,000
以前と似たようなアップデートをかます。

142
00:05:04,170 --> 00:05:05,460
もちろんこれはこの特定のアップデートで

143
00:05:05,610 --> 00:05:08,310
何をしているかの背後にある直感に過ぎない。

144
00:05:08,910 --> 00:05:10,130
数学的には、コスト関数

145
00:05:10,580 --> 00:05:12,950
Jのシータに

146
00:05:13,130 --> 00:05:14,330
まさに最急降下法を実行しているだけだ、

147
00:05:15,150 --> 00:05:16,020
そのコスト関数としては、前回のスライドで定義した

148
00:05:16,480 --> 00:05:18,820
正規化項を用いた物を使うだけで。

149
00:05:19,780 --> 00:05:21,210
最急降下法は

150
00:05:21,470 --> 00:05:23,050
線形回帰のモデルにフィッティングする

151
00:05:24,470 --> 00:05:25,530
2つある方法のうちの、一つに過ぎなかった。

152
00:05:26,630 --> 00:05:28,090
二つめのアルゴリズムとしては

153
00:05:28,160 --> 00:05:29,130
正規方程式にもとづく物があった。

154
00:05:29,680 --> 00:05:31,650
そこでは我らは

155
00:05:31,740 --> 00:05:32,980
デザイン行列Xを構築した、

156
00:05:33,060 --> 00:05:34,770
それは各行が

157
00:05:35,080 --> 00:05:37,830
別個のトレーニング手本を表すような物だった。

158
00:05:38,520 --> 00:05:39,790
そしてベクトルyを構築した、

159
00:05:40,170 --> 00:05:41,780
これはm次元の

160
00:05:41,940 --> 00:05:43,320
ベクトルで、

161
00:05:43,590 --> 00:05:45,520
そしてその中身は

162
00:05:46,010 --> 00:05:47,750
トレーニングセットのラベルだった。

163
00:05:48,470 --> 00:05:49,600
つまり一方でXは

164
00:05:49,830 --> 00:05:52,660
m掛けるn+1 次元行列で、

165
00:05:53,590 --> 00:05:55,220
yはm次元ベクトルだ。

166
00:05:55,780 --> 00:05:57,550
そしてコスト関数を

167
00:05:58,030 --> 00:05:59,200
最小化する為に、

168
00:05:59,470 --> 00:06:00,940
我らの見つけた

169
00:06:01,470 --> 00:06:03,000
方法とは、

170
00:06:03,230 --> 00:06:04,440
シータに

171
00:06:04,670 --> 00:06:06,790
イコール、これと置く。

172
00:06:07,540 --> 00:06:09,040
X転置 Xの逆行列に、

173
00:06:10,860 --> 00:06:12,770
X転置に、 y。

174
00:06:13,020 --> 00:06:13,920
ここは後の為に空けておく。

175
00:06:14,120 --> 00:06:17,160
するとこのシータの値は、

176
00:06:17,650 --> 00:06:18,820
コスト関数

177
00:06:19,180 --> 00:06:20,980
Jのシータを

178
00:06:21,250 --> 00:06:22,710
最小化する、

179
00:06:22,840 --> 00:06:26,280
正規化をしていない時には。

180
00:06:26,460 --> 00:06:28,580
今回は正規化を使うのだから、

181
00:06:28,780 --> 00:06:30,290
もし最小を導出したら、

182
00:06:30,520 --> 00:06:31,820
ここでどんな感じで

183
00:06:31,910 --> 00:06:32,760
最小を導出するのか、

184
00:06:32,980 --> 00:06:34,110
軽く触れておくと、

185
00:06:34,220 --> 00:06:35,220
それを導出する方法は、

186
00:06:35,930 --> 00:06:37,910
各パラメータごとによる

187
00:06:38,340 --> 00:06:40,600
偏微分をとって、

188
00:06:40,830 --> 00:06:41,910
これをイコール0とセットする。

189
00:06:42,060 --> 00:06:42,920
そしてたくさん計算すると、

190
00:06:43,100 --> 00:06:45,060
こんな感じの式が得られて、

191
00:06:45,550 --> 00:06:47,640
それがコスト関数を最小化する物となる。

192
00:06:48,590 --> 00:06:52,130
ちゃんと書くと、

193
00:06:52,240 --> 00:06:54,080
正規化をしている場合には、

194
00:06:54,250 --> 00:06:56,320
この式はこう変わる。

195
00:06:56,480 --> 00:06:59,120
このカッコの中に、こんな行列が入る。

196
00:06:59,460 --> 00:07:00,940
0, 1, 1, 1, 1...

197
00:07:01,800 --> 00:07:03,520
と、一番下まで1。

198
00:07:04,510 --> 00:07:05,510
つまりここにあるこれは、

199
00:07:05,630 --> 00:07:07,810
一番左上が0で、その0以外の

200
00:07:08,560 --> 00:07:10,080
対角成分は全て1が入るような

201
00:07:10,190 --> 00:07:11,960
行列となる。

202
00:07:13,050 --> 00:07:14,020
これは手抜きで描いてしまったが、

203
00:07:15,180 --> 00:07:16,790
具体的に例えば、

204
00:07:17,060 --> 00:07:18,210
もしn=2なら、

205
00:07:19,090 --> 00:07:21,110
この行列は

206
00:07:21,840 --> 00:07:23,500
3掛ける3 行列となる。

207
00:07:24,300 --> 00:07:26,210
より一般的には、この行列は

208
00:07:26,360 --> 00:07:27,660
n+1掛けるn+1 次元の

209
00:07:28,270 --> 00:07:30,290
行列となる。

210
00:07:31,620 --> 00:07:33,150
だからn=2の時は

211
00:07:33,370 --> 00:07:35,410
こんな感じの行列となる。

212
00:07:35,980 --> 00:07:37,360
最初に0、そしてそれ以降の対角成分は

213
00:07:37,640 --> 00:07:39,020
1で、非対角成分は

214
00:07:39,160 --> 00:07:41,100
全て0という行列。

215
00:07:42,390 --> 00:07:43,990
もう一度言うとここで導出はするつもりは無い、

216
00:07:44,620 --> 00:07:46,280
それは割と長くてかったるいし、しかも結構難しいから。

217
00:07:46,620 --> 00:07:47,530
でもこの新しい定義の

218
00:07:47,970 --> 00:07:49,550
Jのシータ、

219
00:07:49,940 --> 00:07:50,770
正規化の目的関数を

220
00:07:51,250 --> 00:07:53,730
使うと、以下の事が証明出来る。

221
00:07:54,780 --> 00:07:56,070
それは、この新しい

222
00:07:56,220 --> 00:07:57,180
シータの式がJのシータの

223
00:07:57,390 --> 00:08:00,080
グローバル最小を与える物となる、という事。

224
00:08:01,420 --> 00:08:02,460
最後に、非可逆の問題について

225
00:08:02,610 --> 00:08:05,460
簡単に触れておく。

226
00:08:06,800 --> 00:08:08,110
これは本当にアドバンスドな内容だ。

227
00:08:08,600 --> 00:08:09,530
だからこれはおまけと思ってもらって、

228
00:08:09,770 --> 00:08:11,600
ご自由にスキップしてもらって構わないし、

229
00:08:11,750 --> 00:08:12,520
もし聞いてみて

230
00:08:12,660 --> 00:08:14,180
いまいち良く分からんなぁ、と

231
00:08:14,320 --> 00:08:15,680
思ったとしても、あんま気にしないでいいです。

232
00:08:16,400 --> 00:08:18,950
さて、以前正規方程式法について触れた時、

233
00:08:19,700 --> 00:08:20,920
非可逆の問題についてのおまけのビデオが

234
00:08:21,800 --> 00:08:22,960
あった。

235
00:08:23,700 --> 00:08:25,740
つまりこれもまたおまけとなるのだが、

236
00:08:26,170 --> 00:08:27,070
これは以前のおまけの非可逆性のビデオの

237
00:08:27,700 --> 00:08:30,100
追加となる話だ。

238
00:08:31,610 --> 00:08:33,350
いま、m、つまりトレーニング手本の

239
00:08:33,850 --> 00:08:35,340
総数が、n以下の場合、

240
00:08:35,690 --> 00:08:37,530
ここでnはフィーチャーの総数だが、そういう状況を考えてみよう。

241
00:08:38,650 --> 00:08:40,080
もしフィーチャーよりも少ない手本しか

242
00:08:40,200 --> 00:08:41,480
持っていなければ、この行列、

243
00:08:42,170 --> 00:08:43,870
X転置 Xは

244
00:08:44,070 --> 00:08:47,770
非可逆あるいは特異行列、

245
00:08:48,060 --> 00:08:50,120
あるいは別の用語を使えば

246
00:08:50,360 --> 00:08:51,470
縮退した行列

247
00:08:51,530 --> 00:08:53,390
となる。

248
00:08:53,860 --> 00:08:54,780
そしてこれをOctaveでとりあえず実装したいなら、

249
00:08:55,300 --> 00:08:56,380
pinv関数を使って、これは

250
00:08:56,620 --> 00:08:58,570
pseudo inverseの略だが、これを使って擬似逆行列を取れば、

251
00:08:58,850 --> 00:08:59,800
それはよきにはからってくれるが、

252
00:09:00,080 --> 00:09:01,900
それが良い仮説を

253
00:09:02,240 --> 00:09:03,450
与えてくれるかは

254
00:09:03,560 --> 00:09:04,570
あまり良く分からない、

255
00:09:05,410 --> 00:09:07,720
数値計算的には、Octaveの

256
00:09:08,370 --> 00:09:09,670
pinv関数は、

257
00:09:10,020 --> 00:09:11,050
ある程度意味をなした答えを

258
00:09:11,340 --> 00:09:13,210
返してはくれるのだけれども。

259
00:09:13,440 --> 00:09:15,460
だが、もしこれを別の言語でやっていて、

260
00:09:16,270 --> 00:09:17,590
しかも通常の

261
00:09:17,710 --> 00:09:19,030
逆行列をとっていたら、それはOctaveでは

262
00:09:20,470 --> 00:09:22,070
invという関数で表されている物だが、

263
00:09:23,240 --> 00:09:24,010
通常の逆行列を

264
00:09:24,330 --> 00:09:25,620
X転置 Xについて取ろうとすると、

265
00:09:26,300 --> 00:09:28,030
この状況では、

266
00:09:28,150 --> 00:09:30,340
X転置 Xが特異行列で

267
00:09:30,450 --> 00:09:32,750
非可逆である事が判明し、

268
00:09:32,790 --> 00:09:33,740
もし別のプログラミング言語で

269
00:09:33,990 --> 00:09:35,830
何らかの線形代数ライブラリを使って

270
00:09:36,230 --> 00:09:39,160
行列の逆行列を計算したら、

271
00:09:39,840 --> 00:09:41,080
それはうまく行かないかもしれない。

272
00:09:41,220 --> 00:09:43,060
何故ならこの行列は非可逆、特異なのだから。

273
00:09:44,650 --> 00:09:47,110
幸運にも、正規化はまた

274
00:09:47,110 --> 00:09:49,850
この件もうまく対応してくれる。具体的には、

275
00:09:50,010 --> 00:09:53,370
正規化パラメータが0より大きい（イコールを含まない）場合は、

276
00:09:53,870 --> 00:09:55,220
実際に行列 X転置 X に

277
00:09:55,300 --> 00:09:56,840
足す事の、

278
00:09:57,080 --> 00:09:58,690
パラメータのラムダ掛けることの

279
00:09:59,080 --> 00:10:00,400
このへんてこな行列は、

280
00:10:00,970 --> 00:10:02,250
この行列は

281
00:10:02,470 --> 00:10:03,650
特異行列にはならず、逆行列が計算出来る、

282
00:10:03,760 --> 00:10:05,710
という事が証明出来る。

283
00:10:07,450 --> 00:10:09,430
つまり正規化を用いる事で、

284
00:10:09,700 --> 00:10:11,910
X転置 X 行列が非可逆問題にも

285
00:10:12,580 --> 00:10:14,470
対応した事になる。

286
00:10:15,260 --> 00:10:18,000
つまり、いまやあなたは正規化した線形回帰の実装方法を知った訳だが、

287
00:10:18,870 --> 00:10:19,910
これを用いる事で、オーバーフィッティングを

288
00:10:20,300 --> 00:10:21,970
避ける事が出来る、たとえ

289
00:10:22,210 --> 00:10:24,720
たくさんのフィーチャーがあって、相対的に小さなトレーニングセットしか無かったとしても。

290
00:10:25,360 --> 00:10:26,630
そしてこれは、線形回帰を

291
00:10:26,980 --> 00:10:29,000
もっとたくさんの問題に適用する事が出来る。

292
00:10:30,060 --> 00:10:31,190
次のビデオでは、この正規化のアイデアを

293
00:10:31,390 --> 00:10:34,310
ロジスティック回帰にも適用してみる。

294
00:10:35,140 --> 00:10:36,170
そうする事で、ロジスティック回帰でも

295
00:10:36,280 --> 00:10:37,630
オーバーフィットの問題を回避する事が出来、

296
00:10:37,920 --> 00:10:39,830
またよりうまく実行する事も出来るようになるだろう。