到现在为止 你已经见识了 几种不同的学习算法 包括线性回归和逻辑回归 它们能够有效地解决许多问题 但是当将它们应用到 某些特定的机器学习应用时 会遇到过度拟合(over-fitting)的问题 可能会导致它们效果很差 在这段视频中 我将为你解释 什么是过度拟合问题 并且 在此之后接下来的几个视频中 我们将谈论一种 称为正则化(regularization)的技术 它可以改善或者 减少过度拟合问题 以使学习算法更好实现 那么什么是过度拟合呢？ 让我们继续使用 那个用线性回归 来预测房价的例子 我们通过建立 以住房面积为自变量的函数来预测房价 我们可以 对该数据做线性回归 如果这么做 我们也许能够获得 拟合数据的这样一条直线 但是 这不是一个很好的模型 我们看看这些数据 很明显 随着房子面积增大 住房价格的变化趋于稳定 或者越往右越平缓 因此该算法 没有很好拟合训练数据 我们把这个问题称为欠拟合(underfitting) 这个问题的另一个术语叫做 高偏差(bias) 这两种说法大致相似 意思是它只是没有很好地拟合训练数据 这个词是 过去传下来的一个专业名词 它的意思是 如果拟合一条直线 到训练数据 就好像算法 有一个很强的偏见 或者说非常大的偏差 因为该算法认为房子价格与面积仅仅线性相关 尽管与该数据的事实相反 尽管相反的证据 被事前定义为 偏差 它还是接近于 拟合一条直线 而此法最终导致拟合数据效果很差 我们现在可以在中间 加入一个二次项 在这组数据中 我们用二次函数来拟合它 然后可以拟合出一条曲线 事实证明这个拟合效果很好 另一个极端情况是 如果我们拟合一个四次多项式 因此在这里我们有五个参数 θ0到θ4 这样我们可以拟合一条曲线 通过我们的五个训练样本 你可以得到看上去如此的一条曲线 一方面 似乎 对训练数据 做了一个很好的拟合 因为这条曲线通过了所有的训练实例 但是 这仍然是一条扭曲的曲线 对吧？ 它不停上下波动 因此事实上 我们并不认为它是一个预测房价的好模型 所以 这个问题我们把他叫做 过度拟合或过拟合(overfitting) 另一个描述该问题的术语是 高方差(variance) 高方差是另一个 历史上的叫法 但是 从第一印象上来说 如果我们拟合一个 高阶多项式 那么 这个函数能很好的拟合训练集 能拟合几乎所有的 训练数据 这就面临可能函数太过庞大的问题 变量太多 同时如果我们没有足够的数据 去约束这个变量过多的模型 那么这就是过度拟合 在两者之间的情况 叫"刚好合适" 这并不是一个真正的名词 我只是把它写在这里 这个二次多项式 二次函数 可以说是恰好拟合这些数据 概括地说 过度拟合的问题 将会在变量过多的时候 发生 这种时候训练出的方程总能很好的拟合训练数据 所以 你的代价函数 实际上可能非常接近于0 或者 就是0 但是 这样的曲线 它千方百计的拟合于训练数据 这样导致 它无法泛化到 新的数据样本中 以至于无法预测新样本价格 在这里 术语"泛化" 指的是一个假设模型能够应用到新样本的能力 新样本数据是 没有出现在训练集中的房子 在这张幻灯片上 我们看到了 线性回归情况下的过拟合 类似的方法同样可以应用到逻辑回归 这里是一个以x1与x2为变量的 逻辑回归 我们可以做的就是 用这样一个简单的假设模型 来拟合逻辑回归 和以前一样 字母g代表S型函数 如果这样做 你会得到一个假设模型 这个假设模型是一条直线 它直接分开了正样本和负样本 但这个模型并不能够很好的拟合数据 因此 这又是一个欠拟合的例子 或者说假设模型具有高偏差 相比之下 如果 如果再加入一些变量 比如这些二次项 那么你可以得到一个判定边界 像这样 这样就很好的拟合了数据 这很可能 是训练集的最好拟合结果 最后 在另一种极端情况下 如果你用高阶多项式来拟合数据 你加入了很多 高阶项 那么逻辑回归可能发生自身扭曲 它千方百计的 形成这样一个 判定边界 来拟合你的训练数据 以至于成为一条扭曲的曲线 使其能够拟合每一个训练集中的样本 而且 如果x1和x2 能够预测 癌症 你知道 癌症是一种恶性肿瘤 同时肿瘤也可能是良性 确实 这个假设模型不是一个很好的预测 因此 这又是一个过拟合例子 是一个 有高方差的假设模型 并且不能够很好泛化到新样本 在今后课程中 我们会讲到调试和诊断 诊断出导致学习算法故障的东西 我们告诉你如何用 专门的工具来识别 过拟合 和可能发生的欠拟合 但是 现在 让我们谈谈 过拟合 的问题 我们怎么样解决呢 在前面的例子中 当我们使用一维或二维数据时 我们可以通过绘出假设模型的图像来研究问题所在 再选择合适的多项式来拟合数据 因此 以之前的房屋价格为例 我们可以 绘制假设模型的图像 就能看到 模型的曲线 非常扭曲并通过所有样本房价 我们可以通过绘制这样的图形 来选择合适的多项式阶次 因此绘制假设模型曲线 可以作为决定多项式阶次 的一种方法 但是这并不是总是有用的 而且事实上更多的时候我们 会遇到有很多变量的假设模型 并且 这不仅仅是选择多项式阶次的问题 事实上 当我们 有这么多的特征变量 这也使得绘图变得更难 并且 更难使其可视化 因此并不能通过这种方法决定保留哪些特征变量 具体地说 如果我们试图 预测房价 同时又拥有这么多特征变量 这些变量看上去都很有用 但是 如果我们有 过多的变量 同时 只有非常少的训练数据 就会出现过度拟合的问题 为了解决过度拟合 有两个办法 来解决问题 第一个办法是要尽量 减少选取变量的数量 具体而言 我们可以人工检查 变量的条目 并以此决定哪些变量更为重要 然后 决定保留哪些特征变量 哪些应该舍弃 在今后的课程中 我们会提到模型选择算法 这种算法是为了自动选择 采用哪些特征变量 自动舍弃不需要的变量 这种减少特征变量 的做法是非常有效的 并且可以减少过拟合的发生 当我们今后讲到模型选择时 我们将深入探讨这个问题 但是其缺点是 舍弃一部分特征变量 你也舍弃了 问题中的一些信息 例如 也许所有的 特征变量 对于预测房价都是有用的 我们实际上并不想 舍弃一些信息 或者舍弃这些特征变量 第二个选择 我们将在接下来的视频中讨论 就是正则化 正则化中我们将保留 所有的特征变量 但是数量级 或参数数值的大小 θ(j) 这个方法非常有效 当我们有很多特征变量时 其中每一个变量 都能对预测产生一点影响 y的值 正如我们在房价的例子中看到的那样 在那里我们可以有很多特征变量 其中每一个变量 都是有用的 因此我们不希望把它们删掉 这就导致了 正则化概念的发生 我知道 这些东西你们现在可能还听不懂 但是在接下来的视频中 我们将开始详细讲述 怎样应用正则化和什么叫做正则化均值 然后我们将开始 讲解怎样使用正则化 怎样使学习算法正常工作 并避免过拟合 【教育无边界字幕组】翻译:牛仔仔 校对:御姐sama 审核:所罗门捷列夫