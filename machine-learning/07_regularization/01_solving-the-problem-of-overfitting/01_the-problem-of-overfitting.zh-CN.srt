1
00:00:00,360 --> 00:00:01,753
到现在为止 你已经见识了

2
00:00:01,760 --> 00:00:04,097
几种不同的学习算法

3
00:00:04,097 --> 00:00:06,504
包括线性回归和逻辑回归

4
00:00:06,510 --> 00:00:08,583
它们能够有效地解决许多问题

5
00:00:08,583 --> 00:00:09,684
但是当将它们应用到

6
00:00:09,684 --> 00:00:11,903
某些特定的机器学习应用时

7
00:00:11,903 --> 00:00:13,889
会遇到过度拟合(over-fitting)的问题

8
00:00:13,900 --> 00:00:18,052
可能会导致它们效果很差

9
00:00:18,052 --> 00:00:18,866
在这段视频中

10
00:00:18,866 --> 00:00:20,393
我将为你解释

11
00:00:20,393 --> 00:00:22,400
什么是过度拟合问题

12
00:00:22,400 --> 00:00:24,083
并且

13
00:00:24,083 --> 00:00:25,861
在此之后接下来的几个视频中

14
00:00:25,861 --> 00:00:27,759
我们将谈论一种

15
00:00:27,760 --> 00:00:29,787
称为正则化(regularization)的技术

16
00:00:29,787 --> 00:00:31,529
它可以改善或者

17
00:00:31,529 --> 00:00:33,607
减少过度拟合问题

18
00:00:33,607 --> 00:00:36,844
以使学习算法更好实现

19
00:00:36,860 --> 00:00:39,607
那么什么是过度拟合呢？

20
00:00:39,607 --> 00:00:41,616
让我们继续使用

21
00:00:41,620 --> 00:00:44,030
那个用线性回归

22
00:00:44,050 --> 00:00:46,146
来预测房价的例子

23
00:00:46,146 --> 00:00:47,123
我们通过建立

24
00:00:47,123 --> 00:00:50,730
以住房面积为自变量的函数来预测房价

25
00:00:50,730 --> 00:00:51,870
我们可以

26
00:00:51,910 --> 00:00:53,620
对该数据做线性回归

27
00:00:53,620 --> 00:00:54,892
如果这么做

28
00:00:54,892 --> 00:00:56,296
我们也许能够获得

29
00:00:56,296 --> 00:00:58,913
拟合数据的这样一条直线

30
00:00:58,913 --> 00:01:01,012
但是 这不是一个很好的模型

31
00:01:01,012 --> 00:01:02,543
我们看看这些数据

32
00:01:02,560 --> 00:01:04,100
很明显

33
00:01:04,100 --> 00:01:06,274
随着房子面积增大

34
00:01:06,274 --> 00:01:08,268
住房价格的变化趋于稳定

35
00:01:08,270 --> 00:01:11,721
或者越往右越平缓

36
00:01:11,740 --> 00:01:14,020
因此该算法

37
00:01:14,020 --> 00:01:15,898
没有很好拟合训练数据

38
00:01:15,898 --> 00:01:19,166
我们把这个问题称为欠拟合(underfitting)

39
00:01:19,180 --> 00:01:20,494
这个问题的另一个术语叫做

40
00:01:20,500 --> 00:01:24,666
高偏差(bias)

41
00:01:25,140 --> 00:01:26,841
这两种说法大致相似

42
00:01:26,890 --> 00:01:30,760
意思是它只是没有很好地拟合训练数据

43
00:01:30,760 --> 00:01:32,328
这个词是

44
00:01:32,328 --> 00:01:34,515
过去传下来的一个专业名词

45
00:01:34,515 --> 00:01:36,109
它的意思是

46
00:01:36,110 --> 00:01:37,303
如果拟合一条直线

47
00:01:37,303 --> 00:01:38,909
到训练数据

48
00:01:38,920 --> 00:01:40,290
就好像算法

49
00:01:40,330 --> 00:01:42,638
有一个很强的偏见

50
00:01:42,638 --> 00:01:44,633
或者说非常大的偏差

51
00:01:44,650 --> 00:01:46,339
因为该算法认为房子价格与面积仅仅线性相关

52
00:01:46,339 --> 00:01:49,988
尽管与该数据的事实相反

53
00:01:50,000 --> 00:01:51,281
尽管相反的证据

54
00:01:51,290 --> 00:01:54,174
被事前定义为

55
00:01:54,174 --> 00:01:55,413
偏差 它还是接近于

56
00:01:55,440 --> 00:01:56,974
拟合一条直线

57
00:01:56,974 --> 00:02:00,638
而此法最终导致拟合数据效果很差

58
00:02:00,638 --> 00:02:02,173
我们现在可以在中间

59
00:02:02,210 --> 00:02:04,626
加入一个二次项

60
00:02:04,626 --> 00:02:06,222
在这组数据中

61
00:02:06,222 --> 00:02:07,793
我们用二次函数来拟合它

62
00:02:07,810 --> 00:02:10,211
然后可以拟合出一条曲线

63
00:02:10,211 --> 00:02:14,361
事实证明这个拟合效果很好

64
00:02:14,361 --> 00:02:17,543
另一个极端情况是 如果我们拟合一个四次多项式

65
00:02:17,550 --> 00:02:19,442
因此在这里我们有五个参数

66
00:02:19,470 --> 00:02:23,196
θ0到θ4

67
00:02:23,210 --> 00:02:23,926
这样我们可以拟合一条曲线

68
00:02:23,926 --> 00:02:26,727
通过我们的五个训练样本

69
00:02:26,727 --> 00:02:29,507
你可以得到看上去如此的一条曲线

70
00:02:31,260 --> 00:02:32,454
一方面

71
00:02:32,460 --> 00:02:33,791
似乎

72
00:02:33,791 --> 00:02:35,052
对训练数据

73
00:02:35,052 --> 00:02:36,291
做了一个很好的拟合

74
00:02:36,291 --> 00:02:38,269
因为这条曲线通过了所有的训练实例

75
00:02:38,270 --> 00:02:40,284
但是 这仍然是一条扭曲的曲线 对吧？

76
00:02:40,300 --> 00:02:41,660
它不停上下波动

77
00:02:41,660 --> 00:02:43,430
因此事实上

78
00:02:43,430 --> 00:02:46,996
我们并不认为它是一个预测房价的好模型

79
00:02:47,000 --> 00:02:48,924
所以 这个问题我们把他叫做

80
00:02:48,924 --> 00:02:51,967
过度拟合或过拟合(overfitting)

81
00:02:51,970 --> 00:02:53,165
另一个描述该问题的术语是

82
00:02:53,170 --> 00:02:57,304
高方差(variance)

83
00:02:57,890 --> 00:02:59,951
高方差是另一个

84
00:02:59,951 --> 00:03:02,110
历史上的叫法

85
00:03:02,130 --> 00:03:03,797
但是 从第一印象上来说

86
00:03:03,800 --> 00:03:05,080
如果我们拟合一个

87
00:03:05,080 --> 00:03:07,326
高阶多项式 那么

88
00:03:07,330 --> 00:03:08,603
这个函数能很好的拟合训练集

89
00:03:08,620 --> 00:03:09,584
能拟合几乎所有的

90
00:03:09,584 --> 00:03:11,995
训练数据

91
00:03:11,995 --> 00:03:14,159
这就面临可能函数太过庞大的问题

92
00:03:14,159 --> 00:03:16,601
变量太多

93
00:03:16,610 --> 00:03:18,052
同时如果我们没有足够的数据

94
00:03:18,052 --> 00:03:19,279
去约束这个变量过多的模型

95
00:03:19,279 --> 00:03:22,714
那么这就是过度拟合

96
00:03:22,740 --> 00:03:24,340
在两者之间的情况 叫"刚好合适"

97
00:03:24,350 --> 00:03:26,990
这并不是一个真正的名词 我只是把它写在这里

98
00:03:26,990 --> 00:03:29,911
这个二次多项式 二次函数

99
00:03:29,911 --> 00:03:32,559
可以说是恰好拟合这些数据

100
00:03:32,559 --> 00:03:34,684
概括地说

101
00:03:34,690 --> 00:03:37,042
过度拟合的问题

102
00:03:37,042 --> 00:03:38,258
将会在变量过多的时候

103
00:03:38,258 --> 00:03:40,729
发生

104
00:03:40,729 --> 00:03:43,881
这种时候训练出的方程总能很好的拟合训练数据

105
00:03:43,881 --> 00:03:46,023
所以 你的代价函数

106
00:03:46,023 --> 00:03:47,344
实际上可能非常接近于0

107
00:03:47,344 --> 00:03:48,446
或者

108
00:03:48,446 --> 00:03:50,750
就是0

109
00:03:50,750 --> 00:03:52,063
但是

110
00:03:52,063 --> 00:03:53,950
这样的曲线

111
00:03:53,950 --> 00:03:55,314
它千方百计的拟合于训练数据

112
00:03:55,314 --> 00:03:57,103
这样导致

113
00:03:57,110 --> 00:03:59,233
它无法泛化到

114
00:03:59,250 --> 00:04:01,117
新的数据样本中

115
00:04:01,120 --> 00:04:03,018
以至于无法预测新样本价格

116
00:04:03,050 --> 00:04:04,337
在这里

117
00:04:04,350 --> 00:04:06,853
术语"泛化"

118
00:04:06,853 --> 00:04:10,868
指的是一个假设模型能够应用到新样本的能力

119
00:04:10,868 --> 00:04:12,274
新样本数据是

120
00:04:12,320 --> 00:04:16,467
没有出现在训练集中的房子

121
00:04:16,600 --> 00:04:17,910
在这张幻灯片上 我们看到了

122
00:04:17,910 --> 00:04:20,802
线性回归情况下的过拟合

123
00:04:20,810 --> 00:04:24,182
类似的方法同样可以应用到逻辑回归

124
00:04:24,190 --> 00:04:26,090
这里是一个以x1与x2为变量的

125
00:04:26,090 --> 00:04:28,871
逻辑回归

126
00:04:28,910 --> 00:04:30,136
我们可以做的就是

127
00:04:30,140 --> 00:04:31,522
用这样一个简单的假设模型

128
00:04:31,522 --> 00:04:34,518
来拟合逻辑回归

129
00:04:34,530 --> 00:04:38,076
和以前一样 字母g代表S型函数

130
00:04:38,120 --> 00:04:39,334
如果这样做

131
00:04:39,334 --> 00:04:41,593
你会得到一个假设模型

132
00:04:41,600 --> 00:04:42,923
这个假设模型是一条直线

133
00:04:42,923 --> 00:04:45,713
它直接分开了正样本和负样本

134
00:04:45,713 --> 00:04:49,071
但这个模型并不能够很好的拟合数据

135
00:04:49,100 --> 00:04:50,659
因此

136
00:04:50,659 --> 00:04:52,577
这又是一个欠拟合的例子

137
00:04:52,577 --> 00:04:56,040
或者说假设模型具有高偏差

138
00:04:56,210 --> 00:04:57,504
相比之下 如果

139
00:04:57,504 --> 00:04:59,146
如果再加入一些变量

140
00:04:59,170 --> 00:05:01,032
比如这些二次项

141
00:05:01,032 --> 00:05:02,613
那么你可以得到一个判定边界

142
00:05:02,613 --> 00:05:05,620
像这样

143
00:05:05,620 --> 00:05:07,784
这样就很好的拟合了数据

144
00:05:07,784 --> 00:05:10,838
这很可能

145
00:05:10,860 --> 00:05:13,991
是训练集的最好拟合结果

146
00:05:14,010 --> 00:05:15,157
最后

147
00:05:15,170 --> 00:05:16,169
在另一种极端情况下

148
00:05:16,169 --> 00:05:18,207
如果你用高阶多项式来拟合数据

149
00:05:18,207 --> 00:05:20,036
你加入了很多

150
00:05:20,036 --> 00:05:22,461
高阶项

151
00:05:22,490 --> 00:05:24,730
那么逻辑回归可能发生自身扭曲

152
00:05:24,750 --> 00:05:26,551
它千方百计的

153
00:05:26,560 --> 00:05:28,233
形成这样一个

154
00:05:28,233 --> 00:05:31,742
判定边界

155
00:05:31,742 --> 00:05:33,013
来拟合你的训练数据

156
00:05:33,030 --> 00:05:35,006
以至于成为一条扭曲的曲线

157
00:05:35,006 --> 00:05:37,689
使其能够拟合每一个训练集中的样本

158
00:05:37,700 --> 00:05:38,757
而且

159
00:05:38,757 --> 00:05:39,547
如果x1和x2

160
00:05:39,550 --> 00:05:41,435
能够预测

161
00:05:41,435 --> 00:05:43,350
癌症

162
00:05:43,390 --> 00:05:46,448
你知道 癌症是一种恶性肿瘤 同时肿瘤也可能是良性

163
00:05:46,448 --> 00:05:47,988
确实

164
00:05:47,988 --> 00:05:51,893
这个假设模型不是一个很好的预测

165
00:05:51,930 --> 00:05:53,463
因此

166
00:05:53,463 --> 00:05:55,432
这又是一个过拟合例子

167
00:05:55,432 --> 00:05:57,128
是一个

168
00:05:57,128 --> 00:05:59,403
有高方差的假设模型

169
00:05:59,403 --> 00:06:04,243
并且不能够很好泛化到新样本

170
00:06:04,560 --> 00:06:06,158
在今后课程中

171
00:06:06,158 --> 00:06:08,453
我们会讲到调试和诊断

172
00:06:08,460 --> 00:06:09,794
诊断出导致学习算法故障的东西

173
00:06:09,810 --> 00:06:11,490
我们告诉你如何用

174
00:06:11,490 --> 00:06:13,297
专门的工具来识别

175
00:06:13,297 --> 00:06:14,953
过拟合

176
00:06:14,953 --> 00:06:17,503
和可能发生的欠拟合

177
00:06:17,503 --> 00:06:18,775
但是 现在 让我们谈谈

178
00:06:18,780 --> 00:06:20,342
过拟合

179
00:06:20,360 --> 00:06:22,206
的问题

180
00:06:22,250 --> 00:06:24,864
我们怎么样解决呢

181
00:06:24,864 --> 00:06:26,640
在前面的例子中

182
00:06:26,660 --> 00:06:28,701
当我们使用一维或二维数据时

183
00:06:28,701 --> 00:06:31,335
我们可以通过绘出假设模型的图像来研究问题所在

184
00:06:31,335 --> 00:06:34,612
再选择合适的多项式来拟合数据

185
00:06:34,620 --> 00:06:36,836
因此 以之前的房屋价格为例

186
00:06:36,836 --> 00:06:38,405
我们可以

187
00:06:38,410 --> 00:06:40,597
绘制假设模型的图像

188
00:06:40,600 --> 00:06:41,628
就能看到

189
00:06:41,628 --> 00:06:42,830
模型的曲线

190
00:06:42,830 --> 00:06:46,339
非常扭曲并通过所有样本房价

191
00:06:46,339 --> 00:06:47,701
我们可以通过绘制这样的图形

192
00:06:47,740 --> 00:06:50,667
来选择合适的多项式阶次

193
00:06:50,680 --> 00:06:54,166
因此绘制假设模型曲线

194
00:06:54,166 --> 00:06:55,728
可以作为决定多项式阶次

195
00:06:55,750 --> 00:06:58,160
的一种方法

196
00:06:58,160 --> 00:07:00,163
但是这并不是总是有用的

197
00:07:00,180 --> 00:07:02,019
而且事实上更多的时候我们

198
00:07:02,019 --> 00:07:06,075
会遇到有很多变量的假设模型

199
00:07:06,075 --> 00:07:07,563
并且

200
00:07:07,563 --> 00:07:10,599
这不仅仅是选择多项式阶次的问题

201
00:07:10,630 --> 00:07:12,147
事实上 当我们

202
00:07:12,170 --> 00:07:13,779
有这么多的特征变量

203
00:07:13,779 --> 00:07:15,593
这也使得绘图变得更难

204
00:07:15,630 --> 00:07:17,698
并且

205
00:07:17,710 --> 00:07:19,211
更难使其可视化

206
00:07:19,211 --> 00:07:22,396
因此并不能通过这种方法决定保留哪些特征变量

207
00:07:22,420 --> 00:07:24,142
具体地说 如果我们试图

208
00:07:24,160 --> 00:07:27,849
预测房价 同时又拥有这么多特征变量

209
00:07:27,880 --> 00:07:31,373
这些变量看上去都很有用

210
00:07:31,373 --> 00:07:32,609
但是 如果我们有

211
00:07:32,609 --> 00:07:34,123
过多的变量 同时

212
00:07:34,123 --> 00:07:35,820
只有非常少的训练数据

213
00:07:35,840 --> 00:07:37,776
就会出现过度拟合的问题

214
00:07:37,776 --> 00:07:39,180
为了解决过度拟合

215
00:07:39,180 --> 00:07:40,651
有两个办法

216
00:07:40,651 --> 00:07:43,780
来解决问题

217
00:07:43,780 --> 00:07:45,759
第一个办法是要尽量

218
00:07:45,770 --> 00:07:47,976
减少选取变量的数量

219
00:07:47,990 --> 00:07:49,337
具体而言

220
00:07:49,337 --> 00:07:51,383
我们可以人工检查

221
00:07:51,383 --> 00:07:53,236
变量的条目

222
00:07:53,236 --> 00:07:54,894
并以此决定哪些变量更为重要

223
00:07:54,894 --> 00:07:57,256
然后

224
00:07:57,256 --> 00:07:58,476
决定保留哪些特征变量

225
00:07:58,476 --> 00:08:01,844
哪些应该舍弃

226
00:08:01,844 --> 00:08:03,401
在今后的课程中

227
00:08:03,401 --> 00:08:06,018
我们会提到模型选择算法

228
00:08:06,040 --> 00:08:08,361
这种算法是为了自动选择

229
00:08:08,361 --> 00:08:09,788
采用哪些特征变量

230
00:08:09,800 --> 00:08:12,500
自动舍弃不需要的变量

231
00:08:12,500 --> 00:08:13,987
这种减少特征变量

232
00:08:13,987 --> 00:08:15,562
的做法是非常有效的

233
00:08:15,562 --> 00:08:17,853
并且可以减少过拟合的发生

234
00:08:17,853 --> 00:08:19,383
当我们今后讲到模型选择时

235
00:08:19,383 --> 00:08:22,534
我们将深入探讨这个问题

236
00:08:22,534 --> 00:08:24,386
但是其缺点是

237
00:08:24,386 --> 00:08:25,603
舍弃一部分特征变量

238
00:08:25,603 --> 00:08:27,010
你也舍弃了

239
00:08:27,370 --> 00:08:30,615
问题中的一些信息

240
00:08:30,650 --> 00:08:31,942
例如 也许所有的

241
00:08:31,942 --> 00:08:33,760
特征变量

242
00:08:33,780 --> 00:08:35,050
对于预测房价都是有用的

243
00:08:35,070 --> 00:08:36,636
我们实际上并不想

244
00:08:36,640 --> 00:08:37,687
舍弃一些信息

245
00:08:37,687 --> 00:08:40,990
或者舍弃这些特征变量

246
00:08:41,540 --> 00:08:44,515
第二个选择

247
00:08:44,515 --> 00:08:45,995
我们将在接下来的视频中讨论

248
00:08:46,010 --> 00:08:49,268
就是正则化

249
00:08:49,268 --> 00:08:50,390
正则化中我们将保留

250
00:08:50,390 --> 00:08:52,579
所有的特征变量

251
00:08:52,579 --> 00:08:55,063
但是数量级

252
00:08:55,063 --> 00:08:56,506
或参数数值的大小

253
00:08:56,520 --> 00:08:58,745
θ(j)

254
00:08:58,750 --> 00:09:00,690
这个方法非常有效

255
00:09:00,690 --> 00:09:01,925
当我们有很多特征变量时

256
00:09:01,925 --> 00:09:03,822
其中每一个变量

257
00:09:03,822 --> 00:09:05,502
都能对预测产生一点影响

258
00:09:05,502 --> 00:09:07,723
y的值

259
00:09:07,740 --> 00:09:10,283
正如我们在房价的例子中看到的那样

260
00:09:10,283 --> 00:09:11,413
在那里我们可以有很多特征变量

261
00:09:11,413 --> 00:09:12,720
其中每一个变量

262
00:09:12,750 --> 00:09:16,902
都是有用的 因此我们不希望把它们删掉

263
00:09:16,930 --> 00:09:19,247
这就导致了

264
00:09:19,250 --> 00:09:22,790
正则化概念的发生

265
00:09:22,790 --> 00:09:24,354
我知道

266
00:09:24,360 --> 00:09:26,763
这些东西你们现在可能还听不懂

267
00:09:26,763 --> 00:09:28,316
但是在接下来的视频中

268
00:09:28,316 --> 00:09:30,960
我们将开始详细讲述

269
00:09:30,960 --> 00:09:35,117
怎样应用正则化和什么叫做正则化均值

270
00:09:35,140 --> 00:09:36,810
然后我们将开始

271
00:09:36,810 --> 00:09:38,310
讲解怎样使用正则化

272
00:09:38,310 --> 00:09:40,412
怎样使学习算法正常工作

273
00:09:40,412 --> 00:09:42,460
并避免过拟合 【教育无边界字幕组】翻译:牛仔仔 校对:御姐sama 审核:所罗门捷列夫