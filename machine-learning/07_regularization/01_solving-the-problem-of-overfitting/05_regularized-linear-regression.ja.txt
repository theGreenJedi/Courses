線形回帰に関しては 我らは以前、2つの学習アルゴリズムを 扱った。一つは最急降下法に基づくもの、 もう一つは正規方程式(normal equation)に基づく物。 この動画では、これら2つのアルゴリズムを 正規化した線形回帰へと 一般化する。 これが最適化の目的関数で 前回得た正規化した 線形回帰の物だ。 この最初の部分は、いつも通りの 線形回帰の目的関数だ。 そしてそこに、この追加の 正規化項がある。 ここでラムダは正規化パラメータ。 そしてこのコスト関数を最小化するような パラメータシータを見つけたい。 この正規化されたコスト関数、Jのシータを。 以前に、元のコスト関数に対して 最急降下法を適用した、 正規化項無しのコスト関数に。 そして以下のようなアルゴリズムを 通常の正規化無しの 線形回帰に関しては得た。 繰り返し、以下のように パラメータのシータjをアップデートしていく、 j=0、1、2、、、とnまで。 これを、シータ0だけを 分けて書くように 直してみよう。 つまり、シータ0の アップデートルールだけは 別に書く、 パラメータの1、2、3、、、 とnまでについては。 つまりまだ何も変えてない。 ここまでは単に、シータ0に関する アップデートを、 シータ1、シータ2、シータ3、、、と シータnまでとを分けて書いただけ。 こうした理由は、 覚えてるかもしれないが、 正規化した線形回帰では 我らはパラメータのシータ1、シータ2、などとシータnまでに ペナルティを課した。 だがシータ0にはペナルティを課していない。 だから、このアルゴリズムを 正規化した線形回帰へと 修正する時には、 シータ0をちょっとだけ異なる形で扱う事になる。 具体的には、 このアルゴリズムに対して 正規化の目的関数を使うように 修正したい時には この一番下の項を 以下のように修正すれば良い。 この項に、-ラムダ/m の シータj を 追加する。 これを実装すると、 正規化されたコスト関数 Jのシータを最小化する 最急降下法が得られる。具体的には ここで証明の為に 計算する事はしないが、 この項を見ると、 この、ここの大カッコでくくられた所を見ると、 解析学をおさめていたら、 この項はJのシータの シータjによる偏微分である事が、 正規化の項の入ったJのシータの 偏微分である事が 示せる。 同様に、この上の項は、 これは 青緑の箱で 描いていたと思うが、 これもまた、シータ0による Jのシータの偏微分である事が分かる。 シータjのアップデートを見ると、 なかなか面白い事が 分かる。つまり シータjは シータj マイナスの アルファ掛けることの このもう一つシータjに依存する項があり、 これでシータj をアップデートする。 だからこの シータjに依存する項を 一箇所にまとめると、 このアップデートは 以下のように書く事が出来る。 ここで私がやった事は ここのシータjは シータj掛ける1と、 そしてこの項は ラムダ/m  と、ここにアルファがあるから 結局は、 アルファ ラムダ/mとなり、 それにシータjを 掛ける。そしてここでこの 1マイナス アルファ掛けるラムダ/mという項は なかなか興味深い項だ。これはとても面白い効果を与える。 つまり、この項、 1 引く アルファの ラムダ/m というのは 通常、1より小さい、、、 1より小さい数となる。 何故なら アルファ掛けるラムダ/m は通常正で、普通ラーニングレートは小さい値で、mは大きい。 だから普通は凄く小さい。 だからこのここの項は 普通は1よりもちょっとだけ小さいような数となる。 だから例えばその数は 0.99とかそういう感じの数だと思っておけばよい。 そうすると、シータjの アップデートに対する影響としては シータjを、シータj掛ける0.99で 置き換える、と言ってる事になる。 ふむ、シータj掛ける0.99というのは シータjをちょっとだけ 0の方に向かって縮める効果を与える。 だからこれは、シータjをちょっと小さくする。 よりフォーマルに言うと、 このシータjの二乗が 小さくなる。 そこに、その後ろにある この二番目の項は、それは 元の最急降下法のアップデートの時と 同じ物だ。 この正規化に関する物を追加する前の。 以上でこの最急降下法は このアップデートは納得出来たかな。 正規化線形回帰を使う時には 我らがやる事は 各イテレーションごとにシータjに ちょっとだけ1より小さい数を 掛ける事だ。 つまりパラメータをちょっとだけ 縮める。そしてそこに 以前と似たようなアップデートをかます。 もちろんこれはこの特定のアップデートで 何をしているかの背後にある直感に過ぎない。 数学的には、コスト関数 Jのシータに まさに最急降下法を実行しているだけだ、 そのコスト関数としては、前回のスライドで定義した 正規化項を用いた物を使うだけで。 最急降下法は 線形回帰のモデルにフィッティングする 2つある方法のうちの、一つに過ぎなかった。 二つめのアルゴリズムとしては 正規方程式にもとづく物があった。 そこでは我らは デザイン行列Xを構築した、 それは各行が 別個のトレーニング手本を表すような物だった。 そしてベクトルyを構築した、 これはm次元の ベクトルで、 そしてその中身は トレーニングセットのラベルだった。 つまり一方でXは m掛けるn+1 次元行列で、 yはm次元ベクトルだ。 そしてコスト関数を 最小化する為に、 我らの見つけた 方法とは、 シータに イコール、これと置く。 X転置 Xの逆行列に、 X転置に、 y。 ここは後の為に空けておく。 するとこのシータの値は、 コスト関数 Jのシータを 最小化する、 正規化をしていない時には。 今回は正規化を使うのだから、 もし最小を導出したら、 ここでどんな感じで 最小を導出するのか、 軽く触れておくと、 それを導出する方法は、 各パラメータごとによる 偏微分をとって、 これをイコール0とセットする。 そしてたくさん計算すると、 こんな感じの式が得られて、 それがコスト関数を最小化する物となる。 ちゃんと書くと、 正規化をしている場合には、 この式はこう変わる。 このカッコの中に、こんな行列が入る。 0, 1, 1, 1, 1... と、一番下まで1。 つまりここにあるこれは、 一番左上が0で、その0以外の 対角成分は全て1が入るような 行列となる。 これは手抜きで描いてしまったが、 具体的に例えば、 もしn=2なら、 この行列は 3掛ける3 行列となる。 より一般的には、この行列は n+1掛けるn+1 次元の 行列となる。 だからn=2の時は こんな感じの行列となる。 最初に0、そしてそれ以降の対角成分は 1で、非対角成分は 全て0という行列。 もう一度言うとここで導出はするつもりは無い、 それは割と長くてかったるいし、しかも結構難しいから。 でもこの新しい定義の Jのシータ、 正規化の目的関数を 使うと、以下の事が証明出来る。 それは、この新しい シータの式がJのシータの グローバル最小を与える物となる、という事。 最後に、非可逆の問題について 簡単に触れておく。 これは本当にアドバンスドな内容だ。 だからこれはおまけと思ってもらって、 ご自由にスキップしてもらって構わないし、 もし聞いてみて いまいち良く分からんなぁ、と 思ったとしても、あんま気にしないでいいです。 さて、以前正規方程式法について触れた時、 非可逆の問題についてのおまけのビデオが あった。 つまりこれもまたおまけとなるのだが、 これは以前のおまけの非可逆性のビデオの 追加となる話だ。 いま、m、つまりトレーニング手本の 総数が、n以下の場合、 ここでnはフィーチャーの総数だが、そういう状況を考えてみよう。 もしフィーチャーよりも少ない手本しか 持っていなければ、この行列、 X転置 Xは 非可逆あるいは特異行列、 あるいは別の用語を使えば 縮退した行列 となる。 そしてこれをOctaveでとりあえず実装したいなら、 pinv関数を使って、これは pseudo inverseの略だが、これを使って擬似逆行列を取れば、 それはよきにはからってくれるが、 それが良い仮説を 与えてくれるかは あまり良く分からない、 数値計算的には、Octaveの pinv関数は、 ある程度意味をなした答えを 返してはくれるのだけれども。 だが、もしこれを別の言語でやっていて、 しかも通常の 逆行列をとっていたら、それはOctaveでは invという関数で表されている物だが、 通常の逆行列を X転置 Xについて取ろうとすると、 この状況では、 X転置 Xが特異行列で 非可逆である事が判明し、 もし別のプログラミング言語で 何らかの線形代数ライブラリを使って 行列の逆行列を計算したら、 それはうまく行かないかもしれない。 何故ならこの行列は非可逆、特異なのだから。 幸運にも、正規化はまた この件もうまく対応してくれる。具体的には、 正規化パラメータが0より大きい（イコールを含まない）場合は、 実際に行列 X転置 X に 足す事の、 パラメータのラムダ掛けることの このへんてこな行列は、 この行列は 特異行列にはならず、逆行列が計算出来る、 という事が証明出来る。 つまり正規化を用いる事で、 X転置 X 行列が非可逆問題にも 対応した事になる。 つまり、いまやあなたは正規化した線形回帰の実装方法を知った訳だが、 これを用いる事で、オーバーフィッティングを 避ける事が出来る、たとえ たくさんのフィーチャーがあって、相対的に小さなトレーニングセットしか無かったとしても。 そしてこれは、線形回帰を もっとたくさんの問題に適用する事が出来る。 次のビデオでは、この正規化のアイデアを ロジスティック回帰にも適用してみる。 そうする事で、ロジスティック回帰でも オーバーフィットの問題を回避する事が出来、 またよりうまく実行する事も出来るようになるだろう。