लिनीअर रेग्रेशन के लिए, हमने पहले बनाए थे दो लर्निंग अल्गोरिद्म्स. एक आधारित था ग्रेडीयंट डिसेंट पर और एक आधारित था नोर्मल इक्वेज़न पर. इस वीडियो में, हम लेंगे उन दो अल्गोरिद्म्स को और जनरलाइज करेंगे उन्हें रेगुलेराईज़ड लिनीअर रेग्रेशन के लिए. यहाँ है ऑप्टिमायज़ेशन अब्जेक्टिव जो हमने बनाया था पिछली बार रेगुलराइज्ड लिनीअर रेग्रेशन के लिए. यह पहला हिस्सा है हमारा हमेशा का अब्जेक्टिव लिनीअर रेग्रेशन का. और अब हमारे पास है यह अतिरिक्त रेगुलराइज़ेशन टर्म, जहाँ लैम्डा है हमारा रेगुलराइज़ेशन पेरामिटर, और हम चाहते हैं ढूँढना पेरमिटर्स थीटा जो न्यूनतम करता हैैं इस कॉस्ट फ़ंक्शन को, इस रेगुलराइज्ड कॉस्ट फ़ंक्शन को, जे ऑफ़ थीटा. पहले हम इस्तेमाल कर रहे थे ग्रेडीयंट डिसेंट प्रारम्भिक कॉस्ट फ़ंक्शन के लिए, बिना रेगुलराइज़ेशन टर्म के. और हमारे पास था निम्न अल्गोरिद्म लिनीअर रेग्रेशन के लिए बिना रेगुलराइज़ेशन के, हम बार-बार अप्डेट करेंगे पेरमिटर्स थीटा j इस प्रकार j बराबर 0, 1, 2, से n तक के लिए. तो मैं सिर्फ़ यह लेता हूँ और सिर्फ़ लिखता हूँ केस थीटा 0 का अलग से. तो मैं सिर्फ़ लिखूँगा थीटा 0 का अप्डेट अलग से पेरमिटर्स 1, 2, 3 से n तक के अप्डेट से. और इसलिए यह है, मैंने कुछ भी नहीं बदला है अभी, ठीक है. यह है सिर्फ़ लिखना अप्डेट थीटा 0 का अलग से बाक़ी के अप्डेट से थीटा 1, थीटा 2, थीटा 3 आगे थीटा n तक. और कारण कि मैं यह करना चाहता हूँ है आपको शायद याद होगा कि हमारे रेग्युलराइज्ड लिनीअर रेग्रेशन के लिए, हम दण्डित करते हैं पेरमिटर्स थीटा 1, थीटा 2, और आगे थीटा n तक को. लेकिन हम थीटा 0 दंडित नहीं करते. तो, जब हम बदलेंगे इस अल्गोरिद्म को रेग्युलराइज्ड लिनीअर रेग्रेशन के लिए, हम सम्बोधित करेंगे थीटा 0 को थोड़ा भिन्न. वस्तुतः, हम लेना चाहते हैं इस अल्गोरिद्म को और बदलना चाहते हैं इसे इस्तेमाल करने के लिए रेग्युलराइज्ड अब्जेक्टिव, हमें सिर्फ़ आवश्यकता है लेने की इस टर्म को नीचे वाली और बदलना है इसे निम्न तरह से. हम लेंगे यह टर्म और जोड़ेंगे माइनस लैम्डा ओवर m गुणा थीटा j. और यदि आप इम्प्लमेंट करते हैं इसे, तब आपके पास है ग्रेडीयंट डिसेंट न्यूनतम करने के लिए रेगुलराइज्ड कॉस्ट फ़ंक्शन को, जे ऑफ़ थीटा. और वस्तुतः, मैं नहीं कर रहा हूँ कैल्क्युलुस साबित करने लिए इसे, लेकिन वास्तव में यदि आप देखें इस टर्म को, यह टर्म जो मैंने लिखी है वर्ग कोष्ठक में, यदि आप जानते हैं कैल्क्युलुस यह सम्भव है साबित करना कि वह टर्म है पर्शियल डेरिवेटिव विद रिस्पेक्ट टु J ऑफ़ थीटा इस्तेमाल करते हुए नई परिभाषा J ऑफ़ थीटा की रेग्युलराइज़ेशन टर्म के साथ. और इसी तरह, ऊपर की टर्म जहाँ मैं बना रहा हूँ सियान बॉक्स, वह भी है पर्शियल डेरिवेटिव विद रिस्पेक्ट टु थीटा ज़ीरो J ऑफ़ थीटा का. यदि आप देखें थीटा j के अप्डेट को, यह सम्भव है दिखा पाना कुछ बहुत दिलचस्प चीज़. थीटा j अपडेट होता है ऐसे, थीटा j माइनस अल्फ़ा टाइम्ज़, और फिर आपके पास है यह अन्य टर्म यहाँ जो निर्भर करती है थीटा j पर. तो यदि आप इकट्ठा करते हैं सारी टर्म्ज़ को एक साथ जो निर्भर करती हैं थीटा j पर, आप दिखा सकते हैं कि यह अप्डेट लिखा जा सकता है समान रूप से निम्न तरह से. और मैंने सिर्फ़ क्या किया कि जोड़ा थीटा j यहाँ है, तो थीटा j टाइम्ज़ 1. और यह टर्म है, ठीक है, लैम्डा ओवर m, यहाँ है एक अल्फ़ा यहाँ, तो आपको मिलता है अल्फ़ा लैम्डा ओवर m गुणा किया थीटा j से. और यह टर्म यहाँ, 1 माइनस अल्फ़ा गुणा लैम्डा m, है एक काफ़ी दिलचस्प टर्म. इसका है बहुत दिलचस्प प्रभाव. वास्तव में यह टर्म, 1 माइनस अल्फ़ा टाइम्ज़ लैम्डा ओवर m, होगी एक संख्या जो है आमतौर पर एक से थोड़ी कम, क्योंकि अल्फ़ा टाइम्ज़ लैम्डा ओवर m होगा पॉज़िटिव, और अक्सर यदि आपकी लर्निंग रेट छोटी हैं और यदि m बड़ा है, यह होता है अक्सर छोटा. अत: यह टर्म यहाँ होगी एक संख्या जो है आमतौर पर 1 से थोड़ी कम, तो सोचे इसे एक संख्या जैसे 0.99, मान लो. और इसलिए प्रभाव हमारे अप्डेट का थीटा j को है, हम कहेंगे कि थीटा j बदल दिया जाता है थीटा j टाइम्ज़ 0.99 से, ठीक है? तो थीटा j टाइम्ज़ 0.99 का प्रभाव है छोटा करना थीटा j थोड़ा सा ज़ीरो की तरफ़. तो यह बनाता है थीटा j को थोड़ा छोटा. और अधिक औपचारिक रूप से, स्क्वेर टर्म इस थीटा j की है थोड़ी छोटी. और तब उसके बाद, दूसरी टर्म यहाँ, वह है वास्तव में बिल्कुल वही जो थी पहले के ग्रेडीयंट डिसेंट अप्डेट में जो हमारे पास थी, हमारे ये सब रेगुलराइज़ेशन डालने से पहले. तो उम्मीद है यह ग्रेडीयंट डिसेंट, उम्मीद है यह अप्डेट समझ आया होगा. जब हम इस्तेमाल कर रहे हैं एक रेगुलराइज्ड लिनीअर रेग्रेशन और हम क्या कर रहे हैं कि प्रत्येक इटरेशन में हम गुणा कर रहे हैं थीटा j को एक नम्बर से जो है थोड़ा छोटा एक से, तो यह छोटा कर रहा है पेरामिटर को थोड़ा, और और फिर हम कर रहे हैं एक समान अप्डेट पहले जैसे. निश्चित रूप से वह है सिर्फ़ एक अनुभव कि यह ख़ास अप्डेट क्या कर रहा है. गणितीय रूप में यह क्या कर रहा है कि यह है वास्तव में ग्रेडीयंट डिसेंट कॉस्ट फ़ंक्शन J ऑफ़ थीटा पर जो हमने परिभाषित किया था पिछली स्लाइड पर जो इस्तेमाल करता है रेगुलराइज़ेशन टर्म. ग्रेडीयंट डिसेंट था सिर्फ़ एक हमारे दो अल्गोरिद्म्स में से फ़िट करने के लिए लिनीअर रेग्रेशन मॉडल. दूसरा अल्गोरिद्म आधारित था नोर्मल इक्वेज़न पर, जहाँ हमने क्या किया था कि हमने बनाया था डिज़ाइन मेट्रिक्स X जहाँ प्रत्येक रो कॉरेस्पॉंड करती है एक अलग ट्रेनिंग इग्ज़ाम्पल को. और हमने बनाया एक वेक्टर y, तो यह है एक वेक्टर, जो है एक m डिमेन्शनल वेक्टर. और उसमें थे लेबल्ज़ मेरे ट्रेनिंग सेट के. तो जहाँ X है एक m बाई (n+1) डिमेन्शनल मेट्रिक्स, y है एक म डिमेन्शनल वेक्टर. और न्यूनतम करने के लिए कॉस्ट फ़ंक्शन J, हमने पाया कि एक ढंग करने का इसे है कि सेट करें थीटा बराबर इसके. ठीक है, आपके पास है X ट्रान्स्पोज़, X इन्वर्स, X ट्रान्स्पोज़ Y. मैं यहाँ जा रहा हूँ कमरे से सामान भरने के लिए. और क्या करती है यह वैल्यू थीटा की कि यह न्यूनतम करती है कॉस्ट फ़ंक्शन J ऑफ़ थीटा, जब हम नहीं ले रहे रेगुलराइज़ेशन. अब जब हम कर रहे हैं रेगुलराइज़ेशन, यदि आपको डिराइव करना होता क्या है न्यूनतम, और सिर्फ़ देने के लिए आपको एक अभिप्राय कि कैसे डिराइव करते हैं न्यूनतम, जिस तरह से आप डिराइव करते हैं इसे है कि आप लेते हैं पर्शियल डेरिवेटिव विद रिस्पेक्ट टु प्रत्येक पेरामिटर. सेट करते हैं उसे 0, और फिर करते हैं थोड़ा गणित और आप तब दिखा सकते हैं यह है एक फ़ॉर्म्युला इस तरह का जो न्यूनतम करता है कॉस्ट फ़ंक्शन. और वस्तुत:, यदि आप इस्तेमाल कर रहे हैं रेगुलराइज़ेशन, तब यह फ़ॉर्म्युला बदल जाता है निम्न तरह से. इस कोष्ठकों के अंदर, आपको मिलती है एक मैट्रिक्स इस तरह की. 0, 1, 1, 1, और इसी प्रकार आगे 1, पूरा नीचे तक. तो यह चीज़ यहाँ है एक मेट्रिक्स जिसकी सबसे ऊपर बाईं तरफ़ की एंट्री है 0. विकर्णो पर एक हैं, और ज़ीरो हैं बाक़ी सब जगह इस मेट्रिक्स में. क्योंकि मैं बना रहा हूँ थोड़े बेकार ढंग से. लेकिन यह है एक उदाहरण, यदि n = 2, तब यह होगी एक तीन बाई तीन मेट्रिक्स. अधिक सामान्य रूप में, यह मेट्रिक्स है एक (n+1) बाई (n+1) डिमेन्शनल मेट्रिक्स. तो यदि n = 2, तब वह मेट्रिक्स बन जाती है कुछ इस तरह से. यह होगा 0, और फिर 1 विकर्णो पर, और फिर 0 बाक़ी सब जगह. और एक बार फिर से, मैं इस डेरिवेशन को नहीं करूँगा, जो है स्पष्ट रूप से थोड़ा लम्बा और जटिल, लेकिन यह साबित करना सम्भव है कि यदि आप इस्तेमाल कर रहे हैं नई परिभाषा J ऑफ़ थीटा की, रेगुलराइज़ेशन अब्जेक्टिव के साथ, तब यह नया फ़ॉर्म्युला थीटा के लिए है जो हम देते हैं आपको, ग्लोबल मिनिमम J ऑफ़ थीटा का. और अंत में आप आपको सिर्फ़ जल्दी से बताना चाहता हूँ नॉन-इन्वर्टीबिलिटी के बारे में. यह अपेक्षाकृत एडवांसड मटीरीयल है, आप इसे वैकल्पिक सोच सकते हैं. और इसे चाहें तो छोड़ सकते हैं, यदि आप इसे सुनते हैं और यह वास्तव में समझ नहीं आता है, तो इसकी चिंता न करें. लेकिन पहले जब हमने बात की थी नोर्मल इक्वेज़नज़ विधि की, हमारे पास था एक वैकल्पिक वीडियो, नॉन-इन्वर्टीबिलिटी पर. तो यह है एक और वैकल्पिक हिस्सा उसका, एक प्रकार से हिस्सा हमारे पहले वैकल्पिक वीडियो का, नॉन-इन्वर्टीबिलिटी पर. अब सोचो एक स्थिति जहाँ m, संख्या इग्ज़ाम्पल्ज़ की, है कम या बराबर n के, संख्या फ़ीचर्ज़ की. यदि आपके पास हैं कम इग्ज़ाम्पल्ज़ तुलना में फ़ीचर्ज़ से, तब यह मेट्रिक्स X ट्रान्स्पोज़ X होगी नॉन-इन्वर्टिबल, या सिंगुलर. या अन्य टर्म इस मेट्रिक्स के लिए होगी डिजेनेरेट. और यदि आप इम्प्लमेंट करते हैं इसे ओकटेव में किसी तरह और आप इस्तेमाल करते हैं pinv फ़ंक्शन का लेने के लिए स्यूडो इन्वर्स, यह करेगा एक तरह से सही काम, लेकिन यह स्पष्ट नहीं है कि यह देगा आपको एक अच्छी हायपॉथिसस, जबकि नूमेरिक्ली, ओकटेव pinv फ़ंक्शन देगा आपको एक परिणाम जो समझ में आता है. लेकिन यदि आप कर रहे हैं इसे एक भिन्न लैंग्विज में, और यदि आप ले रहे हैं हमेशा का इन्वर्स, जो ओकटेव में डिनोट करते हैं फ़ंक्शन inv से, हम प्रयास कर रहे हैं लेने का हमेशा का इन्वर्स X ट्रान्स्पोज़ X का. तब उस स्थिति में आपको मिलेगा कि X ट्रान्स्पोज़ X है सिंगुलर, है नॉन-इन्वर्टिबल, और यदि आप कर रहे हैं इसे एक भिन्न लैंग्विज में और इस्तेमाल कर रहे हैं लिनीअर ऐल्जेब्रा लाइब्रेरी लेने के लिए इन्वर्स इस मेट्रिक्स का, यह शायद काम न करे क्योंकि वह मेट्रिक्स है नॉन-इन्वर्टिबल या सिंगुलर. सौभाग्य से, रेग्युलराइज़ेशन से भी यह समस्या हल हो जाती है हमारे लिए. और वस्तुत:, जब तक रेगुलराइज़ेशन पेरामिटर लैम्डा है बड़ा 0 से, यह वास्तव में सम्भव है साबित करना कि यह मेट्रिक्स, X ट्रान्स्पोज़ X जमा लैम्डा गुणा यह मेट्रिक्स यहाँ, यह सम्भव है साबित करना यह मेट्रिक्स नहीं होगी सिंगुलर और कि यह मेट्रिक्स होगी इन्वर्टीबल. तो इस्तेमाल करने से रेग्युलराइज़ेशन हल हो जाती है यह समस्या नॉन-इन्वर्हटीबिलिटी X ट्रान्स्पोज़ X मेट्रिक्स की भी. तो आप अब जानते हैं कैसे इम्प्लमेंट करना हैरेगुलराइज्ड लिनीअर रेग्रेशन. इसको इस्तेमाल करने से आप ओवर फ़िटिंग से बच पाएँगे यदि आपके पास बहुत से फ़ीचर्ज़ भी है एक अपेक्षाकृत छोटे ट्रेनिंग सेट में. और इससे लिनीअर रेग्रेशन करना चाहिए अधिक बेहतर बहुत सी प्राब्लम्ज़ के लिए. अगले वीडियो में हम लेंगे यह रेग्युलराइज़ेशन का सुझाव और अप्लाई करेंगे इसे लॉजिस्टिक रिग्रेशन को. ताकि आप बच पाएँ ओवर फ़िटिंग से लॉजिस्टिक रिग्रेशन में और पर्फ़ॉर्म कर पाएँ अधिक बेहतर.