Para la regresión lineal, hemos desarrollado anteriormente dos algoritmos de aprendizaje, uno basado en el gradiente de descenso y el otro basado en la ecuación normal. En este video tomaremos esos dos algoritmos y los generalizaremos para el caso de la regresión lineal regularizada. Este es el objetivo de optimización, que desarrollamos la última vez para la regresión lineal regularizada. Esta primera parte es nuestro habitual objetivo para la regresión lineal y ahora tenemos este término adicional, regulación, donde «lambda» es nuestro parámetro de regularización, y queremos encontrar los parámetros «theta», que minimicen esta función de costos, esta función de costos regularizada, "J" de «theta». Anteriormente, estábamos usando el gradiente de descenso para la original función de costos, sin el término regularización, y tuvimos el siguiente algoritmo para la regresión lineal normal, sin regularización. En varias ocasiones actualizaremos los parámetros «theta» de "j" como sigue para J = 0, 1, 2 hasta "n". Déjame tomar esto y escribir el caso de «theta»0 por separado. Así es que, como sabes, voy a escribir la actualización para «theta»0 por separado, entonces para la actualización de los parámetros 1, 2, 3 y así sucesivamente hasta "n". Entonces, no he cambiado nada todavía, ¿correcto? Esto es solo la escritura de la actualización para «theta»0 por separado de las actualizaciones para «theta»1, «theta»2, «theta»3, hasta «theta» "n". Y la razón por la que quiero hacer esto es que quizá recuerdes que para nuestra regresión lineal regularizada, penalizamos los parámetros «theta»1, theta2 y así sucesivamente sucesivamente hasta «theta» "n", pero no penalizamos «theta»0. Así que cuando modificamos este algoritmo para la regresión lineal regularizada, vamos a terminar tratando a «theta»0 ligeramente diferente. Específicamente, se queremos tomar este algoritmo y modificarlo para usar el objetivo regularizado, todo lo que necesitamos hacer es tomar este término en la parte inferior y modificarlo de la siguiente manera. Vamos a tomar este término y añadir menos «lambda» sobre "m", multiplicado por «theta» j. Y así implementas esto, entonces tienes al gradiente de descenso para tratar de minimizar la función de costos regularizada "J" de «theta», y específicamente, no voy a hacer el cálculo para probarlo, pero específicamente si observas este término, este término que está escrito entre corchetes cuadrados, y si sabes cálculo, es posible probar que ese término es una derivada parcial, con respecto de "J" de «theta», usando la nueva definición de "J" de «theta» con el término de regularización. Y de repente este término en la parte superior, que creo que estoy dibujando en la caja saliente, aún es la derivada parcial con respecto a «theta»0 de "J" de «theta». Si miras la actualización para «theta» j, es posible que muestre algo muy interesante, específicamente «theta» j se actualiza como «theta» j - «alfa» multiplicado por, y entonces tienes este otro término aquí que depende de «theta» j . Así que si agrupas todos los términos que dependen de «theta» j, podremos demostrar que esta actualización puede escribirse equivalente como sigue a continuación y todo lo que hice, como sabes, «theta» j aquí es «theta» j multiplicada por 1 y este término es «lambda» sobre m. También hay un «alfa» aquí, así que terminas con «alfa» «lambda» sobre m, multiplícalas por «theta» j y este término de aquí, uno menos «alfa» multiplicado por «lambda» m, es un término muy interesante, tiene un efecto muy interesante. Específicamente, este término 1 menos «alfa» multiplicado por «lambda» sobre m, va a ser un número que, como sabes, generalmente un número que hace un bucle y es menor que 1, ¿Correcto? Porque «alfa» multiplicada por «lambda» sobre m va a ser positivo y generalmente, si tu índice de aprendizaje es pequeño y m es grande, será bastante pequeño. Así es que este término de aquí, va a ser un número, generalmente, como sabes, un poco menor que uno. Piensa en este número como 0.99, digamos, y así, el efecto de nuestras actualizaciones de «theta» j si vamos a decir que «theta» j se remplaza por «theta» j multiplicada por 0.99. Bien, entonces «theta» j multiplicada por 0.99 tiene el efecto de reducir «theta» de j un poco hacia 0. Así que esto hace un poco más pequeña a «theta» j. Más formalmente, esto como sabes, es la norma cuadrada de «theta» j que es menor y entonces después del segundo término de aquí, es en realidad exactamente lo mismo que la actualización original del gradiente de descenso que teníamos antes de agregar todas estas cosas de la regularización. Así es que, espero que este gradiente de descenso, que esta actualización tenga sentido, cuando estamos usando la regresión lineal regularizada lo que estamos haciendo en cada regularización es multiplicar los datos de J por un número un poco menor a uno, para reducir el parámetro un poco, y para que realicemos una, como sabes, actualización similar como antes. Por supuesto que es sólo la intuición detrás de lo que esta actualización en particular está haciendo. Matemáticamente, lo que está haciendo exactamente es el gradiente de descenso en la función de costos J de «theta» que hemos definido en la anterior diapositiva y que utiliza el término regularización. El gradiente de descenso fue simplemente uno de nuestros dos algoritmos para ajustar un modelo de regresión lineal. El segundo algoritmo fue el que se basa en la ecuación normal, en donde, lo que hicimos fue crear la matriz de diseño "X" donde cada fila corresponde para separar el ejemplo de entrenamiento. Y creamos un vector "Y", así es que esto es un vector, que es un vector de "m" dimensiones y eso contiene el valor asignado para el conjunto de entrenamiento. Así que mientras que "X" es una matriz dimensional "m" multiplicada por n + 1, y es un vector de "m" dimensiones en orden de minimizar la función de costos, encontramos que una manera de hacerlo, es establecer que «theta» es igual a esto. Tenemos que x'x, inversa x'y. Voy a dejar espacio aquí, para poner otras cosas, desde luego. Y lo que este valor para «theta» hace, es minimizar la función de costos J de «theta» cuando no estamos usado la regularización. Ahora que estamos usando la regularización, si vas a derivar lo que el mínimo es, y solo para darte un sentido de cómo derivar el mínimo, la forma en que lo derivaste es, como sabes, tomando las derivadas parciales con respecto a cada parámetro, y establecerlas a cero, entonces haciendo un poco de matemáticas, puedes entonces demostrar que es una fórmula como esta que minimiza la función de costos. En específico, si estás usando la regularización entonces esta fórmula cambia de la siguiente manera. Dentro de estos paréntesis, terminas con una matriz como esta. Cero, uno, uno, uno, y así sucesivamente, hasta el final. Así es que esto de aquí es una matriz, cuya entrada superior izquierda es cero. Hay unos en los diagonales y ceros en cualquier otra parte de esta matriz. Porque estoy dibujándola un poco descuidado. Pero como ejemplo específico si "n" es igual a 2, entonces esta matriz va a ser una matriz de 3x3. De forma más general, esta matriz es una matriz de dimensiones n+1 multiplicado por n+1. Entonces "n" es igual a dos, luego esa matriz se convierte en algo parecido a esto. Cero y unos en diagonal, y luego ceros en el resto de las diagonales. Y una vez más, como sabes, no voy a quienes conocen esta derivación. Que es francamente un poco largo e involucrado. Pero es posible demostrar que si estás usando la nueva definición de J de «theta», con el objetivo de regularización, entonces esta nueva fórmula para «theta» es uno que dará el mínimo global de J de «theta». Finalmente, quiero describir rápidamente el problema de la no invertibilidad. Esto es material relativamente avanzado, así es que debes considerar esto como material opcional y siéntete libre de saltártelo o si lo escuchas y como sabes, posiblemente no te hace sentido, no te preocupes tampoco. Pero anteriormente cuando hablamos del método de ecuación normal, también tuvimos un video opcional con respecto a la no invertibilidad. Esta es otra parte opcional, es una especie de añadidura al video opcional anterior sobre la no invertibilidad. Ahora consideramos establecer dónde "m", el número de ejemplos es menor o igual que "n", el número de variables. Si tienes menos ejemplos que variables en esta matriz x'x será no invertible o singular, o el otro término para esto es que la matriz será degenerada y si implementas esto en Octave, de todos modos, y utilizas la función pinv para tomar la seudoinversa, hará más o menos lo correcto pero no está claro si te dará una muy buena hipótesis aunque numéricamente la función pinv en Octave te dará un resultado que más o menos tendrá sentido. Pero, si estás haciendo esto en un lenguaje diferente, y si estás tomando solo la inversa regular que en Octave se denota con la función Inv, estamos tratando de tomar la inversa regular de x'x, luego en esta configuración encontrarás que x'x es singular, es no invertible y si estás haciendo esto en un lenguaje de programación diferente y usando alguna biblioteca de álgebra lineal trata de tomar la inversa de esta matriz. Tal vez no funcione porque esa matriz es no invertible o singular. Afortunadamente, la regularización también se encarga de esto para nosotros, y en específico, mientras el parámetro de regularización «lambda» es estrictamente mayor que cero, en realidad es posible demostrar que esta matriz x'x + «lambda» multiplicado por, como sabes, esta graciosa matriz de aquí, posiblemente demostrará que esta matriz no será singular y que esta matriz en invertible. Así que usar la regularización también toma en cuenta cualquier problema de no invertibilidad de la matriz x'x. Así que, ya sabes cómo implementar la regularización de la regresión lineal. Con esto, podrás evitar el sobreajuste, incluso si tienes muchas variables en un conjunto de entrenamiento relativamente pequeño. Y esto debería permitirte lograr que la regresión lineal funcione mucho mejor para una variedad de problemas. En el siguiente video, tomaremos esta idea de regularización y la aplicaremos a la regresión logística. Con esto serás capaz de lograr que la regresión logística evite el sobreajuste y se desempeñe mucho mejor.