1
00:00:00,144 --> 00:00:02,011
В этом видео я хотел бы

2
00:00:02,011 --> 00:00:03,990
показать основные моменты как

3
00:00:03,990 --> 00:00:05,771
работает регуляризация

4
00:00:05,771 --> 00:00:07,386
И так же мы запишем функцию затрат, которую мы будем использовать,

5
00:00:07,386 --> 00:00:11,724
когда будем использовать регуляризацию.

6
00:00:11,780 --> 00:00:13,327
Я полагаю, что при помощи примеров, которые я нарисовал в этой

7
00:00:13,327 --> 00:00:14,916
лекции, вы отчасти сможете получить представление о

8
00:00:14,950 --> 00:00:17,642
регуляризации.

9
00:00:17,700 --> 00:00:19,608
Но гораздо лучше будет, если вы не просто прослушаете лекции,

10
00:00:19,608 --> 00:00:21,192
а  реализуете

11
00:00:21,192 --> 00:00:22,643
регуляризацию самостоятельно и увидите

12
00:00:22,643 --> 00:00:25,869
сами, как она работает.

13
00:00:25,869 --> 00:00:26,888
Если вы выполните все упражнения, относящиеся к

14
00:00:26,888 --> 00:00:28,603
этому разделу, то вы сможете увидеть

15
00:00:28,603 --> 00:00:30,053
регуляризацию

16
00:00:30,053 --> 00:00:33,927
в действии.

17
00:00:33,930 --> 00:00:36,519
Итак, приступим.

18
00:00:36,519 --> 00:00:38,233
В предыдущем

19
00:00:38,233 --> 00:00:39,771
видео мы могли заметить, что приближение квадратичной

20
00:00:39,771 --> 00:00:41,420
функцией дает довольно хорошие

21
00:00:41,420 --> 00:00:44,283
результаты.

22
00:00:44,283 --> 00:00:45,286
Но если

23
00:00:45,310 --> 00:00:47,175
нам нужно использовать полиномиальную

24
00:00:47,210 --> 00:00:48,823
функцию

25
00:00:48,850 --> 00:00:50,111
гораздо большего порядка, мы сталкиваемся с тем, что кривая

26
00:00:50,111 --> 00:00:51,760
очень хорошо покрывает обучающую

27
00:00:51,760 --> 00:00:53,381
выборку, но плохо

28
00:00:53,420 --> 00:00:54,497
переобучается, нет

29
00:00:54,497 --> 00:00:57,225
возможности обобщения.

30
00:00:57,900 --> 00:01:00,453
Предположим следующее: нам нужно придумать штраф с тем, чтобы

31
00:01:00,453 --> 00:01:02,088
добиться максимального

32
00:01:02,088 --> 00:01:04,753
уменьшения параметров тета-3 и тета-4.

33
00:01:04,753 --> 00:01:06,543
Вот что я имею в виду. Возьмем нашу целевую

34
00:01:06,543 --> 00:01:09,676
функцию, или задачу оптимизации, в

35
00:01:09,690 --> 00:01:10,859
которой мы минимизируем обычный

36
00:01:10,870 --> 00:01:12,574
квадрат отклонения функции

37
00:01:12,580 --> 00:01:15,526
затрат.

38
00:01:15,526 --> 00:01:17,350
Эту целевую функцию мы

39
00:01:17,370 --> 00:01:19,125
немного изменяем: мы

40
00:01:19,160 --> 00:01:23,291
прибавляем 100 тета-3 в квадрате, плюс

41
00:01:23,291 --> 00:01:28,334
1000 тета-4 в квадрате.

42
00:01:28,334 --> 00:01:32,354
1000 я беру как просто какое-то большое число.

43
00:01:32,354 --> 00:01:33,538
Теперь, если нам надо минимизировать

44
00:01:33,540 --> 00:01:35,127
эту функцию, то единственным

45
00:01:35,140 --> 00:01:36,688
способом сделать ее минимальной - это

46
00:01:36,710 --> 00:01:38,620
уменьшить

47
00:01:38,620 --> 00:01:40,769
тета-3 и тета-4 тоже.

48
00:01:40,769 --> 00:01:42,133
Верно?

49
00:01:42,133 --> 00:01:43,264
Потому что в противном случаеу нас будет тета-3,

50
00:01:43,264 --> 00:01:44,956
умноженная на 1000, что дает большое

51
00:01:44,970 --> 00:01:48,103
значение целевой функции.

52
00:01:48,140 --> 00:01:49,245
Таким образом,

53
00:01:49,245 --> 00:01:50,402
минимизируя новую целевую

54
00:01:50,402 --> 00:01:52,107
функцию мы получаем тета-3 близкое к

55
00:01:52,110 --> 00:01:53,776
нулю, тета-4 близкое к

56
00:01:53,776 --> 00:01:56,700
нулю и таким образом

57
00:01:56,700 --> 00:01:59,691
избавляемся от них

58
00:01:59,691 --> 00:02:03,206
совсем.

59
00:02:03,710 --> 00:02:05,282
А если мы это сделаем, то при

60
00:02:05,290 --> 00:02:06,783
тета-3 и тета-4 близких к

61
00:02:06,783 --> 00:02:07,973
нулю, мы получаем

62
00:02:07,973 --> 00:02:09,643
квадратичную функцию мы выравниваем

63
00:02:09,643 --> 00:02:11,089
данные это, как вы понимаете,

64
00:02:11,110 --> 00:02:13,343
квадратичная функция плюс, возможно, небольшие

65
00:02:13,343 --> 00:02:15,463
добавочные значения тета-3

66
00:02:15,463 --> 00:02:17,856
и тета-4, близкие к

67
00:02:17,860 --> 00:02:20,207
нулю.

68
00:02:20,207 --> 00:02:27,293
И мы получаем в сущности квадратичную функцию,

69
00:02:27,293 --> 00:02:29,386
что хорошо.

70
00:02:29,386 --> 00:02:30,544
Потому что это лучшая для

71
00:02:30,544 --> 00:02:34,060
нас гипотеза.

72
00:02:34,104 --> 00:02:36,666
В этом примере мы рассмотрели результат

73
00:02:36,700 --> 00:02:39,023
применения штрафа к

74
00:02:39,023 --> 00:02:41,446
двум параметрам, которые были достаточно большие.

75
00:02:41,446 --> 00:02:46,510
В целом, в этом и состоит идея регуляризации.

76
00:02:46,980 --> 00:02:48,924
Идея заключается в том, что если у нас есть

77
00:02:48,924 --> 00:02:50,303
маленькие

78
00:02:50,303 --> 00:02:53,083
значения параметров, то имея

79
00:02:53,083 --> 00:02:55,250
маленькие значения параметров, мы

80
00:02:55,250 --> 00:02:57,866
обычно упрощаем соответствующую

81
00:02:57,866 --> 00:03:00,386
им гипотезу.

82
00:03:00,386 --> 00:03:02,279
Итак, для нашего последнего примера мы добавили

83
00:03:02,279 --> 00:03:04,024
штраф только к тета-3 и тета-4 и сделали

84
00:03:04,024 --> 00:03:05,666
их близкими к нулю. Мы

85
00:03:05,666 --> 00:03:07,046
свели результат к более

86
00:03:07,046 --> 00:03:08,450
простой гипотезе,

87
00:03:08,480 --> 00:03:12,549
просто к квадратичной функции.

88
00:03:12,549 --> 00:03:13,991
В более широком смысле, мы

89
00:03:13,991 --> 00:03:15,989
можем наложить штраф на все параметры,

90
00:03:15,989 --> 00:03:17,416
полагая, что это даст нам более

91
00:03:17,420 --> 00:03:19,076
простую гипотезу, как в нашем последнем

92
00:03:19,110 --> 00:03:20,943
примере, где устремление параметров к

93
00:03:20,943 --> 00:03:22,380
нулю привело нас

94
00:03:22,410 --> 00:03:23,700
к квадратичной

95
00:03:23,700 --> 00:03:26,105
функции.

96
00:03:26,105 --> 00:03:29,038
Но также можно показать, что меньшие

97
00:03:29,038 --> 00:03:30,493
значения параметров соответствуют обычно более

98
00:03:30,530 --> 00:03:32,536
гладким функциям, а

99
00:03:32,540 --> 00:03:34,416
также более

100
00:03:34,416 --> 00:03:36,780
простым.

101
00:03:36,780 --> 00:03:41,667
Которые поэтому хуже поддаются переобучению.

102
00:03:41,680 --> 00:03:43,245
Я понимаю, почему хочется, чтобы

103
00:03:43,245 --> 00:03:45,441
все параметры были небольшими.

104
00:03:45,441 --> 00:03:46,944
Почему это соответствует более простой

105
00:03:46,960 --> 00:03:48,916
гипотезе. Я также понимаю, что для вас это

106
00:03:48,916 --> 00:03:51,572
возможно пока не очевидно.

107
00:03:51,590 --> 00:03:52,784
Довольно сложно объяснять до тех пор, пока вы

108
00:03:52,784 --> 00:03:54,477
сами не реализуете и не увидите

109
00:03:54,480 --> 00:03:56,446
результат.

110
00:03:56,470 --> 00:03:58,247
Но я надеюсь,

111
00:03:58,247 --> 00:03:59,610
что пример с тета-3 и тета-4, устремленными

112
00:03:59,650 --> 00:04:01,230
к нулю и то как нам это дало

113
00:04:01,230 --> 00:04:02,535
более простую гипотезу, я надеюсь,

114
00:04:02,540 --> 00:04:04,776
что это поможет вам понять, хотя

115
00:04:04,800 --> 00:04:06,314
бы отчасти, почему же это так

116
00:04:06,330 --> 00:04:09,320
происходит.

117
00:04:09,320 --> 00:04:11,476
Давайте рассмотрим на конкретном примере.

118
00:04:12,010 --> 00:04:13,873
Для нашего примера с ценой на жилье мы можем

119
00:04:13,873 --> 00:04:15,465
рассмотреть все наши сто характеристик, о

120
00:04:15,480 --> 00:04:17,223
которых мы говорили, среди

121
00:04:17,250 --> 00:04:18,756
которых может быть x1 - размер, x2 - количества

122
00:04:18,756 --> 00:04:20,096
спальных комнат, x3 - количество

123
00:04:20,096 --> 00:04:21,963
этажей и так далее

124
00:04:21,963 --> 00:04:24,502
И у нас может быть сотня характеристик.

125
00:04:24,502 --> 00:04:26,896
И в отличие от нашего полиномиального

126
00:04:26,920 --> 00:04:28,459
примера мы не знаем, что тета-3 и

127
00:04:28,460 --> 00:04:29,826
тета-4 - это составляющие полинома

128
00:04:29,826 --> 00:04:32,641
высокого порядка.

129
00:04:32,641 --> 00:04:34,515
Если у нас есть просто багаж, набор из сотни

130
00:04:34,540 --> 00:04:35,863
признаков, то сложно

131
00:04:35,863 --> 00:04:38,074
выбрать заранее те,

132
00:04:38,100 --> 00:04:40,210
которые скорее всего

133
00:04:40,260 --> 00:04:42,729
нам подходят.

134
00:04:42,729 --> 00:04:45,773
У нас сто или сто один параметр.

135
00:04:45,780 --> 00:04:47,340
Мы не знаем, какой взять.

136
00:04:47,340 --> 00:04:48,987
Мы не знаем, какие параметры надо

137
00:04:49,010 --> 00:04:50,445
учитывать в большей

138
00:04:50,450 --> 00:04:54,272
или меньшей степени.

139
00:04:54,430 --> 00:04:56,237
Итак, для регуляризации, вот что

140
00:04:56,237 --> 00:04:58,438
мы сделаем: мы возьмем

141
00:04:58,438 --> 00:05:01,213
функцию затрат (вот функция затрат для линейной регресии).

142
00:05:01,213 --> 00:05:02,656
Я собираюсь изменить

143
00:05:02,660 --> 00:05:04,326
функцию затрат, чтобы

144
00:05:04,340 --> 00:05:06,246
уменьшить все параметры,

145
00:05:06,270 --> 00:05:07,643
потому что, я не знаю, какой из них

146
00:05:07,643 --> 00:05:09,059
(один или два)

147
00:05:09,059 --> 00:05:10,440
стоит уменьшать.

148
00:05:10,440 --> 00:05:11,690
Я собираюсь изменить функцию затрат, добавив элемент

149
00:05:11,690 --> 00:05:16,732
в конце.

150
00:05:17,390 --> 00:05:20,436
*закрываем квадратную скобку*

151
00:05:20,440 --> 00:05:22,212
Когда я

152
00:05:22,212 --> 00:05:23,516
добавляю новый

153
00:05:23,530 --> 00:05:25,510
элемент регуляризации в

154
00:05:25,560 --> 00:05:27,286
конце для
того, чтобы уменьшить каждый

155
00:05:27,320 --> 00:05:28,745
параметр. И этот элемент в конце

156
00:05:28,760 --> 00:05:30,747
призван уменьшить все мои

157
00:05:30,747 --> 00:05:32,746
параметры: тета-1, тета-2, тета-3 итд до

158
00:05:32,746 --> 00:05:35,490
тета-100.

159
00:05:36,790 --> 00:05:39,629
Кстати, по соглашению сумма начинается с единицы,

160
00:05:39,629 --> 00:05:41,007
таким образом, я не налагаю

161
00:05:41,007 --> 00:05:43,341
штраф на тета-0, которое

162
00:05:43,360 --> 00:05:45,416
может быть большим.

163
00:05:45,470 --> 00:05:46,435
Это всего

164
00:05:46,435 --> 00:05:48,664
лишь

165
00:05:48,664 --> 00:05:50,185
соглашение, о том, с какого числа считать i с нуля

166
00:05:50,190 --> 00:05:51,953
до N или с единицы до N.

167
00:05:51,960 --> 00:05:53,464
На практике же, не имеет особого значения,

168
00:05:53,490 --> 00:05:54,788
включено ли тета-0 или нет. Это

169
00:05:54,788 --> 00:05:56,221
очень слабо отражается на

170
00:05:56,221 --> 00:05:59,532
результатах.

171
00:05:59,540 --> 00:06:01,804
Но давайте по умолчанию

172
00:06:01,804 --> 00:06:03,356
производить

173
00:06:03,360 --> 00:06:06,084
регуляризацию  в диапазоне  от тета-1 до тета-100.

174
00:06:06,084 --> 00:06:08,978
Записываем нашу задачу оптимизации, нашу

175
00:06:08,978 --> 00:06:10,655
регуляризованную целевую функцию снова.

176
00:06:10,655 --> 00:06:11,718
Вот она.

177
00:06:11,718 --> 00:06:13,903
Здесь J от тета, где этот

178
00:06:13,970 --> 00:06:15,863
элемент справа - это элемент

179
00:06:15,863 --> 00:06:17,548
регуляризации ламбда - так

180
00:06:17,570 --> 00:06:23,950
называемый параметр

181
00:06:23,973 --> 00:06:26,334
и ламбда нужна

182
00:06:26,334 --> 00:06:28,480
для того, чтобы задавать

183
00:06:28,510 --> 00:06:30,636
соотношение между двумя разными целями.

184
00:06:30,636 --> 00:06:32,478
Первая цель, выраженная

185
00:06:32,500 --> 00:06:34,399
первым слагаемым, - это то, что

186
00:06:34,399 --> 00:06:36,081
мы тренируем,то чему

187
00:06:36,090 --> 00:06:38,350
должна соответствовать наша обучающая выборка.

188
00:06:38,390 --> 00:06:41,083
Мы хотим соответствовать обучающей выборке.

189
00:06:41,083 --> 00:06:42,954
А вторая цель - это мы хотим сохранить

190
00:06:42,954 --> 00:06:44,474
параметры небольшими и это достигается при помощи

191
00:06:44,474 --> 00:06:46,053
второго слагаемого при помощи регуляризационной

192
00:06:46,060 --> 00:06:49,103
цели.При помощи элемента регуляризации.

193
00:06:49,103 --> 00:06:53,583
А для чего нужна ламбда,

194
00:06:53,583 --> 00:06:55,937
параметр регуляризации,

195
00:06:55,937 --> 00:06:57,694
так для того, чтобы регулировать

196
00:06:57,694 --> 00:06:58,938
соотношение между этими целями. То есть

197
00:06:58,960 --> 00:07:00,562
целью соответствовать обучающему множеству и целью

198
00:07:00,562 --> 00:07:02,043
сдерживания роста значений параметров для поддержания

199
00:07:02,080 --> 00:07:05,688
простоты гипотезы,

200
00:07:05,688 --> 00:07:09,134
чтобы предотвратить переобучение.

201
00:07:09,290 --> 00:07:11,026
Для нашего примера с ценами на жилье где мы

202
00:07:11,030 --> 00:07:13,026
изначально хотели использовать полином

203
00:07:13,030 --> 00:07:14,256
высокого порядка

204
00:07:14,256 --> 00:07:15,968
мы пришли к

205
00:07:15,968 --> 00:07:17,461
тому что у нас получилась такая вот

206
00:07:17,480 --> 00:07:19,020
волнистая изогнутая

207
00:07:19,020 --> 00:07:22,460
функция.

208
00:07:22,460 --> 00:07:24,120
Если вы все еще хотите использовать полином со всеми свойствами полинома. Но

209
00:07:24,120 --> 00:07:26,038
вместо этого вы просто используете  одну регуляризированную

210
00:07:26,038 --> 00:07:27,956
целевую функцию

211
00:07:27,970 --> 00:07:30,798
получаете кривую, которая не

212
00:07:30,798 --> 00:07:32,272
совсем

213
00:07:32,272 --> 00:07:34,332
является квадратной функцией, но она гораздо более гладкая и гораздо проще,

214
00:07:34,340 --> 00:07:36,465
примерно как

215
00:07:36,490 --> 00:07:38,510
красная линия,

216
00:07:38,510 --> 00:07:39,870
которая дает

217
00:07:39,870 --> 00:07:42,261
нам  гораздо лучшую гипотезу для этих

218
00:07:42,261 --> 00:07:45,445
данных.

219
00:07:45,445 --> 00:07:46,613
Опять-таки, я понимаю, что может вызвать у вас

220
00:07:46,613 --> 00:07:47,919
сложности понимание того,  что

221
00:07:47,919 --> 00:07:50,064
ограничение параметров может  оказать

222
00:07:50,064 --> 00:07:51,668
такое влияние,

223
00:07:51,690 --> 00:07:54,584
но если вы сами  реализуете регуляризацию, то вы

224
00:07:54,650 --> 00:07:56,063
увидите сами,  что такой

225
00:07:56,090 --> 00:07:58,859
эффект имеет место.

226
00:08:00,620 --> 00:08:02,777
В регуляризированной

227
00:08:02,777 --> 00:08:05,748
линейной регресии в

228
00:08:05,748 --> 00:08:07,669
случае если регуляризационный

229
00:08:07,669 --> 00:08:09,542
коэффициент

230
00:08:09,542 --> 00:08:11,698
очень

231
00:08:11,698 --> 00:08:13,513
большой,то штраф к параметрам

232
00:08:13,520 --> 00:08:15,207
тета-1,  тета-2, тета-3, тета-4  очень

233
00:08:15,230 --> 00:08:17,409
большой.

234
00:08:17,430 --> 00:08:21,916
Это в том случае, если наша гипотеза вот эта вот, которая внизу.

235
00:08:21,930 --> 00:08:23,674
Если мы штрафуем

236
00:08:23,674 --> 00:08:24,913
тета-1, тета-2, тета-3,тета-4 сильно,

237
00:08:24,990 --> 00:08:26,145
то в результате мы получаем эти

238
00:08:26,145 --> 00:08:29,463
параметры близкие к нулю.

239
00:08:29,463 --> 00:08:32,240
Тета-1 будет близка к нулю, тета-2 будет близка к нулю.

240
00:08:32,240 --> 00:08:34,410
Тета-3 и тета-4 будут близки к

241
00:08:34,410 --> 00:08:36,646
нулю тоже.

242
00:08:36,646 --> 00:08:37,810
И если мы так сделаем, если

243
00:08:37,810 --> 00:08:39,143
мы избавимся от этих

244
00:08:39,160 --> 00:08:41,189
компонентов в гипотезе, то у

245
00:08:41,189 --> 00:08:43,597
нас получится гипотеза,  о

246
00:08:43,597 --> 00:08:44,224
которой мы только что говорили.

247
00:08:44,230 --> 00:08:46,020
Согласно ей, цена на жилье

248
00:08:46,020 --> 00:08:48,624
равна тета-0,  и это отображается

249
00:08:48,650 --> 00:08:50,830
на графике как горизонтальная

250
00:08:50,830 --> 00:08:54,679
прямая.

251
00:08:54,679 --> 00:08:56,533
И это пример недостаточного соответствия

252
00:08:56,570 --> 00:08:58,773
точности.

253
00:08:58,773 --> 00:09:00,926
Эта гипотеза,  эта прямая линия

254
00:09:00,950 --> 00:09:02,552
не соответствует  даже тренировочной  выборке в

255
00:09:02,570 --> 00:09:04,063
достаточной

256
00:09:04,070 --> 00:09:05,423
степени.

257
00:09:05,423 --> 00:09:07,173
Это просто жирная прямая линия, которая не проходит даже близко от наших точек.

258
00:09:07,173 --> 00:09:10,432
Она не проходит близко от большинства тренировочных примеров.

259
00:09:10,432 --> 00:09:11,592
Иными словами,

260
00:09:11,592 --> 00:09:13,697
гипотеза

261
00:09:13,720 --> 00:09:15,410
слишком сильно привязана,

262
00:09:15,450 --> 00:09:17,091
слишком сильно убеждена,  что цена на

263
00:09:17,120 --> 00:09:18,446
жилье равна тета-0,  что игнорирует

264
00:09:18,460 --> 00:09:20,183
сами данные,

265
00:09:20,230 --> 00:09:22,123
которые это опровергают,

266
00:09:22,123 --> 00:09:23,207
и предпочитает быть

267
00:09:23,207 --> 00:09:25,648
просто  плоской линией, простой горизонтальной

268
00:09:25,650 --> 00:09:28,230
линией.Я не очень хорошо это нарисовал.

269
00:09:28,230 --> 00:09:30,447
Это просто прямая горизонтальная линия к

270
00:09:30,447 --> 00:09:33,059
данным.

271
00:09:33,060 --> 00:09:35,626
Чтобы регуляризация хорошо работала,  нам

272
00:09:35,626 --> 00:09:37,835
нужно позаботиться о том,  чтобы

273
00:09:37,850 --> 00:09:39,903
правильно выбрать  параметр

274
00:09:39,903 --> 00:09:42,991
регуляризации ламбда.

275
00:09:42,991 --> 00:09:44,908
Когда мы будем говорить про множественный

276
00:09:44,920 --> 00:09:46,717
выбор в этом курсе чуть позже, мы

277
00:09:46,717 --> 00:09:48,413
рассмотрим несколько способов

278
00:09:48,420 --> 00:09:50,803
автоматического выбора  регуляризационного

279
00:09:50,810 --> 00:09:54,833
параметра ламбда.

280
00:09:54,833 --> 00:09:56,570
Итак, это идея регуляризации

281
00:09:56,570 --> 00:09:58,254
высоких степеней и пересмотра

282
00:09:58,254 --> 00:10:00,454
функции затрат с тем,  чтобы использовать

283
00:10:00,454 --> 00:10:01,885
регуляризацию.

284
00:10:01,885 --> 00:10:03,736
В следующих двух видео,  мы

285
00:10:03,750 --> 00:10:05,440
применим эти идеи  к линейным

286
00:10:05,440 --> 00:10:07,111
регрессиям и к логистическим регрессиям,

287
00:10:07,111 --> 00:10:09,020
таким образом, чтобы в них мы

288
00:10:09,060 --> 00:10:10,982
тоже смогли избежать избыточной точности.