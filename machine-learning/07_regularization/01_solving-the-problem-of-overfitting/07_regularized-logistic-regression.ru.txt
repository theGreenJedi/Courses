Ранее мы говорили о двух типах алгоритмов оптимизации для логистической регрессии. Мы рассказали как использовать градиентный спуск чтобы оптимизировать значение функции J от тета. Мы также рассказали о продвинутых методах оптимизации. Единственное что требуется это что вы обеспечите возможность вычислить значение функции затрат J от тета и возможность вычислить производные. В этом видео мы покажем, как вы можете адаптировать оба эти способа, оба метода градиентного спуска, и более передовые методы оптимизации, с целью заставить их работать в регуляризованной логистической регрессии. Итак, вот сама идея. Мы увидели ранее что логистическая регрессия может быть склонна к переобучению, если вы, скажем, аппроксимируете ее полиномом признаков высокого порядка такие как этот. Где G есть сигмоидная функция. И в данном случае, вы, в конце концов, придете к гипотезе, граница разрешимости которой будет такой чересчур сложной и весьма кривой функцией, определенно не лучшей для данного учебного набора. Вообще, если у вас есть логистическая регрессия со многими признаками, -- не обязательно полиномиальными, просто со многими -- вы, в конечном итоге, можете получить переобучение. Это была наша функция затрат для логистической регрессии. И если мы хотим использовать регуляризацию, то все, что нам для этого нужно - добавить следующее слагаемое lambda, деленное на 2M и умноженное на сумму по J от 1, где суммирование по J начинается с 1. А не с 0, от квадратов тета с индексом j. А это, в свою очередь, оказывает ограничивающий эффект на параметры тета 1 и тета 2  и т.д. до тета N, предупреждая их неограниченный рост. Если вы проделаете это, даже несмотря на использование полиномов очень высокого порядка со множеством параметров, эффект сохранится. Пока вы применяете регуляризацию и сохраняете параметры малыми, вы, скорее всего, получите границу разрешения. Которая может быть более похожа на это. Кажется, более разумным для отделения положительных и отрицательных примеров. Таким образом, когда используется регуляризация даже со многими признаками, это может помочь избавиться от проблемы переобучения. Как мы можем реализовать это на практике? Ну, это и было усовершенствование для исходного метода градиентного спуска. Мы последовательно произведем следующее обновление для тета с индексом j. Этот слайд во многом похож на предыдущий для линейной регрессии. Но то, что я собираюсь сделать – записать обновление тета c индексом 0 отдельно. Итак, первая строка - обновление тета с индексом 0, а вторая строка – моё обновление для тета с индексами от 1 до N. Поскольку я собираюсь рассмотреть тета c индексом 0 отдельно. Чтобы модифицировать этот алгоритм и использовать регуляризованную функцию затрат, все что мне нужно сделать - это просто изменить второе измененное правило похожим на то, что мы делали для линейной регрессии, таким образом, а именно. Повторюсь, это, внешне похоже на тот алгоритм, что у нас был для линейной регрессии. Но это, естественно, не тот же самый алгоритм, как ранее, потому что сейчас гипотеза определена, используя вот это. Итак, это не такой же алгоритм, как для регуляризованной линейной регрессии. Поскольку гипотеза другая. Несмотря на те изменения, что я записал. На самом деле, внешне выглядит так же как и то, что было раньше. Когда мы получали метод градиентного спуска для регуляризованной линейной регрессии. И, чтобы резюмировать обсуждение, это выражение в квадратных скобках, вот здесь - это новая частная производная по тета с индексом j от новой функции стоимости J от тета. Где J от тета - функция затрат, использующая регуляризацию, которую мы определили на предыдущем слайде А это - метод градиентного спуска для регуляризованной линейной регрессии. Теперь давайте поговорим о том, как заставить работать регуляризованную линейную регрессию, используя продвинутые методы оптимизации. И только для того, чтобы напомнить о том, что необходимо делать в этих методах, - нужно было определить функцию, которая называется функцией затрат и принимает в качестве аргумента вектор параметров тета, при этом во всех уравнениях, которые мы здесь писали, использовались вектора, начинающиеся с индекса 0. Итак, у нас была тета с индексами от 0 до N. Но из-за того, что Octave индексирует вектора начиная с индекса 1.Тета с индексом 0 записывается в Octave в виде тета с индексом 1. Тета с индексом 2 записывается как тета 2, и так далее до тета с индексом N+1. И то, что нам нужно было сделать - определить функцию. Давайте определим функцию, называемую функцией затрат, которую бы мы затем подставили в то, что у нас есть и что мы видели ранее. Мы будем использовать fmiunc для функции затрат, и так далее, правильно? Здесь, fminunc - функция поиска минимум F min без ограничения параметров. Мы будем работать с fminunc, которая просто  возьмет функцию затрат и минимизирует ее для нас. Итак, две основные вещи, которые функция затрат должна возвращать, это, во-первых J-val. Для этого нам необходимо написать код вычисления функции J от тета. Теперь, когда мы используем логистическую регрессию, функция затрат J от тета, конечно же, меняется и, в частности, теперь необходимо так же включить это дополнительное регуляризующее слагаемое в конце в функцию затрат. Убедитесь, что включили это слагаемое в конце, когда вычисляете J от тета. А также другие вещи, необходимые в функции затрат для получения градиента. Так, градиент с индексом 0 - частная производная J от  тета по тета с индексом 0, градиент с индексом 2 - вот это, и так далее. Повторюсь, индекс смещен на единицу. Правильно, из-за индексирования с единицы, которое использует Octave. И, глядя на эти слагаемые. Этот термин здесь. Мы уже получали его на предыдущем слайде, что это, вообще-то, равно вот этому. Оно не меняется. Поскольку производная по тета  с индексом 0 не меняется. По сравнению с версией без регуляризации. А другие слагаемые меняются. В частности, производные по тета с индексом 1. Мы также получали это на предыдущем слайде. Оно равняется изначальному слагаемому минус lambda, деленная на M и умножить на тета с индексом 1. Таким образом, убеждаемся, что провели это без ошибок. И мы можем добавить скобки сюда. Так, что суммирование не распространяется. И, аналогично, это другое слагаемое вот здесь выглядит как то с дополнительным слагаемым на предыдущем слайде, которое соответствует градиенту от их регуляризованной целевой функции. Так что если вы реализуете эту новую функцию затрат и передадите в fminuic или в один из тех продвинутых оптимизаторов, которые минимизируют новую регуляризованную функцию затрат J от тета. И параметры, которые вы получите, будут теми, которые соответствуют логистической регрессии с регуляризацией. Теперь вы знаете, как реализовать регуляризованную логистическую регрессию. Если пройтись по Кремниевой Долине, а я живу в Кремниевой Долине, то здесь много инженеров, которые зарабатывают кучу денег для своих компаний, используя методы машинного обучения Я знаю, что мы с вами изучаем это совсем недавно. Но если вы к настоящему моменту поняли линейную регрессию, продвинутые алгоритмы оптимизации и регуляризацию, то, честно говоря, вы возможно уже знаете намного больше о машинном обучении, конечно сейчас, намного больше, чем значительная часть преуспевающих инженеров Кремниевой Долины. Которые зарабатывают кучу денег для компаний. Или создают программные продукты используя алгоритмы машинного обучения. Итак, - мои поздравления. Вы проделали большой путь. Теперь вы знаете достаточно, чтобы применить эти подходы на практике для решения множества задач. Поздравляю Вас с этим. Конечно, предстоит изучить еще многое и в следующих видео мы начнем изучать мощные инструменты нелинейной классификации . Тогда, как в линейной регрессии, логистической регрессии вы можете формировать полиномиальные выражения, оказывается что существуют более мощные нелинейные квантификаторы, которые могут затем выделить полиномиальную регрессию. И в следующих за этим видео я начну рассказывать вам о них. Чтобы у вас были еще более мощные алгоритмы, чем сейчас, и чтобы вы могли применить их и к другим задачам.