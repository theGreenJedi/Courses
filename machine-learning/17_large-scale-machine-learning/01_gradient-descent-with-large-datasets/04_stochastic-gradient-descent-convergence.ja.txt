いまや、あなたは確率的最急降下法のアルゴリズムについて知った。 だがアルゴリズムを実行している時、あなたはどうやってバグが無い、とかちゃんと収束している、という事を確認すれば良いだろうか？ 同じように重要な事として、どうやって確率的最急降下法においてどうやって学習率のアルファをチューンしたら良い？ このビデオでは、これらを行う幾つかのテクニックを紹介する、収束を確認する方法と学習率アルファを選ぶ方法。 バッチ最急降下法を使ってた頃を思い返すと、最急降下法が収束していたかを 確認する標準的な方法は、最適化の目的関数の値を繰り返しの回数の関数としてプロットする事だった。 これがコスト関数で、このコスト関数が各イテレーションで減少している事を確認したい。 トレーニングサイズが小さい時はそれが出来た。
何故なら和の計算がとても早く行えたからだ。 だが大量のトレーニングセットのサイズがあると、定期的にアルゴリズムを止めて、、、 確率的最急降下法を定期的に止めてこのコスト関数を計算したくは無い、何故なら、 このコスト関数の計算には、トレーニングセットサイズ全体に渡る和を必要とするから。 そもそもに確率的最急降下法のポイントは、全て、アルゴリズムの途中でトレーニングセット全体を スキャンする必要無しに、一つの手本を見ただけで歩を進める事が出来る、 という物だった。
コスト関数などを計算する為だけにトレーニングセット全体を見る、というような事無しに。 だから確率的最急降下法においてアルゴリズムが収束しているのを確認する為にやる事としては、代わりにこんな事をやる。 前に定義したコスト関数を使おう。 単体のトレーニング手本に関するパラメータシータでのコストは、単にそのトレーニング手本における二乗誤差の半分だ。 そして、確率的最急降下法を学習させている間、ある特定のサンプルを学習させる直前、 つまり確率的最急降下法で順番に見ていって、あるサンプルxi, yiをこれから見よう、という時、 この次にはこのサンプルによるちょっとの更新を行う訳だ。 そして次の手本、x(i+1), y(i+1)に進む、などなど。 以上が確率的最急降下法がやる事だが、 つまりアルゴリズムが手本xi, yiを見ているが、まだパラメータシータをその手本を使ってアップデートしていない時の、 その手本のコストを計算してみよう。 同じ事をちょっとだけ異なる言葉で言い換えてみよう。 確率的最急降下法がトレーニングセットをスキャンしていく訳だが、ある手本 x(i), y(i) を使ってシータをアップデートする直前で、 そのトレーニング手本に対し仮説がどれだけ良いかを計算してみよう。 これをシータをアップデートする前に行いたいのは、もしシータをその手本でアップデートした後では、 その手本については代表的な値よりももっと良くなってしまうから。 最後に、確率的最急降下法が収束しているかをチェックする為に出来る手段としては、各1000繰り返しごとに その前のステップで計算したこれらのコスト関数をプロットする、というのがある。 アルゴリズムに処理された最後の1000手本に渡るコストの平均をプロット出来る。 これをやると、アルゴリズムがどれくらいうまく行ってるかのランニングでの推計が得られる。 アルゴリズムが見た最後の1000手本に関しての。 J trainを定期的に計算するのと比べると、そちらはトレーニングセット全体をスキャンする必要があるが、 この方法だと、確率的最急降下法の一部として、 パラメータシータをアップデートする直前にこれらのコストを計算するのは、そんなに高くはつかない。 我らがやる事は、各1000イテレーションごととかに、そこまでに計算した最後の1000コストを平均して、それをプロットする。 そのプロットを見る事で、確率的最急降下法が収束しているかをチェックする事が出来る。 ここに、そのプロットがどんな風になりうるかの例がある。 最後1000手本に渡るコストの平均をプロットしたとしよう、 これは1000個だけの手本に渡る平均なので、ちょっとノイジーになるだろう、そして 各イテレーションで必ず減少する、という訳でも無かろう。 そしてこんな感じの図が得られたとすると、プロットはノイジーでしょう、 何故なら小さなサブセット、1000個のトレーニング手本に渡ってだけの平均だから。 で、もしこんな感じの図を得られたなら、これは結構良くアルゴリズムは実行されている、 コストが下がっていって、その先である点から台地のように平坦になってる、こんな場合は。 コストがこんな感じの時は、学習アルゴリズムはきっと収束している。 もしもっと小さい学習率を用いて試したければ、その結果はこんな見た目で、 アルゴリズムは最初はゆっくりと学習していく。だからコストはもっとゆっくりと下がっていく。 だがやがてより小さい学習率だと、アルゴリズムは、たぶんちょっとだけ良い解となる。 赤い線で、よりゆっくりな、より小さい学習率を用いた時の確率的最急降下法の場合を表すとする。 この場合により良い解となる理由は、確率的最急降下法はグローバル最小に収束するのでは無く、 グローバル最小の回りをちょっとだけ振動するのだった。 だからより小さい学習率を使う事で、最終的にはより小さな振幅にする事が出来る。 時にはこの小さな違いは無視出来る物だろう、 時にはより小さい方がわずかに良いパラメータの値を得られるだろう。 こんな場合もありうる。 確率的最急降下法を走らせて、これらの1000個の手本に渡ってコストを平均してプロットしたとして、 こんな結果が得られる場合もある。 この場合も、一種の収束しているように見える。 もしこの数字、1000を増やして5000手本に渡って平均をとれば、 もっとスムースなカーブ、もっとこんな感じのが得られたと思われる。 1000手本の代わりに5000手本に渡って平均を取るとすると、もっとスムースなカーブ、こんな感じの物が得られるだろう。 それが平均を取る対象の手本の数を増やす効果だ。 この値を大きくし過ぎた場合の欠点はもちろん、5000手本につき、たった一つの点しか得られないという事。 だからアルゴリズムがどの位良く動いているかのフィードバックを得るのが、より遅れる事になる。 何故ならプロット上の1点を得る為に1000手本じゃなくて5000手本ごとになるからだ。 同様に最急降下法を走らせると、こんなプロットが得られる事もある。 このプロットでは、コストは全く減少してないように見える。 アルゴリズムは全く学習していないように見える。 ここはフラットなカーブで、コストは低下してないように見える。 だがこの場合も、平均を取る範囲を大きくすると、 この赤い線のような物が得られる可能性がある。 コストは実際に減少しているように見える。
青い線は2, 3の手本に渡ってだけの平均。 青い線はあまりにもノイジーなので、実際のトレンド、コストが実際に低下しているというトレンドが見えない。 そして1000の代わりに5000手本に渡って平均を取るという事が、助けになるかもしれない。 もちろん、大きな数の手本に渡って平均をとっても、ここでは5000手本に渡って平均をとってみたが、 ここでは別の色を使ったが、その時に、こんな風に学習曲線がなる場合もありうる。 大きな数の手本に渡って平均しても、フラットなままだ。 そしてそれが得られたら、それは不運にも何らかの理由で、 アルゴリズムがあまり学習出来ていない、という事に、より固く確信を持てる。 そして学習率を変えるなりフィーチャーを変えるなり、またはアルゴリズムに関しての何かを変えるなりをしなくてはならない。 最後にもう一つ、これらの曲線をプロットしてみたら、 そうしたらこんな曲線を得たとすると、つまり実際に増加しているようにみえたら、 その時はそれはアルゴリズムが発散しているサインだ。 その場合にすべき事は、より小さい値の学習率アルファを使う事だ。 以上で、ある範囲の手本に渡るコスト関数の平均をプロットした時に、 どんな事が起こりうるのか、そのそれぞれのプロットごとのオススメの対応について、 感じがつかめたかな。 もしプロットがあまりにもノイジーに見えたら、またはくねくねあがったり下がったりしすぎているようなら、平均を取る手本の範囲を増やしてみてくれ、 するとプロットの全体的なトレンドをより良く分かるようになるだろう。 そして誤差が実際に増加していたら、コストが実際に増加していたら、より小さい値のアルファを試してみてくれ。 最後に、学習率の問題についてもうちょっと良く見てみよう。 確率的最急降下法を走らせると、アルゴリズムはここから始まって、最小に向かってくねくねと歩くのを見た。 そしてそれは実際には収束せずに、そのかわりに最小の付近を永遠にうろちょろし続ける。 つまり、最終的にはグローバル最小に近いパラメータが得られる事が期待出来るが、完全にグローバル最小に一致する訳では無い。 もっとも典型的な確率的最急降下法の実装では、学習率アルファは定数のまま据え置くのが普通だ。 つまり最終的に得られるのはまさにこんな図となる。 もし確率的最急降下法に実際にグローバル最小に収束してほしい、と思うなら、 一つ考えられる手としては、学習率アルファを時間がたつにつれて徐々に下げていく、という物がある。 割と良くやるのは、アルファをイコール、constant1割る事のイテレーション数+constant2、とかそんな数字にする。ここでconstant1とconstant2は何らかの定数。 イテレーション数というのは確率的最急降下法の何回目のイテレーションか、を表す物で、 ようするにそこまで見たトレーニング手本の数だ。 そしてconst1とconst2はアルゴリズムの追加のパラメータで、 良いパフォーマンスを得る為にいじらなくてはいけないかもしれない物だ。 この方法を人々があんまり取らない理由としては、これら二つの追加のパラメータ、constant1とconstant2を 調整するのに時間を食われるからだ。
そのせいでアルゴリズムが気難しくなる。 つまりアルゴリズムがうまく行くように時間を浪費するハメになるパラメータが増えるのだ。 だがもしパラメータをいい感じにチューン出来たら、得られる図は、 アルゴリズムが最初はふらつきつつ、最小に向かっていくが、だが近づくと、 学習率もそれにつれてどんどん下がっていくので、ふらつきは小さくなり、 グローバル最小に至るまで小さくなり続ける。
これは納得出来るだろう。 そしてこの式が納得出来る理由は、アルゴリズムが走るにつれて、イテレーション回数も大きくなっていくので、アルファはゆっくりと小さくなっていき、 すると一歩一歩がどんどん小さくなっていき、それはグローバル最小に収束するまで小さくなり続ける。 つまり、アルファをゆっくりと0へと減少させていくと、最終的にはちょっとだけ良い仮説が得られる。 だが、定数をいじるのにかかる余計な仕事と、さらにざっくばらんに言ってしまえばグローバル最小に近いんなら、 どんなパラメータの値でもまったく幸せなので、 典型的には、このアルファをゆっくり減少させる、という手続きは、普通はやらん。で、確率的最急降下法を適用する時には、 アルファは定数のままにしておく方がもっと普通だ。
どちらのバージョンを使う人も見かけはするけど。 まとめると、このビデオでは、確率的最急降下法がどうなってるかを コスト関数の観点から近似的にモニタリングする方法を議論した。 これはコスト関数を計算する為に定期的にトレーニングセット全体をスキャンする必要が無くて、 代わりに例えば最後の1000手本とかを見る手法だ。 そしてこの手法は確率的最急降下法がうまく機能していて、収束している、という事を確認するのにも、 学習率アルファをチューンするのにも用いる事が出来る。