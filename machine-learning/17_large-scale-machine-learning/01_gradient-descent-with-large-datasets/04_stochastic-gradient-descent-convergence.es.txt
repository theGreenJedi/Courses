Ustedes ahora ya saben acerca del algoritmo de gradiente de descenso estocástico, pero cuando están ejecutando el algoritmo, ¿cómo se aseguran de que está completamente depurado y que está convergiendo bien? Igualmente importante, ¿cómo sintonizan el índice de aprendizaje «alfa» con el gradiente de descenso estocástico?. En este vídeo hablaremos de algunas técnicas para hacer esto, para asegurarse de que está convergiendo, y para captar el índice de aprendizaje «alfa». Antes, cuando usamos el gradiente de descenso por lotes, nuestra forma estándar para asegurarnos de que el gradiente de descenso estaba convergiendo, fue que trazamos la función de costos de optimización como una función del número de iteraciones. Así que esa fue la función de costos y nos debemos asegurar de que esta función de costos disminuya en cada iteración. Cuando los tamaños de los conjuntos de entrenamiento eran pequeños, podíamos hacer eso porque podíamos calcular la suma de manera eficaz. Pero cuando se tiene un tamaño enorme de conjunto de entrenamiento, entonces usted no desea tener que pausar su algoritmo de manera periódica, no quiere pausar el gradiente de descenso estocástico periódicamente a fin de calcular la función de costos ya que requiere una suma del tamaño del conjunto de entrenamiento completo y todo el punto del gradiente estocástico fue que deseaban empezar a hacer progresos después de ver sólo un ejemplo, sin necesidad de revisar de vez en cuando a través de todo el conjunto de entrenamiento justo a la mitad del algoritmo, sólo para calcular cosas como la función de costos de todo el conjunto de entrenamiento. Así que para el gradiente de descenso estocástico, a fin de verificar que el algoritmo está convergiendo, esto es lo que podemos hacer en su lugar. Tomemos la definición del costo que teníamos con anterioridad, de modo que el costo de los parámetros «theta» con respecto a un solo ejemplo de entrenamiento es sólo una mitad del error al cuadrado en ese ejemplo de entrenamiento. Después, mientras que el gradiente de descenso estocástico está aprendiendo, justo antes de que entrenemos en un ejemplo concreto, en el gradiente de descenso estocástico vamos a mirar los ejemplos «xi», «yi» en orden, y después tomamos una pequeña actualización con respecto a este ejemplo, y pasamos al siguiente ejemplo, «xi» más 1, «yi» más 1, y así sucesivamente, ¿correcto? Eso es lo que hace el gradiente de descenso estocástico. Así que, mientras el algoritmo está mirando el ejemplo «xi, yi», pero antes de que haya actualizado los parámetros «theta» usando ese ejemplo, vamos a calcular el costo de ese ejemplo. Sólo para decir lo mismo otra vez, pero usando palabras ligeramente diferentes, un gradiente de descenso estocástico está buscando a través de nuestro conjunto de entrenamiento justo antes de que actualicemos «theta», utilizando un ejemplo de entrenamiento específico «x(i)» coma «y(i)»; vamos a calcular qué tan bien está funcionando nuestra hipótesis en ese ejemplo de entrenamiento. Y queremos hacer esto antes de actualizar «theta» porque si sólo hemos actualizado «theta» utilizando ese ejemplo de entrenamiento, ya saben, eso podría estar funcionando mejor en ese ejemplo de lo que sería representativo. Por último, a fin de comprobar la convergencia del gradiente de descenso estocástico, lo que podemos hacer es cada, digamos, cada mil iteraciones, podemos trazar estos costos que hemos estado calculando en el paso anterior. Podemos trazar esos costos promedio sobre, digamos, los últimos mil ejemplos procesados ​​por el algoritmo. Y si lo hacen así, es posible que les dé un cálculo sobre qué tan bien está funcionando el algoritmo sobre, ya saben, los últimos 1000 ejemplos de entrenamiento que su algoritmo ha observado. Así, en lugar de calcular «J entrenar» periódicamente, lo que haría necesario revisar a través de todo el conjunto de entrenamiento,</u> con este otro procedimiento, como parte del gradiente de descenso estocástico, no cuesta mucho calcular estos costos también, justo antes de actualizar al parámetro «theta». Y todo lo que estamos haciendo es, cada mil integraciones más o menos, simplemente promediamos los últimos 1000 costos que hemos calculado y trazamos eso. Y al ver esos gráficos, esto nos permitirá comprobar si el gradiente de descenso estocástico está convergiendo. Así que aquí están algunos ejemplos de cómo pudieran verse estos gráficos. Supongan que han trazado el costo promedio sobre los últimos mil ejemplos, debido a que éstos se promedian sobre sólo un millar de ejemplos, van a ser un poco ruidosos, así que pudieran no disminuir en cada iteración individual. Entonces, si obtienen una figura como esta, de manera que el gráfico es ruidoso porque su promedio está sobre sólo un pequeño subconjunto, por decir, un millar de ejemplos de entrenamiento, si obtiene una figura que se vea así, ya saben, eso sería una ejecución bastante decente con el algoritmo tal vez, en donde parece que el costo ha bajado y entonces esta meseta que parece un poco aplanada, ya saben, empezando alrededor de ese punto. Así que parece que así es como se ven sus costos; entonces tal vez su algoritmo de aprendizaje ha convergido. Si desean probar el uso de una frecuencia de aprendizaje más pequeña, algo que pueden ver es que el algoritmo puede aprender más lentamente al inicio, por lo que el costo se reduce más lentamente, pero luego, eventualmente, tienen una frecuencia de aprendizaje más pequeña. En realidad, es posible que el algoritmo termine en una solución ligeramente mejor. De modo que la línea roja puede representar el comportamiento del gradiente en descenso estocástico usando una frecuencia de aprendizaje menor, más lenta. Y la razón de que este es el caso se debe a que, si recuerdan, el gradiente de descenso estocástico no sólo converge en el mínimo global, es que lo que hace es que los parámetros oscilarán un poco alrededor del mínimo global. Así que, mediante el uso de un índice de aprendizaje más pequeño, terminarán con oscilaciones más pequeñas. Y a veces, esta pequeña diferencia será insignificante, y algunas veces con el más pequeño pueden obtener un valor ligeramente mejor para los parámetros. Aquí hay algunas otras cosas que podrían ocurrir. Digamos que ejecutan el gradiente de descenso  estocástico y tienen un  promedio de más de mil ejemplos cuando trazan estos costos. Así que aquí podría estar el resultado de otro de estos gráficos. De nuevo, parece que ha convergido. Si fueran a tomar este número, mil, y aumentar a un promedio de más de 5000 ejemplos, entonces es posible que pudieran obtener una curva más suave que se parece más a esto. Y al promediar sobre estos, digamos 5000 ejemplos en lugar de 1000, podrían ser capaces de obtener una curva más suave como esta. Y eso es el efecto de aumentar el número de ejemplos sobre los cuales promediar. La desventaja de hacer esto demasiado grande, es que, por supuesto, ahora tienen un punto de datos sólo cada 5,000 ejemplos. Así que la retroalimentación que obtienen sobre lo bien que está funcionando su algoritmo de aprendizaje es tal vez más retrasada debido a que obtuvieron un punto de datos en su gráfico sólo cada 5,000 ejemplos, en vez de cada 1,000 ejemplos. Siguiendo una linea de pensamiento similar, algunas veces pudieran ejecutar un gradiente de descenso estocástico y terminar con un gráfico que se parece a esto. Y con un gráfico que se parezca a esto, ya saben, parece que el costo simplemente no disminuye en absoluto, parece que el algoritmo sencillamente no está aprendiendo. Sólo parece que aquí hay una curva plana y que el costo no está disminuyendo. Pero, de nuevo, si aumentaran esto para promediar sobre un mayor número de ejemplos, es posible que observen algo como esta línea roja, parece que el costo realmente está disminuyendo, es sólo que la línea azul con un promedio de más de 2, 3 ejemplos, la línea azul era demasiado ruidosa, así que no se podía ver la tendencia real del costo disminuyendo en realidad y posiblemente promediar más de 5,000 ejemplos, en lugar de 1,000, pudiera ayudar. Por supuesto, cuando promediamos sobre un número de ejemplos más grande, si promediáramos sobre 5,000 ejemplos, sólo estoy utilizando un color diferente, también es posible que vean una curva de aprendizaje que termina viéndose así. Que sigue siendo plana, incluso cuando promedian sobre un número mayor de ejemplos. Y si obtienen eso, entonces eso es una verificación más firme de que, desafortunadamente, el algoritmo no está aprendiendo mucho por alguna razón. Y necesitan cambiar el índice de aprendizaje, o cambiar las variables, o cambiar algo más sobre el algoritmo. Finalmente, una última cosa que pudieran observar si tuvieran que trazar estas curvas y ven una curva que se ve así, en donde realmente parece que está aumentando, y si ese es el caso, entonces esto es una señal de que el algoritmo es divergente. Y lo que realmente deben hacer es utilizar un valor menor de la «alfa» del índice de aprendizaje. Así que espero que esto les dé un sentido de los fenómenos que pudieran ver cuando trazan este promedio de costos sobre algún rango de ejemplos, al igual que sugerir el tipo de cosas que pudieran tratar de hacer cuando ven diferentes gráficos. De modo que si los gráficos parecen demasiado ruidosos, o si se menea demasiado hacia arriba y hacia abajo, entonces traten de aumentar el número de ejemplos sobre los que están promediando, de modo que puedan ver mejor la tendencia general en el gráfico. Y si ven que los errores están en realidad aumentando, los costos están aumentando, traten de utilizar un valor de «alfa» más pequeño. Por último, vale la pena examinar la cuestión del índice de aprendizaje un poco más. Vimos que cuando ejecutamos el gradiente de descenso estocástico, el algoritmo comienza aquí y hará un tipo de serpenteo hacia el mínimo, y entonces realmente no convergerá y, en su lugar, va a deambular alrededor de la mínima por siempre. Así que terminan con un valor de parámetro que con suerte está cerca del global mínimo  pero que no estará exactamente en el mínimo global. En las implementaciones más típicas del gradiente de descenso estocástico, el índice de aprendizaje «alfa» suele mantenerse constante. Así que con lo que terminamos, es una imagen como esta. Si desean que el gradiente de descenso estocástico converja realmente al mínimo global, hay una cosa que pueden hacer, que es que pueden disminuir lentamente el índice de aprendizaje «alfa» a través del tiempo. Por lo tanto, una forma muy típica de hacerlo sería establecer «alfa» es igual a cierta constante 1, dividida por el número de iteración, más la constante 2. De modo que el número de iteración es el número de iteraciones que han ejecutado del gradiente de descenso estocástico, en realidad es el número de ejemplos de entrenamiento que han visto, y la const 1 y la const 2 son los parámetros adicionales del algoritmo con los que tuviera que jugar un poco a fin de obtener un buen desempeño. Una de las razones por la que las personas tienden a no hacer esto es porque terminan teniendo que invertir tiempo jugando con estos 2 parámetros adicionales, la constante 1 y la constante 2, y esto hace que el algoritmo sea más meticuloso. Ya saben, son sólo más parámetros con los que se puede juguetear a fin de hacer que el algoritmo funcione bien. Pero si consiguen sintonizar bien los parámetros, entonces la imagen que pueden obtener es que el algoritmo realmente serpenteará alrededor hacia el mínimo, pero a medida que se acerca debido a que están disminuyendo el índice de aprendizaje, el serpenteo se hará cada vez más pequeño, hasta que prácticamente simplemente converge hacia el mínimo global. Espero que esto tenga sentido, ¿cierto? Y la razón por la que esta fórmula tiene sentido es que, a medida que se ejecuta el algoritmo, el número de iteración se hace grande, de manera que «alfa» se hará lentamente pequeño, así que tomarán pasos más y más pequeños hasta que, con suerte, converjan hacia el global mínimo. Así que si disminuyen lentamente «alfa» a cero, pueden terminar con una hipótesis ligeramente mejor. Pero debido al trabajo extra que se necesita para juguetear con las constantes, y porque, francamente, generalmente nos ponemos muy contentos con cualquier valor de parámetro que esté, ya saben, muy cerca del mínimo global, normalmente, este proceso de disminución lenta de «alfa» generalmente no se hace y mantener constante el índice de aprendizaje «alfa» es la aplicación más común del gradiente de descenso estocástico, aunque verán personas que usan cualquiera de las versiones. En resumen, en este video hablamos de una manera para monitorear de manera aproximada cómo está funcionando el gradiente de descenso estocástico en términos de la optimización de la función de costos. Y este es un método que no requiere de exploración en todo el conjunto de entrenamiento de manera periódica para calcular la función de costos en todo el conjunto de entrenamiento. Pero en vez de eso, mira, por decir,  sólo los últimos mil ejemplos más o menos. Y pueden utilizar este método ya sea para asegurarse de que el gradiente de descenso estocástico está bien y que está convergiendo, o utilizarlo para ajustar el índice de aprendizaje «alfa».