Agora você conhece o algoritmo do gradiente decrescente estocástico. Mas quando estamos usando este algoritmo, como saber se ele está funcionando perfeitamente e convergindo? E também, como você ajusta o taxa de aprendizado alfa para este algoritmo? Neste vídeo falaremos sobre algumas técnicas para nos dar a certeza de que o algoritmo está convergindo e de que utilizamos o alfa correto. Quando nós usávamos o gradiente decrescente de lote completo, a maneira que usávamos para ter certeza de que o algoritmo estava convergindo era visualizar no gráfico a função custo em relação ao número de iterações. E com a função custo nós queríamos verificar que ela decresceria a cada iteração. Quando o conjunto de treinamento era pequeno, nós podíamos fazer isso, pois nós conseguíamos calcular a soma de maneira eficiente. Mas quando se tem um conjunto de treinamento enorme, então você não irá querer ficar parando o seu algoritmo frequentemente. Você não quer parar o gradiente decrescente estocástico periodicamente para calcular a função custo, uma vez que esse cálculo exige uma soma envolvendo o seu conjunto de treinamento inteiro. E o ponto principal do gradiente decrescente estocástico era que poder progredir com apenas um único exemplo, sem necessidade de passar por todo o seu conjunto de treinamento durante o algoritmo. Sendo que isso é feito para calcular a função custo do seu conjunto inteiro de treinamento. Então para o gradiente decrescente estocástico, para que possamos verificar se o algoritmo está convergindo, o que podemos fazer é o seguinte. Usemos a definição de custo que tínhamos antes. Então o custo do parâmetro teta em relação à um único exemplo de treinamento é apenas metade do erro ao quadrado desse exemplo. Enquanto o gradiente decrescente estocástico está sendo treinado, antes de treiná-lo com um exemplo em específico. Então, no gradiente decrescente estocástico nós iremos pegar os exemplos xi, yi, e os usaremos para fazer uma pequena atualização nos parâmetros em relação a esse exemplo. E partimos para o próximo exemplo, xi mais 1, yi mais 1 e assim por diante, certo? É isso que o gradiente decrescente faz. Então, enquanto o algoritmo está pegando o exemplo xy, yi, mas antes que ele atualize os parâmetros teta, e usando esse mesmo exemplo de treinamento, vamos calcular o custo desse único exemplo. Apenas para reforçar, mas usando palavras um pouco diferentes. O gradiente decrescente estocástico está processando ao longo do nosso conjunto de treinamento, antes de utilizarmos esse exemplo de treinamento específico x(i) y(i), vamos utilizá-lo para calcular o quão bem a nossa hipótese se ajusta a esse único exemplo de treinamento. E nós queremos fazer isso antes de atualizar o teta, pois se ajustamos teta usando esse exemplo, será esperado que ele irá ajustar-se melhor a esse exemplo e o custo fica menos representativo. Finalmente, para que possamos verificar a convergência do algoritmo, o que podemos fazer é fazer esse passo a mais uma vez a cada, digamos, mil iterações. Nós podemos desenhar esses custos que nós calculamos no passo anterior. Nós podemos calcular a média desses custos, digamos, entre os últimos mil exemplos processados pelo algoritmo. E se você fizer isso, você terá uma boa estimativa em tempo real de quão bem seu algoritmo está indo, em relação os últimos 1000 exemplos de treinamento que o algoritmo passou por. Portanto, ao contrário de calcular J treino periodicamente, que necessita de um processamento ao longo de todo o conjunto de treinamento, com esse outro procedimento, como parte do gradiente decrescente estocástico, não será tão pesado calcular esses custos antes de fazer a atualização do parâmetro teta. E tudo que estamos fazendo é apenas pegar a cada mil iterações e fazer uma média desses 1,000 últimos custos que calculamos e colocar isso no gráfico. E ao olhar para esse gráfico poderemos verificar se o gradiente decrescente estocástico está convergindo. E aqui temos algum exemplos da cara que esses gráficos terão. Suponha que você tenha montado o gráfico para o custo média dos últimos mil exemplos. Como temos a média de apenas mil exemplos, teremos essa aparência um pouco ruidosa, e pode até não apresentar decréscimo em cada iteração. Se você chegar em uma figura como essa, e o gráfico pode estar com ruído, pois é a média usando apenas um pequeno subconjunto de, por exemplo, mil exemplos de treinamento. Se você chegar em uma figura que pareça com essa, você sabe que o algoritmo realizou um bom trabalho. Podemos ver que o custo foi decrescendo até chegar nessa região aqui que mais parece um planalto, onde ela parece ter estabilizado, começando mais ou menos desse ponto. Se é assim que o gráfico do seu custo se parece, então o seu algoritmo de aprendizado provavelmente convergiu. Se você quiser tentar usar uma taxa de aprendizado menor, o que você verificará é que o algoritmo aprenderá inicialmente mais devagar, então o custo irá cair de maneira mais lenta. Mas, eventualmente, ter uma taxa de aprendizado menor pode levar o algoritmo para uma solução levemente melhor. A linha vermelha representa o comportamento do gradiente decrescente estocástico usando uma taxa de aprendizado menor. E a razão para que isso aconteça é que, como você deve recordar, o gradiente decrescente estocástico não converge simplesmente para o mínimo global. O que ocorre é que os parâmetros irão oscilar em torno do mínimo global. Portanto, ao usar uma taxa de aprendizado menor, você irá conseguir oscilações menores nesse entorno. E às vezes essa pequena diferença será negligenciável, enquanto em outras você conseguirá um resultado um pouco melhor para os parâmetros. Aqui são os outros casos possíveis. Digamos que você rode o gradiente decrescente estocástico e você tome a média ao longo de mil exemplos quando for fazer o gráfico do custo. E este aqui pode ser um outro resultado possível desse gráfico. Novamente, parece-nos que o algoritmo convergiu. Se você pegar esse número da média, os mil exemplos, e aumentá-lo para uma média com 5 mil exemplos. Então é possível que você chegue em uma curva mais suave, parecida com esta. E ao fazer a média com, digamos, 5000 exemplos ao invés de 1000, você pode conseguir uma curva mais suave, como esta. E este é o efeito que o uso de mais exemplos na média trará. A desvantagem disso é que para gerar um único ponto desse gráfico teremos agora que olhar para 5000 exemplos. E, portanto, o retorno que você tem de quão bem o seu algoritmo está operando acaba por tornar-se um pouco mais defasado, pois você gera apenas um ponto do seu gráfico a cada 5000 exemplos ao invés de a cada 1000 exemplos. Seguindo o mesmo raciocínio, às vezes você pode rodar o gradiente decrescente e obter um gráfico assim. E com um gráfico assim, como vemos, o custo parece não estar decrescendo. Parece que o algoritmo não está aprendendo. Parece apenas com uma curva plana e que o custo não decresce. Mas, novamente, se você pegar e fizer a média com um número grande de exemplos, é possível que você chegue em algo parecido com essa linha vermelha, parece-nos que o custo está, na verdade, decrescendo, é que a linha azul fazia a média com poucos exemplos, a linha azul continha tanto ruído que não podíamos ver qual era a verdadeira tendência do custo, então, fazer a média com 5000 exemplos ao invés de 1000 pode, possivelmente, ajudar. É claro que fizemos aqui a média usando muitos exemplos, nós usamos aqui 5000 exemplos, Usando uma cor diferente, é possível que a sua curva de treinamento acabe por parecer-se com algo assim. Ela continua plana mesmo se você usar um número maior de exemplos. E como você pode perceber, aqui apenas verificamos com maior rigor que, infelizmente, o algoritmo não está aprendendo por alguma razão. Então você terá que modificar alguma coisa, seja a taxa de aprendizado, as suas variáveis, ou mudar algo do algoritmo em si. Para terminar, um último caso que você poderia encontrar ao produzir essas curvas seria quando você encontra algo assim, onde ela parece estar aumentando. E se esse é o caso, então o algoritmo está divergindo. E o que você deveria tentar é usar um valor menor para a taxa de aprendizado alfa. Espero que você agora tenha uma idéia das possibilidades que poderão aparecer quando você produz esses gráficos de média de custo sobre um certo intervalo de exemplos, assim como sugestões do que você poderia tentar caso encontrasse algum desses diferentes gráficos. Portanto, se o gráfico ficar com muito ruido, ou se serpenteia demais pra cima e pra baixo, então aumentar o número de exemplos usados na média irá ajudar a verificar a tendência da curva melhor. E se você perceber que o erro está aumentando, os custos estão aumentando, tente usar um valor menor para alfa. Finalmente, vamos discutir um pouco mais sobre a taxa de aprendizado. Vimos que quando rodamos o gradiente decrescente estocástico, o algoritmo irá começar aqui e irá passar a buscar o mínimo. E ele não irá de fato convergir, mas apenas rondar o ponto mínimo para sempre. E, portanto, terminaremos com parâmetros que esperamos serem próximos suficiente do mínimo global, mas que não o são de fato. Na implementação mais comum do gradiente decrescente estocástico, a taxa de aprendizado alfa é geralmente mantida constante. E o que conseguiremos será exatamente uma figura como essa. Se você quer que o gradiente decrescente estocástico realmente convirja para o mínimo global, há algo que possa ser feito: você pode reduzir a taxa alfa lentamente ao longo do tempo. E uma maneira comum de fazer isso é definir alfa como constante 1 dividida pelo número de iterações mais a constante 2. O número de iterações é o número de vezes que você rodou o gradiente decrescente estocástico, então é também o número de exemplos de treinamento pelos quais você passou. E a constante 1 e a constante 2 são parâmetros adicionais do algoritmo, que você terá que analisar brevemente para pode chegar em uma boa performance. Uma das razões pelas quais as pessoas não usam muito esse procedimento é porque você acaba precisando investir tempo na definição dos parâmetros extra, constante 1 e constante 2, e isso fará o algoritmo mais sensível às suas escolhas. Pois serão mais parâmetros que precisarão ser bem definidos para que o algoritmo faça bem o seu trabalho. Mas se você conseguir definir bem os parâmetros, então você conseguirá que o algoritmo fique rondando o mínimo, mas quando ele chegar bem perto, devido ao fato de vocês estar decrescendo a taxa de aprendizado alfa, as variações da média se tornarão cada vez menores. E isso durará até que ele chegue praticamente no mínimo global. Espero que tenha ficado claro. E o motivo pelo qual essa fórmula faz sentido é porque enquanto o algoritmo roda, o número de iterações torna-se maior. Então o alfa irá, lentamente, tornar-se menor. E ao tomar um alfa menor, o algoritmo dará passos menores em direção, espera-se, ao mínimo global. Portanto, se você aplica decréscimos ao alfa até zero, você poderá conseguir uma hipótese um pouco melhor. Mas devido ao trabalho extra que é a definição das constantes e porque, geralmente, já estamos bem suficiente com a versão anterior, que já chega perto suficiente do mínimo global, então esse processo de decréscimo do alfa não é feito geralmente e mantém-se a taxa alfa constante, que é a aplicação mais comum do algoritmo de gradiente decrescente estocástico, embora você verá as pessoas usando ambas as versões. Para resumir o que aprendemos: aprendemos sobre como monitorar o quão bem o nosso algoritmo está indo em termos de optimização da função custo. E esse é um método que não necessita que passemos por todo o conjunto de treinamento periodicamente para calcular a função custo para o conjunto de treinamento inteiro. Ao invés disso, olhamos para, digamos, mil exemplos ou algo assim. E você pode usar esse método tanto para ter certeza que o algoritmo está convergindo, quanto para ajudá-lo a ajustar a taxa de aprendizado alfa.