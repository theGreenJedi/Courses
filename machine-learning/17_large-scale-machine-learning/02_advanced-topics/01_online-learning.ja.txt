このビデオでは、新しい 大規模の機械学習の シチュエーションである、 オンライン学習の場合について話したい。 オンライン学習の状況は、 問題を、以下のように定義出来る物だ： 連続的な流れ、または 連続的なストリームのデータが 流入し続けていて、そしてアルゴリズムに そこから学習させたい、という。 こんにちでは、大きなwebサイトの多くは または、大きな会社のwebサイトの多くで、 各会社は様々なバージョンの オンライン学習アルゴリズムを どんどんやって来たり戻ってきたりする ユーザーの群れから学習するのに 使っている。 具体的には、サイトに次々とやってくる 連続的なユーザーによって生成される 連続的なデータのストリームが あるとすると、 そこにあなたは オンライン学習のアルゴリズムを用いて データのストリームから ユーザーの嗜好を学習して、 あなたのwebサイトの 意思決定を最適化するのに 使う事が出来る場合がある。 配達サービスを運営しているとしよう。 つまりユーザーがやってきて 彼らの荷物を配達するのを手伝ってくれ、と頼まれる、 場所Aから場所Bまで。 そしてあなたはwebサイトを運営していて、 ユーザーは繰り返しやってきては あなたに荷物をどこから、 そしてどこまで送りたいか、 それを伝える。 つまり配達元と配達先だ。 そしてあなたのwebサイトは荷物の配達に なんらかの価格をユーザーに提示する。 だから私はあなたの荷物を$50で送り届けよう、 私は$20で送り届けよう。 そしてあなたがユーザーにオファーした 価格に基づいて、 ユーザーは時には配達サービスを使う事を選ぶ； その場合は陽性のサンプルだ。 時にはユーザーは立ち去り、 あなたの配達サービスを 購入しない事を選ぶ。 さて、我らはユーザーに オファーしたい、と思う提示価格を 最適化する為に使えるような 学習アルゴリズムを求めているとする。 具体的には、ユーザーの特徴を捉えた なんらかのフィーチャーを 考え出したとする。 ユーザーの年齢層などで分かってる事とか、 荷物の送付元と送付先とか、つまり どこに荷物を送り届けたいのか、などを捉えた物。 そして彼らにオファーする 荷物の配達の価格。 そして我らがやりたいのは、 荷物を送る事を 選択する確率を 学習したい、 これらのフィーチャーが与えられた時に 我らの配達サービスを使ってくれる確率を。 もう一度繰り返しておくと、このフィーチャーxには 我らの提示する価格も含まれている。 だからもし我らが ある価格を所与として、その価格で ユーザーが我らのサービスを使う事に 同意してくれる確率を見積もる事が出来るなら、 その時は我らはユーザーが 高い確率で我らのサービスを使ってくれるような 価格でありながら、同時に 我らの側にも公正なリターンが、 我らの側にも公正な利益が 彼らの荷物を配達する事で得られるような 価格を選ぶ事を試みる事が出来る。 つまりもし特定の価格やその他のフィーチャーを 提示された時の y=1となる条件付き確率を求める事が出来たら、 それを実際に用いて 新しいユーザーが来た時に 適切な価格を提供する事が出来る。 つまりy=1となる確率を モデリングする為に 我らに出来る事といえば、 ロジスティック回帰かニューラルネットワークか、 とにかく何かしらそれ系のアルゴリズムを使う事だ。 どれでも良いが、ロジスティック回帰を使う事から始めてみよう。 今、継続的に運営されている webサイトを所有していたとして、 オンライン学習アルゴリズムがやるのはこんな事だ。 無限の繰り返しを書いて、 これは単に、我らのwebサイトが 起き続けていると 言っているに過ぎない。 webサイトに起こる事といえば、 たまにユーザーが来て そして訪れたユーザーに対して その客なりユーザーなりに 対応したあるペア、 x, yを 得る事になる。 フィーチャーxは このユーザーに指定された 起点と目的地、 それと彼らに今回 オファーした価格、 そしてyは1から0で、 それは彼らが我らの配送サービスを 利用したかどうかを 表す値。 今、ひとたびこのx, yのペアを得ると、 オンライン学習のアルゴリズムが 行う事は パラメータのシータを この手本 x, yだけを用いてアップデートする、という事。 具体的に書くと パラメータシータを、このように シータjを シータj 引くことの学習率アルファ掛けることの いつも通りのロジスティック回帰の 最急降下法のアップデートルール で、 アップデートする。 これをjが0からnまで 実行する事になる。 そこで中括弧を閉じる。 その他のアルゴリズムだったら、 x-yと書く代わりに xi, yiと書いてきた。 だが、 オンライン学習の状況では、 固定したトレーニングセットの 記述を捨てている、 その代わりにこのアルゴリズムがある。 今回やる事は、手本を取り出したら、 その手本を使って こんな感じで学習を行い、 そしてその手本を捨て去ってしまう。 我らはその手本を捨て去り、 それをもう一度用いる事は無い。 だから一度に手本を一つしか見ない。 その手本から学習する。 それを捨てる。 そんな訳だから、 このiでインデックスされる 固定されたトレーニングセットの 記述無しでやっていける。 そしてもしあなたが本当に大規模な webサイトを運営していて、 連続的なやって来るユーザーのストリームが あるなら、 この種のオンライン学習アルゴリズムは 現実にも極めて合理的なアルゴリズムだろう。 そんなにたくさんのデータがあるなら、 データは本質的にはタダだから、 そんなデータは本質的には 無制限だから、 その場合は本当に トレーニング手本を 一回よりも多く見る理由は全く無い。 もちろん、もしちょっとの数のユーザーしか いなかったら、その時は このようなオンライン学習アルゴリズムを 用いるよりも、データの全てを 固定したトレーニングセットに保存して、 そのトレーニングセットに対して なんらかの学習アルゴリズムを走らせる方が賢いだろう。 だがもし本当に連続的なデータのストリームを 持っているなら、その時は オンライン学習アルゴリズムはとても効率的だ。 また、この種のオンライン学習アルゴリズムの 興味深い効果の一つに、 ユーザーの嗜好に適応する事が出来る、 というのがある事は、指摘しておくべきだろう。 特に、時間とともに 経済状況が変わって、 ユーザーはより 価格感応性が高まって、 そして喜んで払っても良いと思う価格が、、、 あー、高い価格を払うのを、より嫌がるようになる。 あるいは、より価格感応度が下がれば、彼らはより高い価格でも、払って良いと思うようになる。 あるいは、ユーザーにとって 以前とは異なる物がより重要になった場合、 webサイトに新しい種類のユーザー層が 来るようになった場合など。 その場合もこの種のオンライン学習のアルゴリズムは ユーザーの嗜好の変化や あなたにお金を払ってくれる ユーザー層の変化に 適用し続ける事を 可能にしてくれる。 それが可能な理由は、 ユーザーのプールが変化した時に、 これらのアルゴリズムは パラメータのシータを、ゆっくりと適用させていく、 あたなのパラメータをどんな物であれ最新のあなたの ユーザーのプールに合わせて。 これはオンライン学習アルゴリズムを適用したいような、 もう一つの例だ。 これは商品検索のアプリケーションで、 ユーザーに 良い検索結果のリストを与えるよう学習するために 機械学習のアルゴリズムを用いたい。 電話機を売る オンラインストアを運営しているとしよう。 そこでは携帯電話を売っている。 そしてユーザーがwebサイトに来て 検索のクエリをタイプするような UIがそこにはあるとする。 クエリは「Android phone 1080p camera」とかそういう物。 1080pは電話機に 携帯電話に ついていて欲しいビデオカメラの 仕様だ。 商店に100個の電話機があるとしよう。 そしてwebサイトの レイアウトの方法は、 ユーザーがクエリをタイプした時には、 もしそれが検索のクエリなら、 10台の別々の電話機を ユーザーに提示する為に 選びたい。 我らがやりたい事は、 100台の電話機の中から どの10台の電話機を ユーザーがこんな検索クエリを行ったら 表示すべきかを 見出す助けとなるような学習アルゴリズムが欲しい。 これがその問題にどう取り組むかだ。 各電話機と特定のユーザーのクエリが 与えられたとして、 フィーチャーベクトルxを構築出来る。 フィーチャーベクトルxは電話機の 様々な性質を捉える事となるだろう。 それは例えば 電話機とユーザーの検索のクエリがどの位近いか、を捕捉した物だろう、 ユーザーの検索のクエリから どれだけの単語が電話機の名前に マッチしたのかを捕捉した物だろう。 ユーザーのサーチのクエリの中の単語のうち、 どれだけの単語が電話の詳細情報の項目にマッチしたか、などなども。 つまりフィーチャーxは、 電話の性質を捉えた物で、 そしてまた、ユーザーのクエリに どれだけ似ているか、あるいはどれだけ良くマッチしたかを 様々な次元から見たような物も捉えた物だろう。 我らがやりたい事は 特定の電話機を ユーザーがクリックするであろう 確率を推計したい。 何故なら我らはユーザーに 彼らが買いそうな電話機を 見せたいから、 彼らのwebブラウザ内でクリックしてくれそうな 確率が高い電話機を ユーザーに見せたいからだ。 その為に、y=1を ユーザーが電話機をクリックした場合、と 定義する。 そしてそれ以外の場合はy=0とする。 そこで私がやりたいのは、 ユーザーが特定の電話機を クリックする確率だ、 電話機の性質や クエリがどれだけ電話機にマッチしたかを捉えたような フィーチャーが与えられた時に。 このようなwebサイトを 運営している人達が この問題に与えた名前は、 これを学習する問題は実際には クリックスルー率の予測値、またはCTRの予測値を 学習する問題、と呼ばれている。 それは単に、ユーザーに リンクをオファーした時に そのリンクをクリックする確率を 学習するって意味なだけ。 CTRはClick Through Rateの略。 そしてもしクリックスルー率の予測値を 各電話機に対して 推計出来たなら、 これを用いてユーザーに もっともクリックしてもらえそうな電話機を 見せる、という事が出来る、 何故なら100台の電話機から 100台の電話機それぞれの これを計算する事が出来て、 ユーザーがもっともクリックしそうな 10台の電話機を選ぶ事が出来る、 そしてこれはユーザーに、どの10台を見せるかを 決定する極めて合理的な方法だと言えよう。 明確にする為、ユーザーが 検索をする都度、 10の結果を返すとしよう。 その場合にそれがする事は 実際は10組のx, yのペアを与えてくれる事で、 これは実際は10のトレーニング手本を 我らに与えてくれる、 ユーザーが我らのwebサイトに来るたび毎に、 何故なら、 我らがユーザーに見せる為に選んだ 10台の電話機は それらの10台の電話機それぞれに フィーチャーベクトルxが得られ、 そしてまた10台の電話機それぞれに yの値も 得られる事になる。 我らはyの値も観測する事になる、 ユーザーがそのリンクを クリックしたか否かに 応じて。 つまり、こんな類のwebサイトを 運営する方法の一つとして、 ユーザーに継続的に 10個の最もユーザーが好きそうな 電話機を見せる、という事で、 そうする事でユーザーが来る都度、 10個の手本、10組のx, yのペアを 得る事となり、 そして次にオンライン学習アルゴリズムを用いて 本質的にはこれら10個の手本に対する 10ステップの最急降下法で パラメータをアップデートする。 その後はデータを 捨てて良くて、 そして実際にwebサイトを訪れる 連続的なユーザーのストリームを 保持しているなら、 これはあなたのアルゴリズムの為に パラメータを学習する、極めて合理的な方法だろう。 あなたのユーザーが、 もっともクリックしそうな10台の 電話を見せる為の。 以上が商品検索の問題、言い換えると 電話のランキングを学習する、 電話の検索を学習する例だ。 その他の例にもちょっとだけ触れておこう。 一つには、もしwebサイトを運営していて、 ユーザーに提示する スペシャルオファーをどんな物とするかを 決定したいとする。 これはとても電話機と似ているし、 または別々のユーザーに別々のニュース記事を見せるような webサイトを運営していても、 つまりあたなのサービスがニュースアグリゲーターのwebサイトだとしても、 その場合でもあなたは 同様のシステムを用いて ユーザーに何の記事を 見せるのかを 選択するのに、 彼らがもっとも興味をもちそうで、 クリックしそうな物を選ぶ事が出来る。 スペシャルオファーに密接に関係している物として、リコメンデーションも有効に活用出来る。 実際、もし協調的フィルタリングの システムがあるなら、 協調的フィルタリングシステムが ロジスティック回帰の分類器に 食わせる為の、追加のフィーチャーを 提供してくれて、 その分類器を用いてユーザーにリコメンドする 商品のそれぞれのクリックスルー率を予測する事が出来る。 もちろん、これらの問題はどれも 通常の機会学習の問題として 定式化する事も出来る、という事は指摘しておくべきだろう。 その場合は固定したトレーニングセットを持っているという形になる。 例えば2, 3日webサイトを 運営してみて、 そしてトレーニングセットを保存し分けて 固定されたトレーニングセットとし、 それに対して学習アルゴリズムを走らせる事も出来る。 だがこれらは現実に、 大きな会社が大量にデータを 集めているシーンに遭遇する事が多々あるたぐいの 問題でもある。その場合は、 固定したトレーニングセットを保存し分ける必要は無く、 その代わりにオンライン学習アルゴリズムを用いて、 単純にユーザーがwebサイトにおいて生成するデータを 継続的に学習させてしまう事も出来る。 以上がオンライン学習の 問題設定だ。 ここまで見てきた通り、それに適用する アルゴリズムは、確率的最急降下法のアルゴリズムと 本当にとっても良く似ている。 唯一違う所は 固定したトレーニングセットを スキャンしていく代わりに、 ユーザー達から一つの手本だけを取り出して、 その手本から学習し、 その手本を捨てて、次に進む。 そしてもし何らかの応用に際し、 連続的なデータのストリームがある時は、 この種のアルゴリズムはあなたのアプリの為に 検討してみるに値する物だろう。 もちろん、オンライン学習の 利点の一つにはまた、 変わっていくユーザーのプールとか または予測しようとしている事が ゆっくりと変わっていくような 事である場合、例えばユーザーの嗜好が ゆっくり変わっていくとか、そういう場合は、 オンライン学習アルゴリズムは ユーザーの最新の振る舞いが、それがどんな物であれ それに学習した仮説を ゆっくりと適応させていく事が出来る。