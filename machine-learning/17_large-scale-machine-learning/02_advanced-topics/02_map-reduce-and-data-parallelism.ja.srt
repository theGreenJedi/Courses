1
00:00:00,320 --> 00:00:01,510
ここ数回のビデオでは、

2
00:00:01,810 --> 00:00:03,430
確率的最急降下法についてや、

3
00:00:03,620 --> 00:00:05,020
その他の確率的最急降下法の変種について

4
00:00:05,120 --> 00:00:06,530
ーーオンライン学習アルゴリズムの適用などーー

5
00:00:06,910 --> 00:00:09,150
議論して来た。

6
00:00:09,490 --> 00:00:10,420
だがそれらは全て

7
00:00:10,610 --> 00:00:11,810
一つのマシン、または一つのコンピュータで

8
00:00:12,110 --> 00:00:13,740
実行出来る物だった。

9
00:00:14,800 --> 00:00:15,870
幾つかの機械学習の問題は

10
00:00:16,310 --> 00:00:17,270
一つのマシンで実行するには

11
00:00:17,520 --> 00:00:19,160
あまりにも大きくて、

12
00:00:19,300 --> 00:00:21,050
時には単純にデータがあまりにも大きい為に

13
00:00:21,170 --> 00:00:22,350
一つのコンピュータで走らせてみようとは

14
00:00:22,670 --> 00:00:23,980
考えもしないような状況もあるかもしれない、

15
00:00:24,100 --> 00:00:26,270
そのコンピュータでどんなアルゴリズムを使うにせよ、だ。

16
00:00:28,470 --> 00:00:29,640
そこでこのビデオでは、

17
00:00:29,740 --> 00:00:31,240
大規模機械学習における、

18
00:00:31,770 --> 00:00:33,610
異なるアプローチである所の、Map Reduceアプローチと呼ばれる物を

19
00:00:34,010 --> 00:00:36,190
議論したい。

20
00:00:37,030 --> 00:00:38,080
我らは確率的最急降下法について

21
00:00:38,380 --> 00:00:39,400
結構たくさんのビデオを費やし

22
00:00:39,970 --> 00:00:41,230
Map Reduceに関しては

23
00:00:41,550 --> 00:00:43,100
相対的にはちょっとしか扱わないが、

24
00:00:43,460 --> 00:00:45,350
それを持って確率的最急降下法に比べると

25
00:00:45,560 --> 00:00:46,750
Map Reduceはそんなに重要では無い、とは

26
00:00:47,160 --> 00:00:48,240
判断しないでもらいたい、

27
00:00:48,690 --> 00:00:49,590
このそれぞれのアイデアに関して私が費やす

28
00:00:49,660 --> 00:00:51,480
時間を元に判断するのは。

29
00:00:52,230 --> 00:00:53,380
多くの人々が、Map Reduceは

30
00:00:53,790 --> 00:00:54,840
少なくとも同程度には、

31
00:00:55,090 --> 00:00:56,330
そして人によってはもっと重要な

32
00:00:56,580 --> 00:00:57,850
アイデアだと言うだろう、確率的最急降下法と

33
00:00:58,500 --> 00:01:00,620
比較した時に。

34
00:01:01,460 --> 00:01:03,040
単にMap Reduceは相対的には説明するのが簡単なだけ、

35
00:01:03,160 --> 00:01:04,620
その為にそれについて

36
00:01:04,720 --> 00:01:05,580
あんまり時間を使わないだけだ。

37
00:01:05,830 --> 00:01:07,040
だがこのアイデアを用いる事で

38
00:01:07,670 --> 00:01:08,400
確率的最急降下法を用いる事で可能な範囲よりも

39
00:01:09,070 --> 00:01:10,640
学習アルゴリズムを

40
00:01:10,880 --> 00:01:12,520
ずっとスケールさせる事が

41
00:01:12,630 --> 00:01:14,530
出来るかもしれない。

42
00:01:18,720 --> 00:01:19,000
そのアイデアとはこうだ。

43
00:01:19,810 --> 00:01:21,020
例えば線形回帰とか

44
00:01:21,490 --> 00:01:22,960
ロジスティック回帰とか、とにかくその辺のモデルに

45
00:01:23,140 --> 00:01:24,440
フィッティングしたい、としよう。

46
00:01:24,540 --> 00:01:26,100
ここではバッチ最急降下法から

47
00:01:26,430 --> 00:01:27,660
始める事としよう。

48
00:01:27,840 --> 00:01:30,300
これが我らのバッチ最急降下法のルールとなる。

49
00:01:31,240 --> 00:01:32,430
そしてこのスライドの記述が

50
00:01:32,850 --> 00:01:34,170
追いやすいように、

51
00:01:34,340 --> 00:01:36,990
ここではm=400の手本と仮定して進めていく事にする。

52
00:01:37,530 --> 00:01:39,560
もちろん、我らの基準からすると

53
00:01:39,750 --> 00:01:40,850
大規模スケールの機械学習という

54
00:01:41,090 --> 00:01:42,050
観点からすれば、mは極めて小さい、と

55
00:01:42,170 --> 00:01:43,210
言えるだろう。

56
00:01:43,770 --> 00:01:45,390
どちらかといえばより一般的な状況としては

57
00:01:45,870 --> 00:01:46,920
4億個とかそれに近い数字の方が

58
00:01:47,050 --> 00:01:48,190
より典型的な

59
00:01:48,740 --> 00:01:49,940
数字と言える。

60
00:01:50,080 --> 00:01:51,310
だが、スライドの記述を

61
00:01:51,390 --> 00:01:52,330
シンプルにする為に、

62
00:01:52,770 --> 00:01:55,000
我らの手持ちの手本が400個であるフリをしてみよう。

63
00:01:55,690 --> 00:01:57,460
その場合、

64
00:01:57,790 --> 00:01:59,080
バッチ最急降下法の学習ルールは

65
00:01:59,570 --> 00:02:00,930
この400個に対して行われ、

66
00:02:01,500 --> 00:02:02,930
和をi=1から400までの

67
00:02:03,330 --> 00:02:05,050
この400個の手本に渡って取る、

68
00:02:05,590 --> 00:02:06,890
もしmが大きければこれは、

69
00:02:07,050 --> 00:02:09,780
計算量的に高くつくステップとなる。

70
00:02:10,890 --> 00:02:12,830
そこでMapReduceのアイデアが行う事は

71
00:02:13,250 --> 00:02:14,470
以下のような事だ。

72
00:02:14,890 --> 00:02:15,740
ここでMap Reduceのアイデアは

73
00:02:15,950 --> 00:02:16,940
二人の研究者による物だと言及しておくべきだろう、

74
00:02:17,680 --> 00:02:20,190
Jeff Deanと

75
00:02:20,700 --> 00:02:22,060
Sanjay Gimawatだ。

76
00:02:22,640 --> 00:02:23,490
ところでJeff Deanは

77
00:02:24,190 --> 00:02:26,520
シリコンバレー中でも

78
00:02:26,660 --> 00:02:28,300
もっとも伝説的なエンジニアの一人で、

79
00:02:28,420 --> 00:02:29,530
今日Googleで動いている

80
00:02:29,820 --> 00:02:31,670
アーキテクチャ的なインフラのかなりの部分を

81
00:02:32,310 --> 00:02:34,770
創り上げた男だ。

82
00:02:36,000 --> 00:02:37,320
話を戻して、これがMap Reduceというアイデアだ。

83
00:02:37,850 --> 00:02:38,570
あるトレーニングセットが

84
00:02:38,700 --> 00:02:39,840
あるとして、

85
00:02:39,900 --> 00:02:41,220
この箱でxyのペアを

86
00:02:41,610 --> 00:02:42,760
表すとして、

87
00:02:44,250 --> 00:02:47,730
これはx1, y1から400個の手本まで

88
00:02:47,990 --> 00:02:49,640
xm, ymまで

89
00:02:50,520 --> 00:02:51,660
降りていく。

90
00:02:52,190 --> 00:02:53,780
つまりこれがトレーニングセットで400個の手本がある。

91
00:02:55,060 --> 00:02:56,550
Map Reduceのアイデアでは、一つのやり方としては、

92
00:02:56,690 --> 00:02:58,190
このトレーニングセットを

93
00:02:58,570 --> 00:03:00,510
別々のサブセットに分割する。

94
00:03:01,890 --> 00:03:02,590
今回の例ではマシンは

95
00:03:02,950 --> 00:03:04,150
4台だと

96
00:03:04,290 --> 00:03:05,530
想定していこう。

97
00:03:06,160 --> 00:03:07,160
言い換えると4台のマシンがトレーニングセットに渡って

98
00:03:07,300 --> 00:03:08,670
並列に走る。

99
00:03:08,890 --> 00:03:10,570
そんな訳だから4台のマシンに分割した。

100
00:03:10,920 --> 00:03:12,290
もしあなたの手持ちが10台のマシンだったり

101
00:03:12,400 --> 00:03:13,810
100台のマシンなら、その場合は

102
00:03:13,970 --> 00:03:15,890
それに応じてトレーニングセットを10個とか100個とか、持ってるマシンの台数に応じて分割する事になる。

103
00:03:18,040 --> 00:03:19,710
そして4台のマシンの最初の一台が

104
00:03:19,850 --> 00:03:20,840
やるべき事は、

105
00:03:21,100 --> 00:03:23,170
トレーニングセットのうちの

106
00:03:23,270 --> 00:03:25,170
最初の1/4を用いて

107
00:03:25,300 --> 00:03:28,680
つまり最初の100個のトレーニング手本を用いて、

108
00:03:30,020 --> 00:03:31,440
具体的に言うと、それがやる事は

109
00:03:31,480 --> 00:03:32,520
この和を見てくれ。

110
00:03:32,630 --> 00:03:34,800
そして最初の100個のトレーニング手本に対して

111
00:03:35,490 --> 00:03:38,560
この和を計算する事だ。

112
00:03:40,030 --> 00:03:40,960
書きだしてみよう。

113
00:03:41,110 --> 00:03:42,530
temp上付き添字1 jという変数を

114
00:03:43,560 --> 00:03:46,230
計算してみる。この1は最初のマシンを表す。

115
00:03:46,320 --> 00:03:49,410
これはイコール

116
00:03:50,450 --> 00:03:52,150
和を取る事の 1から100までの

117
00:03:52,260 --> 00:03:53,160
ここでここにある項を

118
00:03:53,500 --> 00:03:56,610
代入する。つまり、

119
00:03:57,260 --> 00:04:00,140
h シータのxi 引く事の yi、

120
00:04:01,800 --> 00:04:03,230
掛けるx ij。いい？

121
00:04:03,740 --> 00:04:05,680
つまりこれは単なる

122
00:04:05,910 --> 00:04:07,460
ここの最急降下法の項だ。

123
00:04:08,300 --> 00:04:09,780
そして次に、同様に、

124
00:04:10,010 --> 00:04:11,330
二番目の1/4のデータを

125
00:04:11,600 --> 00:04:13,130
取ってきて、それを二番目のマシンに

126
00:04:13,320 --> 00:04:14,520
送りつける。

127
00:04:14,690 --> 00:04:15,680
二番目のマシンはトレーニング手本の

128
00:04:15,900 --> 00:04:18,750
101番目から200番目を使う。

129
00:04:19,350 --> 00:04:21,170
そして同様の値、temp(2) jを

130
00:04:21,720 --> 00:04:22,880
計算する。それは同様の和を

131
00:04:23,110 --> 00:04:24,450
インデックスが101から200までに対する

132
00:04:24,890 --> 00:04:26,620
トレーニングセットに対し取った物だ。

133
00:04:26,840 --> 00:04:29,680
そして以下同様にマシン3と4は

134
00:04:29,830 --> 00:04:32,720
トレーニングセットの

135
00:04:32,830 --> 00:04:34,110
三番目の1/4と、四番目の1/4を

136
00:04:34,570 --> 00:04:36,550
使う事になる。

137
00:04:37,530 --> 00:04:38,950
つまりいまや、各マシンは

138
00:04:39,190 --> 00:04:40,580
400に渡る和では無くて

139
00:04:41,060 --> 00:04:42,570
100手本に対する和だけとなる。

140
00:04:42,760 --> 00:04:43,750
つまりやらなくてはならない仕事が1/4となり、

141
00:04:44,050 --> 00:04:45,220
つまり4倍早く終えられる事が

142
00:04:45,900 --> 00:04:48,000
期待される。

143
00:04:49,380 --> 00:04:50,630
最後に、これら全てのマシンが

144
00:04:50,990 --> 00:04:51,740
仕事を終えたら、

145
00:04:51,850 --> 00:04:53,560
これらのtemp変数を取り出して

146
00:04:55,350 --> 00:04:56,480
一つに戻さないといけない。

147
00:04:56,870 --> 00:04:58,400
だからこれらの変数を

148
00:04:58,530 --> 00:04:59,950
中央のサーバーに

149
00:05:00,090 --> 00:05:03,080
送りつける。

150
00:05:03,300 --> 00:05:04,750
そしてマスターサーバーがやる事は

151
00:05:05,140 --> 00:05:06,720
これらの結果を一つに結合する事。

152
00:05:07,360 --> 00:05:08,470
具体的には、パラメータのシータjを

153
00:05:08,780 --> 00:05:10,780
シータjを、以下のように更新する：

154
00:05:11,000 --> 00:05:13,160
シータj引く事の

155
00:05:13,410 --> 00:05:14,720
学習率の

156
00:05:15,730 --> 00:05:17,560
アルファ 掛ける事の

157
00:05:17,680 --> 00:05:19,510
1/400 掛ける事の

158
00:05:20,120 --> 00:05:22,940
temp (i) j

159
00:05:23,300 --> 00:05:27,410
足す事の

160
00:05:27,760 --> 00:05:30,290
temp (2) j 足す事の temp (3) j

161
00:05:32,400 --> 00:05:35,470
足すことのtemp(4) j。

162
00:05:35,560 --> 00:05:37,890
そしてもちろん、これをj=0から

163
00:05:37,980 --> 00:05:39,570
nまで、nはフィーチャーの数だが、

164
00:05:39,820 --> 00:05:41,220
それらのjに対してそれぞれ行わなくてはならない。

165
00:05:42,550 --> 00:05:45,420
こんな風に複数の等式に分割出来る。

166
00:05:45,670 --> 00:05:47,870
この式がやってる事は、

167
00:05:50,930 --> 00:05:53,220
完全にこれと同じだ。

168
00:05:53,290 --> 00:05:54,570
中央のマスターサーバーが

169
00:05:54,660 --> 00:05:56,140
これらの結果を

170
00:05:56,680 --> 00:05:57,950
受け取り、つまりtemp 1j、

171
00:05:58,040 --> 00:05:58,780
temp 2j、

172
00:05:59,000 --> 00:05:59,850
temp 3j、temp 4jと、

173
00:05:59,970 --> 00:06:01,760
それらを足し合わせると

174
00:06:02,030 --> 00:06:03,430
つまり当然これら4つの

175
00:06:04,090 --> 00:06:04,960
和となる訳だ。

176
00:06:06,360 --> 00:06:07,810
いいかい？これは単に

177
00:06:08,060 --> 00:06:09,440
これ、足す、

178
00:06:09,760 --> 00:06:11,490
この和、足す、

179
00:06:11,630 --> 00:06:13,000
この和、足す、

180
00:06:13,120 --> 00:06:14,290
この和。そしてこれら4つの物を

181
00:06:14,470 --> 00:06:15,830
足しあわせると、

182
00:06:15,920 --> 00:06:17,740
この和と等しくなる。これは

183
00:06:17,880 --> 00:06:19,580
もともとのバッチ最急降下法で計算していた和だ。

184
00:06:20,590 --> 00:06:21,550
そしてそこに アルファ 掛けることの

185
00:06:21,860 --> 00:06:22,910
1/400、 アルファ掛ける1/400。

186
00:06:23,350 --> 00:06:24,690
そしてこれは厳密に

187
00:06:25,020 --> 00:06:27,020
バッチ最急降下法と

188
00:06:27,140 --> 00:06:29,390
等価である。

189
00:06:29,910 --> 00:06:30,880
ただ、400個のトレーニング手本にたいして

190
00:06:31,290 --> 00:06:32,540
和を取らなくては

191
00:06:32,810 --> 00:06:33,900
いけなかった代わりに、

192
00:06:34,040 --> 00:06:35,280
ワークロードを4つのマシンに

193
00:06:35,760 --> 00:06:37,460
分割出来るようになっている。

194
00:06:39,090 --> 00:06:40,190
さて、これは、一般的なMap Reduceの

195
00:06:40,630 --> 00:06:43,410
テクニックがどんなかを表した図だ。

196
00:06:45,060 --> 00:06:46,510
あるトレーニングセットがあって、

197
00:06:46,670 --> 00:06:48,200
それを4つのマシンに渡って並列化したいとすると、

198
00:06:48,420 --> 00:06:49,100
トレーニングセットを

199
00:06:49,170 --> 00:06:51,670
同じサイズに分割する、

200
00:06:52,120 --> 00:06:54,640
4つのサブセットに等しく分割する。

201
00:06:56,470 --> 00:06:57,110
そして次に、この4つのトレーニングデータのサブセットを

202
00:06:57,180 --> 00:06:59,560
4つの別々のコンピュータに送る。

203
00:07:00,530 --> 00:07:01,660
そして4つのコンピュータはおのおの、

204
00:07:02,130 --> 00:07:03,570
1/4のトレーニングセットについてだけ

205
00:07:03,950 --> 00:07:04,850
和を計算する事が出来る。

206
00:07:04,910 --> 00:07:06,230
そして次に、

207
00:07:06,340 --> 00:07:07,720
最終的に各コンピュータの結果を

208
00:07:07,780 --> 00:07:09,310
取り出して、中央のサーバーに

209
00:07:09,580 --> 00:07:12,720
送る。そしてそこで結果を一つに結合する。

210
00:07:13,570 --> 00:07:14,900
前のスライドの例では

211
00:07:15,190 --> 00:07:16,540
最急降下法の

212
00:07:16,800 --> 00:07:17,910
仕事の大半は、

213
00:07:18,330 --> 00:07:20,140
i=1から400までの何かの和を

214
00:07:20,430 --> 00:07:22,270
計算する事だった。

215
00:07:22,670 --> 00:07:24,110
より一般的に言うと、

216
00:07:24,370 --> 00:07:25,570
最急降下法の式の

217
00:07:26,320 --> 00:07:28,180
i=1からmまでの和。

218
00:07:29,160 --> 00:07:30,430
そしてここで、各4つのコンピュータは

219
00:07:30,550 --> 00:07:31,890
その仕事の1/4しか

220
00:07:32,190 --> 00:07:33,800
行わないので、

221
00:07:34,350 --> 00:07:35,940
潜在的には4倍のスピードアップの可能性がある。

222
00:07:38,820 --> 00:07:39,980
特に、もし仮に

223
00:07:40,190 --> 00:07:41,900
ネットワークの遅延も無く

224
00:07:42,100 --> 00:07:42,970
データをあちこちに送るのに

225
00:07:43,400 --> 00:07:44,450
ネットワークのコミュニケーションのコストも

226
00:07:44,600 --> 00:07:45,450
存在しないとすると、

227
00:07:45,610 --> 00:07:47,820
4倍のスピードアップの可能性がある。

228
00:07:48,050 --> 00:07:49,410
もちろん、現実には、

229
00:07:50,100 --> 00:07:52,080
ネットワークのレイテンシもあるし、

230
00:07:52,810 --> 00:07:54,500
結果を結合するオーバーヘッドもあるし、

231
00:07:54,600 --> 00:07:55,880
その他のファクターもあるので、

232
00:07:56,640 --> 00:07:59,150
実際には4倍のスピードアップよりはわずかに少ないだろう。

233
00:08:00,140 --> 00:08:01,280
だが、それにも関わらず、

234
00:08:01,360 --> 00:08:02,710
この種のMap Reduceのアプローチは

235
00:08:03,110 --> 00:08:04,560
単体のコンピュータのみを使う事に比べると

236
00:08:04,870 --> 00:08:05,940
より大きなデータセットを処理する方法を

237
00:08:06,270 --> 00:08:07,550
提供してくれるアプローチと言える。

238
00:08:08,770 --> 00:08:10,060
もしあなたがある学習アルゴリズムを

239
00:08:10,730 --> 00:08:12,200
複数のコンピュータに渡って

240
00:08:12,350 --> 00:08:14,260
計算を並列化する事で

241
00:08:14,750 --> 00:08:16,160
スピードアップをする為に

242
00:08:16,900 --> 00:08:18,480
Map Reduceを適用することを検討している時は、

243
00:08:18,730 --> 00:08:20,040
自身に問うてみるべき鍵となる問いは、

244
00:08:20,760 --> 00:08:22,190
あなたの使おうとしている学習アルゴリズムは

245
00:08:22,880 --> 00:08:25,150
トレーニングセットに渡る和の形で表現出来るのか？という事だ。

246
00:08:25,440 --> 00:08:26,430
そして多くの学習アルゴリズムは

247
00:08:26,670 --> 00:08:28,100
実際にトレーニングセットに渡って

248
00:08:28,410 --> 00:08:29,880
関数の和を取る形に表現出来る事が

249
00:08:30,170 --> 00:08:31,820
分かっている。

250
00:08:32,610 --> 00:08:34,030
そして大きなデータセットに対して

251
00:08:34,250 --> 00:08:35,480
それらを走らせる時の計算量のコストは

252
00:08:35,600 --> 00:08:37,810
とても大きなトレーニングセットに渡って和を取る必要がある事に起因している。

253
00:08:38,620 --> 00:08:39,870
だから、あなたの学習アルゴリズムがなんであれ、

254
00:08:40,200 --> 00:08:41,350
トレーニングセットに渡る和として

255
00:08:41,450 --> 00:08:42,410
表現する事が出来て、

256
00:08:42,660 --> 00:08:43,760
そして学習アルゴリズムの

257
00:08:43,860 --> 00:08:44,810
仕事の大部分が

258
00:08:45,200 --> 00:08:46,170
トレーニングセットに渡る和として

259
00:08:46,320 --> 00:08:47,780
表現出来れば、

260
00:08:48,030 --> 00:08:49,030
MapReduceはあなたの学習アルゴリズムを

261
00:08:50,100 --> 00:08:52,830
とても大きなデータセットに対してスケールさせてくれる為の、とても有力な候補となる。

262
00:08:53,880 --> 00:08:54,910
もう一つ例を見てみよう。

263
00:08:56,020 --> 00:08:58,120
アドバンスドな最適化のアルゴリズムの一つを使いたいとしよう。

264
00:08:58,410 --> 00:08:59,430
つまり、L-BFGSとか

265
00:08:59,550 --> 00:09:00,460
conjugate gradientとか

266
00:09:00,900 --> 00:09:02,960
そういう奴。

267
00:09:03,070 --> 00:09:05,190
そして、ロジスティック回帰をそのアルゴリズムを使って訓練したいとする。

268
00:09:06,080 --> 00:09:08,680
その為には、我らは二つの主な値を計算する必要がある。

269
00:09:09,300 --> 00:09:10,460
一つめは、

270
00:09:10,960 --> 00:09:13,520
L-BFGSやconjugate gradientのような最適化アルゴリズムに対して

271
00:09:14,310 --> 00:09:15,270
我らは最適化の目的関数である、

272
00:09:15,530 --> 00:09:17,210
コスト関数を計算するルーチンを

273
00:09:17,460 --> 00:09:18,760
渡してやらないといけない。

274
00:09:20,220 --> 00:09:21,690
そしてロジスティック回帰においては

275
00:09:21,820 --> 00:09:22,870
コスト関数はこんな感じの物を

276
00:09:23,660 --> 00:09:24,700
トレーニングセットに渡って

277
00:09:24,960 --> 00:09:26,340
和を取る物だった。

278
00:09:26,970 --> 00:09:28,980
すると10台のマシンに渡って

279
00:09:29,110 --> 00:09:29,970
並列化したいなら、トレーニングセットを

280
00:09:30,310 --> 00:09:31,640
10分割して、10台のマシンに割り振り、

281
00:09:31,910 --> 00:09:33,150
そして10台の各マシンが、

282
00:09:33,360 --> 00:09:35,380
トレーニングデータの

283
00:09:35,860 --> 00:09:37,460
十分の一に渡って

284
00:09:37,760 --> 00:09:38,660
この量の和を

285
00:09:40,370 --> 00:09:40,370
計算する。

286
00:09:40,670 --> 00:09:41,550
次に、他にアドバンスドな最適化アルゴリズムが

287
00:09:42,110 --> 00:09:43,400
必要としている物としては、

288
00:09:43,660 --> 00:09:44,790
これらの偏微分項を計算する

289
00:09:45,190 --> 00:09:47,160
ルーチンだ。

290
00:09:47,280 --> 00:09:48,980
ふたたび、これらの微分項は、

291
00:09:49,100 --> 00:09:50,350
ロジスティック回帰なら、

292
00:09:50,540 --> 00:09:51,840
トレーニングセットの和として

293
00:09:52,010 --> 00:09:53,130
表現する事が出来て、だからふたたび、

294
00:09:53,330 --> 00:09:54,600
前の例と同様に、

295
00:09:54,950 --> 00:09:56,060
各マシンに、トレーニングデータの

296
00:09:56,520 --> 00:09:57,800
少しの部分ずつだけを

297
00:09:58,800 --> 00:10:01,170
計算させる事が出来る。

298
00:10:02,440 --> 00:10:04,590
そして最後に、これらを全て

299
00:10:05,050 --> 00:10:06,260
計算し終えたら、各マシンが

300
00:10:06,400 --> 00:10:07,520
その結果を中央のサーバーに

301
00:10:07,680 --> 00:10:09,400
送りつける。

302
00:10:09,640 --> 00:10:12,760
そしてそこで部分和を足し合わせる事が出来る。

303
00:10:13,320 --> 00:10:14,410
これはこれらのtemp i、

304
00:10:14,500 --> 00:10:17,000
あるいはtemp ij変数を

305
00:10:17,550 --> 00:10:21,880
足し合わせる事に対応する、

306
00:10:22,100 --> 00:10:23,610
ここでiはマシン番号iを表し、そのマシンローカルで

307
00:10:23,980 --> 00:10:25,390
計算された物。

308
00:10:25,420 --> 00:10:26,800
つまり中央のサーバーはこれらの物を

309
00:10:27,050 --> 00:10:28,220
足し合わせる事が出来て、

310
00:10:28,450 --> 00:10:30,230
それで全体のコスト関数を得る事が出来る、

311
00:10:30,870 --> 00:10:32,750
そこから全体の偏微分項が得られて、

312
00:10:33,390 --> 00:10:35,710
それをアドバンスドな最適化アルゴリズムに渡す事が出来る。

313
00:10:36,890 --> 00:10:38,100
より一般的に言うと、

314
00:10:39,080 --> 00:10:40,790
その他の学習アルゴリズムでも、

315
00:10:41,020 --> 00:10:42,430
それらを和の形に

316
00:10:42,720 --> 00:10:43,800
表現すれば、あるいは

317
00:10:44,340 --> 00:10:45,660
トレーニングセットに渡る関数の和の

318
00:10:45,990 --> 00:10:47,100
形に表現すれば、

319
00:10:47,740 --> 00:10:49,290
その他のアルゴリズムでもMap Reduceのテクニックを用いて

320
00:10:49,440 --> 00:10:51,420
同様に並列化する事が出来る。

321
00:10:51,710 --> 00:10:53,310
そしてとても大きなトレーニングセットに対してスケールさせる事が出来る。

322
00:10:54,340 --> 00:10:55,850
最後に、一つコメントを。

323
00:10:56,390 --> 00:10:57,170
ここまで我らは

324
00:10:57,510 --> 00:10:59,630
Map Reduceのアルゴリズムを

325
00:10:59,850 --> 00:11:01,400
複数のコンピューターに渡って、

326
00:11:02,090 --> 00:11:03,630
またはコンピュータクラスタの複数のコンピュータ、

327
00:11:03,940 --> 00:11:05,020
またはデータセンターの複数のコンピュータに渡って

328
00:11:05,220 --> 00:11:08,060
並列化する為の物として議論してきた。

329
00:11:09,150 --> 00:11:10,580
だが時には、一つしかコンピュータが無くても

330
00:11:10,770 --> 00:11:12,010
Map Reduceが適応可能な場合が

331
00:11:13,090 --> 00:11:14,390
ある事が分かっている。

332
00:11:15,530 --> 00:11:16,970
具体的には、こんにちの多くの

333
00:11:17,320 --> 00:11:18,510
コンピュータは、

334
00:11:18,780 --> 00:11:20,520
複数のプロセッサコアを持っている。

335
00:11:21,170 --> 00:11:21,860
複数のCPUを持っている事があり得るし、

336
00:11:22,180 --> 00:11:23,120
各CPU内にも

337
00:11:23,240 --> 00:11:26,170
複数のプロセッサコアがある場合もある。

338
00:11:26,310 --> 00:11:27,170
もし大きなトレーニングセットがある時に、

339
00:11:27,520 --> 00:11:28,460
あなたがとれる手段としては、

340
00:11:28,570 --> 00:11:29,540
もしあなたの手元に

341
00:11:29,740 --> 00:11:31,520
4つの計算コアを持つ

342
00:11:31,880 --> 00:11:33,400
コンピュータがあったとすると、

343
00:11:33,460 --> 00:11:34,390
それが一つのコンピュータでしか無かったとしても、

344
00:11:34,550 --> 00:11:35,580
トレーニングセットを

345
00:11:35,760 --> 00:11:37,680
複数のピースに分割して

346
00:11:37,810 --> 00:11:39,140
一つのマシンの中の別々のコアに

347
00:11:39,660 --> 00:11:40,960
トレーニングセットを送り込む、という事が出来る。

348
00:11:41,220 --> 00:11:42,570
一つのマシンとは一つのデスクトップコンピュータかもしれないし、

349
00:11:43,240 --> 00:11:45,070
一つのサーバーかもしれない。

350
00:11:45,370 --> 00:11:47,200
そしてMap Reduceをこんな風に使う事で、ワークロードを分散出来る。

351
00:11:48,000 --> 00:11:49,010
そして各コアはトレーニングセットの

352
00:11:49,200 --> 00:11:50,240
1/4に渡る和を

353
00:11:50,950 --> 00:11:52,000
実行出来る。

354
00:11:52,050 --> 00:11:53,440
そして次にそれらの部分和を

355
00:11:53,510 --> 00:11:55,090
取ってきて結合する事が出来る、

356
00:11:55,510 --> 00:11:56,890
トレーニングセット全体に渡る

357
00:11:57,220 --> 00:11:59,360
和を得る為に。

358
00:11:59,750 --> 00:12:01,280
Map Reduceをこんな風に、

359
00:12:01,600 --> 00:12:02,880
一つのマシンの中の複数コアに対する並列化と

360
00:12:03,350 --> 00:12:04,760
考えるメリットは、複数のマシンに渡る

361
00:12:04,900 --> 00:12:06,720
並列化として

362
00:12:06,910 --> 00:12:08,480
考えることに比べて、

363
00:12:09,060 --> 00:12:09,970
ネットワークのレイテンシを

364
00:12:10,100 --> 00:12:11,740
気にする必要が無くなる、という事がある。

365
00:12:12,020 --> 00:12:13,380
何故なら全てのコミュニケーションは、

366
00:12:13,460 --> 00:12:14,810
temp j変数を行ったり来たり送る事は、

367
00:12:15,890 --> 00:12:18,020
それらは全て一つのマシン内で起こる事だから。

368
00:12:18,420 --> 00:12:20,170
だからデータセンター内の別々のマシンを

369
00:12:20,590 --> 00:12:21,530
使う事と比べると、

370
00:12:21,960 --> 00:12:23,050
ネットワークのレイテンシは

371
00:12:23,540 --> 00:12:26,080
より重要度が低くなる。

372
00:12:27,040 --> 00:12:27,930
最後にマルチコアのマシンでの

373
00:12:27,990 --> 00:12:30,740
並列化の落とし穴の最後の一つを挙げておこう。

374
00:12:31,580 --> 00:12:32,600
実装の詳細によっては、

375
00:12:32,930 --> 00:12:34,290
もしマルチコアのマシンがあって、

376
00:12:34,610 --> 00:12:35,920
もしある種の数値計算線形代数ライブラリが

377
00:12:36,190 --> 00:12:38,130
あるなら、

378
00:12:39,350 --> 00:12:40,490
幾つかの数値計算線形代数ライブラリは

379
00:12:41,490 --> 00:12:43,940
線形代数計算を自動的にマシン内の複数コアに

380
00:12:44,680 --> 00:12:47,500
並列化する物がある。

381
00:12:48,770 --> 00:12:50,140
つまり、それらの線形代数数値計算ライブラリの

382
00:12:50,280 --> 00:12:51,300
一つを使えるような程度の幸運に恵まれたなら、

383
00:12:51,710 --> 00:12:52,980
そしてこれは確かに

384
00:12:53,640 --> 00:12:55,120
どのライブラリでも適用出来るという訳でも無いが、

385
00:12:55,830 --> 00:12:57,800
もしあなたがそれらのライブラリの一つを使っていて

386
00:12:58,200 --> 00:13:00,680
そしてとても良いベクトル化した実装の学習アルゴリズムを用いているなら、

387
00:13:01,720 --> 00:13:02,710
ただ標準的な学習アルゴリズムを

388
00:13:03,160 --> 00:13:05,060
ベクトル化した形で

389
00:13:05,150 --> 00:13:06,460
実装するだけで、

390
00:13:06,710 --> 00:13:08,630
そして並列化について思い煩う事無く、数値計算線形代数ライブラリが

391
00:13:10,030 --> 00:13:12,480
そのうちのいくらかをあなたの代わりに受け持ってくれる。

392
00:13:12,620 --> 00:13:14,710
だからMap Reduceで実装する必要は無い。

393
00:13:14,860 --> 00:13:16,570
だがそれ以外の学習問題では、

394
00:13:17,180 --> 00:13:18,660
この種のMap Reduceの実装を有効利用する事により、

395
00:13:19,240 --> 00:13:20,690
このMap Reduceの定式化を用いる事で

396
00:13:20,880 --> 00:13:22,070
明示的に複数コアに渡る並列化を

397
00:13:22,170 --> 00:13:23,410
自分自身で行う事もまた

398
00:13:23,890 --> 00:13:24,970
同様に良いアイデアだと思う事もあるだろう、

399
00:13:25,070 --> 00:13:27,310
そしてそれを用いてあなたの学習アルゴリズムを高速化する事が可能かもしれない。

400
00:13:29,860 --> 00:13:31,390
このビデオでは、機械学習を

401
00:13:31,730 --> 00:13:33,650
並列化するためのアプローチとして

402
00:13:34,460 --> 00:13:35,850
Map Reduceを議論する。

403
00:13:36,070 --> 00:13:37,450
データセンターのたくさんのマシンに対して

404
00:13:37,830 --> 00:13:39,660
データをばらまくやり方だ。

405
00:13:40,160 --> 00:13:41,930
だが、このアイデアは

406
00:13:42,290 --> 00:13:43,970
一つのマシン内の複数コアで

407
00:13:44,290 --> 00:13:45,400
並列化する為にも

408
00:13:46,870 --> 00:13:47,150
極めて重要な物である。

409
00:13:47,650 --> 00:13:48,600
こんにちでは、Map Reduceの

410
00:13:49,260 --> 00:13:51,080
とても良いオープンソース実装がある。

411
00:13:51,440 --> 00:13:52,210
Hadoopと呼ばれる

412
00:13:52,710 --> 00:13:54,480
オープンソースのシステムには

413
00:13:54,890 --> 00:13:55,820
たくさんのユーザーが居る。だから、自分の

414
00:13:56,010 --> 00:13:57,580
独自実装を使うにせよ誰かの作った

415
00:13:57,850 --> 00:13:59,770
オープンソース実装を使うにせよ、

416
00:13:59,920 --> 00:14:01,090
これらのアイデアを用いて

417
00:14:01,410 --> 00:14:02,730
学習アルゴリズムを並列化する事が出来て、

418
00:14:03,540 --> 00:14:04,580
それらを一つのマシンだけを使う場合と比べたら

419
00:14:04,950 --> 00:14:05,980
より大きなデータセットに対して

420
00:14:06,320 --> 00:14:07,770
走らせる事が可能となる。