在上面几个视频中 我们讨论了 随机梯度下降 以及梯度下降算法的 其他一些变种 包括如何将其 运用于在线学习 然而所有这些算法 都只能在一台计算机上运行 但是 有些机器学习问题 太大以至于不可能 只在一台计算机上运行 有时候 它涉及的数据量如此巨大 以至于不论你使用何种算法 你都不希望只使用 一台计算机来处理这些数据 因此 在这个视频中 我希望介绍 进行大规模机器学习的另一种方法 称为映射约减 (map reduce) 方法 尽管我们 用了多个视频讲解 随机梯度下降算法 而我们将只用少量时间 介绍映射化简 但是请不要根据 我们所花的时间长短 来判断哪一种技术 更加重要 事实上 许多人认为 映射化简方法至少是 同等重要的 还有人认为映射化简方法 甚至比梯度下降方法更重要 我们之所以只在 映射化简上花的时间比较少 只是因为它相对简单 容易解释 然而 实际上 相比于随机梯度下降方法 映射化简方法 能够处理 更大规模的问题 这个方法如下 假设我们要 拟合一个线性回归模型 或者逻辑回归模型 或者其他的什么模型 让我们再次从随机梯度下降算法开始吧 这就是我们的随机梯度下降学习算法 为了让幻灯片上的文字 更容易理解 我们将假定m固定为400个样本 当然 根据 大规模机器学习的标准 m等于400 实在是太小了 也许在实际问题中 你更有可能遇到 样本大小为4亿 的数据 或者其他差不多的大小 但是 为了使我们的讲解更加简单和清晰 我们假定我们只有400个样本 这样一来 随机梯度下降学习算法中 这里是400 以及400个样本的求和 这里i从1取到400 如果m很大 那么这一步的计算量将会很大 因此 下面我们来介绍 映射化简算法 这里我必须指出 映射化简算法的基本思想 来自Jeffrey Dean和Sanjay Ghemawat 这两位研究者 Jeff Dean是硅谷 最为传奇般的 一位工程师 今天谷歌 (Google) 所有的服务 所依赖的后台基础架构 有很大一部分是他创建的 扯远了 我们还是回到映射化简的基本思想 假设我们有一个 训练样本 我们将它表示为 这个方框中的一系列x~y数据对 从x(1) y(1)开始 涵盖我所有的400个样本 直到x(m) y(m) 总之 这就是我的400个训练样本 根据映射化简的思想 一种解决方案是 将训练集划分成几个不同的子集 好 我们基本上已经讲完了两本书 我假定我有 4台计算机 它们并行的 处理我的训练数据 因此我要将数据划分成4份 分给这4台计算机 如果你有10台计算机 或者100台计算机 那么你可能会将训练数据划分成10份或者100份 我的4台计算机中 第一台 将处理第一个 四分之一训练数据 也就是前100个训练样本 具体来说 这台计算机 将参与处理这个求和 它将对前100个训练样本进行求和运算 让我把公式写下来吧 我将计算临时变量 temp(1) 这里的上标(1) 表示第一台计算机 其下标为j 该变量等于从1到100的求和 然后我在这里写的部分 和这里的完全相同 也就是h_θ(x(i))-y(i) 乘以x(i)j 这其实就是 这里的梯度下降公式中的这一项 然后 类似地 我将用第二台计算机 处理我的 第二个四分之一数据 也就是说 我的第二台计算机 将使用第101到200号训练样本 类似地 我们用它 计算临时变量 temp(2)_j 也就是从101到200号 数据的求和 类似的 第三台和第四台 计算机将会使用 第三个和第四个 四分之一训练样本 这样 现在每台计算机 不用处理400个样本 而只用处理100个样本 它们只用完成 四分之一的工作量 这样 也许可以将运算速度提高到原来的四倍 最后 当这些计算机 全都完成了各自的工作 我会将这些临时变量 收集到一起 我会将它们 送到一个 中心计算服务器 这台服务器会 将这些临时变量合并起来 具体来说 它将根据以下公式 来更新参数θj 新的θj将等于 旧的θj减去 学习速率α乘以 400分之一 乘以临时变量 temp(1)_j 加temp(2)_j 加temp(3)_j 加temp(4)_j 当然 对于j等于0的情况我们需要单独处理 这里 j从0 取到特征总数n 通过将这个公式拆成多行讲解 我希望大家已经理解了 其实 这个公式计算的数值 和原先的梯度下降公式计算的数值 是完全一样的 只不过 现在我们有一个中心运算服务器 它收集了一些部分计算结果 temp(1)_j temp(2)_j temp(3)_j 和 temp(4)_j 把它们加了起来 很显然 这四个 临时变量的和 就是这个求和 加上这个求和 再加上这个求和 再加上这个求和 它们加起来的和 其实和原先 我们使用批量梯度下降公式 计算的结果是一样的 接下来 我们有 α乘以400分之一 这里也是α乘以400分之一 因此这个公式 完全等同于批量梯度下降公式 唯一的不同是 我们原本需要在一台计算机上 完成400个训练样本的求和 而现在 我们将这个工作分给了4台计算机 总结来说 映射约减技术是这么工作的 我们有一些训练样本 如果我们希望使用4台计算机 并行的运行机器学习算法 那么我们将训练样本等分 尽量均匀地分成4份 然后 我们将这4个 训练样本的子集送给4台不同的计算机 每一台计算机 对四分之一的 训练数据 进行求和运算 最后 这4个求和结果 被送到一台中心计算服务器 负责对结果进行汇总 在前一张幻灯片中 在那个例子中 梯度下降计算 的内容是对i等于1到400的 400个样本进行求和运算 更宽泛的来讲 在梯度下降计算中 我们是对i等于1到m的m个样本 进行求和 现在 因为这4台计算机 的每一台都可以 完成四分之一的计算工作 因此你可能会得到4倍的加速 特别的 如果没有网络延时 也不考虑 通过网络来回传输数据 所消耗的时间 那么你可能可以得到4倍的加速 当然 在实际工作中 因为网络延时 数据汇总额外消耗时间 以及其他的一些因素 你能得到的加速总是略小于4倍的 但是 不管怎么说 这种映射化简算法 确实让我们能够处理 将能够处理 所无法处理的大规模数据 如果你打算 将映射化简技术用于 加速某个机器学习算法 也就是说 你打算运用多台不同的计算机 并行的进行计算 那么你需要问自己一个很关键的问题 那就是 你的机器学习算法 是否可以表示为训练样本的某种求和 事实证明 很多机器学习算法 的确可以表示为 关于训练样本的函数求和 而在处理大数据时 这些算法的主要运算量 在于对大量训练数据求和 因此 只要你的机器学习算法 可以表示为 训练样本的一个求和 只要算法的 主要计算部分 可以表示为 训练样本的求和 那么你可以考虑使用映射化简技术 来将你的算法扩展到非常大规模的数据上 让我们再看一个例子 假设我们想使用某种高级优化算法 比如说 LBFGS算法 或者共轭梯度算法等等 假设我们想使用逻辑回归算法 于是 我们需要计算两个值 对于LBFGS算法和共轭梯度算法 我们需要计算的第一个值是 我们需要提供一种方法 用于计算 优化目标的代价函数值 比如 对于逻辑回归 你应该记得它的代价函数 可以表示为 训练样本上的这种求和 因此 如果你想在 10台计算机上并行计算 那么你需要将训练样本 分给这10台计算机 让每台计算机 计算10份之一 训练数据的 是异常困难的 高级优化算法 还需要提供 这些偏导数 的计算方法 同样的 对于逻辑回归 这些偏导数 可以表示为 训练数据的求和 因此 和之前的例子类似 你可以让 每台计算机只计算 部分训练数据上的求和 最后 当这些求和计算完成之后 求和结果 会被发送到 一台中心计算服务器上 这台服务器将对结果进行再次求和 这等同于 对临时变量temp(i) 或者 temp(i)_j 进行求和 而这些临时标量 是第i台计算机算出来的 中心计算服务器 对这些临时变量求和 得到了总的代价函数值 以及总的偏导数值 然后你可以将这两个值传给高级优化函数 因此 更广义的来说 通过将机器学习算法 表示为 求和的形式 或者是 训练数据的函数求和形式 你就可以运用映射化简技术 来将算法并行化 这样就可以处理大规模数据了 最后再提醒一点 目前我们只讨论了 运用映射化简技术 在多台计算机上 实现并行计算 也许是一个计算机集群 也许是一个数据中心中的多台计算机 但实际上 有时即使我们只有一台计算机 我们也可以运用这种技术 具体来说 现在的许多计算机 都是多核的 你可以有多个CPU 而每个CPU 又包括多个核 如果你有一个 很大的训练样本 那么你可以 使用一台 四核的计算机 即使在这样一台计算机上 你依然可以 将训练样本分成几份 然后让每一个核 处理其中一份子样本 这样 在单台计算机 或者单个服务器上 你也可以利用映射化简技术来划分计算任务 每一个核 可以处理 比方说四分之一 训练样本的求和 然后我们再将 这些部分和汇总 最终得到整个训练样本上的求和 相对于多台计算机 这样在单台计算机上 使用映射化简技术 的一个优势 在于 现在你不需要 担心网络延时问题 因为所有的通讯 所有的来回数据传输 都发生在一台计算机上 因此 相比于使用数据中心的 多台计算机 现在网络延时的影响 小了许多 最后 关于在一台多核计算机上的并行运算 我再提醒一点 这取决于你的编程实现细节 如果你有一台 多核计算机 并且使用了某个线性代数函数库 那么请注意 某些线性代数函数库 会自动利用多个核 并行地完成线性代数运算 因此 如果你幸运地 使用了这种 线性代数函数库 当然 并不是每个函数库都会自动并行 但如果你用了这样一个函数库 并且你有一个矢量化得很好的算法实现 那么 有时你只需要 按照标准的矢量化方式 实现机器学习算法 而不用管多核并行的问题 因为你的线性代数函数库会自动帮助你完成多核并行的工作 因此 这时你不需要使用映射化简技术 但是 对于其他的问题 使用基于映射化简的实现 寻找并使用 适合映射化简的问题表述 然后实现一个 多核并行的算法 可能是个好主意 它将会加速你的机器学习算法 在这个视频中 我们介绍了映射化简(map reduce)技术 它可以通过 将数据分配到多台计算机的方式 来并行化机器学习算法 实际上这种方法 也可以利用 单台计算机的多个核 广告 今天 网上有许多优秀的 开源映射化简实现 实际上 一个称为Hadoop 的开源系统 已经拥有了众多的用户 通过自己实现映射化简算法 或者使用别人的开源实现 你就可以利用映射化简技术 来并行化机器学习算法 这样你的算法 将能够处理 单台计算机处理不了的大数据 【教育无边界字幕组】翻译：王祖超 校对/审核：所罗门捷列夫