1
00:00:00,320 --> 00:00:01,510
पिछले कुछ वीडियोस में, हमने बात की 

2
00:00:01,810 --> 00:00:03,430
स्टोकस्टिक ग्रेडीयंट डिसेंट की, और, 

3
00:00:03,620 --> 00:00:05,020
जानते हैं, दूसरे वेरिएशंज / रूपांतरण 

4
00:00:05,120 --> 00:00:06,530
स्टोकस्टिक ग्रेडीयंट डिसेंट अल्गोरिद्म के,

5
00:00:06,910 --> 00:00:09,150
जिसमें शामिल हैं वे एडेप्टेशञ्ज / परिवर्तन ऑनलाइन 

6
00:00:09,490 --> 00:00:10,420
लर्निंग के लिए, लेकिन वे सब 

7
00:00:10,610 --> 00:00:11,810
अल्गोरिद्मज़ रन की जा सकती थीं

8
00:00:12,110 --> 00:00:13,740
एक मशीन पर, या रन कर सकते थे एक कम्प्यूटर पर.

9
00:00:14,800 --> 00:00:15,870
और कुछ मशीन लर्निंग प्रॉब्लम्स 

10
00:00:16,310 --> 00:00:17,270
होती हैं काफ़ी बड़ी कि उन्हें सम्भव नहीं होता रन करना 

11
00:00:17,520 --> 00:00:19,160
एक मशीन पर, कभी-कभी शायद 

12
00:00:19,300 --> 00:00:21,050
आपके पास होता है इतना अधिक डेटा कि आप 

13
00:00:21,170 --> 00:00:22,350
नहीं चाहते रन करना कभी भी 

14
00:00:22,670 --> 00:00:23,980
वह सारा डेटा एक 

15
00:00:24,100 --> 00:00:26,270
अकेले कम्प्यूटर से, इससे अंतर नहीं पड़ता कि आप कौन सा अल्गोरिद्म इस्तेमाल कर रहे हैं उस कम्प्यूटर पर.

16
00:00:28,470 --> 00:00:29,640
अत: इस विडीओ में मैं 

17
00:00:29,740 --> 00:00:31,240
बात करना चाहूँगा एक भिन्न पद्धति की 

18
00:00:31,770 --> 00:00:33,610
बड़े स्केल की मशीन लर्निंग के लिए, जिसे कहते हैं 

19
00:00:34,010 --> 00:00:36,190
मैप रिड़ूस पद्धति.

20
00:00:37,030 --> 00:00:38,080
और यद्यपि हमारे पास हैं 

21
00:00:38,380 --> 00:00:39,400
काफ़ी सारे विडीओज़ स्टोकस्टिक 

22
00:00:39,970 --> 00:00:41,230
ग्रेडीयंट डिसेंट पर और हम करेंगे 

23
00:00:41,550 --> 00:00:43,100
व्यतीत अपेक्षाकृत कम समय 

24
00:00:43,460 --> 00:00:45,350
मैप रिड़ूस पर -- न बनाएँ राय इससे  

25
00:00:45,560 --> 00:00:46,750
तुलनात्मक महत्व मैप रिड़ूस की 

26
00:00:47,160 --> 00:00:48,240
ग्रेडीयंट डिसेंट के मुक़ाबले में 

27
00:00:48,690 --> 00:00:49,590
निर्भर करते हुए मात्रा पर 

28
00:00:49,660 --> 00:00:51,480
समय की जो मैं व्यतीत करूँगा इन सुझावों पर ख़ासकर.

29
00:00:52,230 --> 00:00:53,380
बहुत से लोग कहेंगे कि 

30
00:00:53,790 --> 00:00:54,840
मैप रिड़ूस है कम से कम 

31
00:00:55,090 --> 00:00:56,330
एक उतना ही महत्वपूर्ण, और कुछ 

32
00:00:56,580 --> 00:00:57,850
कहेंगे एक और भी अधिक महत्वपूर्ण सुझाव 

33
00:00:58,500 --> 00:01:00,620
तुलना में ग्रेडीयंट डिसेंट की, केवल 

34
00:01:01,460 --> 00:01:03,040
यह है अपेक्षाकृत सरल 

35
00:01:03,160 --> 00:01:04,620
समझाने के लिए, जिस वजह से मैं 

36
00:01:04,720 --> 00:01:05,580
बिताऊँगा कम समय 

37
00:01:05,830 --> 00:01:07,040
इस पर, लेकिन इन सुझावों को इस्तेमाल करते हुए 

38
00:01:07,670 --> 00:01:08,400
आप शायद कर पाएँगे स्केल 

39
00:01:09,070 --> 00:01:10,640
लर्निंग अल्गोरिद्म्स को स्केल और 

40
00:01:10,880 --> 00:01:12,520
भी प्रॉब्लम्स के लिए जितनी 

41
00:01:12,630 --> 00:01:14,530
सम्भव हैं स्टोकस्टिक ग्रेडीयंट डिसेंट से.

42
00:01:18,720 --> 00:01:19,000
यहाँ है सुझाव.

43
00:01:19,810 --> 00:01:21,020
मान लीजिए हम करना चाहते हैं फ़िट 

44
00:01:21,490 --> 00:01:22,960
एक लिनीअर रेग्रेशन मॉडल या 

45
00:01:23,140 --> 00:01:24,440
एक लोजिस्टिक रेग्रेशन मॉडल या कुछ 

46
00:01:24,540 --> 00:01:26,100
ऐसा, और चलिए शुरू करते हैं फिर से 

47
00:01:26,430 --> 00:01:27,660
बैच ग्रेडीयंट डिसेंट से, तो 

48
00:01:27,840 --> 00:01:30,300
वह है हमारा बैच ग्रेडीयंट डिसेंट लर्निंग रूल.

49
00:01:31,240 --> 00:01:32,430
और रखने के लिए लिखावट  

50
00:01:32,850 --> 00:01:34,170
इस स्लाइड पर ट्रेकटेबल / शिक्षणीय, मैं 

51
00:01:34,340 --> 00:01:36,990
मान कर चलूँगा इस दौरान कि मेरे पास हैं एम बराबर 400 इग्ज़ाम्पल्ज़.

52
00:01:37,530 --> 00:01:39,560
निश्चय ही, हमारे 

53
00:01:39,750 --> 00:01:40,850
स्टैंडर्ड से, बड़े स्केल की 

54
00:01:41,090 --> 00:01:42,050
मशीन लर्निंग के लिए, आप जानते हैं, एम 

55
00:01:42,170 --> 00:01:43,210
शायद काफ़ी छोटा है और इसलिए, 

56
00:01:43,770 --> 00:01:45,390
यह शायद अमूमन 

57
00:01:45,870 --> 00:01:46,920
अप्लाई किया जाता है प्रॉब्लम्स को, जहाँ आपके 

58
00:01:47,050 --> 00:01:48,190
पास होते हैं शायद आसपास 400 

59
00:01:48,740 --> 00:01:49,940
मिल्यन इग्ज़ाम्पल, या कुछ 

60
00:01:50,080 --> 00:01:51,310
इतने, लेकिन सिर्फ़ 

61
00:01:51,390 --> 00:01:52,330
करने के लिए लिखना स्लाइड पर 

62
00:01:52,770 --> 00:01:55,000
सरल, मैं मानूँगा कि हमारे पास हैं 400 इग्ज़ाम्पल्ज़.

63
00:01:55,690 --> 00:01:57,460
अत: उस स्थिति में, 

64
00:01:57,790 --> 00:01:59,080
बैच ग्रेडीयंट डिसेंट लर्निंग रूल

65
00:01:59,570 --> 00:02:00,930
के पास है यह 400 और 

66
00:02:01,500 --> 00:02:02,930
सम आइ ईक्वल्ज़ वन से 

67
00:02:03,330 --> 00:02:05,050
400 तक मेरे 400 इग्ज़ाम्पल्ज़ 

68
00:02:05,590 --> 00:02:06,890
यहाँ, और यदि एम 

69
00:02:07,050 --> 00:02:09,780
है बड़ा, तब यह है एक कॉम्प्यूटेशनली महँगा स्टेप.

70
00:02:10,890 --> 00:02:12,830
तो, जो  मैप रिड़ूस का आइडिया 

71
00:02:13,250 --> 00:02:14,470
करता है वह निम्नलिखित है, और 

72
00:02:14,890 --> 00:02:15,740
मुझे कहना चाहिए मैप 

73
00:02:15,950 --> 00:02:16,940
रिड़ूस आइडिया है बदौलत 

74
00:02:17,680 --> 00:02:20,190
दो खोज करने वालों की, जेफ़ डीन 

75
00:02:20,700 --> 00:02:22,060
और संजय गिमावत.

76
00:02:22,640 --> 00:02:23,490
जेफ़ डीन है, वैसे,

77
00:02:24,190 --> 00:02:26,520
एक सबसे महत्वपूर्ण एंज़िनियर 

78
00:02:26,660 --> 00:02:28,300
पूरी सिलिकन वैली में और उन्होंने 

79
00:02:28,420 --> 00:02:29,530
बनाया है एक तरह से बड़ा 

80
00:02:29,820 --> 00:02:31,670
हिस्सा आर्किटेक्चर के

81
00:02:32,310 --> 00:02:34,770
बुनियादी ढाँचा का जिस पर पूरा गूगल आज रन करता है.

82
00:02:36,000 --> 00:02:37,320
लेकिन यहाँ है मैप रिड़ूस का आइडिया.

83
00:02:37,850 --> 00:02:38,570
तो, मान लो मेरे पास है 

84
00:02:38,700 --> 00:02:39,840
कोई ट्रेनिंग सेट, यदि हम 

85
00:02:39,900 --> 00:02:41,220
चाहते हैं डिनोट करना इस बॉक्स से यहाँ 

86
00:02:41,610 --> 00:02:42,760
एक्स वाय युग्म के,

87
00:02:44,250 --> 00:02:47,730
जहाँ यह है एक्स 1, वाय 1, नीचे 

88
00:02:47,990 --> 00:02:49,640
मेरे 400 इग्ज़ाम्पल्ज़ तक,

89
00:02:50,520 --> 00:02:51,660
एक्स एम, वाय एम.

90
00:02:52,190 --> 00:02:53,780
तो, वह है मेरा ट्रेनिंग सेट 400 ट्रेनिंग इग्ज़ाम्पल्ज़ का.

91
00:02:55,060 --> 00:02:56,550
 मैप रिड़ूस के आइडिया में, एक तरीक़ा 

92
00:02:56,690 --> 00:02:58,190
करने का है, कि विभाजित करें इस ट्रेनिंग 

93
00:02:58,570 --> 00:03:00,510
सेट को भिन्न भिन्न सबसेट्स में.

94
00:03:01,890 --> 00:03:02,590
मैं करूँगा

95
00:03:02,950 --> 00:03:04,150
मान लूँगा कि इस उदाहरण में जहाँ 

96
00:03:04,290 --> 00:03:05,530
मेरे पास हैं 4 कम्प्यूटर्ज़, 

97
00:03:06,160 --> 00:03:07,160
या 4 मशींज़ रन करने के लिए 

98
00:03:07,300 --> 00:03:08,670
समानांतर मेरे ट्रेनिंग सेट पर,

99
00:03:08,890 --> 00:03:10,570
इस वजह से मैं विभाजित कर रहा हूँ इसे 4 मशींज़ पर.

100
00:03:10,920 --> 00:03:12,290
यदि आपके पास हैं 10 मशींज़ या 

101
00:03:12,400 --> 00:03:13,810
100 मशींज़, तब आप करेंगे 

102
00:03:13,970 --> 00:03:15,890
विभाजित आपके ट्रेनिंग सेट को 10 हिस्सों या 100 हिस्सों या जो भी आपके पास है.

103
00:03:18,040 --> 00:03:19,710
और क्या मेरी पहली इन 

104
00:03:19,850 --> 00:03:20,840
4 मशींज़ को करना है,

105
00:03:21,100 --> 00:03:23,170
मान लो, इस्तेमाल करेगी सिर्फ़ 

106
00:03:23,270 --> 00:03:25,170
पहला एक चौथाई मेरे 

107
00:03:25,300 --> 00:03:28,680
ट्रेनिंग सेट का - अत: केवल इस्तेमाल करेगी मेरे पहले 100 ट्रेनिंग इग्ज़ाम्पल्ज़.

108
00:03:30,020 --> 00:03:31,440
और विशेषत:, यह क्या 

109
00:03:31,480 --> 00:03:32,520
करेगी कि देखेगी 

110
00:03:32,630 --> 00:03:34,800
इस समेशन पर, और कम्प्यूट करेगी 

111
00:03:35,490 --> 00:03:38,560
उस समेशन को केवल पहले 100 ट्रेनिंग इग्ज़ाम्पल्ज़ के लिए.

112
00:03:40,030 --> 00:03:40,960
तो मैं लिखता हूँ वह 

113
00:03:41,110 --> 00:03:42,530
मैं करूँगा कम्प्यूट एक वेरीयबल 

114
00:03:43,560 --> 00:03:46,230
टेम्प 1 सूपर स्क्रिप्ट 1 

115
00:03:46,320 --> 00:03:49,410
पहली मशीन जे बराबर है 

116
00:03:50,450 --> 00:03:52,150
सम बराबर 1 से 

117
00:03:52,260 --> 00:03:53,160
100 तक, और तब मैं करूँगा प्लग 

118
00:03:53,500 --> 00:03:56,610
इन बिल्कुल वही टर्म वहाँ - तो मेरे पास है 

119
00:03:57,260 --> 00:04:00,140
एक्स-थीटा, एक्स आइ, माइनस वाय आइ 

120
00:04:01,800 --> 00:04:03,230
टाइम्ज़ एक्स आइ जे, सही?

121
00:04:03,740 --> 00:04:05,680
तो वह है केवल वह 

122
00:04:05,910 --> 00:04:07,460
ग्रेडीयंट डिसेंट टर्म ऊपर यहाँ.

123
00:04:08,300 --> 00:04:09,780
और इसी प्रकार, मैं जा रहा हूँ 

124
00:04:10,010 --> 00:04:11,330
लेने दूसरा एक चौथाई 

125
00:04:11,600 --> 00:04:13,130
मेरे डेटा का और भेजूँगा इसे 

126
00:04:13,320 --> 00:04:14,520
मेरी दूसरी मशीन को, और 

127
00:04:14,690 --> 00:04:15,680
मेरी दूसरी मशीन इस्तेमाल करेगी 

128
00:04:15,900 --> 00:04:18,750
ट्रेनिंग इग्ज़ाम्पल्ज़ 101 से 200 तक 

129
00:04:19,350 --> 00:04:21,170
और आप करेंगे कम्प्यूट वैसे ही वेरीयबल्स 

130
00:04:21,720 --> 00:04:22,880
टेम्प जे के जो 

131
00:04:23,110 --> 00:04:24,450
है वही सम इंडेक्स 

132
00:04:24,890 --> 00:04:26,620
इग्ज़ाम्पल्ज़ 101 से 200 तक.

133
00:04:26,840 --> 00:04:29,680
और इसी प्रकार मशीन्स 3 

134
00:04:29,830 --> 00:04:32,720
और 4 इस्तेमाल करेंगे 

135
00:04:32,830 --> 00:04:34,110
तीसरा और चौथा 

136
00:04:34,570 --> 00:04:36,550
एक चौथाई मेरे ट्रेनिंग सेट का.

137
00:04:37,530 --> 00:04:38,950
तो अब प्रत्येक मशीन को 

138
00:04:39,190 --> 00:04:40,580
सम करना है 100 पर बजाय 

139
00:04:41,060 --> 00:04:42,570
400 इग्ज़ाम्पल्ज़ पर और इसलिए 

140
00:04:42,760 --> 00:04:43,750
करना है सिर्फ़ एक एक चौथाई 

141
00:04:44,050 --> 00:04:45,220
काम और इसलिए सम्भवत:

142
00:04:45,900 --> 00:04:48,000
यह करेगी इसे लगभग 4 गुणा अधिक तीव्र.

143
00:04:49,380 --> 00:04:50,630
अंत में, बाद में ये सारी मशीन्स 

144
00:04:50,990 --> 00:04:51,740
का यह काम हो जाने पर, मैं 

145
00:04:51,850 --> 00:04:53,560
लूँगा ये टेम्प वेरीयबल्स 

146
00:04:55,350 --> 00:04:56,480
और उनको रखूँगा वापिस एक साथ.

147
00:04:56,870 --> 00:04:58,400
तो मैं लेता हूँ ये वेरीयबल्स और 

148
00:04:58,530 --> 00:04:59,950
भेजता हूँ उन सबको एक आप 

149
00:05:00,090 --> 00:05:03,080
जानते हैं केंद्रीय मास्टर सर्वर पर और 

150
00:05:03,300 --> 00:05:04,750
मास्टर क्या करेगा कि 

151
00:05:05,140 --> 00:05:06,720
मिलाएगा इन परिणामों को एक साथ.

152
00:05:07,360 --> 00:05:08,470
और विशेषत:, यह करेगा 

153
00:05:08,780 --> 00:05:10,780
अप्डेट मेरे पेरमिटर्स थीटा 

154
00:05:11,000 --> 00:05:13,160
जे इस प्रकार थीटा 

155
00:05:13,410 --> 00:05:14,720
जे अप्डेट होगा इस प्रकार थीटा जे 

156
00:05:15,730 --> 00:05:17,560
माइनस 

157
00:05:17,680 --> 00:05:19,510
लर्निंग रेट अल्फ़ा टाइम्ज़ वन 

158
00:05:20,120 --> 00:05:22,940
ओवर 400 टाइम्ज़ टेम्प,

159
00:05:23,300 --> 00:05:27,410
1, जे, प्लस टेम्प 

160
00:05:27,760 --> 00:05:30,290
2जे प्लस टेम्प 3जे 

161
00:05:32,400 --> 00:05:35,470
प्लस टेम्प 4जे और 

162
00:05:35,560 --> 00:05:37,890
निश्चय ही हमें यह करना है अलग से जे ईक्वल्ज़ 0 के लिए॰ 

163
00:05:37,980 --> 00:05:39,570
आप जानते हैं, इतने तक 

164
00:05:39,820 --> 00:05:41,220
और फ़ीचर्ज़ इस संख्या के अंदर तक के लिए.

165
00:05:42,550 --> 00:05:45,420
तो मैं लिख रहा था यह इक्वेज़न बहुत सी लाइन्स में, आशा है यह स्पष्ट है.

166
00:05:45,670 --> 00:05:47,870
तो यह इक्वेज़न क्या 

167
00:05:50,930 --> 00:05:53,220
करती है बिल्कुल 

168
00:05:53,290 --> 00:05:54,570
वैसा ही जो जब आपके 

169
00:05:54,660 --> 00:05:56,140
पास है एक केंद्रीय मास्टर सर्वर 

170
00:05:56,680 --> 00:05:57,950
जो लेता है परिणाम, दस 

171
00:05:58,040 --> 00:05:58,780
एक जे दस दो जे 

172
00:05:59,000 --> 00:05:59,850
दस तीन जे और दस चार 

173
00:05:59,970 --> 00:06:01,760
जे और जोड़ देता है उन्हें 

174
00:06:02,030 --> 00:06:03,430
और इसलिए निश्चय ही सम 

175
00:06:04,090 --> 00:06:04,960
है इन चार चीज़ों का.

176
00:06:06,360 --> 00:06:07,810
सही, वह है सिर्फ़ सम 

177
00:06:08,060 --> 00:06:09,440
इसका, प्लस सम 

178
00:06:09,760 --> 00:06:11,490
इसका, प्लस सम 

179
00:06:11,630 --> 00:06:13,000
इसका, प्लस सम 

180
00:06:13,120 --> 00:06:14,290
उसका, और वे चार 

181
00:06:14,470 --> 00:06:15,830
चीज़ें सिर्फ़ जोड़ कर 

182
00:06:15,920 --> 00:06:17,740
बराबर हैं इस सम के जो 

183
00:06:17,880 --> 00:06:19,580
हम आरम्भ में कम्प्यूट कर रहे थे बैच ग्रेडीयंट डिसेंट में.

184
00:06:20,590 --> 00:06:21,550
और तब हमारे पास है अल्फ़ा टाइम्ज़ 

185
00:06:21,860 --> 00:06:22,910
 1 से 400, अल्फ़ा टाइम्ज़ 1

186
00:06:23,350 --> 00:06:24,690
से 100 और यह है 

187
00:06:25,020 --> 00:06:27,020
बिल्कुल बराबर 

188
00:06:27,140 --> 00:06:29,390
बैच ग्रेडीयंट डिसेंट अल्गोरिद्म के ही.

189
00:06:29,910 --> 00:06:30,880
बजाय आवश्यक होने के निकालना सम 

190
00:06:31,290 --> 00:06:32,540
पूरे चार सौ ट्रेनिंग 

191
00:06:32,810 --> 00:06:33,900
इग्ज़ाम्पल्ज़ पर केवल एक 

192
00:06:34,040 --> 00:06:35,280
मशीन पर, हम कर सकते हैं इसके स्थान पर 

193
00:06:35,760 --> 00:06:37,460
विभाजित वर्क लोड को चार मशीन्स पर.

194
00:06:39,090 --> 00:06:40,190
तो, यहाँ है कि क्या है सामान्य 

195
00:06:40,630 --> 00:06:43,410
पिक्चर जो मैप रिड़ूस टेक्नीक दिखती है.

196
00:06:45,060 --> 00:06:46,510
हमारे पास हैं कुछ ट्रेनिंग सेट्स, और 

197
00:06:46,670 --> 00:06:48,200
यदि हम करना चाहते हैं समानांतर चार 

198
00:06:48,420 --> 00:06:49,100
मशीन पर, हम करेंगे कि 

199
00:06:49,170 --> 00:06:51,670
लें ट्रेनिंग सेट को और इसे विभाजित करें, आप जानते हैं बराबर.

200
00:06:52,120 --> 00:06:54,640
विभाजित करे इसे एक सा जितना हो सके चार सब सेट्स में.

201
00:06:56,470 --> 00:06:57,110
तब हम लेंगे 

202
00:06:57,180 --> 00:06:59,560
4 सब सेट्स ट्रेनिंग डेटा के और भेजेंगे उन्हें 4 भिन्न कम्प्यूटर्ज़ पर.

203
00:07:00,530 --> 00:07:01,660
और प्रत्येक उन 4 कम्प्यूटर्ज़ में 

204
00:07:02,130 --> 00:07:03,570
कर सकता है कम्प्यूट एक समेशन 

205
00:07:03,950 --> 00:07:04,850
केवल एक चौथाई 

206
00:07:04,910 --> 00:07:06,230
ट्रेनिंग सेट पर, और तब 

207
00:07:06,340 --> 00:07:07,720
अंत में लेंगे प्रत्येक 

208
00:07:07,780 --> 00:07:09,310
कम्प्यूटर का परिणाम, भेजेंगे 

209
00:07:09,580 --> 00:07:12,720
उन्हें एक केंद्रीय सर्वर पर, जो तब मिलाएगा / जोड़ेगा परिणामों को एक साथ.

210
00:07:13,570 --> 00:07:14,900
तो, पिछली लाइन पर 

211
00:07:15,190 --> 00:07:16,540
उस उदाहरण में, अधिकांश 

212
00:07:16,800 --> 00:07:17,910
कार्य ग्रेडीयंट डिसेंट का,

213
00:07:18,330 --> 00:07:20,140
था कम्प्यूट करना सम 

214
00:07:20,430 --> 00:07:22,270
आइ बराबर 1 से 400 तक किसी चीज़ का.

215
00:07:22,670 --> 00:07:24,110
अत: सामान्य तौर पर, सम 

216
00:07:24,370 --> 00:07:25,570
आइ बराबर 1 से एम 

217
00:07:26,320 --> 00:07:28,180
उस फ़ॉर्म्युला का ग्रेडीयंट डिसेंट के लिए.

218
00:07:29,160 --> 00:07:30,430
और अब, क्योंकि प्रत्येक 

219
00:07:30,550 --> 00:07:31,890
चार कम्प्यूटर्ज़ में से कर सकता है सिर्फ़ 

220
00:07:32,190 --> 00:07:33,800
एक चौथाई काम, सम्भवत:

221
00:07:34,350 --> 00:07:35,940
आपको मिल सकती है एक 4x गति ज़्यादा.

222
00:07:38,820 --> 00:07:39,980
विशेषत:, यदि वहाँ होती 

223
00:07:40,190 --> 00:07:41,900
नहीं कोई नेटवर्क लेटेन्सी और 

224
00:07:42,100 --> 00:07:42,970
न कोई क़ीमत नेटवर्क 

225
00:07:43,400 --> 00:07:44,450
कम्यूनिकेशन पर भेजने के लिए 

226
00:07:44,600 --> 00:07:45,450
डेटा आगे पीछे, आपको 

227
00:07:45,610 --> 00:07:47,820
संभवत: मिल सकती है 4x गति अधिक.

228
00:07:48,050 --> 00:07:49,410
निश्चय ही, व्यवहार में,

229
00:07:50,100 --> 00:07:52,080
नेटवर्क लेटेन्सी की वजह से,

230
00:07:52,810 --> 00:07:54,500
ओवरहेड / ऊपर का ख़र्चा जोड़ने का 

231
00:07:54,600 --> 00:07:55,880
परिणाम बाद में और अन्य फेकटर्ज़ / कारक,

232
00:07:56,640 --> 00:07:59,150
व्यवहार में आपको मिलती है 4x से थोड़ी कम गति.

233
00:08:00,140 --> 00:08:01,280
लेकिन, फिर भी, इस प्रकार 

234
00:08:01,360 --> 00:08:02,710
की मैप रिड़ूस पद्धति अवश्य ही देता है 

235
00:08:03,110 --> 00:08:04,560
हमें एक ढंग प्रॉसेस करने का उससे 

236
00:08:04,870 --> 00:08:05,940
बड़े डेटा सेट्स उससे जो है 

237
00:08:06,270 --> 00:08:07,550
सम्भव एक अकेले कम्प्यूटर से.

238
00:08:08,770 --> 00:08:10,060
यदि आप सोच रहे हैं अप्लाई करने का 

239
00:08:10,730 --> 00:08:12,200
मैप रिड़ूस किसी लर्निंग 

240
00:08:12,350 --> 00:08:14,260
अल्गोरिद्म में, उसे तीव्र करने के लिए.

241
00:08:14,750 --> 00:08:16,160
समानांतर करने से कॉम्प्यूटेशन को  

242
00:08:16,900 --> 00:08:18,480
विभिन्न कम्प्यूटर्ज़ पर, प्रमुख 

243
00:08:18,730 --> 00:08:20,040
प्रश्न जो आपको अपने आप से पूछना चाहिए है,

244
00:08:20,760 --> 00:08:22,190
क्या आपका लर्निंग अल्गोरिद्म व्यक्त किया जा सकता हैं 

245
00:08:22,880 --> 00:08:25,150
एक समेशन की तरह ट्रेनिंग सेट पर?

246
00:08:25,440 --> 00:08:26,430
और ऐसा होता है कि बहुत से 

247
00:08:26,670 --> 00:08:28,100
लर्निंग अल्गोरिद्म्स वास्तव में किए जा सकते हैं 

248
00:08:28,410 --> 00:08:29,880
व्यक्त कम्प्यूट करते हुए सम 

249
00:08:30,170 --> 00:08:31,820
फ़ंक्शन्स की तरह ट्रेनिंग सेट पर और 

250
00:08:32,610 --> 00:08:34,030
कॉम्प्यूटेशनल क़ीमत रन करने की 

251
00:08:34,250 --> 00:08:35,480
उन्हें एक बड़े डेटा सेट पर है 

252
00:08:35,600 --> 00:08:37,810
क्योंकि उन्हें आवश्यकता है सम करने की एक बहुत बड़े ट्रेनिंग सेट पर.

253
00:08:38,620 --> 00:08:39,870
तो, जब भी आपका लर्निंग अल्गोरिद्म 

254
00:08:40,200 --> 00:08:41,350
व्यक्त किया जा सकता हैं एक 

255
00:08:41,450 --> 00:08:42,410
सम की तरह ट्रेनिंग सेट के 

256
00:08:42,660 --> 00:08:43,760
और जब भी अधिकांश 

257
00:08:43,860 --> 00:08:44,810
कार्य लर्निंग अल्गोरिद्म का 

258
00:08:45,200 --> 00:08:46,170
किया जा सकता हैं व्यक्त सम की तरह 

259
00:08:46,320 --> 00:08:47,780
ट्रेनिंग सेट के, तब मैप 

260
00:08:48,030 --> 00:08:49,030
रिड़ूस हो सकता है एक अच्छा विकल्प 

261
00:08:50,100 --> 00:08:52,830
स्केल करने के लिए आपके अल्गोरिद्म को एक बहुत बड़े डेटा सेट से.

262
00:08:53,880 --> 00:08:54,910
चलिये सिर्फ़ एक और उदाहरण पर नज़र डालते हैं.

263
00:08:56,020 --> 00:08:58,120
मान लो हम चाहते हैं इस्तेमाल करना कोई एक एडवांस्ड ऑप्टिमायज़ेशन अल्गोरिद्म.

264
00:08:58,410 --> 00:08:59,430
तो, चीज़ें जैसे, आप 

265
00:08:59,550 --> 00:09:00,460
जानते हैं, एल-बी एफ़ जी एस कॉंजुगेट 

266
00:09:00,900 --> 00:09:02,960
ग्रेडीयंट और इसी प्रकार.

267
00:09:03,070 --> 00:09:05,190
मान लो हम चाहते हैं ट्रेन करना एक लजिस्टिक रेग्रेशन अल्गोरिद्म का.

268
00:09:06,080 --> 00:09:08,680
उसके लिए, हमें कम्प्यूट करनी हैं दो प्रमुख संख्याएँ.

269
00:09:09,300 --> 00:09:10,460
पहली है एडवांस्ड 

270
00:09:10,960 --> 00:09:13,520
ऑप्टिमायज़ेशन अल्गोरिद्म के लिए, जैसे आप जानते हैं, एल-बीएफ़जीएस और कॉंजुगेट ग्रेडीयंट.

271
00:09:14,310 --> 00:09:15,270
हमें देना है इसे एक 

272
00:09:15,530 --> 00:09:17,210
रूटीन कम्प्यूट करने के लिए 

273
00:09:17,460 --> 00:09:18,760
कॉस्ट फ़ंक्शन ऑप्टिमायज़ेशन अब्जेक्टिव का.

274
00:09:20,220 --> 00:09:21,690
और इसलिए लजिस्टिक रेग्रेशन के लिए, आप 

275
00:09:21,820 --> 00:09:22,870
याद करें कि एक कोस्ट फ़ंक्शन के

276
00:09:23,660 --> 00:09:24,700
पास है इस प्रकार का सम 

277
00:09:24,960 --> 00:09:26,340
ट्रेनिंग सेट पर, और इसलिए 

278
00:09:26,970 --> 00:09:28,980
यदि आप समानांतर कर रहे हैं 

279
00:09:29,110 --> 00:09:29,970
दस मशीन्स पर, आप करेंगे विभाजित 

280
00:09:30,310 --> 00:09:31,640
ट्रेनिंग सेट को दस 

281
00:09:31,910 --> 00:09:33,150
मशीन्स पर और करवाएँगे 

282
00:09:33,360 --> 00:09:35,380
दस मशीन्स से कम्प्यूट सम 

283
00:09:35,860 --> 00:09:37,460
इस संख्या का केवल 

284
00:09:37,760 --> 00:09:38,660
दसवें हिस्से पर ट्रेनिंग 

285
00:09:40,370 --> 00:09:40,370
डेटा के.

286
00:09:40,670 --> 00:09:41,550
तब, दूसरी चीज़ जो 

287
00:09:42,110 --> 00:09:43,400
एडवांस्ड ऑप्टिमायज़ेशन अल्गोरिद्म को चाहिए,

288
00:09:43,660 --> 00:09:44,790
वह है एक रूटीन कम्प्यूट करने के लिए

289
00:09:45,190 --> 00:09:47,160
इन पारशियल डेरिवेटिव टर्म्ज़ को.

290
00:09:47,280 --> 00:09:48,980
एक बार फिर, ये डेरिवेटिव टर्म्ज़

291
00:09:49,100 --> 00:09:50,350
जिनके लिए यह एक लजिस्टिक रेग्रेशन है, की जा सकती हैं 

292
00:09:50,540 --> 00:09:51,840
व्यक्त सम की तरह 

293
00:09:52,010 --> 00:09:53,130
ट्रेनिंग सेट पर, और इसलिए एक 

294
00:09:53,330 --> 00:09:54,600
बार फिर से, समान हमारे पहले के 

295
00:09:54,950 --> 00:09:56,060
उदाहरण के, आप के पास होगा 

296
00:09:56,520 --> 00:09:57,800
प्रत्येक मशीन कम्प्यूट करते हुए वह समेशन 

297
00:09:58,800 --> 00:10:01,170
केवल कुछ छोटे अंश पर आपके ट्रेनिंग डेटा के.

298
00:10:02,440 --> 00:10:04,590
और अंत में, कम्प्यूट कर लेने के बाद 

299
00:10:05,050 --> 00:10:06,260
ये सब चीज़ें, वे 

300
00:10:06,400 --> 00:10:07,520
तब भेज सकते हैं उनके परिणाम 

301
00:10:07,680 --> 00:10:09,400
केंद्रीय सर्वर को, जो कर सकता हैं 

302
00:10:09,640 --> 00:10:12,760
तब जमा पर्शियल समज़ को.

303
00:10:13,320 --> 00:10:14,410
यह कॉरेस्पॉंड करता हैं जमा करने को 

304
00:10:14,500 --> 00:10:17,000
वे दसवें आइ या 

305
00:10:17,550 --> 00:10:21,880
दसवें आई जे वेरीयबल्स को, जो 

306
00:10:22,100 --> 00:10:23,610
कम्प्यूट किए गए थे उसी मशीन 

307
00:10:23,980 --> 00:10:25,390
संख्या आइ पर, और इसलिए 

308
00:10:25,420 --> 00:10:26,800
केंद्रीय सर्वर कर सकता है सम 

309
00:10:27,050 --> 00:10:28,220
इन चीज़ों का और पा सकता है 

310
00:10:28,450 --> 00:10:30,230
ओवरॉल कोस्ट फ़ंक्शन 

311
00:10:30,870 --> 00:10:32,750
और पा सकता है ओवरॉल पर्शियल डेरिवेटिव,

312
00:10:33,390 --> 00:10:35,710
जो आप तब भेज सकते हैं एडवांस्ड ऑप्टिमायज़ेशन अल्गोरिद्म को. 

313
00:10:36,890 --> 00:10:38,100
तो, अधिक विस्तार से, लेने से 

314
00:10:39,080 --> 00:10:40,790
दूसरे लर्निंग अल्गोरिद्म्स और 

315
00:10:41,020 --> 00:10:42,430
व्यक्त करके उन्हें इस प्रकार की 

316
00:10:42,720 --> 00:10:43,800
समेशन रूप में या व्यक्त करके 

317
00:10:44,340 --> 00:10:45,660
उन्हें टर्म्ज़ में कम्प्यूट करने के लिए सम 

318
00:10:45,990 --> 00:10:47,100
फ़ंक्शंज़ का ट्रेनिंग सेट पर, 

319
00:10:47,740 --> 00:10:49,290
आप कर सकते हैं इस्तेमाल मैप रिड़ूस टेक्नीक का 

320
00:10:49,440 --> 00:10:51,420
समानांतर करने के लिए दूसरे लर्निंग अल्गोरिद्म्स को भी, 

321
00:10:51,710 --> 00:10:53,310
और स्केल कर सकते हैं उन्हें बहुत बड़े ट्रेनिंग सेट्स पर भी.

322
00:10:54,340 --> 00:10:55,850
अंत में, एक आख़िरी टिप्पणी,

323
00:10:56,390 --> 00:10:57,170
अभी तक हम 

324
00:10:57,510 --> 00:10:59,630
चर्चा कर रहे थे मैप रिड़ूस अल्गोरिद्म की 

325
00:10:59,850 --> 00:11:01,400
जो आपको समानांतर करने दे सकता हैं 

326
00:11:02,090 --> 00:11:03,630
बहुत से कम्प्यूटर्ज़ पर, शायद विभिन्न 

327
00:11:03,940 --> 00:11:05,020
कम्प्यूटर्ज़ पर एक कम्प्यूटर 

328
00:11:05,220 --> 00:11:08,060
क्लस्टर में या विभिन्न कम्प्यूटर्ज़ पर एक डेटा सेंटर में.

329
00:11:09,150 --> 00:11:10,580
ऐसा होता हैं कि कभी कभी यदि 

330
00:11:10,770 --> 00:11:12,010
आपके पास एक अकेला कम्प्यूटर ही है,

331
00:11:13,090 --> 00:11:14,390
मैप रिड़ूस तब भी अप्लाई कर सकते हैं.

332
00:11:15,530 --> 00:11:16,970
ख़ासतौर पर, बहुत से सिंगल 

333
00:11:17,320 --> 00:11:18,510
कम्प्यूटर्ज़ पर आजकल, आपके पास हो सकते हैं 

334
00:11:18,780 --> 00:11:20,520
बहुत से प्रासेसिंग कोरज़.

335
00:11:21,170 --> 00:11:21,860
आपके पास हो सकते हैं बहुत से सीपीयू.

336
00:11:22,180 --> 00:11:23,120
और प्रत्येक सीपीयू में हो सकते हैं 

337
00:11:23,240 --> 00:11:26,170
बहुत से प्रासेसिंग कोरज़.

338
00:11:26,310 --> 00:11:27,170
यदि आपके पास है एक बड़ा ट्रेनिंग 

339
00:11:27,520 --> 00:11:28,460
सेट, आप क्या  

340
00:11:28,570 --> 00:11:29,540
कर सकते हैं, यदि, मान लो, आपके पास है 

341
00:11:29,740 --> 00:11:31,520
एक कम्प्यूटर 4 

342
00:11:31,880 --> 00:11:33,400
कम्प्यूटिंग कोरज़ के साथ, आप क्या 

343
00:11:33,460 --> 00:11:34,390
कर सकते हैं, एक 

344
00:11:34,550 --> 00:11:35,580
सिंगल कम्प्यूटर पर भी आप विभाजित कर सकते हैं 

345
00:11:35,760 --> 00:11:37,680
ट्रेनिंग सेट को हिस्सों में और 

346
00:11:37,810 --> 00:11:39,140
भेज सकते हैं ट्रेनिंग सेट को विभिन्न 

347
00:11:39,660 --> 00:11:40,960
कोर्स पर एक सिंगल बॉक्स में, 

348
00:11:41,220 --> 00:11:42,570
जैसे एक सिंगल डेस्क्टाप कम्प्यूटर में 

349
00:11:43,240 --> 00:11:45,070
या एक सिंगल सर्वर में और इस्तेमाल कर सकते हैं 

350
00:11:45,370 --> 00:11:47,200
मैप रिड़ूस इस प्रकार विभाजित करने के लिए वर्क लोड को.

351
00:11:48,000 --> 00:11:49,010
प्रत्येक कोर तब 

352
00:11:49,200 --> 00:11:50,240
कर सकता है सम, 

353
00:11:50,950 --> 00:11:52,000
मान लो, एक चौथाई आपके 

354
00:11:52,050 --> 00:11:53,440
ट्रेनिंग सेट पर, और तब वे 

355
00:11:53,510 --> 00:11:55,090
ले सकते हैं पर्शियल समज़ और 

356
00:11:55,510 --> 00:11:56,890
मिला / जोड़ सकते हैं उन्हें, पाने 

357
00:11:57,220 --> 00:11:59,360
के लिए समेशन पूरे ट्रेनिंग सेट पर.

358
00:11:59,750 --> 00:12:01,280
लाभ सोचने का 

359
00:12:01,600 --> 00:12:02,880
मैप रिड़ूस के बारे में इस तरह से है कि, 

360
00:12:03,350 --> 00:12:04,760
समानांतर करने का एक 

361
00:12:04,900 --> 00:12:06,720
सिंगल मशीन पर ही, बजाय समानांतर करने के 

362
00:12:06,910 --> 00:12:08,480
विभिन्न मशीन्स पर है कि,

363
00:12:09,060 --> 00:12:09,970
इस तरह आपको नहीं करनी पड़ती 

364
00:12:10,100 --> 00:12:11,740
चिंता नेटवर्क लेटेन्सी की क्योंकि 

365
00:12:12,020 --> 00:12:13,380
पूरा कम्यूनिकेशन, सारा

366
00:12:13,460 --> 00:12:14,810
भेजना [एक्स एक्स] का 

367
00:12:15,890 --> 00:12:18,020
पीछे और आगे, वह पूरा होता है एक सिंगल मशीन में.

368
00:12:18,420 --> 00:12:20,170
और इसलिए नेटवर्क लेटेन्सी हो जाती है 

369
00:12:20,590 --> 00:12:21,530
एक काफ़ी कम समस्या तुलना में 

370
00:12:21,960 --> 00:12:23,050
यदि आप इस्तेमाल कर रहे होते इसे 

371
00:12:23,540 --> 00:12:26,080
विभिन्न कम्प्यूटर्ज़ पर एक डेटा सेंटर में.

372
00:12:27,040 --> 00:12:27,930
अंत में, एक आख़िरी चेतावनी 

373
00:12:27,990 --> 00:12:30,740
समानांतर करने में एक मल्टी-कोर मशीन पर.

374
00:12:31,580 --> 00:12:32,600
निर्भर करते हुए विस्तृत जानकारी पर 

375
00:12:32,930 --> 00:12:34,290
आपकी इम्प्लमेंटेशन की, यदि आपके पास है एक 

376
00:12:34,610 --> 00:12:35,920
मल्टी-कोर मशीन और यदि आपके 

377
00:12:36,190 --> 00:12:38,130
पास हैं कुछ नूमेरिकल ऐल्जेब्रा लाइब्रेरीज़.

378
00:12:39,350 --> 00:12:40,490
ऐसा होता हैं कुछ नूमेरिकल लिनीअर ऐल्जेब्रा लाइब्रेरीज़ 

379
00:12:41,490 --> 00:12:43,940
कर सकती हैं समानांतर अपने आप उनके 

380
00:12:44,680 --> 00:12:47,500
लिनीअर ऐल्जेब्रा ऑपरेशंज़ को बहुत से कोर्स पर उस मशीन पर. 

381
00:12:48,770 --> 00:12:50,140
अत यदि आप भाग्यशाली हैं 

382
00:12:50,280 --> 00:12:51,300
कि आप इस्तेमाल कर रहे हैं वे नूमेरिकल लिनीअर ऐल्जेब्रा 

383
00:12:51,710 --> 00:12:52,980
लाईब्रेरीज़ और निश्चय ही 

384
00:12:53,640 --> 00:12:55,120
यह अप्लाई नहीं करता है प्रत्येक लाइब्रेरी को.

385
00:12:55,830 --> 00:12:57,800
यदि आप इस्तेमाल कर रहे हैं उनमें से एक लाइब्रेरी और 

386
00:12:58,200 --> 00:13:00,680
यदि आपके पास है एक अच्छी वेक्टराइज्ड इम्प्लमेंटेशन लर्निंग अल्गोरिद्म की.

387
00:13:01,720 --> 00:13:02,710
कभी कभी आप सिर्फ़ इम्प्लमेंट कर सकते हैं 

388
00:13:03,160 --> 00:13:05,060
आपका स्टैंडर्ड लर्निंग अल्गोरिद्म 

389
00:13:05,150 --> 00:13:06,460
एक वेक्टराइज्ड तरीक़े से और नहीं करते 

390
00:13:06,710 --> 00:13:08,630
चिंता समानांतर करने की और नूमेरिकल ऐल्जेब्रा लाइब्रेरीज़ 

391
00:13:10,030 --> 00:13:12,480
उसमें से कुछ आपके लिए कर सकती हैं.

392
00:13:12,620 --> 00:13:14,710
तो आपको इम्प्लमेंट करने की आवश्यकता नहीं है [एक्स एक्स] लेकिन 

393
00:13:14,860 --> 00:13:16,570
किसी और प्रॉब्लम के लिए, लाभ उठाने के लिए 

394
00:13:17,180 --> 00:13:18,660
इस प्रकार की मैप रिड़ूस इम्प्लमेंटेशन का, 

395
00:13:19,240 --> 00:13:20,690
ढूँढना और इस्तेमाल करना इस 

396
00:13:20,880 --> 00:13:22,070
मैप रिड़ूस फ़ॉर्म्युलेशन को और 

397
00:13:22,170 --> 00:13:23,410
समानांतर करना विभिन्न मशीन्स पर 

398
00:13:23,890 --> 00:13:24,970
अपने आप शायद होगा एक 

399
00:13:25,070 --> 00:13:27,310
बेहतर आइडिया भी और आपको करने देगा तीव्र आपके लर्निंग अल्गोरिद्म को.

400
00:13:29,860 --> 00:13:31,390
इस विडीओ में, हमने बात की 

401
00:13:31,730 --> 00:13:33,650
मैप रिड़ूस पद्धति की समानांतर करने के लिए 

402
00:13:34,460 --> 00:13:35,850
मशीन लर्निंग को लेकर 

403
00:13:36,070 --> 00:13:37,450
एक डेटा और फैला कर उसे 

404
00:13:37,830 --> 00:13:39,660
बहुत से कम्प्यूटर्ज़ पर एक डेटा सेंटर में.

405
00:13:40,160 --> 00:13:41,930
यद्यपि ये आइडियास हैं 

406
00:13:42,290 --> 00:13:43,970
क्रिटिकल / समीक्षात्मक  समानांतर करने के लिए बहुत से 

407
00:13:44,290 --> 00:13:45,400
कोर्स पर एक सिंगल मशीन में 

408
00:13:46,870 --> 00:13:47,150
भी.

409
00:13:47,650 --> 00:13:48,600
आजकल कुछ अच्छे 

410
00:13:49,260 --> 00:13:51,080
ओपन सोर्स इम्प्लमेंटेशन उपलब्ध हैं मैप रिड़ूस के,

411
00:13:51,440 --> 00:13:52,210
तो बहुत से यूज़र्ज़ हैं 

412
00:13:52,710 --> 00:13:54,480
ओपन सोर्स सिस्टम में जिसे कहते हैं 

413
00:13:54,890 --> 00:13:55,820
हडूप और इस्तेमाल करके आपकी 

414
00:13:56,010 --> 00:13:57,580
अपनी इम्प्लमेंटेशन या इस्तेमाल करके किसी 

415
00:13:57,850 --> 00:13:59,770
और की ओपन सोर्स इम्प्लमेंटेशन, आप 

416
00:13:59,920 --> 00:14:01,090
कर सकते हैं इस्तेमाल इन आइडियास को 

417
00:14:01,410 --> 00:14:02,730
समानांतर करने के लिए लर्निंग अल्गोरिद्म्स को और 

418
00:14:03,540 --> 00:14:04,580
कर सकते हैं रन उन्हें एक काफ़ी 

419
00:14:04,950 --> 00:14:05,980
बड़े डेटा सेट्स पर जो है 

420
00:14:06,320 --> 00:14:07,770
सम्भव एक अकेले कम्प्यूटर के इस्तेमाल से.