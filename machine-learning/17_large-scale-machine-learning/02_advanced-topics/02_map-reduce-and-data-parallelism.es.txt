En los últimos videos, hemos hablado acerca del gradiente de descenso estocástico y, ya saben, otras variaciones del algoritmo de gradiente de descenso estocástico, incluidas las adaptaciones para el aprendizaje en línea, pero todos estos algoritmos pueden ejecutarse en una máquina, se pueden ejecutar en una computadora. Y algunos de los problemas del aprendizaje automático son demasiado grandes para que los ejecuten en una máquina, a veces simplemente tienen tantos datos, que simplemente no quieren  volver a ejecutar todos esos datos a través de una sola computadora, sin importa qué algoritmo usarían en esa computadora. Así que este video me gustaría hablar de un enfoque diferente para el aprendizaje automático a gran escala que se llama el enfoque de MapReduce. Y aunque tenemos bastantes vídeos sobre el gradiente de descenso estocástico, y vamos a pasar relativamente menos tiempo con el MapReduce -no juzguen la importancia relativa del MapReduce contra el gradiente de descenso basándose en la cantidad de tiempo que paso en estas ideas. En particular, mucha gente dirá que el MapReduce es al menos igualmente importante, y algunos que es una idea aún más importante, en comparación con el gradiente de descenso, sólo que es relativamente más fácil de explicar,  por lo que voy a pasar menos tiempo en él, pero usando estas ideas podrán ser capaces de ampliar los algoritmos de aprendizaje para problemas mucho más grandes de lo que es posible cuando usan el  gradiente de descenso estocástico. Esta es la idea. Digamos que queremos ajustar un modelo de regresión lineal o un modelo de regresión logística o alguno de éstos; y vamos a empezar de nuevo con el gradiente de descenso por lotes, así que esa es nuestra regla de aprendizaje con el gradiente de descenso por lotes. Y para mantener la escritura de esta diapositiva manejable, voy a suponer en todo, que tenemos «m» es igual a 400 ejemplos. Desde luego, por nuestros estándares, en términos del aprendizaje automático a gran escala, ustedes saben que «m» puede ser muy pequeña y por eso, esto se podría aplicar más comúnmente a problemas en los que podrían tener tal vez cerca de 400 millones de ejemplos, o algo como eso, pero sólo para hacer que la escritura en la diapositiva sea más sencilla, voy a fingir que tenemos 400 ejemplos. En este caso, la regla de aprendizaje con el gradiente de descenso por lotes tiene este 1 sobre 400 y la suma de “i” es igual a 1 a través de 400, mis 400 ejemplos aquí, y si «m» es grande, entonces este es un paso costoso computacionalmente. Así que lo que hace la idea del MapReduce es lo siguiente, y debo decir que la idea del MapReduce se debe a dos investigadores, Jeff Dean y Sanjay Gimawat. Jeff Dean, por cierto, es uno de los ingenieros más legendarios en todo Silicon Valley y el construyó una gran porción de la infraestructura arquitectónica sobre la que funciona Google en la actualidad. Pero aquí está la idea de MapReduce. Así que digamos que tengo algunos conjuntos de entrenamiento, si deseamos indicarlo mediante este cuadro aquí de pares «X Y», donde está «X1», «Y1», bajando a mis 400 ejemplos «Xm», «Ym». Así que ese es mi conjunto de entrenamiento con 400 ejemplos de entrenamiento. En la idea del MapReduce, una manera de hacerlo es dividir este conjunto de entrenamiento en diferentes subconjuntos. Voy a suponer para este ejemplo que tengo 4 computadoras, o 4 máquinas para correr en paralelo en mi conjunto de entrenamiento, que es por lo que estoy dividiendo esto en 4 máquinas. Si tienen 10 máquinas, o 100 máquinas, entonces dividirían su conjunto de entrenamiento en 10 piezas, o 100 piezas, o lo que sea. Y lo que debe hacer la primera de mis 4 máquinas es, por decir, utilizar sólo el primer cuarto de mi conjunto de entrenamiento -así que usar sólo los primeros 100 ejemplos de entrenamiento. Y, en particular, lo que va a hacer es mirar esta suma y ​​calcular esa suma sólo para los primeros 100 ejemplos de entrenamiento. Así que permítanme escribir eso. Voy a calcular una variable temp 1 al superíndice 1,  que indica la primera máquina, «j»  igual a la suma de “i” es igual a 1 hasta 100, y luego voy a colocar exactamente ese término allí; así que tengo «h» theta, «Xi», menos «Yi» multiplicado por «Xij», ¿correcto? Así que eso es sólo ese término del gradiente de descenso allí. Y luego, de manera similar, voy a tomar el segundo cuarto de mis datos y los voy a enviar a mi segunda máquina, y mi segunda máquina usará los ejemplos de entrenamiento 101 a 200 y calcularán las variables similares de un temp 2 «j», que es la misma suma para el índice de los ejemplos 101 a 200. Y del mismo modo, las máquinas 3 y 4 usarán el tercer cuarto y el último cuarto de mi conjunto de entrenamiento. Así que ahora cada máquina tiene que sumar sobre 100, en lugar de sobre 400 ejemplos, así que sólo tiene que hacer un cuarto del trabajo y, por tanto, presuntamente, podría hacerlo aproximadamente cuatro veces más rápido. Finalmente, después de que todas estas máquinas han realizado este trabajo, voy a tomar estas variables temp y las voy a unir de nuevo. De modo que tomo estas variables y las envío al, ya saben, el servidor maestro centralizado y lo que hará el servidor maestro es combinar estos resultados juntos y, en particular, actualizará mis parámetros «theta» «j» de acuerdo con «theta» «j» se actualiza como «theta» «j» menos el índice de aprendizaje «alfa» multiplicado por uno sobre 400 veces temp, 1, «j», más temp «2j», más temp «3j», más temp «4j» y, desde luego, tenemos que hacer esto por separado para «j» es igual a 0 hasta n donde n es el número de variables. Discúlpenme por desglosar esta ecuación en múltiples líneas pero espero que quede claro. Así que lo que esta ecuación está haciendo es exactamente lo mismo que eso, cuando tienen un servidor maestro centralizado que toma los resultados, los diez 1«j», los diez 2«j», diez 3«j» y diez 4«j» y los suma y, por supuesto, la suma de estas cuatro cosas, ¿cierto? eso es sólo la suma de esto, más la suma de esto, más la suma de esto, más la suma de eso, y esas cuatro cosas sencillamente se suman para ser iguales a esta suma que estábamos calculando originalmente con el descenso de corriente por lotes. Y luego tenemos «alfa» multiplicado por 1 de 400, «alfa» multiplicado por 1 de 100, y esto es exactamente equivalente al algoritmo de gradiente de descenso por lotes, sólo que en lugar de tener que sumar sobre todos los cuatrocientos ejemplos de entrenamiento en una sola máquina, podemos dividir la carga de trabajo en cuatro máquinas. Así que aquí está la imagen general de cómo se ve la técnica de MapReduce. Tenemos algunos conjuntos de entrenamiento, y si queremos paralelizar a través de cuatro máquinas, vamos a tomar el conjunto de entrenamiento y lo vamos a dividir, ya saben, por igual, dividirlo tan uniformemente como sea posible en cuatro subgrupos. Después, vamos a tomar los 4 subconjuntos de los datos de entrenamiento y a enviarlos a 4 computadoras diferentes. Y cada una de las 4 computadoras puede calcular una suma sobre sólo un cuarto del conjunto de aprendizaje y luego, finalmente, cada una de las computadoras toma los resultados, los envía a un servidor centralizado, que entonces combina los resultados juntos. Así que en la línea anterior en ese ejemplo, el grueso del trabajo en el gradiente de descenso fue calcular la suma de «i» es igual a 1 a 400 de algo. Así, de manera más general, la suma de «i» igual a 1 hasta «m» de esa fórmula para el gradiente de descenso. Y ahora, debido a que cada una de las cuatro computadoras puede hacer sólo una cuarta parte del trabajo, potencialmente pueden conseguir hasta un aceleramiento de hasta 4x. En particular, si no existieran latencias de la red y ningún costo de las comunicaciones de la red para enviar los datos de ida y vuelta, podrían conseguir potencialmente un aceleramiento de hasta 4x. Por supuesto, en la práctica, debido a las latencias de la red, la sobrecarga por combinar los resultados después y otros factores, en la práctica obtienen un aceleramiento de poco menos de 4x. Pero, sin embargo, este tipo de enfoque de MapReduce nos ofrece una manera para procesar conjuntos de datos mucho más grandes de lo que es posible utilizando una sola computadora, si están pensando en aplicar el MapReduce a algunos algoritmos de aprendizaje, a fin de acelerar este proceso por medio de paralelizar el cálculo sobre diferentes computadoras, la pregunta clave que deben hacerse es, ¿puede su algoritmo de aprendizaje expresarse como una suma sobre el conjunto de entrenamiento? Y resulta que muchos algoritmos de aprendizaje se pueden expresar en realidad como el cálculo de sumas de funciones sobre el conjunto de entrenamiento y el costo computacional de ejecutarlas en grandes conjuntos de datos es porque tienen que sumar sobre un conjunto de entrenamiento muy grande. De modo que, siempre que su algoritmo de aprendizaje se pueda expresar como una suma sobre el conjunto de entrenamiento, y siempre que el grueso del trabajo del algoritmo de aprendizaje se pueda expresar como la suma del conjunto de entrenamiento, entonces MapReduce puede ser un buen candidato para ampliar sus algoritmos de aprendizaje a través de conjuntos de datos muy grandes. Veamos un ejemplo más. Digamos que queremos usar uno de los algoritmos de optimización avanzada. Asi que cosas como LBFGS, la constante gradiente, etcétera. Y digamos que queremos entrenar un algoritmo de aprendizaje de regresión logística. Para eso, tenemos que calcular dos cantidades principales. Una es para los algoritmos de optimización avanzada como, ya saben, LBFGS y el gradiente constante. Tenemos que proporcionarle una rutina para calcular la función de costos del objetivo de optimización, así que para la regresión logística, recuerdan que una función de costos tiene esta especie de suma sobre el conjunto de entrenamiento, así que si están paralelizando sobre diez máquinas, dividirían el conjunto de entrenamiento en diez máquinas y hacen que cada una de las diez máquinas calcule la suma de esta cantidad sobre sólo un décimo de los datos dimensiones. Entonces, algo más que necesita el algoritmo de optimización avanzada es una rutina para calcular estos términos derivados parciales. Una vez más, estos términos derivados, para la regresión logística, se pueden expresar como una suma sobre el conjunto de entrenamiento, así que una vez más, similar a nuestro ejemplo anterior, harían que cada máquina calculara esa suma sobre solamente una  pequeña fracción de sus datos de entrenamiento. Y, por último, después de haber calculado todas estas cosas,  podrían entonces enviar sus resultados a un servidor centralizado, que puede entonces sumar las sumas parciales. Esto corresponde a sumar esas variables temp «i» o temp «ij», que se calcularon localmente en la máquina número i, y así el servidor centralizado  puede sumar estas cosas y obtener la función de costos general y obtener la derivada parcial general, la cual pueden pasar entonces a través del algoritmo de optimización avanzada. Así que, en general, al tomar otros algoritmos de aprendizaje y expresarlos en una especie de forma sumatoria, o por medio de expresarlos en términos de calcular sumas de funciones sobre el conjunto de entrenamiento, pueden utilizar la técnica de MapReduce para paralelizar otros algoritmos de aprendizaje también, y ampliarlos a grandes conjuntos de entrenamiento. Por último, como un último comentario, hasta ahora hemos estado analizando los algoritmos de MapReduce que les permiten paralelizar sobre varias computadoras, tal vez múltiples computadoras en un clúster de computadoras, o sobre múltiples computadoras en el centro de datos. Resulta que a veces incluso si tienen sólo una computadora, MapReduce también puede ser aplicable. En particular, en muchas computadoras individuales actualmente, pueden tener múltiples núcleos de procesamiento. Puede tener varias CPU, y dentro de cada CPU pueden tener múltiples núcleos de procesamiento. Si tienen un gran conjunto de entrenamiento, lo que pueden hacer si, por ejemplo, tienen una computadora con 4 núcleos de procesamiento, lo que pueden hacer es, incluso en una sola computadora, pueden dividir los conjuntos de entrenamiento en pedazos y enviar el conjunto de entrenamiento a diferentes núcleos dentro de una sola caja, como dentro de una sola computadora de escritorio, o un solo servidor, y usar MapReduce de esta forma para dividir la carga de trabajo. Cada uno de los núcleos puede entonces realizar la suma sobre, por decir, un cuarto de su conjunto de entrenamiento y luego puede tomar las sumas parciales y combinarlas a fin de obtener la suma sobre todo el conjunto de entrenamiento. La ventaja de pensar en MapReduce de esta manera, como paralelizando sobre los núcleos dentro de una sola máquina, en lugar de paralelizar sobre múltiples máquinas es que, de esta manera, no tienen que preocuparse por la latencia de la red, ya que toda la comunicación, todo el envío de las variables temp j de ida y vuelta, todo eso sucede dentro de una sola máquina. Y así la latencia de red se convierte en un problema mucho menor, si lo comparan con el hecho de usar esto para paralelizar sobre diferentes ordenadores dentro del centro de datos. Finalmente, un último detalle sobre la paralelización dentro de una máquina con múltiples núcleos. Dependiendo de los detalles de su implementación, si tienen una máquina de múltiples núcleos y si tienen ciertas bibliotecas de álgebra lineal numérica. Resulta que la suma de las bibliotecas de álgebra lineal numérica puede paralelizar automáticamente sus operaciones de álgebra lineal a través de múltiples núcleos dentro de la máquina. Así que si tienen la suerte de usar una de esas bibliotecas de álgebra lineal numérica, y ciertamente esto no aplica a todas y cada una de las bibliotecas, si están usando una de esas bibliotecas y si tienen una muy buena implementación de vectorización del algoritmo de aprendizaje, algunas veces simplemente pueden  implementar su algoritmo estándar de aprendizaje de una forma vectorizada y no preocuparse por la paralelización, y  las bibliotecas de álgebra lineal numérica pueden hacerse cargo de algunos de ellos por ustedes. Así que no necesitan implementar MapReduce pero, para otros problemas de aprendizaje, aprovecharse de este tipo de aplicación reductora de mapas, encontrar y usar estas formulas de MapReduce y paralelizar a través de los núcleos expresamente por sí mismos, podría ser una buena idea también y le podría permitir acelerar su algoritmo de aprendizaje. En este vídeo hablamos acerca del enfoque MapReduce para paralelizar el aprendizaje automático por medio de tomar los datos y extenderlos a través de muchas computadoras en el centro de datos. Aunque estas ideas son aplicables para paralelizar a través de múltiples núcleos dentro de una sola computadora las ventas. Actualmente existen muchas buenas implementaciones de código abierto de MapReduce, así que hay muchos usuarios en el sistema de código abierto llamado Hadoop, y usando ya sea su propia implementación, o usando la implementación de código abierto de alguien más, pueden usar estas ideas para paralelizar los algoritmos de aprendizaje y conseguir que se ejecuten sobre conjuntos de datos mucho más grandes posible utilizando una sola máquina.