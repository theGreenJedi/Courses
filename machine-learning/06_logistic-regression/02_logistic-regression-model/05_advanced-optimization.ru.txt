В предыдущем видео мы обсудили общий вид гипотезы в затрат J от тета в задачах логистической регрессии. В этом более сложных алгоритмах оптимизации и приемах, которые они используют. Благодаря некоторым из этих приемов мы сможем заставить логистическую регрессию работать гораздо быстрее, чем при использовании градиентного спуска. Кроме того, алгоритмы будут намного лучше масштабироваться к очень большим задачам машинного обучения, например, задачам с очень большим количеством признаков. Вот альтернативный взгляд на то, как работает метод градиентного спуска. У нас есть некоторая функция затрат J и мы хотим ее минимизировать. Для этого нам нужно написать код, который принимает на вход параметры тета и может вычислить значение функции J от тета и значения вот таких частных производных для j от 0 до n. Используя код, который может вычислять такие значения, метод градиентного спуска будет многократно обновлять тета по следующей формуле. Да? То есть градиентный спуск использует код, вычисляющий эти частные производные, подставляет полученные значения сюда и таким образом обновляет параметры тета. И можно представить это так: градиентный спуск требует предоставить код для вычисления J от тета и частных производных, а затем, подставляя результаты в формулу, минимизирует для нас функцию стоимости. На деле, для самого градиентного спуска вычисление функции стоимости J от тета не требуется. Нужен только код для вычисления частных производных. Но для случая, когда ваша программа также некоторым образом следит за сходимостью, мы исходим из того, что должны предоставить и код для вычисления J от тета. Итак, написав код для этих вычислений, мы можем использовать, например, метод градиентного спуска. Но метод градиентного спуска - это не единственный алгоритм, который мы можем использовать. Есть и другие, более сложные, более совершенные алгоритмы, которые используют различные подходы для минимизации функции затрат, основанные на возможности вычислить эти величины. Метод сопряженных градиентов, алгоритм Бройдена — Флетчера — Гольдфарба — Шанно (BFGS) и его модификация с ограниченным использованием памяти (L-BFGS) - это примеры более сложных алгоритмов оптимизации, которые при наличии способа вычисления J от тета и производных могут для минимизации функции потерь применять более сложные стратегии, чем метод градиентного спуска. Подробное описание этих трех алгоритмов выходит далеко за рамки курса. На самом деле, вы можете провести много дней или даже несколько недель, изучая эти алгоритмы, например, в углубленном курсе по численным методам, так что я лишь немного расскажу об их свойствах. У этих трех алгоритмов есть ряд преимуществ. Первое состоит в том, что ни для одного из них вы не должны вручную подбирать скорость обучения альфа. Вы можете представить себе это так: умея некоторым образом вычислять производные и функцию затрат, они используют их в более хитром внутреннем цикле. И действительно, в них есть хитрый внутренний цикл, который называется алгоритмом линейного поиска. Он автоматически проверяет различные значения скорости обучения альфа и благодаря этому даже может подбирать различную скорость обучения для каждой итерации. Таким образом, вам не нужно самим ее выбирать. На самом деле эти алгоритмы выполняют более сложные действия, чем просто выбор хорошей скорости обучения и поэтому часто оказывается, что они сходятся гораздо быстрее, чем метод градиентного спуска. Но детальное обсуждение выбор хорошей скорости обучения и что именно они делают, выходит за рамки этого курса. Вообще-то я долгое время, наверное, лет десять, использовал эти алгоритмы, и довольно часто. И только несколько лет назад я действительно разобрался, в чем суть алгоритмов BFGS, O-BFGS и метода сопряженных градиентов. Так что вы вполне можете успешно применять эти алгоритмы и решать с их помощью различные задачи обучения, не разбираясь в тонкостях устройства внутреннего цикла. Если у этих алгоритмов и есть недостатки, я бы сказал, что основной недостаток состоит в том, что они намного сложнее, чем метод градиентного спуска. В частности, думаю, вам не следует пытаться самостоятельно запрограммировать эти алгоритмы — метод сопряженных градиентов, L-BGFS, BFGS — разве только если вы специалист по численным методам. Вместо этого я посоветовал бы вам использовать специальную библиотеку - по той же причине, по которой не стал бы рекомендовать вам написать свой код для вычисления квадратного корня для чисел или нахождения обратных матриц. Чтобы извлечь квадратный корень, мы используем уже написанную кем-то другим функцию, выполняющую это действие. К счастью, в Octave (и в тесно связанном с ним языке MATLAB), который мы будем использовать, есть очень хорошая...есть весьма неплохая библиотека, где некоторые из более сложных алгоритмов оптимизации уже реализованы. И если вы будете использовать встроенную библиотеку, то получите очень хорошие результаты. Хочу заметить, что между хорошими и плохими реализациями этих алгоритмов есть существенная разница. Так что если для решения задачи машинного обучения вы используете другой язык — C, C++, Java или еще какой-то, — вам, вероятно, стоит пересмотреть несколько библиотек, чтобы быть уверенным, что вы используете хорошую реализацию. Поскольку хорошая реализация метода сопряженных градиентов, или L-BFGS, может отличаться от менее удачной его реализации производительностью. Теперь я хочу объяснить, как эти алгоритмы используются, на примере. Допустим, у вас есть задача с двумя параметрами, тета 1 и тета 2. И, пусть ваша функция затрат J от тета равняется сумме квадратов тета 1 минус 5 и тета 2 минус 5. Для этой функции затрат искомые значения тета 1 и тета 2, значения, при которых J минимальна, это тета 1 равно 5 и тета 2 равно 5. Вы в разной мере знакомы с дифференциальным исчислением, поэтому я просто написал выражения для частных производных J. Я продифференцировал функцию. Итак, если вы хотите применить один из более совершенных алгоритмов для минимизации функции J — представьте, что мы не знаем, что минимум достигается при значениях 5 и 5, и хотим вычислить эти значения программно, желательно, используя что-то получше, чем градиентный спуск, — вам нужно будет написать в Octave примерно такую функцию. То есть мы зададим функцию costFunction(theta), как здесь, которая возвращает два значения. Первый, jVal — это значение самой функции J, поэтому я пишу jVal равно, ну, вы понимаете, тета 1 минус 5 в квадрате плюс тета 2 минус 5 в квадрате. Просто выражение для вычисления функции затрат. А второе возвращаемое значение — это градиент. Градиент — это вектор 2х1, и два его элемента соответствуют двум частным производным, записанным вот здесь. Реализовав таким образом функцию потерь, вы сможете затем вызвать функцию усовершенствованной оптимизации, которая в Octave называется fminunc. Это аббревиатура для Function (функция) MINimization (минимизации) UNConstrained (без ограничений). Вызвать ее можно следующим образом. Вы задаете несколько параметров. Переменная options представляет структуру данных, где хранятся настройки алгоритма: 'GradObj' и 'on' означают, что используется метод с использованием градиента, то есть что вы в самом деле предоставите алгоритму код для вычисления градиента. Максимальное количество итераций я задам равным, допустим, 100. Зададим также начальное значение для тета. Это вектор 2x1. Затем этой командой вы вызываете функцию fminunc. С помощью символа @, коммерческого at, передается указатель на функцию costFunction, которую мы только что определили выше. Когда вы запустите эту команду, вычисления будут выполнены с помощью одного из более совершенных алгоритмов оптимизации. Вы можете считать, что это то же, что и градиентный спуск, только скорость обучения альфа задается автоматически, вам не нужно выбирать его самим. Но на деле будет использован более сложный алгоритм оптимизации, можно сказать, «прокачанный» градиентный спуск, который постарается найти для вас оптимальное значение тета. Давайте я покажу вам, как это выглядит в Octave. Функция costFunction(theta) точно такая же, как на предыдущем слайде. Она вычисляет jVal — значение функции стоимости, и градиент, два элемента которого — частные производные функции затрат по каждому из двух параметров, тета 1 и тета 2. Давайте переключимся в окно Octave. Я введу команды, которые только что описывал. options равно optimset, так в options записываются параметры алгоритма оптимизации, GradObj — on, MaxIter — 100, то есть: не более сотни итераций и я предоставлю алгоритму градиент. И начальное значение initialTheta равно вектору 2х1, заполненному нулями. Это мое изначальное предположение для тета. Теперь получим значения [optTheta, functionVal, exitFlag] равны fminunc — f-min-unconstrained, передадим указатель на функцию затрат, первое предположение о тета, и параметры алгоритма, вот так. И если я нажму Enter, запустится алгоритм оптимизации, и мы очень быстро получим результат. Здесь код выглядит так странно, потому что он слишком длинный, то есть это обозначает, что начало команды скрыто, а видна только часть после переноса строки. А дальше написан, собственно, результат численного решения, алгоритм, так сказать, «прокачанный» градиентный спуск нашел оптимальное значение вектора тета: тета 1 равно 5, тета 2 равно 5, как мы и надеялись. Значение функции в экстремуме равно 10 в минус тридцатой степени, то есть, по сути, ноль, на что мы тоже рассчитывали. Флаг завершения, exitFlag, равен 1 — это показатель того, что алгоритм сошелся. Если хотите, запустите команду help fminunc и прочитайте, какие значения может принимать exitFlag и в каких случаях. Главное, что он позволяет узнать, считает ли алгоритм, что он сошелся. Вот так можно запустить эти алгоритмы в Octave. Должен сказать, что для использования алгоритмов, реализованных в Octave, ваш вектор параметров theta должен принадлежать d-мерному вещественному пространству, где d больше либо равно 2. Так что если theta — одно вещественное число, если размерность вектора меньше двух, fminunc может не сработать. Если вам нужно минимизировать функцию одного вещественного аргумента, почитайте документацию по fminunc в Octave и посмотрите, как это можно сделать. Так мы минимизировали взятую для примера простую квадратичную функцию затрат, но как нам применить этот алгоритм для логистической регрессии? В задаче логистической регрессии у нас есть вектор параметров тета... Я сейчас буду использовать смесь математической нотации и нотации Octave, но, надеюсь, объяснение будет понятным. Так вот, вектор тета содержит параметры от тета 0 до тета n, но Octave нумерует элементы векторов, начиная с 1, то есть тета нулевому в Octave будет соответствовать theta(1), тета первому —theta(2), и так до theta(n+1), понятно? Все потому, что Octave нумерует элементы векторов начиная с индекса 1, а не с 0. Теперь нам нужно написать функцию затрат costFunction, которая соответствует функции затрат для логистической регрессии. А именно, она должна возвращать jVal, то есть нам нужно написать код для вычисления затем, подставляя вычислить градиент. Так, для gradient(1) нам нужно написать код, вычисляющий значение частной производной по тета 0, затем — по тета 1, и так далее. Еще раз, это gradient(1), gradient(2) и так далее, а не gradient(0) и gradient(1), поскольку Octave индексирует векторы начиная с единицы, а не с нуля. Но основная идея, которую, как я надеюсь, вы вынесете из этого слайда, — нам нужно написать функцию, которая возвращает значения функции затрат и градиента. Таким образом, чтобы использовать сложные алгоритмы в задаче логистической регрессии — или даже в задаче линейной регресии, если вам это нужно, — вам необходимо написать здесь соответствующий код. Теперь вы знаете, как использовать более совершенные алгоритмы оптимизации. Из-за того, что для этих алгоритмов вы используете сложные оптимизационные библиотеки, отладка становится немного более непрозрачной и трудной. Поскольку зачастую они работают быстрее, чем градиентный спуск, для объемных задач машинного обучения, я скорее буду использовать именно их. Разобравшись с этими идеями, надеюсь, вы сможете заставить работать логистическую или линейную регрессию для решения много более масштабных задач. На этом я заканчиваю разговор о сложных алгоритмах оптимизации. А в следующем и последнем видео по логистической регрессии я расскажу, как применять алгоритм логистической регрессии, который вы теперь знаете, в задачах многоклассовой классификации.