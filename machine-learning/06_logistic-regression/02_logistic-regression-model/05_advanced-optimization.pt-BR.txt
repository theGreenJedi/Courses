No último vídeo, falamos sobre Gradiente Descendente para minimizar a função de custo "J(θ)", para Regressão Logística. Neste vídeo, eu gostaria de falar sobre alguns algoritmos de otimização mais avançados, e alguns conceitos avançados de otimização. Usando algumas dessas ideias, seremos capazes de rodar Regressão Logística muito mais rápido do que com Gradiente Descendente. E isso também permitirá que os algoritmos escalem muito melhor para problemas muito grandes, como, por exemplo, com um número muito grande de variáveis. Aqui temos uma visão diferente do que o Gradiente Descendente está fazendo. Nós temos uma função de custo "J", e pretendemos minimizá-la. Então, o que precisamos fazer é, precisamos escrever um método que possa receba como entrada os parâmetros "θ", e possa calcular duas coisas: "J(θ)", e essas derivadas parciais para "j=0,1, ..., n". Tendo um programa que possa fazer essas duas coisas, o Gradiente Descendente efetua, repetidamente, a seguinte atualização: OK? Então, dado o código que escrevemos para calcular essas derivadas parciais, o Gradiente Descendente usa isso para atualizar os parâmetros "θ". Então, uma outra maneira de pensar sobre Gradiente Descendente, é que nós precisamos fornecer a função para calcular "J(θ)" e essas derivadas, que então são usadas pelo Gradiente Descendente, que tentará minimizar essa função. Para Gradiente Descendente, tecnicamente não é necessário código para calcular o valor de "J(θ)". Você precisa apenas computar os termos derivativos. Mas, se você considerar que seu código também monitora a convergência, é preciso fornecer código para calcular, tanto a função de custo, quanto os termos derivativos. Então, tendo escrito uma função para calcular essas duas coisas, um algoritmo que podemos usar é Gradiente Descendente Mas o Gradiente Descendente não é o único algoritmo que podemos usar. E existem outros algoritmos, mais avançados, mais sofisticados, que, se só fornecermos uma maneira de computar essas duas coisas, então há diferentes abordagens para otimizar a função de custo. Gradiente Conjugado "BFGS" e "L-BFGS" são exemplos de algoritmos mais sofisticados, que precisam saber como calcular "J(θ)", e como calcular as derivativas, e então, podem usar estratégias mais sofisticadas, que Gradiente
Descendente, para minimizar a função de custo. Os detalhes sobre o que esse três algoritmos fazem, vai além do escopo desse curso. E, na verdade, você acaba, muitas vezes, passando vários dias ou algumas semanas, estudando eles em uma aula de Computação Numérica Avançada. Mas deixe-me falar sobre algumas propriedades. Esses três algoritmos têm várias vantagens. Umas delas é que, com qualquer um desses algoritmos você não precisa escolher manualmente a taxa de aprendizado "α". Uma maneira de enxergar esses algoritmos é, dadas as maneiras de como calcular as derivativas e função custo, eles possuem um laço interno inteligente. Esse laço inteligente é chamado Algoritmo de Busca em Linha, que tenta automaticamente diversos valores para a taxa de aprendizagem "α", e automaticamente seleciona uma taxa adequada. Podendo até usar uma taxa diferente em cada iteração. Assim você não precisa escolher a taxa. Esses algoritmos fazem, na verdade, coisas mais sofisticadas, do que escolher uma boa taxa de aprendizagem, de aprendizagem. Assim, convergem muito mais rápido do que Gradiente Descendente. Repetindo: Esses algoritmos fazem, na verdade, coisas mais sofisticadas do que só escolher uma boa taxa de aprendizagem, e assim, eles acabam convergindo muito mais rápido do que Gradiente Descendente. Mas, uma discussão detalhada do que eles fazem exatamente está fora do escopo deste curso. Na verdade, eu usei alguns desses algoritmos por um longo tempo - mais de uma década. E, apenas alguns anos atrás descobri os detalhes, do que Gradiente Conjugado, BFGS e L-BFGS fazem. Então, é totalmente possível usar esses algoritmos com sucesso e aplicá-los em vários problemas de aprendizado, sem realmente entender o laço interno que eles realizam. Se esses algoritmos têm alguma desvantagem, eu diria que, a principal desvantagem é que eles são muito mais complexos que Gradiente Descendente. E você, provavelmente, não deveria implementar esses algoritmos a não ser que você seja um especialista em Computação Numérica. Ao invés disso, assim como não recomendaria que você escrevesse sua própria função para calcular raiz quadrada, ou inverter matrizes, para esses algoritmos, eu recomendaria que utilizasse as bibliotecas existentes. Assim, para calcular a raiz quadrada, o que fazemos é usar alguma função, que alguém escreveu, para calcular as raízes dos números. E felizmente, Octave e a linguagem parecida, MATLAB - se você estiver usando - tem uma boa biblioteca para implementar alguns desses algoritmos avançados de otimização. E, se você usar a biblioteca embutida, terá resultados muito bons. Eu devo dizer que, existe uma diferença entre boas e más implementações desses algoritmos. Então, se você está usando uma linguagem diferente para suas aplicações de Aprendizado de Máquina, como "C", "C++", "Java", ... você deve testar algumas
bibliotecas diferentes, você talvez queira tentar algumas para encontrar uma biblioteca boa para
implementar esses algoritmos. Porque existe uma diferença em performance, entre uma implementação boa, e uma implementação ruim, de Gradiente de Contorno, ou BFGS/L-BFGS. Agora vamos explicar como usar esses algoritmos, eu vou fazer isso com um exemplo. Digamos que você tenha um problema com dois parâmetros iguais a θ₀ e θ₁. E, digamos que sua função de custo seja "J(θ) =  (θ₁ - 5)² + (θ₂ - 5)²". "J(θ) =  (θ₁ - 5)² + (θ₂ - 5)²". Então, para essa função de custo, com parâmetros "θ₁" e "θ₂", se você deseja minimar "J(θ)" como função de θ, o valor que minimiza será: "θ₁ = 5", "θ₂ = 5". Agora, eu sei que alguns de vocês sabem mais Cálculo que outros, mas as derivativas da função de custo "J(θ)", são essas duas expressões. Eu fiz as cálculos. Então, se você quiser aplicar um dos algoritmos de otimização avançados para minimizar essa função "J", sem saber que o mínimo está em "(5, 5)"; se você quiser calcular o mínimo, numericamente, usando algo, de preferência, mais avançado que Gradiente Descendente; você implementaria uma função em Octave, como essa. Então, nós implementamos uma função de custo em "θ", dessa forma, e isso retorna dois argumentos. O primeiro, "jVal", é como calcularíamos a função de custo "J". Então, temos "jVal= (θ₁ - 5)² + ( θ₂ - 5 )²". Só está calculando essa função de custo. E, o segundo argumento, que essa função retorna, é o gradiente. O gradiente será um vetor "2x1", e os dois elementos do vetor gradiente correspondem aos dois termos da derivada parcial. Tendo implementado essa função custo, você pode então, chamar a função de otimização, chamada "fminunc" - que significa "função de minimização irrestrita" - da seguinte forma: Você define algumas opções, A variável 'options' "options" é uma estrutura que guarda suas opções. ''GradObj', 'on' seta o objeto "gradiente", como "on", o que significa que você fornecerá o gradiente para o algoritmo. Eu vou definir o número máximo de iterações para "100". Vamos passar também uma estimava inicial de "θ", que é um vetor "2x1". E então, esse comando chama "fminunc". O símbolo "@" representa um ponteiro para a função custo que  acabamos de definir. E se você chamar isso, isso vai utilizar um dos algoritmos de otimização mais avançados. Se você quiser, pode pensar nisso como um Gradiente Descendente, mas com escolha automática da taxa de aprendizado "α". Então o programa vai tentar usar um algoritmo de otimização avançado, com um Gradiente Descendente "turbinado", para tentar encontrar o valor ótimo de "θ". Deixe-me mostra qual é a cara disso em Octave. Eu escrevi essa função de custo em "θ", exatamente como tínhamos anteriormente. Ela computa "jVal", que é a função de custo. E computa o gradiente, com os dois elementos sendo as derivadas parciais da função custo com relação aos dois parâmetros, θ₁ e θ₂. Agora vamos trocar para a janela do Octave. Eu vou digitar os comandos que acabei de mostrar. Então, "options=optimset". Isso é uma notação para setar meus parâmetros, com minhas opções para o meu algoritmo de otimização. " 'GradObj', 'on', 'MaxIter', '100' ", há 100 iterações, e eu vou fornecer o gradiente para o meu algoritmo. Digamos que "initialTheta = zeros(2, 1)" Esse é meu chute inicial para "θ". E agora eu tenho " [optTheta, functionVal, exitFlag] " " =  fminunc( ", um ponteiro para a função custo, e meu chute inicial, e minhas opções. E pressionando <enter>, isso vai rodar o algoritmo de otimização. E retornar rapidamente. Esse formato estranho é porque uma linha do código está muito grande, tomando mais de uma linha do terminal. Mas o que isso diz é que é que o "θ" ótimo, encontrado numericamente, com esse algoritmo avançado de otimização foi: "θ₁ = 5" e "θ₂ = 5", exatamente como esperávamos. O valor da função, no ponto ótimo, é algo em torno "10" elevado a "-30", o que é praticamente "0". O que também esperávamos. E o valor de "exitFlag"  é "1", e isso mostra o status de convergência. E você pode digitar "help fminunc", para ver a documentação de como interpretar "exitFlag". Mas, "exitFlag" te ajuda a verificar se o algoritmo convergiu. É assim que você roda esses algoritmos em Octave. Aliás, eu devo mencionar que para a implementação em Octave, esse valor de "θ", deve estar em "R^d", onde "d" é maior ou igual a "2". Então, se "θ" for um número real, se ele não for, pelo menos, um vetor bi-dimensional, ou maior que bi-dimensional, essa "fminunc" pode não funcionar. Se você tiver uma função unidimensional que você quer otimizar, você deve olhar a documentação de Octave, para mais detalhes. Então, é  assim que otimizamos, nosso exemplo inicial, com essa função de custo quadrática. Mas, como aplicamos isso a Regressão Logística? Em Regressão Logística, temos um vetor parâmetro "θ", e eu vou usar uma mistura de notação Octave,
com notação Matemática, mas espero que essa explicação seja clara. O vetor parâmetro "θ" contém esses parâmetros de "θ₀" até "θn". Mas, como Octave indexa vetores usando índices começando em "1", "θ₀" é na verdade, escrito como "θ₁" em Octave, "θ₁" será escrito como "θ₂" e isso será escrito como "θ n+1". Isso por que Octave indexa os vetores começando com índice "1" em vez de índice "0". Então, o que precisamos fazer é escrever uma função de custo que capture a função de custo da Regressão Logística. Na verdade, a função de custo deve retornar "jVal", que requer um comando ou função para calcular "J(θ)" e e requer também o gradiente. Então, "gradiente(1)" será um código para calcular a derivada parcial com relação a "θ₀", a próxima derivada com respeito a "θ₁", e assim por diante. Novamente, esse é o "gradient(1)", "gradient(2)", e assim por diante, ao invés de "gradient(0)", "gradient(1)", porque Octave indexa os vetores começando por "1", em vez de "0". Mas o conceito principal, que espero que você leve, é que, tudo o que precisa fazer, é escrever uma função que retorne a função de custo e o gradiente. E assim, para aplicar isso a Regressão Logística ou mesmo a Regressão Linear, se você quiser usar esses algoritmos para Regressão Linear. O que você precisa fazer é conectar um método apropriado para calcular esses valores. Agora você sabe como usar esses algoritmos de otimização avançados. Como, para esses algoritmos, você está usando uma biblioteca de otimização avançada, o código fica um pouco mais obscuro e, consequentemente, um pouco mais difícil de depurar. Mas como esses algoritmos geralmente rodam muito mais rápido que Gradiente Descendente, sempre que eu tenho um grande problema de Aprendizado de Máquina, eu uso esses algoritmos, ao invés de Gradiente Descendente. Eu espero que, com essas ideias, você seja capaz de aplicar Regressão Logística e Regressão Linear em problemas muito maiores. Então, é isso, para otimização avançada. E no próximo, e último vídeo sobre Regressão Logística, eu quero lhe falar sobre como pegar o algoritmo de Regressão Logística que você já conhece, e fazê-lo funcionar também em problemas de classificação com múltiplas classes.
Tradução: Eduardo Bonet | Revisão: Pablo de Morais Andrade