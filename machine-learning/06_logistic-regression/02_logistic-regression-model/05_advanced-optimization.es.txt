En el último vídeo hablamos sobre el gradiente de descenso para minimizar la función de costo J de «theta» para la regresión logística. En este video, me gustaría hablarte sobre algunos algoritmos avanzados de optimización y sobre algunos conceptos avanzados de optimización. Usando alguna de estas ideas, vamos a poder hacer que la regresión logística se ejecute mucho más rápido de lo que es posible con el gradiente de descenso. Y esto también permitirá que los algoritmos se escalen mucho mejor a problemas muy largos de aprendizaje automático, como si tuviéramos un gran número de variables. Aquí está una visión alternativa de lo que el gradiente de descenso está haciendo. Tenemos una función de costo J y queremos minimizarla. Lo que tenemos que hacer es escribir el código que puede tomar como entrada los parámetros «theta» y que pueda calcular dos cosas: J de «theta» y y estos términos derivados parciales para, ya sabes, J es igual a 0, 1 hasta N.  El código que pueda hacer estas cosas, qué gradiente de descenso realiza de forma repetida la siguiente actualización, ¿Correcto? Entonces, dado el código que escribimos para calcular estas derivadas parciales, el gradiente de descenso se inserta aquí y que se utiliza para actualizar nuestros parámetros «theta». Entonces, otra forma de pensar en los gradientes de descenso, es que necesitamos suministrar código para calcular J de «theta» y estas derivadas, y luego éstos se insertan en gradientes de descenso, que pueden intentar minimizar la función para nosotros. Para el gradiente de descenso, creo que técnicamente, en realidad, no necesitas código calcular la función de costo J de «theta». Sólo necesitas código para calcular los términos derivados. Pero si consideras que tu código también monitorea la convergencia de algo así, pensaremos que sólo estamos proveyendo código para calcular la función de costo y los términos derivados. Así que, después de haber escrito código para calcular estas dos cosas, un algoritmo que podemos usar es el gradiente de descenso. Pero el gradiente de descenso no es el único algoritmo que podemos usar. Y hay otros algoritmos más avanzados y más sofisticados que, si sólo les proporcionamos una forma para calcular estas dos cosas, entonces estos son enfoques distintos para optimizar la función de costo para nosotros. Entonces, el gradiente conjugado BFGS y L-BFGS son ejemplos de algoritmos de optimización más sofisticados que requieren de una forma para calcular J de «theta», y que requieren una forma para calcular las derivadas, y entonces pueden usar estrategias más sofisticadas que el gradiente de descenso para minimizar la función de costo. Los detalles de lo que son estos tres algoritmos exactamente está más allá del alcance de este curso. Y, de hecho, con frecuencia uno termina invirtiendo, ya sabes, muchos días o algunas semanas estudiando estos algoritmos. Si tomas una clase y avanzas el cálculo numérico por computadora. Pero voy a hablar sobre algunas de sus propiedades. Estos tres algoritmos tienen varias ventajas. Una es que, con cualquiera de estos algoritmos generalmente no necesitas seleccionar manualmente el «alfa» de la tasa de aprendizaje. Entonces, una forma de considerar estos algoritmos es que es la forma dada para calcular la derivada y la función de costo. Puedes pensar en estos algoritmos como en tener un ciclo for inteligente. Y, de hecho, tienen un ciclo for inteligente llamado algoritmo de búsqueda de línea que automáticamente prueba distintos valores para el «alfa» de la tasa de aprendizaje y, automáticamente selecciona un buen «alfa» de la tasa de aprendizaje de forma que incluso puede seleccionar una tasa de aprendizaje diferente para cada iteración. Y entonces no tienes que elegirlo tú mismo. Estos algoritmos, de hecho, hacen cosas más sofisticadas que sólo elegir un buen «alfa» de la tasa de aprendizaje, y por lo tanto, con frecuencia terminan convergiendo mucho más rápido que el gradiente de descenso. Estos algoritmos, de hecho, hacen cosas más sofisticadas que sólo elegir un buen «alfa» de la tasa de aprendizaje, y a menudo terminan convergiendo mucho más rápido que el gradiente de descenso, pero una descripción detallada de lo que hacen exactamente está más allá del alcance de este curso. De hecho, yo utilicé estos algoritmos por mucho tiempo, quizás por más de una década, con frecuencia y sólo fue, ya sabes, hace algunos años que yo, de hecho, descubrí por mí mismo los detalles de lo que hacen el gradiente conjugado BFGS y O-BFGS Así que es enteramente posible usar estos algoritmos con éxito y aplicarlos a muchos problemas de aprendizaje diferentes sin realmente comprender el ciclo for entrelazado de lo que hacen estos algoritmos. Si estos algoritmos tienen una desventaja, yo diría que la principal desventaja es que son mucho más complejos que el gradiente de descenso. Y, en particular, probablemente no deberías implementar estos algoritmos - gradiente conjugado, L-BGFS, BFGS - tú mismo a menos que seas experto en cálculo numérico por computadora. En cambio, así como yo no te recomendaría que escribas tu propio código para calcular raíces cuadradas de números o para calcular matrices inversas, para estos algoritmos, lo que también te recomendaría es sólo usar una librería de software. Así que ya sabes, para sacar una raíz cuadrada, lo que todos hacemos es usar alguna función que alguien más ha escrito para calcular las raíces cuadradas de los números. Y, afortunadamente, Octave y el lenguaje estrechamente relacionado MATLAB -Usaremos eso- Octave tiene una muy buena, una muy razonable librería que implementa algunos de estos algoritmos de optimización avanzados. Y si sólo usas la librería integrada, ya sabes, tendrás muy buenos resultados. Debo decir que hay diferencias entre buenas y malas implementaciones de estos algoritmos. Entonces, si estás utilizando un lenguaje diferente para tu aplicación de aprendizaje automático, si estás usando C, C++, Java, y así, puedes querer probar un par de librerías diferentes para asegurarte de encontrar una buena librería para implementar estos algoritmos. Porque hay una diferencia de desempeño entre una buena y una mala implementación de, ya sabes, un gradiente de contorno o LPFGS contra una implementación menos buena de un gradiente de contorno o LPFGS. Entonces, ahora voy a explicar cómo usar estos algoritmos, y voy a hacerlo con un ejemplo. Digamos que tienes un problema con dos parámetros iguales a «theta» cero y «theta» uno. Y digamos que tu función de costo es J de «theta» igual a «theta» uno menos cinco al cuadrado, más teta dos menos cinco al cuadrado. Entonces, con esta función de costo, conoces el valor de «theta» 1 y «theta» 2. Si quieres minimizar J de «theta» como una función de «theta», el valor que la minimiza será «theta» 1 igual a 5, «theta» 2 igual a 5. Ahora, nuevamente, conozco algunos, ya sabes, cálculos más que otras personas, pero las derivadas de la función de costo de J resultan ser estas dos expresiones. Ya hice los cálculos. Entonces, si quieres aplicar uno de los algoritmos avanzados de optimización para minimizar la función de costo J, entonces, ya sabes, si no supiéramos que el mínimo está en 5, 5, pero si quisieras tener una función de costo 5, el mínimo numérico, usando algo como el gradiente descenso, pero preferiblemente más más avanzado que el gradiente de descenso, lo que harías sería implementar una función de Octave como ésta, entonces, implementamos una función de costo; función de costo de la función de «theta» como esa, Y lo que esto hace es devolver dos argumentos, el primer J-val es como nosotros calcularíamos la función de costo J. Y entonces, esto dice que J-val es igual a, ya sabes, «theta» uno menos cinco al cuadrado más «theta» dos menos cinco al cuadrado. Entonces, sólo se trata de calcular la función de costo de aquí. Y el segundo argumento que devuelve esta función es un gradiente. Entonces, el gradiente va a ser un vector de dos por uno, y los dos elementos del vector gradiente corresponden a los dos términos de la derivada parcial de aquí. Después de haber implementado esta función de costo, podrías, puedes entonces llamar la función de optimización avanzada llamada fminunc - se refiere a la minimización sin restricciones de la función en Octave - y la forma de llamarla es la siguiente. Configuras algunas opciones. Estas son opciones como una estructura de datos que almacena las opciones que quieras. Entonces, esto enciende el parámetro del objetivo de gradiente. Esto sólo significa que, de hecho, vas a proporcionar un gradiente a este algoritmo. Voy a definir el número máximo de iteraciones a, digamos, cien. Voy a darle una suposición inicial de «theta». Ahí hay un vector de 2 por 1. Y luego este comando llama a fminunc. Este símbolo de arroba presenta un indicador hacia la función de costo que acabamos de definir arriba. Y si llamas esto, ésto se calculará, ya sabes, usará uno de los algoritmos de optimización más avanzados. Y si quieres, puedes considerarlo sólo como un gradiente de descenso. Pero que elige automáticamente el «alfa» de la tasa de aprendizaje para que no tengas que hacerlo tú mismo. Pero luego intentará usar el tipo de algoritmos de optimización avanzados, como el gradiente de descenso con esteroides, para tratar de encontrar el valor óptimo de «theta» para usted. Déjame mostrarte cómo se ve esto en Octave. Entonces, escribí esta función de costo de la función de «theta» exactamente como la teníamos en la línea anterior. Calcula el J-val, que es la función de costo.. Y computa el gradiente con los dos elementos que son las derivadas parciales de la función de costo con respecto a, ya sabes, los dos parámetros, «theta» 1 y «theta» 2. Ahora, pasemos a mi ventana de Octave. Voy a ingresar los comandos que tenía ahora. Entonces, las opciones son iguales a optimset. Esta es la notación para establecer mis parámetros en mis opciones, para mi algoritmo de optmización. Opción Grant encendida, maxIter, 100 para que diga 100 iteraciones, y voy a proporcionar el gradiente a mi algoritmo. Digamos que la «theta» inicial es igual al dos por uno de cero. Entonces, esa es mi suposición inicial para «theta». Y ahora tengo de «theta», función val exit flag igual a la restricción de fminunc. Un indicador hacia la función de costo. Y proporciona mi suposición inicial. Al igual que las otras opciones. Y si presiono Enter, esto ejecutará el algoritmo de optimización. Y regresa muy rápido. Este formato gracioso se debe a mi línea, ya sabes, mi código resumido. Entonces, esta cosa graciosa se debe sólo a que mi línea de comando se envolvió. Pero lo que esto significa es que numéricamente expresa, ya sabes, considéralo un gradiente de descenso con esteroides, que encontró el valor óptimo para A «theta» es «theta» 1 igual a 5, «theta» 2 es igual a 5,  exactamente como lo esperábamos. El valor de la función en el óptimo es esencialmente 10 a la menos 30. Entonces, eso es esencialmente cero, que también es lo que estábamos esperando. Y la bandera de salida es 1 y esto muestra cuál es el estado de convergencia de esto. Y si quieres, puedes ingresar help fminunc para leer la documentación para saber cómo interpretar la bandera de salida. Pero la bandera de salida te permite verificar si este algoritmo ha convergido. Así es cómo se ejecutan estos algoritmos en Octave. Debo mencionar, por cierto, que para la implementación en Octave, este valor de «theta», tu vector parámetro de «theta», debe estar en rd para d mayor que o igual a 2. Entonces, si «theta» sólo es un número real. Y, si no lo es, al menos un vector de dos dimensiones o un poco superior al vector bidimensional, este fminunc podría no funcionar, entonces, y en el caso de que tengas una función unidimensional que utilizas para optimizar, puedes consultar la documentación de Octave sobre fminunc para obtener más detalles. Entonces, así es cómo optimizamos nuestro ejemplo prueba de esta simple función de costo de conducción rápida. Sin embargo, aplicamos esto a, digamos, la progresión logística en la que tenemos un vector de parámetro «theta», y voy a usar una mezcla de notación de Octave y un tipo de notación matemática. Pero espero que esta explicación será clara, pero nuestro vector de parámetro «theta» comprende estos parámetros «theta» 0 hasta «theta» n, porque los índices de Octave, vectores usando la indexación de 1, sabes, «theta» 0, realmente, se escribe «theta» 1 en Octave, «theta» 1 se va a escribir como «theta» 2 en Octave, y esto se va a escribir «theta» n + 1, ¿cierto? Y esto se debe a que Octave indexa los vectores a partir del índice de 1 como el índice de 0. Entonces, lo que debemos hacer es escribir una función de costo que capture la función de costo para la regresión logística. Concretamente, la función de costo debe devolver J-val, que es, ya sabes, J-val dado que necesitas algunos códigos para calcular J de «theta» y también necesitamos darle el gradiente. Entonces, el gradiente 1 va a ser algún código para calcular la derivada parcial respecto a «theta» 0, la siguiente derivada parcial respecto a «theta» 1 y así sucesivamente. Una vez más, estos son el gradiente 1, el gradiente 2 y así sucesivamente, en lugar de gradiente 0, gradiente 1, porque los índices de Octave son vectores que comienzan desde uno en lugar de desde cero. Pero el concepto principal que espero que comprendas de esta diapositiva es que, lo que tienes que hacer, es escribir una función que devuelva la función de costo y devuelva el gradiente. Así, para aplicar esto a la regresión logística o, incluso a la regresión lineal, s quieres usar estos algoritmos de optimización para la regresión lineal. Lo que tienes que hacer es insertar el código apropiado para calcular las cosas de aquí. Entonces, ahora sabes cómo usar estos algoritmos avanzados de optimización. Porque, para estos algoritmos estás usando una librería de optimización sofisticada, que lo hace un poco más opaco y, entonces, quizás un poco más difícil de depurar. Pero como estos algoritmos suelen ejecutarse mucho más rápido que el gradiente de descenso, a menudo muy típicamente cuando tengo un problema de aprendizaje automático muy grande, usaré estos algoritmos en lugar de usar el gradiente de descenso. Y, con estas ideas, espero que puedas poner a trabajar la progresión logística y también la regresión lineal en problemas mucho más grande. Entonces, eso es todo en cuanto a los conceptos de optimización. Y en el siguiente y último video sobre regresión logística, quiero contarles sobre cómo tomar el algoritmo de regresión logística que ya conoces y hacerla trabajar en problemas de clasificación multiclase.