在本节视频中 我们将谈到如何使用逻辑回归 (logistic regression) 来解决多类别分类问题 具体来说 我想通过一个叫做"一对多" (one-vs-all) 的分类算法 让你了解什么是多类别分类问题 先看这样一些例子 假如说你现在需要 一个学习算法 能自动地 将邮件归类到不同的文件夹里 或者说可以自动地加上标签 那么 你也许需要一些不同的文件夹 或者不同的标签来完成这件事 来区分开来自工作的邮件、来自朋友的邮件 来自家人的邮件或者是有关兴趣爱好的邮件 那么 我们就有了 这样一个分类问题 其类别有四个 分别用y=1、y=2、y=3、 y=4 来代表 另一个例子是有关药物诊断的 如果一个病人 因为鼻塞 来到你的诊所 他可能并没有生病 用 y=1 这个类别来代表 或者患了感冒 用 y=2 来代表 或者得了流感 y=3 第三个例子 也是最后一个例子 如果你正在做有关 天气的机器学习分类问题 那么你可能想要区分 哪些天是晴天、多云、雨天、 或者下雪天 对上述所有的例子 y 可以取 一个很小的数值 一个相对"谨慎"的数值 比如1到3、1到4或者其它数值 以上说的都是多类分类问题 顺便一提的是 对于下标是 0 1 2 3 还是 1 2 3 4 都不重要 我更喜欢将分类 从 1 开始标而不是 0 其实怎样标注都不会影响最后的结果 然而对于之前的一个 二元分类问题 我们的数据看起来可能是像这样 对于一个多类分类问题 我们的数据集 或许看起来像这样 我用三种不同的符号来代表三个类别 问题就是 给出三个类型的数据集 这是一个类别中的样本 而这个样本是属于 另一个类别 而这个样本属于第三个类别 我们如何得到一个学习算法来进行分类呢？ 我们现在已经知道如何 进行二元分类 可以使用逻辑斯特回归 对于直线或许你也知道 可以将数据集一分为二为正类和负类 用一对多的 分类思想 我们可以 将其用在多类分类问题上 下面将介绍如何进行一对多的分类工作 有时这个方法也被称为"一对余"方法 现在我们有一个训练集 好比左边表示的 有三个类别 我们用三角形表示 y=1 方框表示 y=2 叉叉表示 y=3 我们下面要做的就是 使用一个训练集 将其分成三个二元分类问题 所以我将它分成三个 二元分类问题 我们先从用三角形代表的类别1开始 实际上我们可以创建一个 新的"伪"训练集 类型2和类型3 定为负类 类型1 设定为正类 我们创建一个新的 训练集 如右侧所示的那样 我们要拟合出一个合适的分类器 我们称其为 h 下标 θ 上标(1) (x) 这里的三角形是正样本 而圆形代表负样本 可以这样想 设置三角形的值为1 圆形的值为0 下面我们来训练一个标准的 逻辑回归分类器 这样我们就得到一个正边界 对吧? 这里上标(1)表示类别1 我们可以像这样对三角形类别这么做 下面 我们将为类别2做同样的工作 取这些方块样本 然后将这些方块 作为正样本 设其它的为三角形和叉形类别为负样本 这样我们找到第二个合适的逻辑回归分类器 我们称为 h 下标 θ 上标(2) (x) 其中上标(2)表示 是类别2 所以我们做的就是 把方块类当做正样本 我们可能便会得到这样的一个分类器 最后 同样地 我们对第三个类别采用同样的方法 并找出 第三个分类器 h 下标 θ 上标(3) (x) 或许这么做 可以给出一个像这样的 判别边界 或者说分类器 能这样分开正负样本 总而言之 我们已经拟合出三个分类器 对于 i 等于1、2、3 我们都找到了一个分类器 h 上标(i) 下标θ 括号 x 通过这样来尝试 估计出 给出 x 和先验 θ 时 y的值等于 i 的概率 对么？ 在一开始 对于第一个在这里的 分类器 完成了对三角形的识别 把三角形当做是正类别 所以 h(1) 实际上是在计算 给定x 以 θ 为参数时 y的值为1的 概率是多少 概率是多少 同样地 这个也是这么处理 矩形类型当做一个正类别 同样地 可以计算出 y=2 的概率和其它的概率值来 现在我们便有了三个分类器 且每个分类器都作为其中一种情况进行训练 总之 我们已经把要做的做完了 现在要做的就是训练这个 逻辑回归分类器 h(i) 逻辑回归分类器 h(i) 其中 i 对应每一个可能的 y=i 最后 为了做出预测 我们给出输入一个新的 x 值 用这个做预测 我们要做的 就是 在我们三个分类器 里面输入 x 然后 我们选择一个让 h 最大的 i 你现在知道了 基本的挑选分类器的方法 选择出哪一个分类器是 可信度最高效果最好的 那么就可认为得到一个正确的分类 无论i值是多少 我们都有最高的概率值 我们预测 y 就是那个值 这就是多类别分类问题 以及一对多的方法 通过这个小方法 你现在也可以将 逻辑回归分类器 用在多类分类的问题上 【教育无边界字幕组】 翻译：Yuens  校对/审核：Naplessss