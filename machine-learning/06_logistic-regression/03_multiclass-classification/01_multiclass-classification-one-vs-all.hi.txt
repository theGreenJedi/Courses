इस वीडियो में हम बात करेंगे कि कैसे लजिस्टिक रेग्रेशन काम करता है मल्टीक्लास क्लैसिफ़िकेशन प्रॉब्लम्स में. और विशेष तौर पर मैं बताना चाहता हूँ आपको एक अल्गोरिद्म के बारे में जिसे कहते हैं वन-वर्सेस-ऑल. क्लैसिफ़िकेशन. क्या है मल्टीक्लास क्लैसिफ़िकेशन प्रॉब्लम? यहाँ हैं कुछ उदाहरण. मान लो आप चाहते है एक लर्निंग अल्गोरिद्म को कि वह अपने आप डाल दे आपकी ईमेल भिन्न-भिन्न फ़ोल्डर्ज़ में या अपने आप टैग कर दे आपकी ईमेल्स को ताकि आपको मिलें भिन्न फ़ोल्डर्ज़ या भिन्न टैग्ज़ वर्क ईमेल के, मित्रों से ईमेल के, परिवार से ईमेल के और आपके शौक़ के ईमेल के. और इसलिए यहाँ हमारे पास है एक क्लैसिफ़िकेशन प्राब्लम चार क्लास की जो हम शायद असाइन करें क्लास, y=1, y=2, y=3 और y=4 को. और एक और उदाहरण, चिकित्सा निदान के लिए, यदि एक मरीज़ आपके ऑफ़िस में आता हैं शायद बंद नाक के साथ, संभव निदान हो सकता है कि वे बीमार नहीं हों. शायद वह है y = 1. या शायद उन्हें सर्दी हो, 2. या उन्हें फ़्लू हो. और एक तीसरा तथा अंतिम उदाहरण यदि आप इस्तेमाल कर रहे हैं मशीन लर्निंग क्लैसिफ़ाई करने के लिए मौसम, आप जानते हैं शायद कि आप तय करना चाहते हैं कि मौसम धूप निकली है , बादल है, बारिश है या बर्फ़, या बर्फ़ गिरेगी, तो इन सब उदाहरणों में y ले सकता है कुछ छोटी संख्या में वैल्यूज़, शायद एक से तीन, एक से चार और ऐसा कुछ, और ये है मल्टीक्लास क्लैसिफ़िकेशन प्रॉब्लम्स. और वैसे तो इससे फर्क नहीं पड़ता कि हम इंडेक्स करें इसे 0, 1, 2, 3 या 1, 2, 3, 4 के जैसे. मेरा झुकाव रहता है शुरू करने से 1 की तरफ़ बजाय शुरू करने से 0, लेकिन किसी भी तरह हम कर सकते हैं और इस से वास्तव में कोई फर्क नहीं पड़ता. जबकि पहले बाइनेरी क्लैसिफ़िकेशन प्रॉब्लम के लिए, हमारा डेटा दिखता हैं ऐसा. एक मल्टी क्लास क्लैसिफ़िकेशन प्रॉब्लम के लिए, हमारा डेटा शायद दिखे ऐसे जहाँ मैं इस्तेमाल कर रहा हूँ तीन भिन्न चिन्ह दर्शाने के लिए हमारी तीन क्लैसेज़. तो प्रश्न यह है कि दिया होने पर डेटा सेट तीन क्लैसेज़ का जहाँ यह है एक उदाहरण एक क्लास का, वह है एक उदाहरण एक भिन्न क्लास का, और वह है एक उदाहरण एक और तीसरी क्लास का. कैसे करवा सकते हैं हम एक लर्निग अल्गोरिद्म को काम इस सेटिंग के लिए. हम पहले से ही जानते हैं कैसे करते है बाइनेरी क्लैसिफ़िकेशन इस्तेमाल करके एक रेग्रेशन. हम अब जानते हैं कैसे, आप जानते हैं, शायद कैसे फ़िट करनी है एक सीधी रेखा सेट को पॉज़िटिव तथा नेगेटिव क्लास के लिए. आप देखें एक सुझाव जिसे कहते हैं वन-वर्सेस-ऑल क्लैसिफ़िकेशन. हम तब इसे ले सकते हैं और चला सकते हैं मल्टी-क्लास क्लैसिफ़िकेशन के लिए भी. यहाँ है कि कैसे एक वन-वर्सेस-ऑल क्लैसिफ़िकेशन काम करता है. इसे कभी-कभी कहते हैं वन-वर्सेस रेस्ट भी. मान लो हमारे पास है एक ट्रेनिंग सेट जैसे दिखाया है बाईं तरफ़, जहाँ हमारे पास हैं तीन क्लास y बराबर 1, हम डिनोट करते हैं उसे एक त्रिकोण से, यदि y बराबर है 2, वर्ग से, और यदि y बराबर है तीन, तो क्रॉस से. हम क्या करेंगे कि लेंगे हमारा ट्रेनिंग सेट और बदल देंगे उसे तीन बाइनेरी क्लास क्लैसिफ़िकेशन प्रॉब्लम्स में. मैं बदलूँगा इसे तीन अलग-अलग दो क्लास क्लैसिफ़िकेशन प्रॉब्लम्स में. तो चलो शुरू करते हैं क्लास एक से जो है त्रिकोण. हम एक प्रकार से अनिवार्यत: बनायेंगे एक नक़ली ट्रेनिंग सेट जहाँ क्लास दो और तीन बन जाती हैं नेगेटिव क्लास. और क्लास एक बन जाती है पॉज़िटिव क्लास. आप बनाना चाहते हैं एक नया ट्रेनिंग सेट जैसे दिखाया है दाईं तरफ़, और हम करेंगे फ़िट एक क्लैसिफ़ायअर जहाँ मैं कहूँगा h सबस्क्रिप्ट थीटा सूपरस्क्रिप्ट एक ऑफ़ x जहाँ यहाँ त्रिकोण हैं पॉज़िटिव इग्ज़ाम्पल्ज़ हैं, वृत्त हैं नेगेटिव इग्ज़ाम्पल्ज़. तो सोचें त्रिकोण को वैल्यू एक के साथ और वृत्तों को वैल्यू ज़ीरो के साथ. और हम सिर्फ़ ट्रेन करेंगे एक स्टैंडर्ड लजिस्टिक रेग्रेशन क्लैसिफ़ायअर और शायद वह देगा हमें एक पोजिशन सीमा/ बाउंड्री जो दिखता है वैसा. सही है? इस सूपरस्क्रिप्ट एक का मतलब है यहाँ क्लास एक, तो हम कर रहे हैं यह त्रिकोण के लिए क्लास एक के. आगे हम करते हैं वही चीज़ क्लास दो के लिए. लेंगे वर्ग और बनायेंगे वर्गों को पॉज़िटिव क्लास, और बाक़ी सब कुछ को बनायेंगे, त्रिकोण और क्रॉस को, एक नेगेटिव क्लास. और फिर हम फ़िट करेंगे एक दूसरा लजिस्टिक रेग्रेशन क्लैसिफ़ायअर और कहेंगे इसे h ऑफ़ x सूपरस्क्रिप्ट दो, जहाँ सूपरस्क्रिप्ट दो डिनोट करती है कि हम अब कर रहे हैं इसे, लेते हुए वर्ग क्लास को पॉज़िटिव क्लास की तरह. और शायद हमें मिलता उस तरह का. और अंत में, हम करते हैं वही चीज़ तीसरी क्लास के लिए और फ़िट करते हैं एक तीसरा क्लैसिफ़ायअर h सूपरस्क्रिप्ट तीन x, और यह शायद देगा हमें एक डिसिज़न बाउंड्री क्रॉस क्लास के लिए. यह अलग करती है पॉज़िटिव या नेगेटिव इग्ज़ाम्पल को उस तरह से. अत: संक्षेप में, हमने क्या किया है कि, हमने फ़िट किए हैं तीन क्लैसिफ़ायअर्स. तो, i = 1, 2, 3 के लिए, हम करेंगे फ़िट एक क्लैसिफ़ायअर x सूपरस्क्रिप्ट i सबस्क्रिप्ट थीटा ऑफ़ x. अत: कोशिश कर रहे हैं अनुमान करने का कि प्रॉबबिलिटी y है बराबर क्लास i, दिए होने पर x और पेरामिटर हैं थीटा. ठीक है? तो, पहले उदाहरण के लिए इस पहले के लिए ऊपर यहाँ, यह क्लैसिफ़ायअर लर्न कर रहा था पहचानने के लिए त्रिकोण. तो यह सोच रहा था त्रिकोण को एक पॉज़िटिव क्लास, तो x सूपरस्क्रिप्ट एक है अनिवार्यत: अनुमान करते हुए कि क्या है प्रॉबबिलिटी कि y है बराबर एक, दिया होने पर x पेरामिटर थीटा के साथ. और इसी प्रकार, लेते हुए वर्ग क्लास को पॉज़िटिव क्लास की तरह और अत: यह कोशिश कर रहा हैं अनुमान करने का कि प्रॉबबिलिटी y = 2 और इसी प्रकार आगे. तो अब हमारे पास हैं तीन क्लैसिफ़ायअर्स, प्रत्येक इनमें से ट्रेन किया गया था पहचानने के तीन में से एक क्लास. अत: संक्षेप में, हमने क्या किया है कि, हम चाहते हैं ट्रेन करना एक लजिस्टिक रेग्रेशन क्लैसिफ़ायअर h सूपरस्क्रिप्ट i ऑफ़ x प्रत्येक क्लास i के लिए प्रिडिक्ट करने के लिए प्रॉबबिलिटी कि y है बराबर i. अंत में प्रिडिक्शन करने के लिए, जब हमें दी जाएगी एक नयी इनपुट x, और हम करना चाहते हैं एक प्रिडिक्शन. हम क्या करते हैं कि हम सिर्फ़ रन करते हैं तीनों हमारे क्लैसिफ़ायअर्स इनपुट x पर और फिर हम चुनते हैं क्लास i जो अधिकतम है तीनों में से. तो हम मूल रूप से लेते हैं क्लैसिफ़ायअर, मैं सोचता हूँ जो भी तीन में से एक क्लैसिफ़ायअर है सबसे अधिक आश्वस्त और इसलिए सबसे अधिक उत्साह से कहता है यह सोचता है इसके पास है सही क्लास. तो जो भी i की वैल्यू देती है हमें अधिकतम प्रॉबबिलिटी हम तब प्रिडिक्ट करते हैं y को वह वैल्यू. तो इतना ही मल्टीक्लास क्लैसिफ़िकेशन के लिए और वन-वर्सेस-ऑल विधि के लिए. और इस छोटी सी विधि से अब आप ले जा सकते हैं लजिस्टिक रेग्रेशन क्लैसिफ़ायअर को और चला सकते हैं इसे मल्टीक्लास क्लैसिफ़िकेशन प्राब्लम्ज़ पर भी.