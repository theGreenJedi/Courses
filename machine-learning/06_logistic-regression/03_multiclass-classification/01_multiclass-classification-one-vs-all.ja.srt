1
00:00:00,200 --> 00:00:01,596
このビデオでは、ロジスティック回帰を

2
00:00:01,620 --> 00:00:03,659
マルチクラスの分類問題に

3
00:00:03,659 --> 00:00:06,089
適用する方法を議論する。

4
00:00:06,089 --> 00:00:07,526
具体的には、one vs all分類と呼ばれる

5
00:00:07,526 --> 00:00:12,070
アルゴリズムを話したい。

6
00:00:12,150 --> 00:00:14,316
マルチクラスの分類問題とは何だろう？

7
00:00:14,316 --> 00:00:15,945
ここにその例がある。

8
00:00:15,945 --> 00:00:17,318
例えばあなたのe-mailを

9
00:00:17,320 --> 00:00:19,691
学習アルゴリズムに

10
00:00:19,710 --> 00:00:21,076
別々のフォルダに移動させたい、としよう。

11
00:00:21,076 --> 00:00:23,398
あるいは自動でe-mailにタグをつけたい、とする。

12
00:00:23,398 --> 00:00:24,749
あなたは様々なフォルダやタグを使うだろう、

13
00:00:24,790 --> 00:00:27,052
仕事用のe-mailとか

14
00:00:27,060 --> 00:00:28,236
友達から来たe-mailとか

15
00:00:28,236 --> 00:00:31,561
家族から来たe-mailとか、趣味に関するe-mailとか。

16
00:00:31,590 --> 00:00:33,145
すると、我らは4つのクラスへの

17
00:00:33,145 --> 00:00:34,856
分類問題に直面する訳だ。

18
00:00:34,900 --> 00:00:36,164
そこに数字を振っておくと、

19
00:00:36,180 --> 00:00:38,129
クラスy=1, y=2,

20
00:00:38,129 --> 00:00:41,326
y=3, y=4と。

21
00:00:41,326 --> 00:00:43,530
もう一つ別の例としては、

22
00:00:44,490 --> 00:00:45,790
医療の診断とかも考えられる：

23
00:00:46,000 --> 00:00:47,260
患者があなたのオフィスに

24
00:00:47,800 --> 00:00:48,910
やってきて、

25
00:00:48,930 --> 00:00:51,395
鼻づまりだと言う。

26
00:00:51,395 --> 00:00:52,762
考えられる診断結果としては、

27
00:00:52,762 --> 00:00:54,140
病気じゃないとか、これをy=1とする、

28
00:00:54,140 --> 00:00:55,474
または風邪とか、これを2とする。

29
00:00:55,490 --> 00:00:59,026
またはインフルエンザかもしれない。

30
00:00:59,026 --> 00:01:00,541
最後に、三番目の例としては、

31
00:01:00,541 --> 00:01:02,056
天気の分類の為に

32
00:01:02,090 --> 00:01:03,906
機械学習を使いたいとする。

33
00:01:03,910 --> 00:01:05,299
例えば晴れ、曇り、

34
00:01:05,299 --> 00:01:07,937
雨、雪を、雪が降りそうな場所ならだが、

35
00:01:07,950 --> 00:01:10,211
分類したいとする。

36
00:01:10,230 --> 00:01:11,165
以上の三つの例は全て

37
00:01:11,165 --> 00:01:12,808
yが離散的な

38
00:01:12,808 --> 00:01:14,300
小数の値を

39
00:01:14,300 --> 00:01:16,498
とる事が出来る。1から3までとか

40
00:01:16,498 --> 00:01:17,810
1から4までとか。

41
00:01:17,890 --> 00:01:20,659
これらがマルチクラスの分類問題だ。

42
00:01:20,659 --> 00:01:21,904
ところで、インデックスを

43
00:01:21,904 --> 00:01:23,632
0123とふるか1234とふるかは

44
00:01:23,632 --> 00:01:27,063
どうでもいい。

45
00:01:27,090 --> 00:01:29,138
私はクラスを1からふって、

46
00:01:29,138 --> 00:01:31,569
0からふらない事が多いが。

47
00:01:31,569 --> 00:01:33,756
だがどっちでもいい。

48
00:01:33,756 --> 00:01:35,243
他方、以前の二択分類問題は

49
00:01:35,243 --> 00:01:39,375
我らのデータセットはこんな感じだった。

50
00:01:39,375 --> 00:01:41,617
マルチクラスの分類問題では、

51
00:01:41,617 --> 00:01:42,792
我らのデータセットはこんな感じになるだろう、

52
00:01:42,792 --> 00:01:44,362
ここで三つの異なる記号を

53
00:01:44,362 --> 00:01:48,399
三つのクラスを表すのに用いた。

54
00:01:48,410 --> 00:01:49,858
そこで問題はこうだ：

55
00:01:49,858 --> 00:01:51,613
三つのクラスのデータセットを与えられて、

56
00:01:51,613 --> 00:01:53,193
ここでは

57
00:01:53,193 --> 00:01:54,651
これが一つのクラスの手本で

58
00:01:54,651 --> 00:01:55,768
これがそれとは別のクラスの手本で、

59
00:01:55,790 --> 00:01:58,389
これがそれとも別のさらに別のクラスの手本だ。

60
00:01:58,410 --> 00:02:01,421
で、これらの状況で、どうやって学習アルゴリズムを機能させられるだろうか？

61
00:02:01,421 --> 00:02:02,598
我らは既に、二択の分類を

62
00:02:02,598 --> 00:02:05,096
どうやるのかは知っている。

63
00:02:05,096 --> 00:02:06,594
ロジスティック回帰を用いる事で、

64
00:02:06,594 --> 00:02:07,736
陽性と陰性のクラスを直線で

65
00:02:07,736 --> 00:02:10,613
どうやって分離するかを知っている。

66
00:02:10,613 --> 00:02:12,116
one vs all分類と言われるアイデアを

67
00:02:12,116 --> 00:02:14,399
用いる事で、

68
00:02:14,400 --> 00:02:15,730
これを、マルチクラスの分類にも

69
00:02:15,730 --> 00:02:18,646
使えるように出来る。

70
00:02:18,650 --> 00:02:21,617
one vs allはこんな風に機能する。

71
00:02:21,620 --> 00:02:25,777
ところで、この戦略はone vs restと呼ばれる事もある。

72
00:02:25,777 --> 00:02:26,941
では、左に示したような

73
00:02:26,941 --> 00:02:28,138
トレーニングセットがあるとしよう。

74
00:02:28,150 --> 00:02:30,456
3つのクラスがあり、

75
00:02:30,470 --> 00:02:32,310
y1で三角形を示し、

76
00:02:32,310 --> 00:02:34,405
y2で四角形を

77
00:02:34,405 --> 00:02:37,970
y3でクロスを示すとする。

78
00:02:37,980 --> 00:02:39,460
そこでやる事は、

79
00:02:39,480 --> 00:02:41,350
トレーニングセットを持ってきて、

80
00:02:41,350 --> 00:02:44,816
これを三つの異なる、二択問題に変換する事だ。

81
00:02:44,816 --> 00:02:46,719
つまり、私はこれを、三つの別個の

82
00:02:46,750 --> 00:02:49,450
2クラス分類問題に変換する。

83
00:02:49,450 --> 00:02:51,660
クラス1、三角形から始めよう。

84
00:02:51,660 --> 00:02:52,990
本質的には、新しい三角形の

85
00:02:53,050 --> 00:02:55,418
偽のトレーニングセットを作る。

86
00:02:55,440 --> 00:02:56,913
そこではクラス2と3は

87
00:02:56,920 --> 00:02:58,151
陰性のクラスに割り当てて、

88
00:02:58,151 --> 00:02:59,873
クラス1は

89
00:02:59,873 --> 00:03:01,134
陽性のクラスに割り当てる。

90
00:03:01,134 --> 00:03:02,352
こうして右側に示したような

91
00:03:02,380 --> 00:03:03,700
トレーニングセットを作り

92
00:03:03,700 --> 00:03:05,508
そこに分類器を

93
00:03:05,508 --> 00:03:07,573
フィッティングさせる。これを

94
00:03:07,573 --> 00:03:10,200
hの下付き添字シータ、

95
00:03:10,220 --> 00:03:12,626
上付き添字1のxと呼ぼう。

96
00:03:12,640 --> 00:03:15,659
ここでは、三角形が陽性の手本で

97
00:03:15,659 --> 00:03:19,008
丸は陰性の手本となる。

98
00:03:19,008 --> 00:03:20,649
つまり三角形に

99
00:03:20,649 --> 00:03:21,800
値1を割り振って、

100
00:03:21,800 --> 00:03:25,291
丸に値0を割り振る。

101
00:03:25,300 --> 00:03:26,723
そして通常のロジスティック回帰の分類器で

102
00:03:26,723 --> 00:03:29,556
トレーニングを行う。

103
00:03:29,556 --> 00:03:34,173
その結果、ある決定境界が得られる訳だ。

104
00:03:34,173 --> 00:03:34,173
OK?

105
00:03:34,890 --> 00:03:37,693
上付き添字1は、クラス1を。

106
00:03:37,693 --> 00:03:40,777
つまりこれを最初の三角形のクラスの為に行う。

107
00:03:40,800 --> 00:03:42,302
次に、同様の事をクラス2に対して行う。

108
00:03:42,302 --> 00:03:44,013
四角形をとり、

109
00:03:44,020 --> 00:03:45,456
四角形に陽性のクラスを

110
00:03:45,470 --> 00:03:47,001
割り振って、それ以外の全てに

111
00:03:47,001 --> 00:03:50,213
つまり三角とバッテンに陰性のクラスを割り振る。

112
00:03:50,220 --> 00:03:54,173
そして二番目のロジスティック回帰分類器をフィッティングする。

113
00:03:54,173 --> 00:03:56,410
これはhの上付き添字2、と

114
00:03:56,420 --> 00:03:58,352
呼ぶ事にする。ここでこの

115
00:03:58,352 --> 00:04:00,029
上付き添字2は、現在我らは

116
00:04:00,029 --> 00:04:01,860
これ、四角形のクラスを

117
00:04:01,870 --> 00:04:03,310
陽性のクラスと扱っている、という事を表している。

118
00:04:03,350 --> 00:04:07,518
そしてこんな分類器が得られるだろう。

119
00:04:07,518 --> 00:04:08,854
そして最後に、同様の事を

120
00:04:08,854 --> 00:04:10,143
三番目のクラスに対して行い、

121
00:04:10,143 --> 00:04:11,598
そして三番目の分類器、

122
00:04:11,610 --> 00:04:14,632
h上付き添字3のxをフィッティングし、

123
00:04:14,632 --> 00:04:16,424
これが我らに

124
00:04:16,440 --> 00:04:18,106
こんな感じの決定境界、あるいは

125
00:04:18,106 --> 00:04:19,749
陽性と陰性を分離する分類器を

126
00:04:19,750 --> 00:04:22,863
与える。

127
00:04:22,870 --> 00:04:24,353
まとめよう。我らがやった事は、

128
00:04:24,353 --> 00:04:27,872
3つの分類器をフィッティングした、という事。

129
00:04:27,890 --> 00:04:29,403
i=1, 2, 3について

130
00:04:29,403 --> 00:04:31,836
h上付き添字i 下付き添字シータ xの

131
00:04:31,880 --> 00:04:33,855
分類器をフィッティングしていく。

132
00:04:33,855 --> 00:04:35,193
かくして、与えられたxと

133
00:04:35,220 --> 00:04:36,446
パラメータシータに対して、

134
00:04:36,450 --> 00:04:38,208
yがiとなる確率を

135
00:04:38,208 --> 00:04:41,834
推計しようと試みる訳だ。

136
00:04:41,834 --> 00:04:41,834
いいかい？

137
00:04:41,834 --> 00:04:43,229
最初のインスタンスでは、

138
00:04:43,230 --> 00:04:44,903
ここの最初の奴は、

139
00:04:44,910 --> 00:04:47,277
この分類器は三角形で

140
00:04:47,280 --> 00:04:49,364
学習している。

141
00:04:49,364 --> 00:04:52,037
つまり三角形を陽性のクラスとみなしている。

142
00:04:52,060 --> 00:04:53,840
つまり、hの上付き添字1は

143
00:04:53,840 --> 00:04:55,163
本質的には

144
00:04:55,170 --> 00:04:57,343
y=1となる確率を

145
00:04:57,350 --> 00:04:59,083
所与のxとパラメータシータの条件の元で

146
00:04:59,083 --> 00:05:02,037
推計している。

147
00:05:02,037 --> 00:05:04,475
同様に、これは四角形のクラスを

148
00:05:04,480 --> 00:05:05,859
陽性の手本と

149
00:05:05,859 --> 00:05:07,400
みなしているので、

150
00:05:07,400 --> 00:05:10,748
これはyが2 となる確率を推計しているのだ。以下同様。

151
00:05:10,750 --> 00:05:13,300
つまり今や、我らは3つの分類器を持ち、

152
00:05:13,310 --> 00:05:16,649
おのおのは3つのクラスのうち一つに向けてトレーニングされている。

153
00:05:16,670 --> 00:05:17,859
まとめると、我らがやった事は

154
00:05:17,860 --> 00:05:19,685
我らはロジスティック回帰の

155
00:05:19,700 --> 00:05:21,280
分類器、hの上付き添字iのxを

156
00:05:21,300 --> 00:05:23,560
yがiとなる確率を

157
00:05:23,560 --> 00:05:24,947
各h iが推計するように

158
00:05:24,950 --> 00:05:26,183
トレーニングしたい。

159
00:05:26,183 --> 00:05:28,550
そして最終的に、

160
00:05:28,570 --> 00:05:29,740
予測を行いたい時には、、、

161
00:05:29,820 --> 00:05:31,772
新規の入力xを与えられた時に、

162
00:05:31,772 --> 00:05:33,326
予測を行いたければ、

163
00:05:33,340 --> 00:05:34,729
我らがやる事は、

164
00:05:34,730 --> 00:05:36,706
我らの手持ちの

165
00:05:36,706 --> 00:05:38,557
3つの分類器を

166
00:05:38,557 --> 00:05:40,010
入力xに対して実行し、

167
00:05:40,010 --> 00:05:41,535
その中で一番大きなクラスのiを

168
00:05:41,535 --> 00:05:44,068
選ぶ、という事をする。

169
00:05:44,068 --> 00:05:45,387
つまり基本的には、

170
00:05:45,387 --> 00:05:47,180
それがなんであれ、

171
00:05:47,180 --> 00:05:49,163
もっとも自信のありそうな分類器を、

172
00:05:49,210 --> 00:05:52,178
言い換えるともっとも大声でこれが正しいクラスだ、と

173
00:05:52,178 --> 00:05:54,352
言っている物を選ぶ。

174
00:05:54,352 --> 00:05:56,153
つまり最も高い確率を

175
00:05:56,190 --> 00:05:58,069
与えるiの値ならなんでもいい。

176
00:05:58,069 --> 00:06:01,056
そしてyの値を予測する。

177
00:06:02,660 --> 00:06:04,453
以上がマルチクラスの分類問題であり、

178
00:06:04,470 --> 00:06:07,677
one vs all法だ。

179
00:06:07,677 --> 00:06:09,120
このちょっとした手法を用いる事で

180
00:06:09,120 --> 00:06:10,521
あなたは今や、ロジスティック回帰

181
00:06:10,521 --> 00:06:12,033
を用いて、マルチクラスの分類器の問題で

182
00:06:12,033 --> 00:06:15,051
それを同様に機能させる事が出来るようになった。