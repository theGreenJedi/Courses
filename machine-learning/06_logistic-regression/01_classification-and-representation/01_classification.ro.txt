In acesta si urmatoarele cateva filme, vreau sa incep sa vorbesc despre probleme de clasificare unde variabila y pe care vrem sa o predictam este discreta. Vom dezvolta un algoritm numit 'Regresie logistica' care este unul dintre cei mai populari si mai utilizati algoritmi de invatare utilizati astazi. Iata cateva exemple de probleme de clasificare. Mai devreme am vorbit despre e-mail-uri, clasificarea mesajelor de spam, ca un exemplu de problema de clasificare Un alt exemplu este clasificarea tranzactiilor online Deci, daca avem un website care vinde diverse lucruri si vrem sa stim daca o tranzactie este frauduloasa sau nu, stiti, cineva foloseste o carte de credit furata, sau a furat parola unui alt utilizator. Aceasta este o alta problema de clasificare si mai devreme am vorbit si despre exemplu de clasificare a tumorilor in canceroase sau maligne, si tumori benigne. In toate aceste probleme, variabila pe care incercam sa o predictam este o variabila Y pe care o putem imagina ca luand doua valori, fie zero (0) fie unu (1) : spam, sau not spam, fraudulos sau non-fraudulos, malign sau benign. Un alt nume pentru clasa pe care o etichetam cu 0 (zero) este clasa negativa, iar un alt nume pentru clasa pe care o etichetam cu 1 (unu) este clasa pozitiva. Deci zero poate determina o tumoare benigna, iar unu (clasa pozitiva) poate determina o tumoare maligna. Asignarea celor doua clase, spam si non-spam, si asa mai departe, asignarea celor doua clase in pozitiv si negativ, zero, sau unu, este intrucatva arbitrara si nu conteaza prea mult. Insa, de cele mai multe ori, este intuitiv ca o clasa negativa sa indice absenta a ceva, de exemplu absenta unei tumori maligne, in timp ce, o clasa pozitiva, sa indice prezenta a ceva, ceva ce ne dorim sa identificam. Dar definitia a ceea ce este negativ si ceea ce este pozitiv este oarecum arbitrara si nu are prea multa importanta. Pentru moment, vom incepe cu probleme de clasificare cu doar doua clase - zero si unu. Mai tarziu, vom vorbi de asemenea despre probleme cu clase multiple, unde variabila Y poate lua, sa zicem, patru valori distincte - zero, unu, doi, trei Aceasta este o problema de clasificare cu clase multiple, dar pentru urmatoarele cateva videoclipuri, vom incepe cu doua clase, sau probleme de clasificare binare, si ne vom ocupa de cazul cu clase multiple mai tarziu. Deci, cum dezvoltam un algoritm de clasificare? Iata un exemplu de set de antrenare pentru a clasifica o tumoare ca maligna sau benigna - obsevati ca aceasta proprietate poate lua numai doua valori, zero - sau nu este maligna, sau unu - este maligna. Deci, ceea ce putem face dat fiind acest set de antrenare este sa aplicam algoritmul pe care il stim deja - regresia liniara - pe acest set si sa incercam sa interpolam datele cu o dreapta. Daca luam acest set de antrenare si interpolam cu o dreapta vom obtine probabil o functie ipoteza care arata asa. OK, deci asta e ipoteza mea h(x)=Theta transpus ori x h(x)=Theta transpus ori x Daca vreti sa faceti predictii, puteti incerca sa impuneti o limita pentru iesirea clasificatorului la 0.5 Adica la valoarea pe care o atinge pe verticala de 0.5 Iar daca ipoteza h ia o valoare care este mai mare decat sau egala cu 0.5, veti predicta y=1. Daca este mai mica de 0.5, veti predicta y=0. Hai sa vedem ce se intampla daca facem asta. Sa luam 0.5 si impunem aici pragul. Folosim regresia liniara in acest fel. Tot ce este in dreapta acestui punct, va predicta clasa pozitiva, pentru ca valorile functiei h sunt mai mari ca 0.5 pe axa verticala, iar tot ce este in stanga acelui punct, va predicta clasa negativa. In acest exemplu, se pare ca regresia liniara da rezultate rezonabile, chiar daca sarcina care ne intereseaza este de fapt una de clasificare. Dar hai sa schimbam  putin problema. Sa zicem ca extind axa orizontala si consider inca un punct de antrenare mai departe, in dreapta. Observati ca noul exemplu de antrenare, acesta de aici, nu schimba lucrurile cu nimic, nu-i asa?