1
00:00:00,500 --> 00:00:04,650
इस और अगले कुछ विडीओस में, मैं बात करना चाहूँगा क्लैसिफ़िकेशन

2
00:00:04,650 --> 00:00:09,510
प्राब्लम्ज़ के बारे में जहाँ वेरीअबल वाय जो आप प्रिडिक्ट करना चाहते हैं वह वैल्यूड होता हैं.

3
00:00:09,510 --> 00:00:12,651
हम डिवेलप करेंगे एक अल्गोरिद्म जिसे कहते हैं लजिस्टिक रिग्रेशन,

4
00:00:12,651 --> 00:00:16,931
जो सर्वाधिक प्रचलित और सर्वाधिक व्यापक लर्निंग अल्गोरिद्म है आज.

5
00:00:19,473 --> 00:00:23,270
यहाँ हैं कुछ उदाहरण हैं क्लैसिफ़िकेशन प्राब्लम्ज़ के.

6
00:00:23,270 --> 00:00:26,530
कुछ पहले हमने बात की थी ईमेल स्पैम क्लैसिफ़िकेशन की

7
00:00:26,530 --> 00:00:29,390
बतौर उदाहरण एक क्लैसिफ़िकेशन प्रॉब्लम के.

8
00:00:29,390 --> 00:00:33,110
एक और उदाहरण होगा क्लैसिफ़ाई करना ऑनलाइन ट्रैन्सैक्शंज़ को.

9
00:00:33,110 --> 00:00:35,540
अत: यदि आपकी है एक वेबसाइट जो बेचती है सामान और

10
00:00:35,540 --> 00:00:39,390
यदि आप जानना चाहते हैं कि एक विशेष ट्रैंज़ैक्शन धोखा है कि नहीं,

11
00:00:39,390 --> 00:00:44,590
क्या कोई इस्तेमाल तो नहीं कर रहा चुराया हुआ क्रेडिट कॉर्ड या चुराया हुआ यूज़र पास्वर्ड.

12
00:00:44,590 --> 00:00:46,830
एक और क्लैसिफ़िकेशन प्रॉब्लम है.

13
00:00:46,830 --> 00:00:50,840
और कुछ पहले हमने बात की थी उदाहरण की

14
00:00:50,840 --> 00:00:53,960
क्लासिफाई करना ट्यूमर्स को कैन्सरस, मालिगनेंट या बिनाइन ट्यूमर्स में.

15
00:00:55,120 --> 00:00:59,450
इन सब प्राब्लम्ज़ में वेरीअबल जो आप प्रिडिक्ट करने की कोशिश कर रहे हैं वह है एक वेरीअबल

16
00:00:59,450 --> 00:01:04,160
वाय जो ले सकता है दो वैल्यूज़ या ज़ीरो या एक,

17
00:01:04,160 --> 00:01:09,080
या स्पैम या नहीं स्पैम, धोखा या नहीं धोखा, मालिगनेंट या बिनाइन.

18
00:01:10,500 --> 00:01:15,670
एक और नाम क्लास के लिए जो हम डिनोट करते है ज़ीरो द्वारा वह है नेगेटिव क्लास, और

19
00:01:15,670 --> 00:01:20,020
एक और नाम क्लास के लिए जो हम डिनोट करते है एक से वह है पॉज़िटिव क्लास.

20
00:01:20,020 --> 00:01:23,930
अत: ज़ीरो हम डिनोट करते हैं बिनाइन ट्यूमर के लिए, और एक,

21
00:01:23,930 --> 00:01:27,110
पॉज़िटिव क्लास हम डिनोट करते हैं एक मालिगनेंट ट्यूमर को.

22
00:01:27,110 --> 00:01:31,370
असाइन करना दो क्लैसेज़ को, स्पैम नॉट स्पैम और इसी प्रकार आगे.

23
00:01:31,370 --> 00:01:35,120
असाइन करना दो क्लैसेज़ को, पॉज़िटिव और नेगेटिव को ज़ीरो और

24
00:01:35,120 --> 00:01:37,290
एक में कुछ मनमाना है और

25
00:01:37,290 --> 00:01:42,220
इससे वास्तव में कोई अंतर नहीं आता लेकिन अक्सर ऐसा अनुभव है कि एक नेगेटिव क्लास

26
00:01:42,220 --> 00:01:46,590
इशारा करती हैं अनुपस्थिति किसी चीज़ की जैसे न होना मालिगनेंट ट्यूमर का.

27
00:01:46,590 --> 00:01:51,460
जबकि एक पॉज़िटिव क्लास इशारा करती है उपस्थिति किसी चीज़ की जो

28
00:01:51,460 --> 00:01:55,170
हम शायद हम ढूँढ रहे थे, लेकिन परिभाषा कि क्या नेगेटिव है और

29
00:01:55,170 --> 00:01:58,790
क्या पॉज़िटिव बहुत कुछ स्वेच्छित है और उससे उतना अंतर नहीं पड़ता.

30
00:02:00,150 --> 00:02:03,080
अभी के लिए हम शुरू करेंगे क्लैसिफ़िकेशन प्राब्लम्ज़

31
00:02:03,080 --> 00:02:05,510
सिर्फ़ दो क्लैसेज़ के साथ ज़ीरो और एक.

32
00:02:05,510 --> 00:02:09,320
बाद में हम बात करेंगे मल्टी-क्लास प्राब्लम्ज़ के बारे में भी जहाँ

33
00:02:09,320 --> 00:02:14,250
इसलिए वाय ले सकता है चार वैल्यूज़ ज़ीरो, एक, दो और तीन.

34
00:02:14,250 --> 00:02:17,720
इसे कहते हैं मल्टीक्लास क्लैसिफ़िकेशन प्रॉब्लम.

35
00:02:17,720 --> 00:02:22,140
लेकिन अगले कुछ विडीओस में, शुरू करते हैं दो क्लास या बाइनेरी

36
00:02:22,140 --> 00:02:25,978
क्लैसिफ़िकेशन प्रॉब्लम से और हम सोचेंगे मल्टीक्लास के बारे में बाद में.

37
00:02:25,978 --> 00:02:30,580
तो कैसे डिवेलप करते हैं हम एक क्लैसिफ़िकेशन अल्गोरिद्म?

38
00:02:30,580 --> 00:02:34,770
यहाँ है एक उदाहरण ट्रेनिंग सेट का एक क्लैसिफ़िकेशन टास्क का

39
00:02:34,770 --> 00:02:37,410
क्लैसिफ़ाई करने के लिए एक ट्यूमर को मालिगनेंट या बिनाइन.

40
00:02:37,410 --> 00:02:44,570
और ध्यान दें, कि मालिगनैन्सी लेती है सिर्फ़ दो वैल्यूज़, ज़ीरो या एक, न या हाँ.

41
00:02:44,570 --> 00:02:47,520
अत: एक काम जो हम कर सकते हैं दिया होने पर यह ट्रेनिंग सेट

42
00:02:47,520 --> 00:02:50,309
कि अप्लाई करें अल्गोरिद्म जो हमें पहले से पता है.

43
00:02:51,410 --> 00:02:53,410
लिनीअर रेग्रेशन इस डेटा सेट को और

44
00:02:53,410 --> 00:02:56,320
कोशिश करें फ़िट करने की सीधी लाइन इस डेटा को.

45
00:02:56,320 --> 00:02:59,840
इसलिए यदि आप लेते हैं यह ट्रेनिंग सेट और फ़िट करते हैं एक सीधी लाइन इसमें

46
00:02:59,840 --> 00:03:03,730
शायद आपको मिले एक हायपॉथिसस जो वैसी दिखे, सही है?

47
00:03:03,730 --> 00:03:05,695
तो वह है मेरी हायपॉथिसस.

48
00:03:05,695 --> 00:03:09,100
एच(एक्स) ईक्वल्ज़ थीटा ट्रैन्स्पोज़ एक्स.

49
00:03:09,100 --> 00:03:14,650
अगर आप करना चाहते हैं प्रिडिक्शंज़, एक काम जो आप कर सकते हैं तब कि थ्रेशोल्ड / सीमा रेखा लें

50
00:03:14,650 --> 00:03:19,165
क्लैसिफ़ायअर आउट्पुट की 0.5 पर जो है एक वर्टिकल / खड़ी

51
00:03:19,165 --> 00:03:23,985
ऐक्सिस वैल्यू 0.5 और यदि हायपॉथिसस

52
00:03:23,985 --> 00:03:27,235
आउट पुट करती है वैल्यू बड़ी या बराबर 0.5 के तो आप ले सकते है वाय=1,

53
00:03:27,235 --> 00:03:29,955
यदि यह कम है 0.5 से तो आप लें वाय=0.

54
00:03:29,955 --> 00:03:32,775
चलिए देखते है क्या होता है जब हम वह करते हैं.

55
00:03:32,775 --> 00:03:36,359
तो 0.5 और तो वह है जहाँ सीमा रेखा है और

56
00:03:36,359 --> 00:03:39,990
वह है लिनीअर रेग्रेशन करना इस प्रकार.

57
00:03:39,990 --> 00:03:43,520
सब कुछ इस पोईँट के दाईं तरफ़ हम प्रिडिक्ट करेंगे

58
00:03:43,520 --> 00:03:44,710
पॉज़िटिव क्लास.

59
00:03:44,710 --> 00:03:50,360
क्योंकि आउट्पुट वैल्यू बड़ी है 0.5 से खड़ी ऐक्सिस पर और सबकुछ

60
00:03:50,360 --> 00:03:54,629
इस पोईँट के बाईं तरफ़ हम प्रिडिक्ट करेंगे एक नेगेटिव वैल्यू.

61
00:03:55,720 --> 00:03:57,620
इस ख़ास उदाहरण में,

62
00:03:57,620 --> 00:04:01,630
ऐसा लगता है कि लिनीअर रेग्रेशन वास्तव में कुछ उचित कर रहा है.

63
00:04:01,630 --> 00:04:05,420
जबकि यह है एक क्लैसिफ़िकेशन टास्क जिसमें हमें दिलचस्पी है.

64
00:04:05,420 --> 00:04:08,120
लेकिन अब चलिए प्रॉब्लम को थोड़ा बदलते हैं.

65
00:04:08,120 --> 00:04:11,530
मैं इक्स्टेंड / बढ़ाता हूँ हॉरिज़ॉंटल /लेटी हुई ऐक्सिस थोड़ी सी और

66
00:04:11,530 --> 00:04:15,263
मान लीजिए हमारे पास एक और ट्रेनिंग इग्ज़ाम्पल है काफ़ी दूर वहाँ दाईं तरफ़.

67
00:04:15,263 --> 00:04:18,900
ध्यान दें कि वह अतिरिक्त ट्रेनिंग इग्ज़ाम्पल,

68
00:04:18,900 --> 00:04:21,960
यह यहाँ पर, यह वास्तव में कुछ बदलता नहीं है, सही है?

69
00:04:21,960 --> 00:04:26,200
ट्रेनिंग सेट को देख कर बिल्कुल स्पष्ट है कि हायपॉथिसस उपयुक्त है.

70
00:04:26,200 --> 00:04:28,970
यह है कि सब कुछ है दायीं तरफ़ लगभग यहाँ पर,

71
00:04:28,970 --> 00:04:31,010
और दायीं तरफ इसके हमें प्रिडिक्ट करना चाहिए इसे पॉज़िटिव.

72
00:04:31,010 --> 00:04:34,930
सबकुछ बाईं तरफ़ हमें शायद प्रिडिक्ट करना चाहिए इसे नेगेटिव क्योंकि इस

73
00:04:34,930 --> 00:04:39,620
ट्रेनिंग सेट से, ऐसा लगता है कि सारे ट्यूमर्स जो बड़े हैं एक निश्चित वैल्यू से यहाँ पर

74
00:04:39,620 --> 00:04:44,210
मालिगनेंट हैं, और ट्यूमर्स जो उससे छोटे हैं वे मालिगनेंट नहीं हैं, कम से कम

75
00:04:44,210 --> 00:04:44,820
इस ट्रेनिंग सेट में.

76
00:04:46,200 --> 00:04:50,730
लेकिन जब हमने लिया यह अतिरिक्त इग्ज़ाम्पल यहाँ पर, अगर अब आप रन करें लिनीअर

77
00:04:50,730 --> 00:04:54,480
रेग्रेशन, आपको इसके स्थान पर मिलेगी एक सीधी लाइन फ़िट इस डेटा को.

78
00:04:54,480 --> 00:04:56,090
जो शायद ऐसी दिखेगी.

79
00:04:57,600 --> 00:05:02,890
और यदि आप जानते हैं थ्रेशोल्ड/ सीमारेखा हायपॉथिसस की है 0.5 पर,

80
00:05:02,890 --> 00:05:06,350
आपको मिलती है एक थ्रेशोल्ड / सीमारेखा जो लगभग यहाँ है, अत:

81
00:05:06,350 --> 00:05:09,750
सब कुछ इस पोईँट के दाईं तरफ़ आप प्रिडिक्ट करेंगे पॉज़िटिव और

82
00:05:09,750 --> 00:05:12,070
सब कुछ बाईं तरफ़ उसके आप प्रिडिक्ट करेंगे नेगेटिव.

83
00:05:14,590 --> 00:05:18,820
और यह प्रतीत होता है एक बुरा काम जो लिनीअर रेग्रेशन ने किया. सही?

84
00:05:18,820 --> 00:05:23,110
क्योंकि आप जानते हैं कि ये हमारे पॉज़िटिव इग्ज़ाम्पल्ज़ हैं, ये हमारे नेगेटिव इग्ज़ाम्पल्ज़ हैं.

85
00:05:23,110 --> 00:05:28,090
यह काफ़ी स्पष्ट है हमें करने चाहिए दोनो अलग लगभग यहाँ कहीं,

86
00:05:28,090 --> 00:05:31,260
लेकिन किसी कारण से लेने से एक अतिरिक्त इग्ज़ाम्पल काफ़ी दूर यहाँ दाईं तरफ़,

87
00:05:31,260 --> 00:05:34,300
यह इग्ज़ाम्पल वास्तव में हमें कोई नई जानकारी नहीं दे रहा है.

88
00:05:34,300 --> 00:05:37,050
मेरा मतलब है, कोई अप्रत्याशित / नई बात नहीं है लर्निंग अल्गोरिद्म के लिए.

89
00:05:37,050 --> 00:05:40,260
कि इग्ज़ाम्पल दूर वहाँ पर निकला मालिगनेंट.

90
00:05:40,260 --> 00:05:45,210
लेकिन किसी कारण से उस दूर वहाँ के इग्ज़ाम्पल ने बदल दिया लिनीअर रेग्रेशन की

91
00:05:45,210 --> 00:05:50,880
सीधी लाइन फ़िट डेटा को इस मजेंटा लाइन जो यहाँ है से

92
00:05:50,880 --> 00:05:55,670
इस नीली लाइन में यहाँ पर, और बना दिया है और भी ख़राब हायपॉथिसस.

93
00:05:56,900 --> 00:06:01,120
अत: अप्लाई करना लिनीअर रेग्रेशन एक क्लैसिफ़िकेशन प्रॉब्लम को

94
00:06:01,120 --> 00:06:04,470
अक्सर एक अच्छा विचार नहीं है.

95
00:06:04,470 --> 00:06:09,870
पहले उदाहरण में, मेरे इस अतिरिक्त ट्रेनिंग इग्ज़ाम्पल को लेने से पहले,

96
00:06:09,870 --> 00:06:14,760
पहले लिनीअर रेग्रेशन था सफल और उसने हमें दिया एक हायपॉथिसस

97
00:06:14,760 --> 00:06:19,940
जो सही थी उस ख़ास उदाहरण के लिए, लेकिन प्रायः अप्लाई करने पर

98
00:06:19,940 --> 00:06:24,760
लिनीअर रेग्रेशन एक डेटा सेट को, शायद आप सफल हो पाएँ, लेकिन अक्सर यह अच्छा विचार नहीं है.

99
00:06:24,760 --> 00:06:28,350
अत: मैं नहीं करूँगा लिनीअर रेग्रेशन एक क्लैसिफ़िकेशन प्रॉब्लम के लिए.

100
00:06:29,700 --> 00:06:33,830
यहाँ है एक और मज़ेदार चीज़ जो हो सकती है यदि हम करेंगे

101
00:06:33,830 --> 00:06:36,740
लिनीअर रेग्रेशन एक क्लैसिफ़िकेशन प्रॉब्लम के लिए.

102
00:06:36,740 --> 00:06:40,630
क्लैसिफ़िकेशन के लिए हम जानते हैं कि वाय या तो ज़ीरो है या एक.

103
00:06:40,630 --> 00:06:44,250
लेकिन अगर आप कर रहे हैं लिनीअर रेग्रेशन जहाँ हायपॉथिसस

104
00:06:44,250 --> 00:06:48,380
आउट्पुट कर सकती है वैल्यूज़ जो हैं बहुत बड़ी या बहुत छोटी ज़ीरो से,

105
00:06:48,380 --> 00:06:52,570
तब भी जब सारे आपके ट्रेनिंग इग्ज़ाम्पल्ज़ के लेबल्ज़ हैं ज़ीरो या एक.

106
00:06:53,920 --> 00:06:56,739
और यह थोड़ा विचित्र प्रतीत होता है कि यद्यपि हम

107
00:06:56,739 --> 00:07:00,786
जानते हैं कि लेबल्ज़ होने चाहिए ज़ीरो या एक, यह एक प्रकार से विचित्र है यदि

108
00:07:00,786 --> 00:07:05,661
अल्गोरिद्म आउट्पुट कर सकता है वैल्यूज़ जो हैं बहुत बड़ी या बहुत छोटी ज़ीरो से,

109
00:07:09,135 --> 00:07:13,795
तो आगे के कुछ विडीओज़ में हम डिवेलप करेंगे एक अल्गोरिद्म जिसे कहते हैं लजिस्टिक

110
00:07:13,795 --> 00:07:17,044
रिग्रेशन, जिसका गुण है कि आउट्पुट,

111
00:07:17,044 --> 00:07:21,635
प्रिडिक्शन लजिस्टिक रेग्रेशन का हमेशा ज़ीरो और एक के बीच होता है, और

112
00:07:21,635 --> 00:07:25,114
एक से बड़ा नहीं होता तथा ज़ीरो से छोटा नहीं होता.

113
00:07:26,250 --> 00:07:29,260
और वैसे तो, लजिस्टिक रेग्रेशन है, और

114
00:07:29,260 --> 00:07:33,370
हम इसे प्रयोग करेंगे एक क्लैसिफ़िकेशन अल्गोरिद्म की तरह, है थोड़ा,

115
00:07:33,370 --> 00:07:38,230
शायद कभी-कभी अस्पष्ट क्योंकि टर्म रेग्रेशन आती है इस नाम में

116
00:07:38,230 --> 00:07:42,150
जबकि लॉजिस्टिक रिग्रेशन है एक क्लैसिफ़िकेशन अल्गोरिद्म.

117
00:07:42,150 --> 00:07:44,720
लेकिन वह सिर्फ़ एक नाम है जो दिया गया था एतिहासिक कारणों से.

118
00:07:44,720 --> 00:07:49,210
अत: आप उससे कन्फ़्यूज़्ड / भ्रमित न हों लॉजिस्टिक रिग्रेशन वास्तव में है एक क्लैसिफ़िकेशन

119
00:07:49,210 --> 00:07:54,542
अल्गोरिद्म जो हम अप्लाई करते हैं सेटिंग्स में जहाँ लेबल वाय एक डिस्क्रीट वैल्यू है,

120
00:07:54,542 --> 00:07:56,610
जब यह या तो ज़ीरो है या एक.

121
00:07:56,610 --> 00:08:01,000
आशा है, इससे आपको अब समझ आया है कि यदि आपके पास एक क्लैसिफ़िकेशन प्रॉब्लम है,

122
00:08:01,000 --> 00:08:03,640
लिनीअर रेग्रेशन प्रयोग करना एक अच्छा विचार नहीं है.

123
00:08:03,640 --> 00:08:04,500
अगले वीडियो में,

124
00:08:04,500 --> 00:08:08,080
हम करेंगे विस्तृत रूप से लॉजिस्टिक रिग्रेशन अल्गोरिद्म पर बात.