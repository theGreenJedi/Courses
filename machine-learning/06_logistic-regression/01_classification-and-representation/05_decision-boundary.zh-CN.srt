1
00:00:00,133 --> 00:00:02,423
在过去的视频中 我们谈到

2
00:00:02,423 --> 00:00:06,653
逻辑回归中假设函数的表示方法

3
00:00:06,700 --> 00:00:07,963
现在 我想

4
00:00:07,963 --> 00:00:09,389
告诉大家一个叫做

5
00:00:09,389 --> 00:00:11,370
决策边界(decision boundary)的概念

6
00:00:11,380 --> 00:00:12,894
这个概念能更好地帮助我们

7
00:00:12,894 --> 00:00:15,017
理解逻辑回归的

8
00:00:15,030 --> 00:00:17,870
假设函数在计算什么

9
00:00:17,870 --> 00:00:20,080
让我们回忆一下

10
00:00:20,080 --> 00:00:21,264
这是我们上次写下的公式

11
00:00:21,280 --> 00:00:22,663
当时我们说

12
00:00:22,663 --> 00:00:24,916
假设函数可以表示为

13
00:00:24,930 --> 00:00:26,119
h(x)=g(θTx)

14
00:00:26,119 --> 00:00:28,363
其中函数g

15
00:00:28,363 --> 00:00:29,871
被称为S形函数（sigmoid function）

16
00:00:29,871 --> 00:00:32,729
看起来是应该是这样的形状

17
00:00:32,750 --> 00:00:35,131
它从零开始慢慢增加至1

18
00:00:35,131 --> 00:00:38,996
逐渐逼近1

19
00:00:38,996 --> 00:00:40,391
现在让我们

20
00:00:40,391 --> 00:00:42,452
更进一步来理解

21
00:00:42,452 --> 00:00:44,054
这个假设函数何时

22
00:00:44,070 --> 00:00:45,327
会将y预测为1

23
00:00:45,327 --> 00:00:47,049
什么时候又会将

24
00:00:47,049 --> 00:00:48,361
y预测为0

25
00:00:48,361 --> 00:00:50,602
让我们更好的理解

26
00:00:50,630 --> 00:00:52,351
假设函数的应该是怎样的

27
00:00:52,351 --> 00:00:56,622
特别是当我们的数据有多个特征时

28
00:00:56,640 --> 00:00:59,064
具体地说 这个假设函数

29
00:00:59,064 --> 00:01:00,827
输出的是

30
00:01:00,827 --> 00:01:02,057
给定x时

31
00:01:02,060 --> 00:01:05,493
y=1的概率

32
00:01:05,530 --> 00:01:06,807
因此 如果我们想

33
00:01:06,807 --> 00:01:08,181
预测y=1

34
00:01:08,181 --> 00:01:09,478
还是等于0

35
00:01:09,478 --> 00:01:12,217
我们可以这样做

36
00:01:12,240 --> 00:01:14,737
只要该假设函数

37
00:01:14,737 --> 00:01:16,412
输出y=1的概率

38
00:01:16,412 --> 00:01:17,570
大于或等于0.5

39
00:01:17,570 --> 00:01:19,340
那么这表示

40
00:01:19,350 --> 00:01:21,068
y更有可能

41
00:01:21,068 --> 00:01:22,295
等于1而不是0

42
00:01:22,295 --> 00:01:26,509
因此 我们预测y=1

43
00:01:26,509 --> 00:01:27,942
在另一种情况下 如果

44
00:01:27,960 --> 00:01:30,168
预测y=1

45
00:01:30,180 --> 00:01:31,898
的概率

46
00:01:31,898 --> 00:01:35,025
小于0.5 那么我们应该预测y=0

47
00:01:35,025 --> 00:01:36,277
在这里 我选择大于等于

48
00:01:36,277 --> 00:01:39,666
在这里我选择小于

49
00:01:39,670 --> 00:01:41,010
如果h(x)的值

50
00:01:41,010 --> 00:01:43,063
正好等于0.5 那么

51
00:01:43,063 --> 00:01:44,670
我们可以预测为1

52
00:01:44,670 --> 00:01:45,820
也可以预测为0

53
00:01:45,820 --> 00:01:47,464
但是这里我选择了大于等于

54
00:01:47,464 --> 00:01:49,220
因此我们默认

55
00:01:49,220 --> 00:01:51,459
如果h(x)等于0.5的话

56
00:01:51,459 --> 00:01:52,883
预测选择为1

57
00:01:52,883 --> 00:01:56,675
这只是一个细节 不用太在意

58
00:01:56,680 --> 00:01:58,136
下面 我希望大家能够

59
00:01:58,140 --> 00:01:59,273
清晰地理解

60
00:01:59,273 --> 00:02:01,187
什么时候h(x)

61
00:02:01,187 --> 00:02:02,927
将大于或等于

62
00:02:02,927 --> 00:02:04,666
0.5 从而

63
00:02:04,666 --> 00:02:09,111
我们最终预测y=1

64
00:02:09,530 --> 00:02:11,525
如果我们看看

65
00:02:11,540 --> 00:02:14,208
S形函数的曲线图 我们会注意到

66
00:02:14,208 --> 00:02:17,094
S函数

67
00:02:17,094 --> 00:02:18,981
只要z大于

68
00:02:18,981 --> 00:02:21,019
或等于0时

69
00:02:21,030 --> 00:02:24,296
g(z)就将大于

70
00:02:24,300 --> 00:02:25,994
或等于0.5

71
00:02:25,994 --> 00:02:28,163
因此 在曲线图的这半边

72
00:02:28,163 --> 00:02:29,963
g的取值

73
00:02:29,963 --> 00:02:32,522
大于或等于0.5

74
00:02:32,522 --> 00:02:34,482
因为这个交点就是0.5

75
00:02:34,482 --> 00:02:35,957
因此 当z大于0时

76
00:02:35,970 --> 00:02:38,352
g(z) 也就是这个

77
00:02:38,352 --> 00:02:41,959
S形函数 是大于或等于0.5的

78
00:02:41,959 --> 00:02:44,226
由于逻辑回归的

79
00:02:44,226 --> 00:02:46,428
假设函数h(x)

80
00:02:46,428 --> 00:02:48,525
等于g(θTx)

81
00:02:48,525 --> 00:02:50,964
因此

82
00:02:50,964 --> 00:02:52,163
函数值将会

83
00:02:52,180 --> 00:02:54,338
大于或等于0.5

84
00:02:54,338 --> 00:02:58,329
只要θ转置乘以x

85
00:02:58,340 --> 00:03:01,642
大于或等于0

86
00:03:01,642 --> 00:03:03,470
因此 我们看到

87
00:03:03,470 --> 00:03:05,835
因为这里θ转置x

88
00:03:05,835 --> 00:03:08,113
取代了z的位置

89
00:03:08,120 --> 00:03:09,543
所以我们看到

90
00:03:09,543 --> 00:03:11,077
我们的假设函数

91
00:03:11,077 --> 00:03:13,191
将会预测y=1

92
00:03:13,200 --> 00:03:15,420
只要θ转置乘以x

93
00:03:15,420 --> 00:03:17,924
大于或等于0

94
00:03:17,924 --> 00:03:20,016
现在让我们来考虑

95
00:03:20,016 --> 00:03:22,380
假设函数

96
00:03:22,380 --> 00:03:25,043
预测y=0的情况

97
00:03:25,043 --> 00:03:27,210
类似的

98
00:03:27,210 --> 00:03:28,987
h(θ)将会

99
00:03:28,987 --> 00:03:30,709
小于0.5 只要

100
00:03:30,730 --> 00:03:32,266
g(z)小于0.5

101
00:03:32,266 --> 00:03:34,711
这是因为

102
00:03:34,720 --> 00:03:36,468
z的定义域上

103
00:03:36,480 --> 00:03:38,013
导致g(z)取值

104
00:03:38,020 --> 00:03:42,626
小于0.5的部分 是z小于0的部分

105
00:03:42,626 --> 00:03:44,916
所以当g(z)小于0.5时

106
00:03:44,916 --> 00:03:46,874
我们的假设函数将会预测

107
00:03:46,874 --> 00:03:48,876
y=0

108
00:03:48,876 --> 00:03:50,540
根据与之前

109
00:03:50,540 --> 00:03:52,608
类似的原因

110
00:03:52,608 --> 00:03:54,293
h(x)等于

111
00:03:54,320 --> 00:03:56,932
g(θTx)

112
00:03:56,932 --> 00:03:58,739
因此 只要

113
00:03:58,739 --> 00:04:01,029
θ转置乘以x小于0

114
00:04:01,029 --> 00:04:04,937
我们就预测y等于0

115
00:04:04,940 --> 00:04:06,461
总结一下我们刚才所讲的

116
00:04:06,470 --> 00:04:08,377
我们看到

117
00:04:08,377 --> 00:04:09,900
如果我们要决定

118
00:04:09,900 --> 00:04:11,076
预测y=1

119
00:04:11,076 --> 00:04:12,396
还是y=0

120
00:04:12,400 --> 00:04:14,216
取决于

121
00:04:14,216 --> 00:04:15,807
y=1的概率

122
00:04:15,807 --> 00:04:17,845
大于或等于0.5

123
00:04:17,845 --> 00:04:19,602
还是小于0.5

124
00:04:19,602 --> 00:04:20,935
这其实就等于说

125
00:04:20,935 --> 00:04:22,920
我们将预测y=1

126
00:04:22,920 --> 00:04:25,010
只需要θ转置乘以x

127
00:04:25,010 --> 00:04:26,002
大于或等于0

128
00:04:26,002 --> 00:04:27,815
另一方面我们将预测y=0

129
00:04:27,815 --> 00:04:30,025
只需要θ转置乘以x

130
00:04:30,025 --> 00:04:32,953
小于0

131
00:04:32,953 --> 00:04:34,192
通过这些 我们能更好地

132
00:04:34,192 --> 00:04:36,890
理解如何利用逻辑回归的假设函数

133
00:04:36,890 --> 00:04:40,029
来进行预测

134
00:04:40,040 --> 00:04:41,535
现在假设我们有

135
00:04:41,535 --> 00:04:43,113
一个训练集

136
00:04:43,113 --> 00:04:45,165
就像幻灯片上的这个

137
00:04:45,165 --> 00:04:47,278
接下来我们假设我们的假设函数是

138
00:04:47,278 --> 00:04:48,678
h(x)等于g()

139
00:04:48,678 --> 00:04:50,254
括号里面是θ0加上θ1x1

140
00:04:50,260 --> 00:04:52,854
加上θ2乘以x2

141
00:04:52,854 --> 00:04:54,516
目前我们还没有谈到

142
00:04:54,516 --> 00:04:56,725
如何拟合此模型中的参数

143
00:04:56,725 --> 00:04:59,355
我们将在下一个视频中讨论这个问题

144
00:04:59,355 --> 00:05:01,770
但是假设我们

145
00:05:01,770 --> 00:05:03,575
已经拟合好了参数

146
00:05:03,575 --> 00:05:06,224
我们最终选择了如下值

147
00:05:06,224 --> 00:05:07,861
比方说 我们选择θ0

148
00:05:07,861 --> 00:05:09,750
等于-3 θ1

149
00:05:09,750 --> 00:05:13,553
等于1 θ2等于1

150
00:05:13,553 --> 00:05:15,430
因此 这意味着我的

151
00:05:15,430 --> 00:05:17,263
参数向量将是

152
00:05:17,263 --> 00:05:22,963
θ等于[-3 1 1]

153
00:05:24,140 --> 00:05:27,055
这样 我们有了

154
00:05:27,060 --> 00:05:30,115
这样的一个参数选择

155
00:05:30,115 --> 00:05:32,243
让我们试着找出

156
00:05:32,280 --> 00:05:33,778
假设函数何时将

157
00:05:33,778 --> 00:05:35,493
预测y等于1

158
00:05:35,493 --> 00:05:39,055
何时又将预测y等于0

159
00:05:39,060 --> 00:05:40,660
使用我们在

160
00:05:40,660 --> 00:05:42,900
在上一张幻灯片上展示的公式 我们知道

161
00:05:42,900 --> 00:05:44,539
y更有可能是1

162
00:05:44,539 --> 00:05:45,849
或者说

163
00:05:45,849 --> 00:05:47,404
y等于1的概率

164
00:05:47,404 --> 00:05:48,943
大于0.5

165
00:05:48,950 --> 00:05:51,553
或者大于等于0.5

166
00:05:51,570 --> 00:05:55,256
只要θ转置x

167
00:05:55,256 --> 00:05:57,211
大于0

168
00:05:57,230 --> 00:05:58,729
我刚刚加了下划线的

169
00:05:58,729 --> 00:06:00,846
这个公式

170
00:06:00,850 --> 00:06:03,033
-3加上x1再加上x2

171
00:06:03,033 --> 00:06:05,216
当然就是θ转置x

172
00:06:05,220 --> 00:06:07,014
这是当θ等于

173
00:06:07,014 --> 00:06:09,746
我们选择的这个参数值时

174
00:06:09,760 --> 00:06:12,516
θ转置乘以x的表达

175
00:06:12,516 --> 00:06:14,640
因此 举例来说

176
00:06:14,640 --> 00:06:16,426
对于任何样本

177
00:06:16,426 --> 00:06:19,300
只要x1和x2满足

178
00:06:19,300 --> 00:06:21,187
这个等式 也就是-3

179
00:06:21,187 --> 00:06:23,526
加上x1再加x2

180
00:06:23,530 --> 00:06:24,723
大于等于0

181
00:06:24,723 --> 00:06:27,028
我们的假设函数就会认为

182
00:06:27,028 --> 00:06:28,066
y等于1

183
00:06:28,066 --> 00:06:32,463
的可能性较大 或者说将预测y=1

184
00:06:32,463 --> 00:06:34,505
我们也可以

185
00:06:34,505 --> 00:06:35,752
将-3放到不等式右边

186
00:06:35,760 --> 00:06:37,703
并改写为x1

187
00:06:37,740 --> 00:06:41,435
加号x2大于等于3

188
00:06:41,435 --> 00:06:43,584
这样是等价的 我们发现

189
00:06:43,590 --> 00:06:45,826
这一假设函数将预测

190
00:06:45,826 --> 00:06:47,561
y=1 只要

191
00:06:47,561 --> 00:06:51,854
x1+x2大于等于3

192
00:06:51,870 --> 00:06:54,893
让我们来看看这在图上是什么意思

193
00:06:54,893 --> 00:06:57,209
如果我写下等式

194
00:06:57,209 --> 00:07:00,217
x1+x2等于3

195
00:07:00,230 --> 00:07:03,356
这将定义一条直线

196
00:07:03,360 --> 00:07:05,040
如果我画出这条直线

197
00:07:05,040 --> 00:07:07,695
它将表示为

198
00:07:07,730 --> 00:07:10,116
这样一条线 它通过

199
00:07:10,116 --> 00:07:11,627
通过x1轴上的3

200
00:07:11,627 --> 00:07:14,946
和x2轴上的3

201
00:07:15,886 --> 00:07:17,250
因此 这部分的输入样本空间

202
00:07:17,270 --> 00:07:18,827
这一部分的

203
00:07:18,827 --> 00:07:21,553
X1-X2平面

204
00:07:21,553 --> 00:07:24,948
对应x1加x2大于等于3

205
00:07:24,948 --> 00:07:27,195
这将是上面这个半平面

206
00:07:27,210 --> 00:07:29,442
也就是所有

207
00:07:29,442 --> 00:07:30,701
上方和所有右侧的部分

208
00:07:30,701 --> 00:07:34,109
相对我画的这条洋红色线来说

209
00:07:34,109 --> 00:07:35,584
所以

210
00:07:35,610 --> 00:07:37,135
我们的假设函数预测

211
00:07:37,135 --> 00:07:38,324
y等于1的区域

212
00:07:38,330 --> 00:07:40,023
就是这片区域

213
00:07:40,023 --> 00:07:41,586
是这个巨大的区域

214
00:07:41,620 --> 00:07:44,393
是右上方的这个半平面

215
00:07:44,393 --> 00:07:45,483
让我把它写下来

216
00:07:45,483 --> 00:07:47,395
我将称它为

217
00:07:47,395 --> 00:07:50,263
y=1区域

218
00:07:50,263 --> 00:07:54,293
与此相对

219
00:07:54,293 --> 00:07:56,500
x1加x2

220
00:07:56,510 --> 00:07:58,691
小于3的区域

221
00:07:58,691 --> 00:08:00,090
也就是我们预测

222
00:08:00,110 --> 00:08:01,988
y等于0的区域

223
00:08:01,988 --> 00:08:04,679
是这一片区域

224
00:08:04,710 --> 00:08:06,096
你看到 这也是一个半平面

225
00:08:06,096 --> 00:08:08,530
左侧的这个半平面

226
00:08:08,530 --> 00:08:11,736
是我们的假设函数预测y等于0的区域

227
00:08:11,740 --> 00:08:13,431
我想给这条线一个名字

228
00:08:13,431 --> 00:08:16,475
就是我刚刚画的这条洋红色线

229
00:08:16,475 --> 00:08:19,458
这条线被称为

230
00:08:19,458 --> 00:08:24,648
决策边界（decision boundary）

231
00:08:24,648 --> 00:08:27,085
具体地说 这条直线

232
00:08:27,085 --> 00:08:28,468
满足x1+x2=3

233
00:08:28,470 --> 00:08:31,170
它对应一系列的点

234
00:08:31,170 --> 00:08:33,334
它对应

235
00:08:33,334 --> 00:08:34,606
h(x)等于

236
00:08:34,606 --> 00:08:37,000
0.5的区域

237
00:08:37,000 --> 00:08:38,731
决策边界 也就是

238
00:08:38,750 --> 00:08:40,696
这条直线

239
00:08:40,720 --> 00:08:42,772
将整个平面分成了两部分

240
00:08:42,772 --> 00:08:44,659
其中一片区域假设函数预测y等于1

241
00:08:44,659 --> 00:08:46,433
而另一片区域

242
00:08:46,433 --> 00:08:49,773
假设函数预测y等于0

243
00:08:49,773 --> 00:08:51,387
我想澄清一下

244
00:08:51,390 --> 00:08:53,353
决策边界是

245
00:08:53,353 --> 00:08:57,458
假设函数的一个属性

246
00:08:57,458 --> 00:09:00,705
它包括参数θ0 θ1 θ2

247
00:09:00,720 --> 00:09:03,216
在这幅图中 我画了一个训练集

248
00:09:03,240 --> 00:09:06,455
我画了一组数据 让它更加可视化

249
00:09:06,480 --> 00:09:07,721
但是 即使我们

250
00:09:07,721 --> 00:09:09,276
去掉这个数据集

251
00:09:09,280 --> 00:09:11,076
这条决策边界

252
00:09:11,076 --> 00:09:12,299
和我们预测y等于1

253
00:09:12,300 --> 00:09:14,321
与y等于0的区域

254
00:09:14,321 --> 00:09:15,513
它们都是

255
00:09:15,513 --> 00:09:16,838
假设函数的属性

256
00:09:16,838 --> 00:09:18,804
决定于其参数

257
00:09:18,820 --> 00:09:22,163
它不是数据集的属性

258
00:09:22,163 --> 00:09:23,606
当然 我们后面还将讨论

259
00:09:23,606 --> 00:09:24,683
如何拟合参数

260
00:09:24,683 --> 00:09:26,736
那时 我们将

261
00:09:26,736 --> 00:09:28,222
使用训练集

262
00:09:28,222 --> 00:09:32,547
使用我们的数据 来确定参数的取值

263
00:09:32,563 --> 00:09:34,550
但是 一旦我们有确定的参数取值

264
00:09:34,550 --> 00:09:37,283
有确定的θ0 θ1 θ2

265
00:09:37,290 --> 00:09:39,645
我们就将完全确定

266
00:09:39,645 --> 00:09:41,721
决策边界

267
00:09:41,721 --> 00:09:43,117
这时 我们实际上并不需要

268
00:09:43,117 --> 00:09:44,886
在绘制决策边界的时候

269
00:09:44,886 --> 00:09:48,180
绘制训练集

270
00:09:49,620 --> 00:09:50,626
现在 让我们看一个

271
00:09:50,626 --> 00:09:52,398
更复杂的例子

272
00:09:52,420 --> 00:09:54,039
和往常一样 我使用十字 (X)

273
00:09:54,040 --> 00:09:55,932
表示我的正样本

274
00:09:55,932 --> 00:09:58,926
圆圈 (O) 的表示我的负样本

275
00:09:58,926 --> 00:10:00,696
给定这样的一个训练集

276
00:10:00,710 --> 00:10:02,873
我怎样才能使用逻辑回归

277
00:10:02,900 --> 00:10:05,550
拟合这些数据呢？

278
00:10:05,550 --> 00:10:07,168
早些时候 当我们谈论

279
00:10:07,168 --> 00:10:09,120
多项式回归

280
00:10:09,120 --> 00:10:10,993
或线性回归时

281
00:10:10,993 --> 00:10:12,530
我们谈到可以添加额外的

282
00:10:12,530 --> 00:10:15,561
高阶多项式项

283
00:10:15,561 --> 00:10:18,996
同样我们也可以对逻辑回归使用相同的方法

284
00:10:18,996 --> 00:10:22,220
具体地说 假如我的假设函数是这样的

285
00:10:22,220 --> 00:10:23,718
我已经添加了两个额外的特征

286
00:10:23,718 --> 00:10:27,691
x1平方和x2平方

287
00:10:27,691 --> 00:10:29,811
所以 我现在有5个参数

288
00:10:29,811 --> 00:10:32,676
θ0 到 θ4

289
00:10:32,676 --> 00:10:34,936
之前讲过 我们会

290
00:10:34,936 --> 00:10:37,398
在下一个视频中讨论

291
00:10:37,420 --> 00:10:39,289
如何自动选择

292
00:10:39,289 --> 00:10:42,511
参数θ0到θ4的取值

293
00:10:42,511 --> 00:10:44,326
但是 假设我

294
00:10:44,326 --> 00:10:46,691
已经使用了这个方法

295
00:10:46,691 --> 00:10:49,243
我最终选择θ0等于-1

296
00:10:49,243 --> 00:10:51,324
θ1等于0

297
00:10:51,324 --> 00:10:52,921
θ2等于0

298
00:10:52,921 --> 00:10:55,664
θ3等于1

299
00:10:55,664 --> 00:10:58,039
θ4等于1

300
00:10:58,039 --> 00:11:00,223
这意味着

301
00:11:00,223 --> 00:11:02,160
在这个参数选择下

302
00:11:02,160 --> 00:11:04,566
我的参数向量

303
00:11:04,566 --> 00:11:09,422
θ将是[-1 0 0 1 1]

304
00:11:10,550 --> 00:11:12,356
根据我们前面的讨论

305
00:11:12,356 --> 00:11:14,439
这意味着我的假设函数将预测

306
00:11:14,439 --> 00:11:16,407
y=1

307
00:11:16,407 --> 00:11:18,259
只要-1加x1平方

308
00:11:18,259 --> 00:11:21,088
加x2平方大于等于0

309
00:11:21,088 --> 00:11:24,184
也就是θ转置

310
00:11:24,184 --> 00:11:26,346
我的θ转置

311
00:11:26,350 --> 00:11:30,030
乘以特征变量大于等于0的时候

312
00:11:30,060 --> 00:11:31,685
如果我将

313
00:11:31,690 --> 00:11:32,950
-1放到不等式右侧

314
00:11:32,950 --> 00:11:34,810
我可以说

315
00:11:34,810 --> 00:11:36,642
我的假设函数将预测

316
00:11:36,642 --> 00:11:38,100
y=1

317
00:11:38,120 --> 00:11:40,710
只要x1平方加

318
00:11:40,710 --> 00:11:43,648
x2的平方大于等于1

319
00:11:43,648 --> 00:11:47,990
那么决策边界是什么样子的呢？

320
00:11:47,990 --> 00:11:49,767
好吧 如果我们绘制

321
00:11:49,780 --> 00:11:51,905
x1平方加

322
00:11:51,905 --> 00:11:53,665
x2的平方等于1的曲线

323
00:11:53,665 --> 00:11:55,531
你们有些人已经

324
00:11:55,531 --> 00:11:58,294
知道这个方程对应

325
00:11:58,294 --> 00:12:01,296
半径为1

326
00:12:01,296 --> 00:12:04,163
原点为中心的圆

327
00:12:04,163 --> 00:12:08,382
所以 这就是我们的决策边界

328
00:12:10,410 --> 00:12:12,190
圆外面的一切

329
00:12:12,250 --> 00:12:14,207
我将预测

330
00:12:14,207 --> 00:12:15,404
y=1

331
00:12:15,404 --> 00:12:17,706
所以这里就是

332
00:12:17,706 --> 00:12:19,337
y等于1的区域

333
00:12:19,360 --> 00:12:22,693
我们在这里预测y=1

334
00:12:22,693 --> 00:12:24,294
而在圆里面

335
00:12:24,310 --> 00:12:27,786
我会预测y=0

336
00:12:27,790 --> 00:12:30,060
因此 通过增加这些

337
00:12:30,060 --> 00:12:33,163
复杂的多项式特征变量

338
00:12:33,163 --> 00:12:35,040
我可以得到更复杂的决定边界

339
00:12:35,040 --> 00:12:36,550
而不只是

340
00:12:36,550 --> 00:12:39,560
用直线分开正负样本

341
00:12:39,560 --> 00:12:41,317
在这个例子中 我可以得到

342
00:12:41,317 --> 00:12:44,258
一个圆形的决策边界

343
00:12:44,258 --> 00:12:46,010
再次强调 决策边界

344
00:12:46,010 --> 00:12:47,888
不是训练集的属性

345
00:12:47,888 --> 00:12:51,636
而是假设本身及其参数的属性

346
00:12:51,640 --> 00:12:53,115
只要我们

347
00:12:53,115 --> 00:12:55,389
给定了参数向量θ

348
00:12:55,389 --> 00:12:57,185
圆形的决定边界

349
00:12:57,185 --> 00:12:59,208
就确定了

350
00:12:59,210 --> 00:13:03,052
我们不是用训练集来定义的决策边界

351
00:13:03,052 --> 00:13:06,563
我们用训练集来拟合参数θ

352
00:13:06,563 --> 00:13:08,632
以后我们将谈论如何做到这一点

353
00:13:08,632 --> 00:13:09,858
但是 一旦你有

354
00:13:09,858 --> 00:13:13,638
参数θ它就确定了决策边界

355
00:13:13,638 --> 00:13:16,388
让我重新显示训练集

356
00:13:16,400 --> 00:13:18,587
以方便可视化

357
00:13:18,587 --> 00:13:22,313
最后 让我们来看看一个更复杂的例子

358
00:13:22,320 --> 00:13:23,303
我们可以得到

359
00:13:23,303 --> 00:13:26,538
更复杂的决策边界吗？

360
00:13:26,538 --> 00:13:28,418
如果我有

361
00:13:28,420 --> 00:13:31,155
高阶多项式特征变量

362
00:13:31,155 --> 00:13:34,505
比如x1平方

363
00:13:34,505 --> 00:13:36,604
x1平方乘以x2 x1平方乘以x2平方

364
00:13:36,604 --> 00:13:37,826
等等

365
00:13:37,826 --> 00:13:39,001
如果我有更高阶

366
00:13:39,001 --> 00:13:41,574
多项式 那么可以证明

367
00:13:41,574 --> 00:13:42,856
你将得到

368
00:13:42,856 --> 00:13:45,268
更复杂的决策边界

369
00:13:45,268 --> 00:13:46,963
而逻辑回归

370
00:13:46,963 --> 00:13:48,480
可以用于找到决策边界

371
00:13:48,500 --> 00:13:50,093
例如

372
00:13:50,093 --> 00:13:52,085
这样一个椭圆

373
00:13:52,085 --> 00:13:53,503
或者参数不同的椭圆

374
00:13:53,503 --> 00:13:55,453
也许你

375
00:13:55,453 --> 00:13:57,834
可以得到一个不同的决定边界

376
00:13:57,840 --> 00:13:59,776
像这个样子

377
00:13:59,776 --> 00:14:04,145
一些有趣的形状

378
00:14:04,145 --> 00:14:06,423
或者更为复杂的例子

379
00:14:06,423 --> 00:14:08,915
你也可以得到决策边界

380
00:14:08,950 --> 00:14:10,381
看起来这样

381
00:14:10,390 --> 00:14:12,045
这样更复杂的形状

382
00:14:12,045 --> 00:14:13,365
在这个区域

383
00:14:13,365 --> 00:14:15,453
你预测y=1

384
00:14:15,453 --> 00:14:17,531
在这个区域外面你预测y=0

385
00:14:17,531 --> 00:14:19,556
因此 这些高阶多项式

386
00:14:19,560 --> 00:14:23,060
特征变量 可以让你得到非常复杂的决策边界

387
00:14:23,070 --> 00:14:24,786
因此 通过这些可视化图形

388
00:14:24,786 --> 00:14:26,163
我希望告诉你

389
00:14:26,163 --> 00:14:28,623
什么范围的假设函数

390
00:14:28,623 --> 00:14:30,676
我们可以使用

391
00:14:30,676 --> 00:14:34,966
逻辑回归来表示

392
00:14:34,966 --> 00:14:37,713
现在我们知道了h(x)表示什么

393
00:14:37,713 --> 00:14:39,004
在下一个视频中

394
00:14:39,004 --> 00:14:40,560
我将介绍

395
00:14:40,560 --> 00:14:44,096
如何自动选择参数θ

396
00:14:44,110 --> 00:14:45,570
使我们能在给定一个训练集时

397
00:14:45,570 --> 00:14:49,359
我们可以根据数据自动拟合参数 【教育无边界字幕组】翻译:h-bar 校对:王祖超 审核:所罗门捷列夫