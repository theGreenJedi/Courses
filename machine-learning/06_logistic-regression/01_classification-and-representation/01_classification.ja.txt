このビデオと続くいくつかのビデオでは、 分類(クラシフィケーション)の問題について 話していきます。 クラシフィケーションとは、 予測したい値yが離散的な値の時の話です。 ロジスティック回帰と呼ばれる アルゴリズムを開発していきます。 それはこんにち、機械学習の分野では、もっともポピュラーで もっとも広く使われているアルゴリズムの一つです。 これが分類問題の例です。 以前に、メールのスパム分類を 分類問題の例だと 言ったと思います。 他の例としては、オンラインの売買を分類する、などが考えられる。 たとえば物を売るwebサイトを 持っているとして、 実際の売買が 詐欺かどうかを知りたいとする。 例えば誰かが 盗まれたクレジットカードを使っているかどうか、 盗まれたパスワードを使っているかどうか。 それも分類問題です。 そして以前、腫瘍を ガンになりうる悪性の物か良性の腫瘍かの 分類の例も話しました。 これら全ての問題で、 我らが予想したい変数は 変数Yで、それは 2つの値のどちらかをとると 考えられる、 0か1か、とか、 スパムかスパムじゃないか、とか、 詐称か詐称でないかとか、悪性か良性かとか。 0で表しているクラス（分類）の もう一つの名前は、 陰性(ネガティブクラス)で、 1で表しているクラスのもう一つの呼び名は 陽性(ポジティブクラス)だ。 つまり0は 良性の腫瘍を表し、 1つまり陽性は、悪性の腫瘍を表すなど。 2つのクラスを割り振る、 スパムかスパムじゃないか などなど。 2つのクラス、陽性か陰性か 0か1か、に何を割り振るかは なんでも良くて、任意。 そこはどうでも良い。 でも良く、陰性は 何かが無い、 例えば悪性の腫瘍が無い、などの 不在っぽい感覚を伝える。 他方、陽性は 何かが存在してる感じを 語感として持つ、我らの探している何かの存在。 だが何が陰性で何が陽性かの 定義は任意で、 それはどうでも良い。 さて、まずは 0と1だけがあるケースの 分類問題から始めよう。 多数のクラスの問題、たとえばYが 0、1、2、3の値を とるようなケースは そのあとで扱おう。 これはマルチクラスの分類問題と呼ばれる。 だがここからの2、3のビデオでは 2つのクラスだけ、つまり バイナリ分類問題から始めよう。 そしてマルチクラスの話はその後に考えることとする。 では、どのように分類アルゴリズムを作るか？ ここにあるのは、 腫瘍を悪性か良性か分類する 分類タスクの トレーニングセットだ。 見ての通り、malignancy(悪性)の値は 2つの値だけをとる、つまり0またはNoか、 1またはYesか。 だからこれらのトレーニングセットが与えられた時 我らに出来る事としては、一つには 既に知ってるアルゴリズム、 線形回帰をこのデータセットに適用して 単に直線をこのデータにフィッティングさせる、という事が考えられる。 だからもし、このトレーニングセットをとり、 そこに直線をフィットさせると、 たぶんえられる仮説は このようになる。 オーライ。つまり以上が私の仮説だ。 h of xはθ transpose xに一致する もしも 予測をしたいなら ひとつ試してみるべきことは 分類器の閾値を0.5に設定することだ これが0.5の値の縦線だ そしてもし仮説が 0.5以上の値を出力すれば yは1だと予測される もし0.5未満であれば、yは0だと予測される こうやったときに何がおこるか見てみよう さて、0.5を持ってきてみよう それはまさに閾値のある所だ。 つまるところ、このように線形回帰を使うと、 この点より右にある全ての点は 結局ポジティブなクラスと 予測する事となる、 何故ならアウトプットの値は 縦軸上では 0.5より大きいから。 そしてその点より左の全ての点は 結局の所、 ネガティブ、と予測する事となる。 この特定の例の場合、 線形回帰は実際に リーズナブルと言えない事も無い事をしている、 興味を持ってる事が 分類問題であるとはいえども。 だが、ここでちょっとだけ問題を変更してみよう。 横軸をちょっと延長して もう一つ追加の トレーニングセットの例が 右側にあるとしよう。 追加のトレーニングの例は 見ての通り、ここある。 それは実際には何も違いは無い。でしょ？