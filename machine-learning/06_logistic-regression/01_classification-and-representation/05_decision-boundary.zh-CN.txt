在过去的视频中 我们谈到 逻辑回归中假设函数的表示方法 现在 我想 告诉大家一个叫做 决策边界(decision boundary)的概念 这个概念能更好地帮助我们 理解逻辑回归的 假设函数在计算什么 让我们回忆一下 这是我们上次写下的公式 当时我们说 假设函数可以表示为 h(x)=g(θTx) 其中函数g 被称为S形函数（sigmoid function） 看起来是应该是这样的形状 它从零开始慢慢增加至1 逐渐逼近1 现在让我们 更进一步来理解 这个假设函数何时 会将y预测为1 什么时候又会将 y预测为0 让我们更好的理解 假设函数的应该是怎样的 特别是当我们的数据有多个特征时 具体地说 这个假设函数 输出的是 给定x时 y=1的概率 因此 如果我们想 预测y=1 还是等于0 我们可以这样做 只要该假设函数 输出y=1的概率 大于或等于0.5 那么这表示 y更有可能 等于1而不是0 因此 我们预测y=1 在另一种情况下 如果 预测y=1 的概率 小于0.5 那么我们应该预测y=0 在这里 我选择大于等于 在这里我选择小于 如果h(x)的值 正好等于0.5 那么 我们可以预测为1 也可以预测为0 但是这里我选择了大于等于 因此我们默认 如果h(x)等于0.5的话 预测选择为1 这只是一个细节 不用太在意 下面 我希望大家能够 清晰地理解 什么时候h(x) 将大于或等于 0.5 从而 我们最终预测y=1 如果我们看看 S形函数的曲线图 我们会注意到 S函数 只要z大于 或等于0时 g(z)就将大于 或等于0.5 因此 在曲线图的这半边 g的取值 大于或等于0.5 因为这个交点就是0.5 因此 当z大于0时 g(z) 也就是这个 S形函数 是大于或等于0.5的 由于逻辑回归的 假设函数h(x) 等于g(θTx) 因此 函数值将会 大于或等于0.5 只要θ转置乘以x 大于或等于0 因此 我们看到 因为这里θ转置x 取代了z的位置 所以我们看到 我们的假设函数 将会预测y=1 只要θ转置乘以x 大于或等于0 现在让我们来考虑 假设函数 预测y=0的情况 类似的 h(θ)将会 小于0.5 只要 g(z)小于0.5 这是因为 z的定义域上 导致g(z)取值 小于0.5的部分 是z小于0的部分 所以当g(z)小于0.5时 我们的假设函数将会预测 y=0 根据与之前 类似的原因 h(x)等于 g(θTx) 因此 只要 θ转置乘以x小于0 我们就预测y等于0 总结一下我们刚才所讲的 我们看到 如果我们要决定 预测y=1 还是y=0 取决于 y=1的概率 大于或等于0.5 还是小于0.5 这其实就等于说 我们将预测y=1 只需要θ转置乘以x 大于或等于0 另一方面我们将预测y=0 只需要θ转置乘以x 小于0 通过这些 我们能更好地 理解如何利用逻辑回归的假设函数 来进行预测 现在假设我们有 一个训练集 就像幻灯片上的这个 接下来我们假设我们的假设函数是 h(x)等于g() 括号里面是θ0加上θ1x1 加上θ2乘以x2 目前我们还没有谈到 如何拟合此模型中的参数 我们将在下一个视频中讨论这个问题 但是假设我们 已经拟合好了参数 我们最终选择了如下值 比方说 我们选择θ0 等于-3 θ1 等于1 θ2等于1 因此 这意味着我的 参数向量将是 θ等于[-3 1 1] 这样 我们有了 这样的一个参数选择 让我们试着找出 假设函数何时将 预测y等于1 何时又将预测y等于0 使用我们在 在上一张幻灯片上展示的公式 我们知道 y更有可能是1 或者说 y等于1的概率 大于0.5 或者大于等于0.5 只要θ转置x 大于0 我刚刚加了下划线的 这个公式 -3加上x1再加上x2 当然就是θ转置x 这是当θ等于 我们选择的这个参数值时 θ转置乘以x的表达 因此 举例来说 对于任何样本 只要x1和x2满足 这个等式 也就是-3 加上x1再加x2 大于等于0 我们的假设函数就会认为 y等于1 的可能性较大 或者说将预测y=1 我们也可以 将-3放到不等式右边 并改写为x1 加号x2大于等于3 这样是等价的 我们发现 这一假设函数将预测 y=1 只要 x1+x2大于等于3 让我们来看看这在图上是什么意思 如果我写下等式 x1+x2等于3 这将定义一条直线 如果我画出这条直线 它将表示为 这样一条线 它通过 通过x1轴上的3 和x2轴上的3 因此 这部分的输入样本空间 这一部分的 X1-X2平面 对应x1加x2大于等于3 这将是上面这个半平面 也就是所有 上方和所有右侧的部分 相对我画的这条洋红色线来说 所以 我们的假设函数预测 y等于1的区域 就是这片区域 是这个巨大的区域 是右上方的这个半平面 让我把它写下来 我将称它为 y=1区域 与此相对 x1加x2 小于3的区域 也就是我们预测 y等于0的区域 是这一片区域 你看到 这也是一个半平面 左侧的这个半平面 是我们的假设函数预测y等于0的区域 我想给这条线一个名字 就是我刚刚画的这条洋红色线 这条线被称为 决策边界（decision boundary） 具体地说 这条直线 满足x1+x2=3 它对应一系列的点 它对应 h(x)等于 0.5的区域 决策边界 也就是 这条直线 将整个平面分成了两部分 其中一片区域假设函数预测y等于1 而另一片区域 假设函数预测y等于0 我想澄清一下 决策边界是 假设函数的一个属性 它包括参数θ0 θ1 θ2 在这幅图中 我画了一个训练集 我画了一组数据 让它更加可视化 但是 即使我们 去掉这个数据集 这条决策边界 和我们预测y等于1 与y等于0的区域 它们都是 假设函数的属性 决定于其参数 它不是数据集的属性 当然 我们后面还将讨论 如何拟合参数 那时 我们将 使用训练集 使用我们的数据 来确定参数的取值 但是 一旦我们有确定的参数取值 有确定的θ0 θ1 θ2 我们就将完全确定 决策边界 这时 我们实际上并不需要 在绘制决策边界的时候 绘制训练集 现在 让我们看一个 更复杂的例子 和往常一样 我使用十字 (X) 表示我的正样本 圆圈 (O) 的表示我的负样本 给定这样的一个训练集 我怎样才能使用逻辑回归 拟合这些数据呢？ 早些时候 当我们谈论 多项式回归 或线性回归时 我们谈到可以添加额外的 高阶多项式项 同样我们也可以对逻辑回归使用相同的方法 具体地说 假如我的假设函数是这样的 我已经添加了两个额外的特征 x1平方和x2平方 所以 我现在有5个参数 θ0 到 θ4 之前讲过 我们会 在下一个视频中讨论 如何自动选择 参数θ0到θ4的取值 但是 假设我 已经使用了这个方法 我最终选择θ0等于-1 θ1等于0 θ2等于0 θ3等于1 θ4等于1 这意味着 在这个参数选择下 我的参数向量 θ将是[-1 0 0 1 1] 根据我们前面的讨论 这意味着我的假设函数将预测 y=1 只要-1加x1平方 加x2平方大于等于0 也就是θ转置 我的θ转置 乘以特征变量大于等于0的时候 如果我将 -1放到不等式右侧 我可以说 我的假设函数将预测 y=1 只要x1平方加 x2的平方大于等于1 那么决策边界是什么样子的呢？ 好吧 如果我们绘制 x1平方加 x2的平方等于1的曲线 你们有些人已经 知道这个方程对应 半径为1 原点为中心的圆 所以 这就是我们的决策边界 圆外面的一切 我将预测 y=1 所以这里就是 y等于1的区域 我们在这里预测y=1 而在圆里面 我会预测y=0 因此 通过增加这些 复杂的多项式特征变量 我可以得到更复杂的决定边界 而不只是 用直线分开正负样本 在这个例子中 我可以得到 一个圆形的决策边界 再次强调 决策边界 不是训练集的属性 而是假设本身及其参数的属性 只要我们 给定了参数向量θ 圆形的决定边界 就确定了 我们不是用训练集来定义的决策边界 我们用训练集来拟合参数θ 以后我们将谈论如何做到这一点 但是 一旦你有 参数θ它就确定了决策边界 让我重新显示训练集 以方便可视化 最后 让我们来看看一个更复杂的例子 我们可以得到 更复杂的决策边界吗？ 如果我有 高阶多项式特征变量 比如x1平方 x1平方乘以x2 x1平方乘以x2平方 等等 如果我有更高阶 多项式 那么可以证明 你将得到 更复杂的决策边界 而逻辑回归 可以用于找到决策边界 例如 这样一个椭圆 或者参数不同的椭圆 也许你 可以得到一个不同的决定边界 像这个样子 一些有趣的形状 或者更为复杂的例子 你也可以得到决策边界 看起来这样 这样更复杂的形状 在这个区域 你预测y=1 在这个区域外面你预测y=0 因此 这些高阶多项式 特征变量 可以让你得到非常复杂的决策边界 因此 通过这些可视化图形 我希望告诉你 什么范围的假设函数 我们可以使用 逻辑回归来表示 现在我们知道了h(x)表示什么 在下一个视频中 我将介绍 如何自动选择参数θ 使我们能在给定一个训练集时 我们可以根据数据自动拟合参数 【教育无边界字幕组】翻译:h-bar 校对:王祖超 审核:所罗门捷列夫