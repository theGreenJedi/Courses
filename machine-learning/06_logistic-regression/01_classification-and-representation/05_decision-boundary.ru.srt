1
00:00:00,133 --> 00:00:02,423
В предыдущем видео мы обсудили общий вид гипотезы в

2
00:00:02,423 --> 00:00:06,653
задачах логической регрессии.

3
00:00:06,700 --> 00:00:07,963
Теперь я хочу рассказать о так называемой

4
00:00:07,963 --> 00:00:09,389
границе решений. Это поможет

5
00:00:09,389 --> 00:00:11,370
нам лучше понять,

6
00:00:11,380 --> 00:00:12,894
что вычисляет функция-гипотеза

7
00:00:12,894 --> 00:00:15,017
для логической

8
00:00:15,030 --> 00:00:17,870
регрессии.

9
00:00:17,870 --> 00:00:20,080
Вкратце

10
00:00:20,080 --> 00:00:21,264
напомню, к

11
00:00:21,280 --> 00:00:22,663
чему мы

12
00:00:22,663 --> 00:00:24,916
пришли в прошлый раз.

13
00:00:24,930 --> 00:00:26,119
Гипотеза h(x) равна g от произведения

14
00:00:26,119 --> 00:00:28,363
транспонированного вектора тета на x,

15
00:00:28,363 --> 00:00:29,871
где функция g — сигмоида — выглядит

16
00:00:29,871 --> 00:00:32,729
так:

17
00:00:32,750 --> 00:00:35,131
медленно растет от нуля и асимптотически

18
00:00:35,131 --> 00:00:38,996
приближается к единице.

19
00:00:38,996 --> 00:00:40,391
Давайте

20
00:00:40,391 --> 00:00:42,452
попробуем

21
00:00:42,452 --> 00:00:44,054
понять,

22
00:00:44,070 --> 00:00:45,327
когда такая гипотеза

23
00:00:45,327 --> 00:00:47,049
будет прогнозировать результат y,

24
00:00:47,049 --> 00:00:48,361
равный единице, а когда — нулю,

25
00:00:48,361 --> 00:00:50,602
и как выглядит эта функция,

26
00:00:50,630 --> 00:00:52,351
особенно в случае

27
00:00:52,351 --> 00:00:56,622
многих характеристик.

28
00:00:56,640 --> 00:00:59,064
Напомню, что значение

29
00:00:59,064 --> 00:01:00,827
гипотезы — это вероятность того,

30
00:01:00,827 --> 00:01:02,057
что y = 1 при заданных x и

31
00:01:02,060 --> 00:01:05,493
тета,

32
00:01:05,530 --> 00:01:06,807
так что если мы хотим получить

33
00:01:06,807 --> 00:01:08,181
предсказание «1» или

34
00:01:08,181 --> 00:01:09,478
предсказание «0», вот что

35
00:01:09,478 --> 00:01:12,217
можно сделать.

36
00:01:12,240 --> 00:01:14,737
Когда вычисленная

37
00:01:14,737 --> 00:01:16,412
гипотезой вероятность

38
00:01:16,412 --> 00:01:17,570
больше или равна 0,5,

39
00:01:17,570 --> 00:01:19,340
это значит, что y = 1

40
00:01:19,350 --> 00:01:21,068
более вероятно,

41
00:01:21,068 --> 00:01:22,295
чем y = 0, и мы

42
00:01:22,295 --> 00:01:26,509
предсказываем y = 1.

43
00:01:26,509 --> 00:01:27,942
Напротив, если

44
00:01:27,960 --> 00:01:30,168
прогнозируемая вероятность

45
00:01:30,180 --> 00:01:31,898
того, что y = 1,

46
00:01:31,898 --> 00:01:35,025
меньше 0,5, мы предсказываем y = 0.

47
00:01:35,025 --> 00:01:36,277
Я выбрал знак «больше или равно» здесь и

48
00:01:36,277 --> 00:01:39,666
знак «меньше» здесь.

49
00:01:39,670 --> 00:01:41,010
Если значение h(x) в

50
00:01:41,010 --> 00:01:43,063
точности равно 0,5, мы можем предсказать

51
00:01:43,063 --> 00:01:44,670
как положительный, так и

52
00:01:44,670 --> 00:01:45,820
отрицательный результат.

53
00:01:45,820 --> 00:01:47,464
Это не слишком существенно, и я

54
00:01:47,464 --> 00:01:49,220
просто решил, что буду

55
00:01:49,220 --> 00:01:51,459
предсказывать положительный результат

56
00:01:51,459 --> 00:01:52,883
при получении h(x) = 0,5.

57
00:01:52,883 --> 00:01:56,675
Это незначительная деталь.

58
00:01:56,680 --> 00:01:58,136
Теперь я хочу понять,

59
00:01:58,140 --> 00:01:59,273
когда именно h(x)

60
00:01:59,273 --> 00:02:01,187
больше или

61
00:02:01,187 --> 00:02:02,927
равняется 0,5, то есть в

62
00:02:02,927 --> 00:02:04,666
каком случае

63
00:02:04,666 --> 00:02:09,111
мы предскажем y = 1.

64
00:02:09,530 --> 00:02:11,525
По графику

65
00:02:11,540 --> 00:02:14,208
сигмоиды

66
00:02:14,208 --> 00:02:17,094
можно

67
00:02:17,094 --> 00:02:18,981
понять, что g(z)

68
00:02:18,981 --> 00:02:21,019
больше или равняется 0,5, если z

69
00:02:21,030 --> 00:02:24,296
больше или равняется

70
00:02:24,300 --> 00:02:25,994
нулю.

71
00:02:25,994 --> 00:02:28,163
То есть в этой половине

72
00:02:28,163 --> 00:02:29,963
графика g принимает значения

73
00:02:29,963 --> 00:02:32,522
от 0,5 и выше.

74
00:02:32,522 --> 00:02:34,482
Вот эта отметка — это 0,5.

75
00:02:34,482 --> 00:02:35,957
То есть при неотрицательных

76
00:02:35,970 --> 00:02:38,352
z сигмоида g(z) принимает

77
00:02:38,352 --> 00:02:41,959
значение 0,5 или больше.

78
00:02:41,959 --> 00:02:44,226
Гипотеза логистической

79
00:02:44,226 --> 00:02:46,428
регрессии, h(x)

80
00:02:46,428 --> 00:02:48,525
равна g от транспонированного тета на x.

81
00:02:48,525 --> 00:02:50,964
Это выражение будет больше или равно 0,5,

82
00:02:50,964 --> 00:02:52,163
если произведение транспонированного

83
00:02:52,180 --> 00:02:54,338
тета на x будет

84
00:02:54,338 --> 00:02:58,329
больше или

85
00:02:58,340 --> 00:03:01,642
равно нулю.

86
00:03:01,642 --> 00:03:03,470
Потому что

87
00:03:03,470 --> 00:03:05,835
здесь это

88
00:03:05,835 --> 00:03:08,113
произведение соответствует z.

89
00:03:08,120 --> 00:03:09,543
Итак, наша гипотеза будет

90
00:03:09,543 --> 00:03:11,077
предсказывать y = 1, когда произведение

91
00:03:11,077 --> 00:03:13,191
транспонированного вектора тета

92
00:03:13,200 --> 00:03:15,420
на x будет

93
00:03:15,420 --> 00:03:17,924
неотрицательным.

94
00:03:17,924 --> 00:03:20,016
Обратимся ко второму случаю,

95
00:03:20,016 --> 00:03:22,380
когда гипотеза

96
00:03:22,380 --> 00:03:25,043
предсказывает y = 0.

97
00:03:25,043 --> 00:03:27,210
Следуя тому же

98
00:03:27,210 --> 00:03:28,987
рассуждению, h(x) будет

99
00:03:28,987 --> 00:03:30,709
меньше 0,5, если g(z)

100
00:03:30,730 --> 00:03:32,266
меньше 0,5; а

101
00:03:32,266 --> 00:03:34,711
область значений z,

102
00:03:34,720 --> 00:03:36,468
при которых g(z)

103
00:03:36,480 --> 00:03:38,013
меньше 0,5 —

104
00:03:38,020 --> 00:03:42,626
отрицательные z.

105
00:03:42,626 --> 00:03:44,916
То есть, когда g(z) меньше 0,5,

106
00:03:44,916 --> 00:03:46,874
наша гипотеза будет

107
00:03:46,874 --> 00:03:48,876
предсказывать y = 0, и,

108
00:03:48,876 --> 00:03:50,540
снова повторяя рассуждение, h(x) это g от

109
00:03:50,540 --> 00:03:52,608
произведения транспонированного

110
00:03:52,608 --> 00:03:54,293
тета на x,

111
00:03:54,320 --> 00:03:56,932
значит, мы будем

112
00:03:56,932 --> 00:03:58,739
предсказывать y = 0, когда

113
00:03:58,739 --> 00:04:01,029
это произведение

114
00:04:01,029 --> 00:04:04,937
меньше нуля.

115
00:04:04,940 --> 00:04:06,461
Еще раз сформулирую

116
00:04:06,470 --> 00:04:08,377
результат наших выкладок.

117
00:04:08,377 --> 00:04:09,900
Мы предсказываем y = 1 или y = 0

118
00:04:09,900 --> 00:04:11,076
исходя из прогнозируемой

119
00:04:11,076 --> 00:04:12,396
вероятности: положительный

120
00:04:12,400 --> 00:04:14,216
ответ при вероятности

121
00:04:14,216 --> 00:04:15,807
больше или

122
00:04:15,807 --> 00:04:17,845
равной 0,5 и отрицательный

123
00:04:17,845 --> 00:04:19,602
в ином случае.

124
00:04:19,602 --> 00:04:20,935
Это эквивалентно

125
00:04:20,935 --> 00:04:22,920
тому, чтобы

126
00:04:22,920 --> 00:04:25,010
предсказывать y = 1, если

127
00:04:25,010 --> 00:04:26,002
произведение

128
00:04:26,002 --> 00:04:27,815
транспонированного вектора

129
00:04:27,815 --> 00:04:30,025
тета на вектор x

130
00:04:30,025 --> 00:04:32,953
больше или равно нулю, и y = 0, если оно меньше нуля.

131
00:04:32,953 --> 00:04:34,192
Попробуем теперь вникнуть

132
00:04:34,192 --> 00:04:36,890
в то, как гипотеза

133
00:04:36,890 --> 00:04:40,029
логистической регрессии выдает эти предсказания.

134
00:04:40,040 --> 00:04:41,535
Допустим, у нас есть

135
00:04:41,535 --> 00:04:43,113
обучающий набор, как

136
00:04:43,113 --> 00:04:45,165
на этом слайде, и

137
00:04:45,165 --> 00:04:47,278
наша гипотеза h(x)

138
00:04:47,278 --> 00:04:48,678
равна g от суммы:

139
00:04:48,678 --> 00:04:50,254
тета нулевое

140
00:04:50,260 --> 00:04:52,854
плюс тета первое на x1 плюс тета второе на x2.

141
00:04:52,854 --> 00:04:54,516
Мы пока не обсуждали,

142
00:04:54,516 --> 00:04:56,725
как подбирать параметры этой модели.

143
00:04:56,725 --> 00:04:59,355
Об этом речь пойдет в следующем видео.

144
00:04:59,355 --> 00:05:01,770
Пока предположим, что,

145
00:05:01,770 --> 00:05:03,575
применив еще не описанную

146
00:05:03,575 --> 00:05:06,224
процедуру, мы получили следующие значения параметров:

147
00:05:06,224 --> 00:05:07,861
тета нулевое равно, скажем,

148
00:05:07,861 --> 00:05:09,750
минус трем, тета

149
00:05:09,750 --> 00:05:13,553
первое и тета второе — единице.

150
00:05:13,553 --> 00:05:15,430
То есть вектор параметров

151
00:05:15,430 --> 00:05:17,263
тета будет

152
00:05:17,263 --> 00:05:22,963
равен [-3; 1; 1].

153
00:05:24,140 --> 00:05:27,055
Теперь, зная эти параметры

154
00:05:27,060 --> 00:05:30,115
гипотезы,

155
00:05:30,115 --> 00:05:32,243
давайте попробуем выяснить,

156
00:05:32,280 --> 00:05:33,778
где гипотеза

157
00:05:33,778 --> 00:05:35,493
будет предсказывать

158
00:05:35,493 --> 00:05:39,055
y = 1, а где — y = 0.

159
00:05:39,060 --> 00:05:40,660
По формулам с предыдущего

160
00:05:40,660 --> 00:05:42,900
слайда мы знаем,

161
00:05:42,900 --> 00:05:44,539
что y более вероятно

162
00:05:44,539 --> 00:05:45,849
равняется единице,

163
00:05:45,849 --> 00:05:47,404
то есть вероятность того,

164
00:05:47,404 --> 00:05:48,943
что y = 1,

165
00:05:48,950 --> 00:05:51,553
больше или равна 0,5,

166
00:05:51,570 --> 00:05:55,256
в случае, если произведение транспонированного

167
00:05:55,256 --> 00:05:57,211
тета на x больше или равно нулю.

168
00:05:57,230 --> 00:05:58,729
И вот это выражение,

169
00:05:58,729 --> 00:06:00,846
которое я подчеркнул, — минус

170
00:06:00,850 --> 00:06:03,033
три плюс x1 плюс x2 — собственно,

171
00:06:03,033 --> 00:06:05,216
и есть это произведение,

172
00:06:05,220 --> 00:06:07,014
при условии, что вектор

173
00:06:07,014 --> 00:06:09,746
тета равен

174
00:06:09,760 --> 00:06:12,516
параметрам, которые мы только что выбрали.

175
00:06:12,516 --> 00:06:14,640
То есть для

176
00:06:14,640 --> 00:06:16,426
любого

177
00:06:16,426 --> 00:06:19,300
примера, характеристики x1 и x2

178
00:06:19,300 --> 00:06:21,187
которого удовлетворяют

179
00:06:21,187 --> 00:06:23,526
этому

180
00:06:23,530 --> 00:06:24,723
неравенству: −3 + x1 + x2 ≥ 0,

181
00:06:24,723 --> 00:06:27,028
наша гипотеза будет считать

182
00:06:27,028 --> 00:06:28,066
более вероятным, что y = 1 и предскажет,

183
00:06:28,066 --> 00:06:32,463
что y = 1.

184
00:06:32,463 --> 00:06:34,505
Перенесем минус

185
00:06:34,505 --> 00:06:35,752
три в

186
00:06:35,760 --> 00:06:37,703
другую часть, и

187
00:06:37,740 --> 00:06:41,435
получим x1 + x2 ≥ 3.

188
00:06:41,435 --> 00:06:43,584
Соответственно, гипотеза

189
00:06:43,590 --> 00:06:45,826
предскажет,

190
00:06:45,826 --> 00:06:47,561
что y = 1, когда

191
00:06:47,561 --> 00:06:51,854
сумма x1 и x2 будет не меньше трех.

192
00:06:51,870 --> 00:06:54,893
Давайте посмотрим, что это означает, на графике.

193
00:06:54,893 --> 00:06:57,209
Если записать равенство,

194
00:06:57,209 --> 00:07:00,217
x1 + x2 = 3, оно

195
00:07:00,230 --> 00:07:03,356
определит прямую.

196
00:07:03,360 --> 00:07:05,040
Вот эта прямая, она

197
00:07:05,040 --> 00:07:07,695
проходит

198
00:07:07,730 --> 00:07:10,116
через точку 3

199
00:07:10,116 --> 00:07:11,627
на обеих осях,

200
00:07:11,627 --> 00:07:14,946
x1 и x2.

201
00:07:15,886 --> 00:07:17,250
И часть пространства

202
00:07:17,270 --> 00:07:18,827
характеристик,

203
00:07:18,827 --> 00:07:21,553
часть плоскости x1-x2, которая

204
00:07:21,553 --> 00:07:24,948
соответствует неравенству x1 + x2 ≥ 3,

205
00:07:24,948 --> 00:07:27,195
это верхняя ее часть:

206
00:07:27,210 --> 00:07:29,442
все, что выше, то есть

207
00:07:29,442 --> 00:07:30,701
выше и правее

208
00:07:30,701 --> 00:07:34,109
этой пурпурной прямой линии, которую я только что нарисовал.

209
00:07:34,109 --> 00:07:35,584
Таким образом, область значений характеристик,

210
00:07:35,610 --> 00:07:37,135
для которых наша гипотеза

211
00:07:37,135 --> 00:07:38,324
предскажет y = 1, это

212
00:07:38,330 --> 00:07:40,023
вся вот эта часть,

213
00:07:40,023 --> 00:07:41,586
вся полуплоскость вверху

214
00:07:41,620 --> 00:07:44,393
справа.

215
00:07:44,393 --> 00:07:45,483
Давайте я это запишу.

216
00:07:45,483 --> 00:07:47,395
Я обозначу это

217
00:07:47,395 --> 00:07:50,263
множество

218
00:07:50,263 --> 00:07:54,293
точек областью y = 1;

219
00:07:54,293 --> 00:07:56,500
вторая область значений,

220
00:07:56,510 --> 00:07:58,691
где сумма x1 и x2

221
00:07:58,691 --> 00:08:00,090
меньше трех,

222
00:08:00,110 --> 00:08:01,988
и мы будем предсказывать

223
00:08:01,988 --> 00:08:04,679
y = 0, —

224
00:08:04,710 --> 00:08:06,096
тоже полуплоскость.

225
00:08:06,096 --> 00:08:08,530
Вот эта область слева — область,

226
00:08:08,530 --> 00:08:11,736
где гипотеза предсказывает y = 0.

227
00:08:11,740 --> 00:08:13,431
Я хочу дать название

228
00:08:13,431 --> 00:08:16,475
пурпурной прямой, которую я нарисовал.

229
00:08:16,475 --> 00:08:19,458
Термин для этой линии —

230
00:08:19,458 --> 00:08:24,648
граница решений.

231
00:08:24,648 --> 00:08:27,085
Строго говоря, эта прямая,

232
00:08:27,085 --> 00:08:28,468
x1 + x2 = 3,

233
00:08:28,470 --> 00:08:31,170
соответствует множеству точек,

234
00:08:31,170 --> 00:08:33,334
где значение h(x) в точности

235
00:08:33,334 --> 00:08:34,606
равно 0,5.

236
00:08:34,606 --> 00:08:37,000
То есть граница решений — линия,

237
00:08:37,000 --> 00:08:38,731
разделяющая область,

238
00:08:38,750 --> 00:08:40,696
где гипотеза

239
00:08:40,720 --> 00:08:42,772
предсказывает y = 1,

240
00:08:42,772 --> 00:08:44,659
и область, где

241
00:08:44,659 --> 00:08:46,433
гипотеза

242
00:08:46,433 --> 00:08:49,773
предсказывает y = 0.

243
00:08:49,773 --> 00:08:51,387
Уточню для ясности:

244
00:08:51,390 --> 00:08:53,353
граница решений — свойство функции-гипотезы при

245
00:08:53,353 --> 00:08:57,458
заданных значениях

246
00:08:57,458 --> 00:09:00,705
параметров тета нулевое, тета первое и тета второе.

247
00:09:00,720 --> 00:09:03,216
Я нарисовал обучающий набор,

248
00:09:03,240 --> 00:09:06,455
некоторые обучающие данные, просто чтобы облегчить понимание графика.

249
00:09:06,480 --> 00:09:07,721
Даже если мы уберем

250
00:09:07,721 --> 00:09:09,276
данные, граница

251
00:09:09,280 --> 00:09:11,076
решений и области, где

252
00:09:11,076 --> 00:09:12,299
мы предсказываем

253
00:09:12,300 --> 00:09:14,321
y = 0 или y = 1, останутся,

254
00:09:14,321 --> 00:09:15,513
потому что они

255
00:09:15,513 --> 00:09:16,838
определяются гипотезой и

256
00:09:16,838 --> 00:09:18,804
ее параметрами и

257
00:09:18,820 --> 00:09:22,163
не зависят от обучающего набора.

258
00:09:22,163 --> 00:09:23,606
Позже мы поговорим о том,

259
00:09:23,606 --> 00:09:24,683
как определить

260
00:09:24,683 --> 00:09:26,736
подходящие параметры,

261
00:09:26,736 --> 00:09:28,222
и тогда,

262
00:09:28,222 --> 00:09:32,547
для вычисления значения параметров мы, конечно, будем использовать обучающие данные.

263
00:09:32,563 --> 00:09:34,550
Но если конкретные тета нулевое, тета первое и тета

264
00:09:34,550 --> 00:09:37,283
второе уже установлены,

265
00:09:37,290 --> 00:09:39,645
они однозначно определяют

266
00:09:39,645 --> 00:09:41,721
границу решений,

267
00:09:41,721 --> 00:09:43,117
и чтобы нарисовать ее на графике,

268
00:09:43,117 --> 00:09:44,886
обучающий набор

269
00:09:44,886 --> 00:09:48,180
нам не нужен.

270
00:09:49,620 --> 00:09:50,626
Рассмотрим более сложный

271
00:09:50,626 --> 00:09:52,398
набор данных.

272
00:09:52,420 --> 00:09:54,039
Как обычно, крестиками отмечены

273
00:09:54,040 --> 00:09:55,932
положительные примеры,

274
00:09:55,932 --> 00:09:58,926
а ноликами — отрицательные.

275
00:09:58,926 --> 00:10:00,696
Как логистическая

276
00:10:00,710 --> 00:10:02,873
регрессия может подобрать

277
00:10:02,900 --> 00:10:05,550
гипотезу к таким данным?

278
00:10:05,550 --> 00:10:07,168
Когда мы говорили о

279
00:10:07,168 --> 00:10:09,120
многомерной линейной

280
00:10:09,120 --> 00:10:10,993
регрессии, мы

281
00:10:10,993 --> 00:10:12,530
обсуждали добавление

282
00:10:12,530 --> 00:10:15,561
членов более высокого порядка к набору характеристик.

283
00:10:15,561 --> 00:10:18,996
То же самое можно сделать в задаче логистической регрессии.

284
00:10:18,996 --> 00:10:22,220
А именно, допустим, что моя гипотеза выглядит так:

285
00:10:22,220 --> 00:10:23,718
я добавил две характеристики,

286
00:10:23,718 --> 00:10:27,691
x1 в квадрате и x2 в квадрате.

287
00:10:27,691 --> 00:10:29,811
Таким образом, теперь у меня пять параметров, от тета нулевого

288
00:10:29,811 --> 00:10:32,676
до тета четвертого.

289
00:10:32,676 --> 00:10:34,936
Мы снова отложим до

290
00:10:34,936 --> 00:10:37,398
следующего видео вопрос о том,

291
00:10:37,420 --> 00:10:39,289
как алгоритмически

292
00:10:39,289 --> 00:10:42,511
выбрать значения параметров.

293
00:10:42,511 --> 00:10:44,326
Предположим,

294
00:10:44,326 --> 00:10:46,691
что при помощи

295
00:10:46,691 --> 00:10:49,243
некого алгоритма я уже

296
00:10:49,243 --> 00:10:51,324
определил, что тета

297
00:10:51,324 --> 00:10:52,921
нулевое равно −1, тета первое и тета

298
00:10:52,921 --> 00:10:55,664
второе равны нулю, а тета третье и тета

299
00:10:55,664 --> 00:10:58,039
четвертое — единице.

300
00:10:58,039 --> 00:11:00,223
То есть мой вектор

301
00:11:00,223 --> 00:11:02,160
параметров

302
00:11:02,160 --> 00:11:04,566
тета

303
00:11:04,566 --> 00:11:09,422
равен [−1; 0; 0; 1; 1].

304
00:11:10,550 --> 00:11:12,356
Согласно тем же

305
00:11:12,356 --> 00:11:14,439
рассуждениям, что и прежде,

306
00:11:14,439 --> 00:11:16,407
гипотеза будет предсказывать,

307
00:11:16,407 --> 00:11:18,259
что y = 1, если

308
00:11:18,259 --> 00:11:21,088
минус один плюс x1 в квадрате плюс x2 в квадрате будет больше или равно нулю.

309
00:11:21,088 --> 00:11:24,184
То есть когда произведение транспонированного

310
00:11:24,184 --> 00:11:26,346
вектора тета на x будет больше или

311
00:11:26,350 --> 00:11:30,030
равно нулю.

312
00:11:30,060 --> 00:11:31,685
Я перенесу −1 в правую часть

313
00:11:31,690 --> 00:11:32,950
и получу, что

314
00:11:32,950 --> 00:11:34,810
гипотеза предсказывает положительный

315
00:11:34,810 --> 00:11:36,642
результат,

316
00:11:36,642 --> 00:11:38,100
если сумма квадратов x1 и x2 больше

317
00:11:38,120 --> 00:11:40,710
или равна

318
00:11:40,710 --> 00:11:43,648
единице.

319
00:11:43,648 --> 00:11:47,990
Как же выглядит граница решений?

320
00:11:47,990 --> 00:11:49,767
Если мы захотим построить

321
00:11:49,780 --> 00:11:51,905
график кривой «x1 в

322
00:11:51,905 --> 00:11:53,665
квадрате плюс x2 в квадрате равно 1»,

323
00:11:53,665 --> 00:11:55,531
многие из вас узнают

324
00:11:55,531 --> 00:11:58,294
уравнение окружности единичного

325
00:11:58,294 --> 00:12:01,296
радиуса с центром в начале

326
00:12:01,296 --> 00:12:04,163
координат.

327
00:12:04,163 --> 00:12:08,382
Это и будет моя граница решений.

328
00:12:10,410 --> 00:12:12,190
Все, что находится вне этого

329
00:12:12,250 --> 00:12:14,207
круга, соответствует

330
00:12:14,207 --> 00:12:15,404
предсказанию y = 1.

331
00:12:15,404 --> 00:12:17,706
То есть здесь, снаружи, моя

332
00:12:17,706 --> 00:12:19,337
область y = 1.

333
00:12:19,360 --> 00:12:22,693
Для этих входных данных я буду предсказывать y = 1.

334
00:12:22,693 --> 00:12:24,294
А внутри окружности я

335
00:12:24,310 --> 00:12:27,786
буду предсказывать y = 0.

336
00:12:27,790 --> 00:12:30,060
Итак добавляя более сложные характеристики,

337
00:12:30,060 --> 00:12:33,163
характеристики более высокой степени,

338
00:12:33,163 --> 00:12:35,040
я могу отделять положительные и отрицательные

339
00:12:35,040 --> 00:12:36,550
результаты не только прямой линией, я могу получать и

340
00:12:36,550 --> 00:12:39,560
менее тривиальные границы решений,

341
00:12:39,560 --> 00:12:41,317
например, здесь граница

342
00:12:41,317 --> 00:12:44,258
решений — окружность.

343
00:12:44,258 --> 00:12:46,010
Повторюсь: граница решений не связана с обучающим

344
00:12:46,010 --> 00:12:47,888
набором, это свойство гипотезы и ее

345
00:12:47,888 --> 00:12:51,636
параметров.

346
00:12:51,640 --> 00:12:53,115
Как только мы получаем вектор параметров тета,

347
00:12:53,115 --> 00:12:55,389
мы можем определить

348
00:12:55,389 --> 00:12:57,185
границу решений,

349
00:12:57,185 --> 00:12:59,208
в нашем случае — окружность.

350
00:12:59,210 --> 00:13:03,052
Но обучающий набор не участвует в определении границы решений.

351
00:13:03,052 --> 00:13:06,563
Обучающий набор может использоваться для поиска подходящих параметров,

352
00:13:06,563 --> 00:13:08,632
позже мы разберемся, как это сделать,

353
00:13:08,632 --> 00:13:09,858
но если у вас уже есть вектор параметров тета, именно

354
00:13:09,858 --> 00:13:13,638
он задает границу решений.

355
00:13:13,638 --> 00:13:16,388
Я верну данные на график, чтобы

356
00:13:16,400 --> 00:13:18,587
он выглядел более понятно.

357
00:13:18,587 --> 00:13:22,313
Наконец, давайте рассмотрим еще более сложный пример.

358
00:13:22,320 --> 00:13:23,303
Можем ли мы получить еще

359
00:13:23,303 --> 00:13:26,538
более сложные границы решений, чем эта?

360
00:13:26,538 --> 00:13:28,418
Если использовать одночлены

361
00:13:28,420 --> 00:13:31,155
более высокой степени, к

362
00:13:31,155 --> 00:13:34,505
примеру, x1 в квадрате, x1 в

363
00:13:34,505 --> 00:13:36,604
квадрате на x2, x1 в квадрате на x2 в квадрате и

364
00:13:36,604 --> 00:13:37,826
так далее,

365
00:13:37,826 --> 00:13:39,001
возможно

366
00:13:39,001 --> 00:13:41,574
получить и

367
00:13:41,574 --> 00:13:42,856
более сложно устроенные

368
00:13:42,856 --> 00:13:45,268
границы решений. С помощью

369
00:13:45,268 --> 00:13:46,963
логистической регрессии можно

370
00:13:46,963 --> 00:13:48,480
получить

371
00:13:48,500 --> 00:13:50,093
границу решений в виде эллипса, а

372
00:13:50,093 --> 00:13:52,085
с каким-нибудь

373
00:13:52,085 --> 00:13:53,503
еще набором

374
00:13:53,503 --> 00:13:55,453
параметров может

375
00:13:55,453 --> 00:13:57,834
выйти граница решений

376
00:13:57,840 --> 00:13:59,776
какого-нибудь забавного вида,

377
00:13:59,776 --> 00:14:04,145
скажем, такого,

378
00:14:04,145 --> 00:14:06,423
а в особенно сложных случаях границы

379
00:14:06,423 --> 00:14:08,915
решений могут

380
00:14:08,950 --> 00:14:10,381
быть еще более замысловатой

381
00:14:10,390 --> 00:14:12,045
формы, например, такой.

382
00:14:12,045 --> 00:14:13,365
И все, что находится

383
00:14:13,365 --> 00:14:15,453
внутри, соответствует

384
00:14:15,453 --> 00:14:17,531
предсказанию y = 1, а все, что снаружи — y = 0.

385
00:14:17,531 --> 00:14:19,556
Многочленам высокой степени

386
00:14:19,560 --> 00:14:23,060
могут отвечать границы решений весьма сложной конфигурации.

387
00:14:23,070 --> 00:14:24,786
Итак, я надеюсь, что вы

388
00:14:24,786 --> 00:14:26,163
смогли наглядно представить

389
00:14:26,163 --> 00:14:28,623
себе, какими могут быть

390
00:14:28,623 --> 00:14:30,676
функции-гипотезы в модели

391
00:14:30,676 --> 00:14:34,966
логистической регресии.

392
00:14:34,966 --> 00:14:37,713
Теперь, понимая, как устроена h(x),

393
00:14:37,713 --> 00:14:39,004
в следующем видео мы поговорим

394
00:14:39,004 --> 00:14:40,560
о том, как автоматически подбирать значения

395
00:14:40,560 --> 00:14:44,096
параметров тета,

396
00:14:44,110 --> 00:14:45,570
как, основываясь на

397
00:14:45,570 --> 00:14:49,359
обучающих данных, алгоритмически получать подходящие параметры.