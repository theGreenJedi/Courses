1
00:00:00,210 --> 00:00:02,931
让我们开始谈谈逻辑回归

2
00:00:02,950 --> 00:00:04,315
在这段视频中

3
00:00:04,315 --> 00:00:07,210
我要给你展示假设函数的表达式

4
00:00:07,210 --> 00:00:08,805
也就是说

5
00:00:08,810 --> 00:00:10,266
在分类问题中

6
00:00:10,300 --> 00:00:15,446
要用什么样的函数来表示我们的假设

7
00:00:15,450 --> 00:00:16,969
此前我们说过

8
00:00:16,969 --> 00:00:20,426
希望我们的分类器

9
00:00:20,426 --> 00:00:21,956
的输出值在0和1之间

10
00:00:21,956 --> 00:00:23,250
因此 我们

11
00:00:23,270 --> 00:00:24,566
希望想出一个

12
00:00:24,566 --> 00:00:26,385
满足某个性质的假设函数

13
00:00:26,385 --> 00:00:30,396
这个性质是它的预测值要在0和1之间

14
00:00:30,396 --> 00:00:32,764
当我们使用线性回归的时候

15
00:00:32,764 --> 00:00:34,262
这是一种假设函数的形式

16
00:00:34,262 --> 00:00:35,604
其中 h(x) 等于

17
00:00:35,604 --> 00:00:38,319
θ 的转置乘以 x

18
00:00:38,330 --> 00:00:39,831
对于逻辑回归来说

19
00:00:39,831 --> 00:00:41,075
我要把这个稍微改一下

20
00:00:41,075 --> 00:00:43,352
把假设函数改成

21
00:00:43,360 --> 00:00:46,218
g(θ 的转置乘以 x)

22
00:00:46,218 --> 00:00:47,711
其中 我将定义

23
00:00:47,711 --> 00:00:50,693
函数g如下：

24
00:00:50,693 --> 00:00:51,926
当z是一个实数时

25
00:00:51,926 --> 00:00:53,633
g(z)=1/(1+e^(-z))

26
00:00:53,640 --> 00:00:55,640
g(z)=1/(1+e^(-z))

27
00:00:55,640 --> 00:00:58,480
g(z)=1/(1+e^(-z))

28
00:00:58,490 --> 00:01:01,716
这称为 S 型函数 (sigmoid function)

29
00:01:01,720 --> 00:01:04,843
或逻辑函数

30
00:01:04,843 --> 00:01:07,089
逻辑函数这个词

31
00:01:07,120 --> 00:01:11,103
就是逻辑回归名字的由来

32
00:01:11,103 --> 00:01:12,781
顺便说一下

33
00:01:12,781 --> 00:01:14,551
S型函数和逻辑函数

34
00:01:14,551 --> 00:01:16,996
基本上是同义词

35
00:01:16,996 --> 00:01:18,362
意思是一样的

36
00:01:18,362 --> 00:01:19,756
因此 这两个术语

37
00:01:19,756 --> 00:01:21,893
基本上是可互换的

38
00:01:21,893 --> 00:01:23,160
哪一个术语都可以

39
00:01:23,160 --> 00:01:24,620
用来表示这个函数 g

40
00:01:24,620 --> 00:01:26,283
如果我们

41
00:01:26,283 --> 00:01:27,734
把这两个方程

42
00:01:27,734 --> 00:01:30,089
合并到一起

43
00:01:30,089 --> 00:01:32,354
这是我的假设

44
00:01:32,354 --> 00:01:34,843
的另一种写法

45
00:01:34,843 --> 00:01:36,533
也就是说

46
00:01:36,540 --> 00:01:38,933
h(x)=1/(1+e^(-θ 转置乘以 x))

47
00:01:38,933 --> 00:01:41,765
h(x)=1/(1+e^(-θ 转置乘以 x))

48
00:01:41,765 --> 00:01:43,106
我所做的是

49
00:01:43,106 --> 00:01:45,353
把这个变量 z

50
00:01:45,353 --> 00:01:46,700
这里 z 是一个实数

51
00:01:46,760 --> 00:01:48,173
把 θ 的转置乘以 x

52
00:01:48,173 --> 00:01:50,201
代入到这里

53
00:01:50,201 --> 00:01:52,560
所以最后得到的是

54
00:01:52,560 --> 00:01:54,933
θ 转置乘以 x 代替了这里的 z

55
00:01:54,940 --> 00:01:57,949
最后 我们看一下S型函数是什么样的

56
00:01:57,949 --> 00:02:00,296
我们在这儿绘制这个图形

57
00:02:00,296 --> 00:02:02,022
S型函数 g(z)

58
00:02:02,022 --> 00:02:04,652
也称为逻辑函数 看起来是这样的

59
00:02:04,652 --> 00:02:07,078
它开始接近0

60
00:02:07,078 --> 00:02:09,366
然后上升 直到在原点处达到0.5

61
00:02:09,366 --> 00:02:13,473
然后它再次变平 像这样

62
00:02:13,500 --> 00:02:16,051
所以这就是S型函数的样子

63
00:02:16,051 --> 00:02:17,898
而且你注意S型函数

64
00:02:17,898 --> 00:02:19,725
而且你注意S型函数

65
00:02:19,740 --> 00:02:21,894
它渐近于1

66
00:02:21,894 --> 00:02:24,256
然后随着横坐标

67
00:02:24,256 --> 00:02:26,388
的反方向趋向于0

68
00:02:26,388 --> 00:02:27,659
随着 z 趋于负无穷

69
00:02:27,659 --> 00:02:29,304
随着 z 趋于负无穷

70
00:02:29,304 --> 00:02:31,396
g(z) 趋近于零

71
00:02:31,396 --> 00:02:33,816
随着 z 趋于正无穷

72
00:02:33,816 --> 00:02:35,864
g(z) 趋近于1

73
00:02:35,880 --> 00:02:37,252
因为 g(z) 的取值

74
00:02:37,252 --> 00:02:39,408
因为 g(z) 的取值

75
00:02:39,408 --> 00:02:41,696
在0和1之间

76
00:02:41,730 --> 00:02:44,592
我们就得到 h(x) 的值

77
00:02:44,610 --> 00:02:47,141
必在0和1之间

78
00:02:47,141 --> 00:02:50,029
最后 有了这个假设函数

79
00:02:50,040 --> 00:02:52,123
我们需要做的是

80
00:02:52,123 --> 00:02:53,740
和之前一样

81
00:02:53,740 --> 00:02:58,841
用参数θ拟合我们的数据

82
00:02:58,841 --> 00:03:00,490
所以拿到一个训练集

83
00:03:00,490 --> 00:03:01,743
我们需要给参数 θ 选定一个值

84
00:03:01,743 --> 00:03:03,773
我们需要给参数 θ 选定一个值

85
00:03:03,773 --> 00:03:06,981
然后用这个假设函数做出预测

86
00:03:06,981 --> 00:03:08,534
稍后我们将讨论一个

87
00:03:08,534 --> 00:03:11,828
用来拟合参数θ的学习算法

88
00:03:11,828 --> 00:03:13,506
但是首先让我们讨论

89
00:03:13,506 --> 00:03:17,379
一下这个模型的解释

90
00:03:17,640 --> 00:03:19,612
这就是我对

91
00:03:19,620 --> 00:03:21,660
假设函数 h(x) 的输出的解释

92
00:03:21,660 --> 00:03:23,637
假设函数 h(x) 的输出的解释

93
00:03:23,637 --> 00:03:26,387
当我的假设函数

94
00:03:26,400 --> 00:03:28,238
输出某个数

95
00:03:28,240 --> 00:03:30,126
我会认为这个数是

96
00:03:30,126 --> 00:03:33,400
对于新输入样本 x 的

97
00:03:33,400 --> 00:03:35,170
y 等于1的概率的估计值

98
00:03:35,170 --> 00:03:38,266
我的意思是这样的

99
00:03:38,266 --> 00:03:40,324
下面举个例子

100
00:03:40,324 --> 00:03:43,932
比方说 我们来看肿瘤分类的例子

101
00:03:43,932 --> 00:03:45,234
我们有一个特征向量 x

102
00:03:45,234 --> 00:03:47,945
和平时一样 x0 等于 1

103
00:03:47,945 --> 00:03:49,860
然后我们的特征变量 x1

104
00:03:49,860 --> 00:03:52,836
是肿瘤的大小

105
00:03:52,836 --> 00:03:54,045
假设我有一个病人来了

106
00:03:54,045 --> 00:03:55,459
而且知道肿瘤的大小

107
00:03:55,459 --> 00:03:57,183
而且知道肿瘤的大小

108
00:03:57,183 --> 00:03:58,759
把他们的特征向量 x

109
00:03:58,759 --> 00:04:00,963
代入我的假设函数

110
00:04:00,970 --> 00:04:03,760
假如假设函数的输出为0.7

111
00:04:03,760 --> 00:04:05,758
我将解释

112
00:04:05,758 --> 00:04:07,298
我的假设如下

113
00:04:07,298 --> 00:04:08,790
我要说 这个

114
00:04:08,790 --> 00:04:10,235
假设告诉我

115
00:04:10,235 --> 00:04:12,143
对于一个特征为 x 的患者

116
00:04:12,143 --> 00:04:14,490
对于一个特征为 x 的患者

117
00:04:14,520 --> 00:04:16,772
y 等于 1 的概率是0.7

118
00:04:16,772 --> 00:04:18,703
换句话说

119
00:04:18,720 --> 00:04:21,106
我要告诉我的病人

120
00:04:21,106 --> 00:04:23,320
非常遗憾

121
00:04:23,320 --> 00:04:27,836
肿瘤是恶性的可能性是70％或者说0.7

122
00:04:27,860 --> 00:04:29,420
要更加正式的写出来

123
00:04:29,420 --> 00:04:30,473
或者说写成数学表达式

124
00:04:30,480 --> 00:04:31,763
我的假设函数等于

125
00:04:31,763 --> 00:04:34,803
我的假设函数等于

126
00:04:34,820 --> 00:04:37,144
P(y=1|x;θ)

127
00:04:37,150 --> 00:04:39,913
P(y=1|x;θ)

128
00:04:39,913 --> 00:04:41,813
P(y=1|x;θ)

129
00:04:41,830 --> 00:04:43,389
对于熟悉概率的人

130
00:04:43,389 --> 00:04:45,320
应该能看懂这个式子

131
00:04:45,320 --> 00:04:46,766
如果你不太熟悉概率

132
00:04:46,766 --> 00:04:48,673
可以这么看这个表达式

133
00:04:48,673 --> 00:04:51,564
可以这么看这个表达式

134
00:04:51,580 --> 00:04:53,215
在给定 x 的条件下

135
00:04:53,215 --> 00:04:54,988
y=1 的概率

136
00:04:54,988 --> 00:04:56,493
给定的 x 就是我的病人的特征 x

137
00:04:56,493 --> 00:04:58,027
给定的 x 就是我的病人的特征 x

138
00:04:58,040 --> 00:04:59,860
特征 x 代表了

139
00:04:59,860 --> 00:05:01,575
我的病人特定的肿瘤大小

140
00:05:01,575 --> 00:05:03,156
这个概率的参数是 θ

141
00:05:03,156 --> 00:05:06,956
这个概率的参数是 θ

142
00:05:07,130 --> 00:05:09,166
所以 我基本上可以认为

143
00:05:09,166 --> 00:05:11,009
假设函数给出的估计

144
00:05:11,009 --> 00:05:13,332
是 y=1 的概率

145
00:05:13,332 --> 00:05:15,349
是 y=1 的概率

146
00:05:15,349 --> 00:05:16,523
现在 因为这是一个

147
00:05:16,523 --> 00:05:18,629
分类的任务 我们知道

148
00:05:18,640 --> 00:05:21,497
y 必须是0或1 对不对？

149
00:05:21,497 --> 00:05:23,373
它们是 y 可能取到的

150
00:05:23,390 --> 00:05:25,466
仅有的两个值

151
00:05:25,466 --> 00:05:26,654
无论是在训练集中

152
00:05:26,654 --> 00:05:28,077
或是对走进我的办公室

153
00:05:28,077 --> 00:05:32,014
或在未来进入医生办公室的新患者

154
00:05:32,014 --> 00:05:33,529
因此 有了 h(x)

155
00:05:33,550 --> 00:05:36,153
我们也可以计算

156
00:05:36,153 --> 00:05:39,116
y=0 的概率

157
00:05:39,116 --> 00:05:41,209
具体地说

158
00:05:41,250 --> 00:05:43,065
因为 y 必须是0或1

159
00:05:43,070 --> 00:05:45,141
我们知道

160
00:05:45,141 --> 00:05:46,329
y=0 的概率

161
00:05:46,329 --> 00:05:47,512
加上 y=1 的概率

162
00:05:47,550 --> 00:05:50,173
必须等于1

163
00:05:50,173 --> 00:05:51,483
这第一个方程看起来

164
00:05:51,483 --> 00:05:52,828
有点复杂

165
00:05:52,828 --> 00:05:54,603
基本上就是说

166
00:05:54,610 --> 00:05:56,287
给定参数 θ

167
00:05:56,320 --> 00:05:58,319
对某个特征为 x 的病人

168
00:05:58,360 --> 00:06:01,002
y=0 的概率

169
00:06:01,010 --> 00:06:02,305
和给定参数 θ 时

170
00:06:02,305 --> 00:06:04,470
对同一个特征为 x 的病人

171
00:06:04,471 --> 00:06:06,334
y=1 的概率相加

172
00:06:06,360 --> 00:06:08,260
必须等于1

173
00:06:08,260 --> 00:06:10,171
如果觉得这个方程看到起来有点儿复杂

174
00:06:10,200 --> 00:06:14,049
可以想象它没有 x 和 θ

175
00:06:14,049 --> 00:06:15,476
这就是说

176
00:06:15,480 --> 00:06:16,993
y=0 的概率

177
00:06:16,993 --> 00:06:19,272
加上 y=1 的概率必须等于1

178
00:06:19,280 --> 00:06:20,365
我们知道这是肯定的

179
00:06:20,365 --> 00:06:23,120
因为 y 要么是0 要么是1

180
00:06:23,120 --> 00:06:24,240
所以 y=0 的可能性

181
00:06:24,240 --> 00:06:25,918
和 y=1 的可能性

182
00:06:25,930 --> 00:06:29,547
它们俩相加肯定等于1

183
00:06:29,547 --> 00:06:31,387
所以 如果你只是

184
00:06:31,440 --> 00:06:33,780
把这一项

185
00:06:33,780 --> 00:06:35,409
移到右边

186
00:06:35,409 --> 00:06:37,327
你就会得到这个等式

187
00:06:37,327 --> 00:06:38,995
就是说 y=0 的概率

188
00:06:38,995 --> 00:06:40,502
等于1减去 y=1 的概率

189
00:06:40,530 --> 00:06:43,548
因此 我们的

190
00:06:43,560 --> 00:06:46,009
假设函数 h(x)

191
00:06:46,009 --> 00:06:47,775
给出的是这一项

192
00:06:47,790 --> 00:06:49,948
你可以简单地计算出这个概率

193
00:06:49,948 --> 00:06:51,508
你可以简单地计算出这个概率

194
00:06:51,510 --> 00:06:53,282
计算出 y=0 的概率的估计值

195
00:06:53,282 --> 00:06:55,411
计算出 y=0 的概率的估计值

196
00:06:55,411 --> 00:06:56,720
所以 你现在知道

197
00:06:56,720 --> 00:06:59,779
逻辑回归的假设函数的表达式是什么

198
00:06:59,790 --> 00:07:01,576
逻辑回归的假设函数的表达式是什么

199
00:07:01,580 --> 00:07:03,534
我们看到了定义逻辑回归的

200
00:07:03,534 --> 00:07:06,701
假设函数的数学公式

201
00:07:06,701 --> 00:07:07,880
在接下来的视频中

202
00:07:07,880 --> 00:07:09,018
我想试着让你

203
00:07:09,040 --> 00:07:11,091
对假设函数是什么样子

204
00:07:11,091 --> 00:07:12,518
有一个更直观的认识

205
00:07:12,518 --> 00:07:13,606
我想告诉你

206
00:07:13,620 --> 00:07:15,294
一个被称为判定边界 (decision) 的东西

207
00:07:15,294 --> 00:07:16,700
一个被称为判定边界 (decision) 的东西

208
00:07:16,700 --> 00:07:18,846
我们会一起看一些可视化的东西

209
00:07:18,846 --> 00:07:20,186
可以更好地理解

210
00:07:20,186 --> 00:07:22,370
逻辑回归的假设函数

211
00:07:22,370 --> 00:07:24,697
到底是什么样子 【教育无边界字幕组】翻译：追风的蜗牛 校对：竹二个 审核：所罗门捷列夫