ロジスティック回帰について話そう。 このビデオでは 仮説の表現を見ていく。 つまり、分類問題に対して どのような関数を 仮説の表現に使っていくか、という事。 以前、我らの望む分類器（classifier）は 0から1までの間の 結果の値を吐く物だと 言った。 だからこの性質を満たす 仮説が欲しい。 これらの予測は0から1の間になるような。 線形回帰を使うと、 仮説の形はこうなった。 h(x)は シータの転置にxを掛けた物。 ロジスティック回帰の場合は これをちょっと変更して、 仮説をgの シータ転置 x と する。ここでgは 以下のように 定義する。 g(z)は、 zを実数として、 = 1+eの-z乗 分の1。 これは sigmoid関数、または ロジスティック関数と呼ばれる。 そしてロジスティック関数という言葉が ロジスティック回帰の語源でもある。 ところで、sigmoid関数と ロジスティック関数という用語は どちらも基本的には略称で そして同じ物を意味する。 つまり2つの用語は 交換可能で、 どちらの用語でも この関数gを指すのに使える。 そして これら2つの等式をとり、 一つにくっつけると、 我らの仮説の形式の 別の書き方となる。 つまり、h(x)は 1足すeの-シータ転置のx 分の一。 自分が今やってみせたのは 変数zをとり、 zはここでは実数で、 そこにシータ転置のxを 代入した。 最終的には、シータ転置のxが、 zの場所に収まった。 最後に、sigmoid関数がどんな感じか見ておこう。 この図にプロットしてみる。 sigmoid関数gのzは、 ロジスティック関数とも呼ばれているが、それはこんなだ。 ゼロのそばから始まって、 進むに連れて上昇し、 原点で0.5となる。そしてふたたび平らになっていく。 以上がsigmoid関数がどんな感じか、だ。 気づいたと思うが sigmoid関数は 1に漸近していき、 0に漸近していく、 横軸のzに対して。 Zがマイナスの無限大に行くと gのzはゼロに 近づく。 そしてzが無限大に近づくと、 gのzは1へと近づく。 つまり、gのzは 0と1の間の値を 提供する。 hのxも 0と1の間になる。 最後にこの仮説の形式で、 我らが知る必要のある物は 前回同様、 我らのデータへのフィットのパラメータ、シータだ。 つまり、所与のトレーニングセットに対し、 パラメータであるシータの値を 選ばなくてはいけない。 そうしてはじめて、この仮説は予測に使えるようになる。 パラメータ シータのフィッティングのアルゴリズムは のちほど議論する。 だがその前に、このモデルの 解釈について少し議論しよう。 hのxの結果は、 こんな感じで 解釈する。 自分の仮説がなんらかの数を 出力したら、 その数字をyが1になる確率の 推計値として扱う、 その新規の入力の標本 xに対する。
ようするにこういう事だ。 例を示そう。 腫瘍を分類する例を使う。 特徴ベクトル X が あるとして、いつものように x1 を 腫瘍の大きさとする。 ある患者の 腫瘍の大きさが わかっているとして、 その特徴ベクトル X を 私の仮説に与え、 0.7 を得たとする。 この仮説を次のように 解釈する。 この仮説が 告げているのは 特徴 X を持った患者の Y=1 である確率は 0.7 だということだ。 言い換えれば その患者の腫瘍は 残念ながら 70%、0.7 の確率で悪性ということだ。 もう少し形式的に、 あるいは数学的に 書き出すと、 私の仮説の 出力を P(y=1) とし、 θ によってパラメータ化された X を与える。 確率に慣れた人なら、 この等式の意味がわかるだろう。 少し不慣れなら、 この式は このように読もう。 これはあるxの時に y が 1 に等しい確率だ。 つまりある患者に対して、という事だ。 その患者がフィーチャーxを持っている。 所与の患者が特定の 腫瘍のサイズだったとして、 ーーそれはフィーチャーxで表されるがーー この確率はシータでパラメトライズされてる。 ようするに、私は基本的には 仮説がy=1となる 確率の推計値を 与えてくれると思う訳だ。 ここで、 これは分類のタスクなので、 yは0か1のどちらかだと知っているのだ。 それら2つのみが、 yがとる事の出来る値なのだ。 それがトレーニングセットだろうと 私のオフィスや医者の所に将来やってきた 新たな患者に対してだろうと。 つまりhのxが与えられると yがゼロとなる確率も 計算出来る。 具体的には、yは 0か1のどちらかなのだから、 yがゼロとなる確率と yが一となる確率を足すと、 1にならなくてはならない事を 知っているのだ。 この等式はちょっと複雑に 見えるかもしれないが、 言ってる事は基本的には、 ある患者の、その患者のフィーチャーがxとして、 あるシータの時に、y=0である確率と その同じ患者が、同じフィーチャーの時、同じシータで y=1となる確率、との和は 合計したら必ず1となる、 と言ってるに過ぎない。 もしこの等式が ちょっと複雑に見えたら 心の目でxとシータ無しにしてしまっていいよ。 するとこれは単に y=0となる確率 足すことの y=1となる確率 は必ず1とならなくてはならない。 yは0か1のどちらかの値しか取らないのだから これが成立しないといけない。 つまりyが0となる場合 足すことの yが1となる場合は それら2つを足し合わせたら1に必ずなる。 だからこの項を 右辺へと移項すると すると結果は この式となり、 その意味する所は、y=0となる確率は 1引くことのy=1とる確率、という事。 従ってもし 我々の仮説 h(x) が この項を与えるなら 極めて簡単に確率、 つまり y=0 となる推定確率を 計算できる。 さて、ロジスティック回帰における 仮説の表現がわかって、 またどんな数式により ロジスティック回帰の仮説が 定義されるかを見ている。 次のビデオでは、 仮説の関数がどんな物かを より良い感覚が得られるように なりたいと思う。 そして決定境界と呼ばれる 物についても説明し、 ある種の可視化も一緒に行うことで、 このロジスティック回帰における仮説の関数が どんな物か より感覚的に分かるように 見ていこう。