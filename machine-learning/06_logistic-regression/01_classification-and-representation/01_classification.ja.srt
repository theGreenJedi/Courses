1
00:00:00,500 --> 00:00:04,650
このビデオと続くいくつかのビデオでは、

2
00:00:04,650 --> 00:00:09,510
分類(クラシフィケーション)の問題について

3
00:00:09,510 --> 00:00:12,651
話していきます。

4
00:00:12,651 --> 00:00:16,931
クラシフィケーションとは、

5
00:00:19,473 --> 00:00:23,270
予測したい値yが離散的な値の時の話です。

6
00:00:23,270 --> 00:00:26,530
ロジスティック回帰と呼ばれる

7
00:00:26,530 --> 00:00:29,390
アルゴリズムを開発していきます。

8
00:00:29,390 --> 00:00:33,110
それはこんにち、機械学習の分野では、もっともポピュラーで

9
00:00:33,110 --> 00:00:35,540
もっとも広く使われているアルゴリズムの一つです。

10
00:00:35,540 --> 00:00:39,390
これが分類問題の例です。

11
00:00:39,390 --> 00:00:44,590
以前に、メールのスパム分類を

12
00:00:44,590 --> 00:00:46,830
分類問題の例だと

13
00:00:46,830 --> 00:00:50,840
言ったと思います。

14
00:00:50,840 --> 00:00:53,960
他の例としては、オンラインの売買を分類する、などが考えられる。

15
00:00:55,120 --> 00:00:59,450
たとえば物を売るwebサイトを

16
00:00:59,450 --> 00:01:04,160
持っているとして、

17
00:01:04,160 --> 00:01:09,080
実際の売買が

18
00:01:10,500 --> 00:01:15,670
詐欺かどうかを知りたいとする。

19
00:01:15,670 --> 00:01:20,020
例えば誰かが

20
00:01:20,020 --> 00:01:23,930
盗まれたクレジットカードを使っているかどうか、

21
00:01:23,930 --> 00:01:27,110
盗まれたパスワードを使っているかどうか。

22
00:01:27,110 --> 00:01:31,370
それも分類問題です。

23
00:01:31,370 --> 00:01:35,120
そして以前、腫瘍を

24
00:01:35,120 --> 00:01:37,290
ガンになりうる悪性の物か良性の腫瘍かの

25
00:01:37,290 --> 00:01:42,220
分類の例も話しました。

26
00:01:42,220 --> 00:01:46,590
これら全ての問題で、

27
00:01:46,590 --> 00:01:51,460
我らが予想したい変数は

28
00:01:51,460 --> 00:01:55,170
変数Yで、それは

29
00:01:55,170 --> 00:01:58,790
2つの値のどちらかをとると

30
00:02:00,150 --> 00:02:03,080
考えられる、

31
00:02:03,080 --> 00:02:05,510
0か1か、とか、

32
00:02:05,510 --> 00:02:09,320
スパムかスパムじゃないか、とか、

33
00:02:09,320 --> 00:02:14,250
詐称か詐称でないかとか、悪性か良性かとか。

34
00:02:14,250 --> 00:02:17,720
0で表しているクラス（分類）の

35
00:02:17,720 --> 00:02:22,140
もう一つの名前は、

36
00:02:22,140 --> 00:02:25,978
陰性(ネガティブクラス)で、

37
00:02:25,978 --> 00:02:30,580
1で表しているクラスのもう一つの呼び名は

38
00:02:30,580 --> 00:02:34,770
陽性(ポジティブクラス)だ。

39
00:02:34,770 --> 00:02:37,410
つまり0は

40
00:02:37,410 --> 00:02:44,570
良性の腫瘍を表し、

41
00:02:44,570 --> 00:02:47,520
1つまり陽性は、悪性の腫瘍を表すなど。

42
00:02:47,520 --> 00:02:50,309
2つのクラスを割り振る、

43
00:02:51,410 --> 00:02:53,410
スパムかスパムじゃないか

44
00:02:53,410 --> 00:02:56,320
などなど。

45
00:02:56,320 --> 00:02:59,840
2つのクラス、陽性か陰性か

46
00:02:59,840 --> 00:03:03,730
0か1か、に何を割り振るかは

47
00:03:03,730 --> 00:03:05,695
なんでも良くて、任意。

48
00:03:05,695 --> 00:03:09,100
そこはどうでも良い。

49
00:03:09,100 --> 00:03:14,650
でも良く、陰性は

50
00:03:14,650 --> 00:03:19,165
何かが無い、

51
00:03:19,165 --> 00:03:23,985
例えば悪性の腫瘍が無い、などの

52
00:03:23,985 --> 00:03:27,235
不在っぽい感覚を伝える。

53
00:03:27,235 --> 00:03:29,955
他方、陽性は

54
00:03:29,955 --> 00:03:32,775
何かが存在してる感じを

55
00:03:32,775 --> 00:03:36,359
語感として持つ、我らの探している何かの存在。

56
00:03:36,359 --> 00:03:39,990
だが何が陰性で何が陽性かの

57
00:03:39,990 --> 00:03:43,520
定義は任意で、

58
00:03:43,520 --> 00:03:44,710
それはどうでも良い。

59
00:03:44,710 --> 00:03:50,360
さて、まずは

60
00:03:50,360 --> 00:03:54,629
0と1だけがあるケースの

61
00:03:55,720 --> 00:03:57,620
分類問題から始めよう。

62
00:03:57,620 --> 00:04:01,630
多数のクラスの問題、たとえばYが

63
00:04:01,630 --> 00:04:05,420
0、1、2、3の値を

64
00:04:05,420 --> 00:04:08,120
とるようなケースは

65
00:04:08,120 --> 00:04:11,530
そのあとで扱おう。

66
00:04:11,530 --> 00:04:15,263
これはマルチクラスの分類問題と呼ばれる。

67
00:04:15,263 --> 00:04:18,900
だがここからの2、3のビデオでは

68
00:04:18,900 --> 00:04:21,960
2つのクラスだけ、つまり

69
00:04:21,960 --> 00:04:26,200
バイナリ分類問題から始めよう。

70
00:04:26,200 --> 00:04:28,970
そしてマルチクラスの話はその後に考えることとする。

71
00:04:28,970 --> 00:04:31,010
では、どのように分類アルゴリズムを作るか？

72
00:04:31,010 --> 00:04:34,930
ここにあるのは、

73
00:04:34,930 --> 00:04:39,620
腫瘍を悪性か良性か分類する

74
00:04:39,620 --> 00:04:44,210
分類タスクの

75
00:04:44,210 --> 00:04:44,820
トレーニングセットだ。

76
00:04:46,200 --> 00:04:50,730
見ての通り、malignancy(悪性)の値は

77
00:04:50,730 --> 00:04:54,480
2つの値だけをとる、つまり0またはNoか、

78
00:04:54,480 --> 00:04:56,090
1またはYesか。

79
00:04:57,600 --> 00:05:02,890
だからこれらのトレーニングセットが与えられた時

80
00:05:02,890 --> 00:05:06,350
我らに出来る事としては、一つには

81
00:05:06,350 --> 00:05:09,750
既に知ってるアルゴリズム、

82
00:05:09,750 --> 00:05:12,070
線形回帰をこのデータセットに適用して

83
00:05:14,590 --> 00:05:18,820
単に直線をこのデータにフィッティングさせる、という事が考えられる。

84
00:05:18,820 --> 00:05:23,110
だからもし、このトレーニングセットをとり、

85
00:05:23,110 --> 00:05:28,090
そこに直線をフィットさせると、

86
00:05:28,090 --> 00:05:31,260
たぶんえられる仮説は

87
00:05:31,260 --> 00:05:34,300
このようになる。

88
00:05:34,300 --> 00:05:37,050
オーライ。つまり以上が私の仮説だ。

89
00:05:37,050 --> 00:05:40,260
h of xはθ transpose xに一致する

90
00:05:40,260 --> 00:05:45,210
もしも

91
00:05:45,210 --> 00:05:50,880
予測をしたいなら

92
00:05:50,880 --> 00:05:55,670
ひとつ試してみるべきことは

93
00:05:56,900 --> 00:06:01,120
分類器の閾値を0.5に設定することだ

94
00:06:01,120 --> 00:06:04,470
これが0.5の値の縦線だ

95
00:06:04,470 --> 00:06:09,870
そしてもし仮説が

96
00:06:09,870 --> 00:06:14,760
0.5以上の値を出力すれば

97
00:06:14,760 --> 00:06:19,940
yは1だと予測される

98
00:06:19,940 --> 00:06:24,760
もし0.5未満であれば、yは0だと予測される

99
00:06:24,760 --> 00:06:28,350
こうやったときに何がおこるか見てみよう

100
00:06:29,700 --> 00:06:33,830
さて、0.5を持ってきてみよう

101
00:06:33,830 --> 00:06:36,740
それはまさに閾値のある所だ。

102
00:06:36,740 --> 00:06:40,630
つまるところ、このように線形回帰を使うと、

103
00:06:40,630 --> 00:06:44,250
この点より右にある全ての点は

104
00:06:44,250 --> 00:06:48,380
結局ポジティブなクラスと

105
00:06:48,380 --> 00:06:52,570
予測する事となる、

106
00:06:53,920 --> 00:06:56,739
何故ならアウトプットの値は

107
00:06:56,739 --> 00:07:00,786
縦軸上では

108
00:07:00,786 --> 00:07:05,661
0.5より大きいから。

109
00:07:09,135 --> 00:07:13,795
そしてその点より左の全ての点は

110
00:07:13,795 --> 00:07:17,044
結局の所、

111
00:07:17,044 --> 00:07:21,635
ネガティブ、と予測する事となる。

112
00:07:21,635 --> 00:07:25,114
この特定の例の場合、

113
00:07:26,250 --> 00:07:29,260
線形回帰は実際に

114
00:07:29,260 --> 00:07:33,370
リーズナブルと言えない事も無い事をしている、

115
00:07:33,370 --> 00:07:38,230
興味を持ってる事が

116
00:07:38,230 --> 00:07:42,150
分類問題であるとはいえども。

117
00:07:42,150 --> 00:07:44,720
だが、ここでちょっとだけ問題を変更してみよう。

118
00:07:44,720 --> 00:07:49,210
横軸をちょっと延長して

119
00:07:49,210 --> 00:07:54,542
もう一つ追加の

120
00:07:54,542 --> 00:07:56,610
トレーニングセットの例が

121
00:07:56,610 --> 00:08:01,000
右側にあるとしよう。

122
00:08:01,000 --> 00:08:03,640
追加のトレーニングの例は

123
00:08:03,640 --> 00:08:04,500
見ての通り、ここある。

124
00:08:04,500 --> 00:08:08,080
それは実際には何も違いは無い。でしょ？