1
00:00:00,230 --> 00:00:03,000
로지스틱 회귀분석을 시작하면서

2
00:00:03,000 --> 00:00:07,010
여러분들에게 표현 모델을 보여주고 싶습니다.

3
00:00:07,010 --> 00:00:11,650
그것은, 우리가 분류문제를 가지고 있을 때에<br />우리의 가설을 표현하기 위해 사용할

4
00:00:11,650 --> 00:00:13,480
함수입니다.

5
00:00:15,460 --> 00:00:19,980
이전에, 우리는 분류문제의 결과값이 0에서 1 사이가 되도록

6
00:00:19,980 --> 00:00:22,940
한다고 말했습니다.

7
00:00:22,940 --> 00:00:27,310
그래서 우리는 이러한 결과값을 만족하는가설 즉,

8
00:00:27,310 --> 00:00:29,840
예측값이 0에서 1사이인 가설을 만들고 싶습니다.

9
00:00:29,840 --> 00:00:34,780
선형 회귀분석을 사용할 때에는, 이것이 가설 형식이었습니다.

10
00:00:34,780 --> 00:00:38,200
h(x)가 Θ의 전치행렬 * x입니다.

11
00:00:38,200 --> 00:00:42,965
로지스틱 회귀분석에서는, 전 이것을 조금 변경하여

12
00:00:42,965 --> 00:00:46,065
g(Θ의 전치행렬 * x)으로

13
00:00:46,065 --> 00:00:50,585
다음과 같은 g함수를 사용하여 변경합니다.

14
00:00:50,585 --> 00:00:56,830
G(z) 중, z는 실수이며, 1 더하기 -z 지수의 e 분의 1로 정합니다.

15
00:00:58,100 --> 00:01:03,093
이것은 시그모이드 함수 혹은 로지스틱 함수이며

16
00:01:03,093 --> 00:01:05,635
로지스틱 함수라는 용어는

17
00:01:05,635 --> 00:01:11,090
로지스틱 회귀분석이라는 이름의 만들었습니다.

18
00:01:11,090 --> 00:01:14,130
이 외에도, 시그모이드라는 용어나

19
00:01:14,130 --> 00:01:18,680
로지스틱 함수라는 용어는 기본적으로<br />동의어이며 같은 뜻을 의미합니다.

20
00:01:18,680 --> 00:01:21,640
그래서 두 용어는 상호간 변경이 가능하며, 그리고

21
00:01:21,640 --> 00:01:25,620
둘 다 함수 g를 나타낼 수 있습니다.

22
00:01:25,620 --> 00:01:29,460
그리고 만일 우리가 이 두 방정식을 합치면

23
00:01:29,460 --> 00:01:34,840
이것이 제 가설의 형태를 쓸 수 있는 다른 방법입니다.

24
00:01:34,840 --> 00:01:41,890
h(x)가 1 더하기 -Θ의 전치행렬 * x 지수의 e분의 1이며

25
00:01:41,890 --> 00:01:45,290
제가 한 것은 변수 z를 가져온 것 뿐입니다.

26
00:01:45,290 --> 00:01:49,970
z는 실수이며, Θ의 전치행렬 * x와 연결됩니다.

27
00:01:49,970 --> 00:01:55,000
그로므로, 전 z의 위치에 Θ의 전치행렬 * x를 위치하고 끝냅니다.

28
00:01:55,000 --> 00:01:57,960
마침내, 여러분들에게 시그모이드 함수를 보여드리겠습니다.

29
00:01:57,960 --> 00:02:00,300
우리는 이것을 여기에 이렇게 그립니다.

30
00:02:00,300 --> 00:02:04,700
시그모이드 함수이자, g(z), 로지스틱 함수는 이렇게 생겼습니다.

31
00:02:04,700 --> 00:02:09,580
0 근처에서 시작하여, 원점위의 0.5를 지날 때까지 오릅니다.

32
00:02:09,580 --> 00:02:13,540
그 후 이렇게 납작해집니다.

33
00:02:13,540 --> 00:02:16,020
그 결과 시그모이드 함수는 이렇게 생겼습니다.

34
00:02:16,020 --> 00:02:21,427
여러분들께서도 아실 수 있다시피, 시그모이드 함수는 1과

35
00:02:21,427 --> 00:02:26,980
0에 수렴하며, z값의 수평축을 기준으로

36
00:02:26,980 --> 00:02:30,940
z가 음의 무한대로 향하면, g(z)는 0로 수렴합니다.

37
00:02:30,940 --> 00:02:35,670
그리고 z가 무한대로 갈수록, g(Z)는 1에 수렴합니다.

38
00:02:35,670 --> 00:02:40,830
그래서 g(z)는 0과 1사이의 양의 값을 가지며,

39
00:02:40,830 --> 00:02:47,170
우리는 h(x)또한 0과 1사이임을 알 수 있습니다.

40
00:02:47,170 --> 00:02:52,930
마침내, 이러한 가설 모형을 통해서, 우리가 할 것은

41
00:02:52,930 --> 00:02:59,160
이전처럼 파라미터들을 우리의 데이터에 맞추는 것입니다.

42
00:02:59,160 --> 00:03:01,760
주어진 훈련 예시들로부터, 우리는 매개변수Θ의 값을 정하고

43
00:03:01,760 --> 00:03:07,030
이 가설들을 통해 우리는 예측을 할 수 있습니다.

44
00:03:07,030 --> 00:03:11,830
우리는 매개변수Θ를 맞추는 학습<br />알고리즘에 대해 나중에 이야기하겠습니다.

45
00:03:11,830 --> 00:03:16,100
먼저 이 모델의 해석에 대해 이야기해보죠.

46
00:03:18,630 --> 00:03:23,905
제 가설 h(x)의 결과값에 대해 해석해보겠습니다.

47
00:03:25,060 --> 00:03:30,060
제 가설의 결과들이 몇개의 수일 때에, 전 그 숫자들을

48
00:03:30,060 --> 00:03:38,050
추가로 추입된 x에서 y가 1일 수 있는 가능성으로 여길 것입니다.

49
00:03:38,050 --> 00:03:40,360
말하자면 이러한 예시와 같습니다.

50
00:03:40,360 --> 00:03:44,190
우리가 종양 분류 예시를 사용한다고 해보죠.

51
00:03:44,190 --> 00:03:48,920
우리들은 특징들인 x벡터들이 있고, x 밑첨자 0은 언제나 그렇듯 1입니다.

52
00:03:48,920 --> 00:03:51,860
그리고 하나의 특징은 종양의 크기입니다.

53
00:03:52,890 --> 00:03:57,063
특정 크기의 종양을 가진 환자들이 추가되었다고 가정하고,

54
00:03:57,063 --> 00:04:00,394
전 그들의 특징 벡터인 x를 제 가설에 추가합니다.

55
00:04:00,394 --> 00:04:03,920
그리고 제 가설의 결과값은 0.7이 나왔습니다.

56
00:04:03,920 --> 00:04:07,340
저는 제 가설을 다음과 같이 해석할 것입니다.

57
00:04:07,340 --> 00:04:11,150
전 가설이 말해주는 것은

58
00:04:11,150 --> 00:04:17,820
특징 x를 가진 환자 사례에서, y가 1일 확률은 0.7이라는 것입니다.

59
00:04:17,820 --> 00:04:21,800
다르게 말하면, 전 제 환자에게 말하기를

60
00:04:21,800 --> 00:04:26,710
비극적이게도, 악성 종양일 확률이 70%라는 것입니다.

61
00:04:26,710 --> 00:04:32,246
이것을 조금 더 잘 짜여지고, 수학적으로 도출하기 위해

62
00:04:32,246 --> 00:04:36,140
전 제 가설의 결과값을

63
00:04:36,140 --> 00:04:41,860
Θ에서 정해진 변수 x에서 y=1일 가능성으로 해석합니다.

64
00:04:41,860 --> 00:04:46,310
여러분들 중에 확률과 친숙하신 분들은<br />이러한 방정식이 이해가 되실 것입니다.

65
00:04:46,310 --> 00:04:49,040
만일 확률과 친숙하지 않은 분들을 위해

66
00:04:49,040 --> 00:04:51,390
이것이 제가 이 표현을 읽는 방식입니다.

67
00:04:51,390 --> 00:04:54,069
이것이 y가 1일 가능성이며

68
00:04:54,069 --> 00:04:57,515
주어진 x, 즉 제 환자가 특징x를 가지고 있을 때에

69
00:04:57,515 --> 00:05:02,698
다시 말하자면 제 환자가 제 특징들인 x로 나타내지는 특정 종양 크기를 가질 때에

70
00:05:02,698 --> 00:05:07,180
이것이 Θ에 매개된 가능성입니다.

71
00:05:07,180 --> 00:05:11,250
그래서 전 기본적으로 제 가설을 저에게

72
00:05:11,250 --> 00:05:15,070
y가 1일 가능성의 측정값을 준다고 여깁니다.

73
00:05:15,070 --> 00:05:18,130
이제, 이것은 분류 문제이기에

74
00:05:18,130 --> 00:05:21,790
우리는 y가 0 혹은 1일 것이라는 걸 알고 있습니다. 그렇죠?

75
00:05:21,790 --> 00:05:25,350
그 2개의 값들은 y가 가질 수 있는 유일한 값들입니다.

76
00:05:25,350 --> 00:05:29,490
훈련 예시들이건, 제 가상 병원으로 걸어 들어오는

77
00:05:29,490 --> 00:05:31,078
새로운 환자이건 말이죠.

78
00:05:31,078 --> 00:05:36,440
주어진 h(x)에서 우리는 y가 0의 값을 가지는 가능성도

79
00:05:36,440 --> 00:05:42,300
계산할 수 있습니다. 왜냐하면 y는 0이거나 1이기 때문입니다.

80
00:05:42,300 --> 00:05:50,280
우리는 y가 0인 가능성과 y가 1인 가능성을 합하면 1이여야 하는 것을 압니다.

81
00:05:50,280 --> 00:05:52,680
이 첫번째 방정식은 조금 더 복잡해 보일 수 있습니다.

82
00:05:52,680 --> 00:05:55,740
이것은 기본적으로 특징 x와 정해진<br />매개변수Θ를 가진 특정한 환자의 경우에서

83
00:05:55,740 --> 00:05:59,700
y가 0일 가능성입니다.

84
00:06:00,750 --> 00:06:04,190
이에 특징 x와 정해진 매개변수를 가지는 같은 환자의 경우에서

85
00:06:04,190 --> 00:06:07,510
y가 1일 확률을 더하면 1이 될 것입니다.

86
00:06:07,510 --> 00:06:09,800
만일 이러한 방정식이 조금 복잡하다면

87
00:06:09,800 --> 00:06:14,300
x와 Θ를 제외하고,

88
00:06:14,300 --> 00:06:17,460
이것이 그냥 y가 0일 확률과 1일 확률을 더한 것이라고

89
00:06:17,460 --> 00:06:19,560
생각하셔도 됩니다.

90
00:06:19,560 --> 00:06:23,480
그리고 우리는 y가 0이거나 1인 것을 알기에 참인 것을 알며,

91
00:06:23,480 --> 00:06:27,260
y가 0일 확률과 1일 확률들은

92
00:06:27,260 --> 00:06:29,560
합이 반드시 1이 됩니다.

93
00:06:29,560 --> 00:06:33,670
그리고 만일 여러분이 이 변수를

94
00:06:33,670 --> 00:06:37,340
오른쪽으로 옮기면, 여러분들은 이 방정식을 끝낼 수 있습니다.

95
00:06:37,340 --> 00:06:41,730
이것은 y가 0일 가능성은 1 빼기 y가 1일 가능성과 같다는 것을 나타냅니다.

96
00:06:41,730 --> 00:06:47,480
그러므로 만일 x에 대한 가설의 그 값(y=1일 가능성)이 주어진다면

97
00:06:47,480 --> 00:06:50,950
여러분들은 매우 쉽게 y=0일

98
00:06:50,950 --> 00:06:55,370
가능성이나 측정 예측값을 계산할 수 있습니다.

99
00:06:55,370 --> 00:06:59,262
이제 여러분들은 로지스틱 회귀분석의 가설 모형이

100
00:06:59,262 --> 00:07:03,570
어떤 건지 알게되었고, 또한 수학적인 공식을 살펴보았으며,

101
00:07:03,570 --> 00:07:06,670
로지스틱 회귀분석의 가설을 정의해봤습니다.

102
00:07:06,670 --> 00:07:10,150
다음 강의에서는, 여러분들이 가설 함수의 모습에 대해

103
00:07:10,150 --> 00:07:12,840
더 나은 직관을 가지도록 하고 싶습니다.

104
00:07:12,840 --> 00:07:16,220
그리고 여러분들에게 결정 경계(decision boundary)라는 것에 대해 말하고

105
00:07:16,220 --> 00:07:20,340
시각화된 것들을 살펴 봄으로써, 로지스틱 회귀분석의 가설 함수가

106
00:07:20,340 --> 00:07:23,900
어떻게 생겼는가에 대해 더 살펴보겠습니다.