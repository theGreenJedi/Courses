このビデオでは、 二番目の種類の 教師なし学習の問題である、 次元削減について始めたいと思う。 次元を削減したい、と思う 幾つかの異なる理由が 存在する。 一つはデータを圧縮したい時、 そして後で見るように、2, 3後のビデオで見るように、 データ圧縮はデータを圧縮して より少ない メモリやディスク容量を 占有するように なるだけでなく、 また学習アルゴリズムのスピードアップにもなる。 だがまずは、次元削減とは何かを 話す事から始めよう。 動機を理解する例として、 たくさん、たくさん、たーくさんのフィーチャーの データセットを集めたとしよう。 そしてそれらのうちの二つだけをここにプロットした。 そして例えばそれら二つのフィーチャーは 実際は何かの センチメートルによる長さと、 それとは別のフィーチャーx2は インチによる長さだと しよう。 つまりこれは、極めて冗長な 表現となっていて、 x1とx2の別々のフィーチャーを 保持し続けるよりは、 それら両方が基本的には同じ長さを測っているのだから、 我らはデータを削減して 一次元にしたい、と 思うだろう。 そしてこの長さを測る数字一つだけを保持すれば良い。 この例はちょっとうさんくさいように 思うかもしれない。でも実の所、 このセンチメーターとインチの例は、そんなに非現実的でも無い。 そして私が実際に産業界で見た物と そんなに違いもしない。 もし何百、何千もの フィーチャーがあるのなら、 すぐに、簡単に何のフィーチャーを 持っていたのか、トラック出来なくなるものだ。 そして時には、 別々のエンジニアのチームが、 例えばあるエンジニアのチームが200の フィーチャーをあなたに与え、 二番目のエンジニアチームがまた別の 300フィーチャーを与え、 そして三番目のエンジニアチームが500フィーチャーを あなたに提供したとする。 すると全部で1000フィーチャーとなる訳だが、 それは実際にどのフィーチャーが どこのチームから来た物かなどを 正確にトラックするのは難しくなる。 しかも現実には、こんなに冗長なフィーチャーを保持したくは無い。 だからもしセンチメーターの 長さが近傍のセンチメーターに 丸めてしまって、 インチの長さは近傍のインチに丸めてしまえば、 それが理由でこの手本は 直線に完全には乗らない事になる、 何故なら、近傍のセンチメーターなり近傍のインチなりへの 丸め誤差の為に。 もしデータを2次元の代わりに 1次元に削減出来たら、 冗長性も削減出来る。 別の例としては、これもまた嘘っぽいかもしれないが、 自律的なヘリコプターパイロットと 何年も仕事をしてきた。 言い換えると私はヘリコプターを飛ばすパイロットと仕事をしてきた。 そして、だ。 もし仮に、、、 もし仮に調査なり試験なりを これらの別々のパイロットに実施したとして、 そこでは一つのフィーチャーx1として 例えばこれらのヘリコプターパイロットの スキルだとして、 そしてx2は例えば パイロットの楽しみ度合いだとする。 つまり、彼らが どれだけ飛行を楽しんだのか、だ。 これら二つのフィーチャーは高く相関しているだろう。 そして本当に気になっているのは、 この種の、この種の、 この方向、本当にパイロットの適性を測っている、 別のフィーチャーかもしれない。 私は適性、という名前を 創り上げた。だがふたたび、 もし高く相関したフィーチャーがあれば、 実際に次元を削減したくなるだろう。 だから、もうちょっと詳しく、 データの次元を 2次元から、2Dから 1次元、1Dへと 削減する、という事が 本当は何を意味しているかを説明しよう。 これらの手本を 別々の色で、 色付けしよう。 そしてこのケースでは、 次元を削減する、という時に 意味している事は、 例えばこの直線を探して、 もっとも多くのデータが載るような 直線の方向を探して、 そこに全てのデータを 射影する、 そうする事で、 この直線上の 各手本の位置を 測る事が出来る。 そして新しい一つのフィーチャーz1という考えに行き着く。 直線上の位置を 示すのに 一つの数だけしか 必要としなくなったので、 つまりz1はこれらの点の この緑の直線上の位置を 示す、新しいフィーチャーなのだ。 これの意味する所は、 前と同じに手本x1が あったとすると、 例えばこれは最初の手本x1だとする。 そして、x1を表す為には もともとのx1には 二次元の数が必要だった、 または二次元のフィーチャーベクトルが必要だった。 その代わりにここでは、z1で表す事が出来る。 私は最初の手本を 表すのに、z1だけで表す事が出来る、 ここでz1は実数。 同様にx2は、x2をここの 二番目の手本とすると、 以前はこれを表すのに 二つの数が必要だったが、 もし代わりに直線上の黒い線に 射影した物を 計算すれば、 そうすれば今や、私は このz2の線上の位置を 示すには、 たった一つの実数しか 必要としない。 などなどという事が、m個の手本を通して言える。 さて、まとめよう。 もし元のデータセットを、 全ての手本を緑の直線に 射影する、という近似を 許容するなら、 その時は一つの 数しか必要としない、 直線の上の点の場所を 示すのに、 たった一つの実数しか必要としない。 つまり、ただ一つの 数を使って、各手本の位置を 表す事が出来る、 各手本を、緑の直線に 射影した後では。 つまりこれは、元のトレーニングセットを 近似した物となっている、 何故ならトレーニング手本を直線に射影しているから。 だが、 いまや私は各手本に対して たった一つの数を保持するだけで良くなっている。 だからこれは必要なメモリ量、または必要なスペース、 またはデータを保存する方法がなんであれ、 それを半減させる。 そしてもっと興味深い事には、 もっと重要な事としては、後で観る事になるが、 あとのビデオで、 それは、これが 我らの学習アルゴリズムを もっと早く走らせてくれる、という事だ。 そしてそれは実際、たぶん、 データを保持するディスクスペース要件や メモリ要件を減らす、という事よりも、 より興味深いデータ圧縮の 適用例と言えるだろう。 前のスライドでは、 データを2Dから1Dへと削減する 例を見た。 このスライドでは、 別のデータ削減の例である、 3次元の3Dから二次元の2Dへの削減をお見せする。 ところで、より典型的な 次元削減の例としては、 1000次元、つまり1000Dとかの データとかもあり、 それを例えば 100次元または100Dに削減したい、とかいう事がある。 だがスライドにプロット可能な限界という 制限の為に、 3Dから2Dと、2Dから1Dの例を使っていく。 さて、ここに見せたようなデータセットがあるとする。 つまり、手本の集合x(i)があり、 それはR 3の点の集まりだ。 つまり、三次元の手本がある。 これはスライド上では 見づらいとは思うが、 3次元プロットの雲を 一応見せておく。 ちょっと見づらいけど、 このデータはだいたい全部 平面に乗っている。 こんな感じ。 そこで次元削減で やる事としては、 このデータを全部持ってきて 二次元平面に 射影する事。 ここで私がやった事は、 データを全部持ってきて、 全てのデータを平面上に乗るように 射影した、という事。 さて、最終的に、 平面上の位置を示す為に、 二つの数字が必要だ。でしょ？ この軸に沿った点の位置を、 示す必要があり、 そしてまたこの軸に沿った 場所も示す必要がある。 つまり我らは二つの数字が要る。 z1とz2と呼ぼうか。 平面上の点の場所を示す為に。 つまりそれの意味する所は、 今や我らは各手本を 各トレーニング手本を、 ここに書いた二つの数 z1とz2で、表す事が出来る。 つまり我らはデータを、R 2のベクトルzを用いて 表す事が出来る、という事だ。 そしてこれらの下付き添字、z下付き添字1、 z下付き添字2は、 それが意味するのは、 このベクトルzは、 二次元のベクトルz1とz2だ、という事だ。 そしてもし私はある特定の手本、 z(i)があるとする、 またはそれは二次元ベクトル z(i) 1と z(i) 2だ。 そして前のスライドで、 データを一次元に 削減した時、 z1しか無かった。よね？ そしてそれこそが前のスライドでの z(1) 下付き添字1 だった。 だがここでは二次元のデータなので、 z1とz2を持ってる。 データの二つの構成要素として。 さてこれらの図の意味を 確認しよう。 その為に、これらの三つの図を 全く同じ物を、けど3Dプロットで再掲する。 我らがやってきたプロセスは、 まず左にあるのがもともとのデータセットで、 真ん中が2Dに投影したデータセット。 そして右側が、 z1とz2としての、 2Dのデータセット。 それらをもうちょっと詳しく見てみよう。 これが私のオリジナルのデータセットで、 左に示した。 つまり私は、 3Dの点の雲から 始めた。そこでは、 軸はx1, x2, x3などと ラベルづけされていた。だから3Dの点があった訳だ。 だがほとんどのデータは だいたいはある2D平面に そんなに離れずに乗っていた。 そこでこんな事が出来る、 このデータを持ってきて、これが真ん中の図だ。 それを2Dに射影する。 つまり、これら全てのデータが 2Dの表面に乗るように射影した。 見ての通り、全てのデータは 平面上にある。何故なら、 全てを平面に射影したから。 つまりこれが意味する事は、 今や平面上の点の位置を 表すには、たった二つの数、 z1とz2しか、必要としない。 以上が、データを 3次元から2次元に削減する時に行う 手続きとなる。 以上が次元削減で、 そしてそれを用いてデータを圧縮する 方法だ。 そして後で見るように、 これは我らの学習アルゴリズムを もっと早く走らせる時にも また用いる事が出来るが、 それはあとのビデオでやろう。