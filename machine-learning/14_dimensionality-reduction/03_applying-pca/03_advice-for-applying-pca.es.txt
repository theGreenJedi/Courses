En un video anterior, había dicho que el ACP a veces se utiliza para acelerar el tiempo de ejecución de un algoritmo de aprendizaje. En este video me gustaría explicar cómo hacer esto realmente y también darle algunos consejos sobre cómo aplicar el ACP. Esto es como usted puede utilizar el ACP para acelerar un algoritmo de aprendizaje, y esta aceleración del algoritmo de aprendizaje supervisado es en realidad, el uso más común que personalmente le doy al ACP. Digamos que usted tienen un problema de aprendizaje supervisado, tome en cuenta que es un problema de aprendizaje supervisado, con entradas "x" y valores asignados "y", y digamos que sus ejemplos xi son de muy altas dimensiones. Así que, digamos que sus ejemplos, xi son vectores de variables de 10000 dimensiones, un ejemplo de esto sería: si usted estuviera trabajando cierto problema de vision computacional, en el que tiene unas imágenes de 100x100, de modo que si usted tiene 100x100, esto es 10000 pixeles, por lo que si "xi" son, ya sabe, vectores de variables que que contienen sus valores de intensidad de 10000 pixeles, entonces tiene vectores de variables de 10000 dimensiones. Así que, con vectores de variables de dimensiones tan altas como estas, la ejecución de un algoritmo de aprendizaje puede ser lenta ¿verdad? Simplemente, si usted alimenta vectores de variables de 10000 dimensiones en regresión logística, o una red neuronal, o una máquina de vectores de soporte o lo que tenga, sólo porque se trata de una gran cantidad de datos, esto es, 10000 números, puede hacer que la ejecución de su algoritmo de aprendizaje sea más lenta. Afortunadamente, con ACP podremos reducir la dimensión de los datos y hacer que nuestros algoritmos se ejecuten de manera más eficiente. Ahora le muestro cómo hacerlo: Primero vamos a tomar nuestro grupo de entrenamiento de valores asignados y extraeremos sólo las entradas, sólo vamos a extraer las "x" y de forma temporal dejaremos a un lado las "y". Así que esto ahora nos dará un conjunto de entrenamiento sin valores asignados de x1 a xm, que son tal vez datos de 10000 dimensiones, tenemos ejemplos de diez mil dimensiones. Entonces, sólo extraemos los vectores de entrada x1 a xm. Luego vamos a aplicar el ACP y esto me dará una representación de los datos con dimensiones reducidas, así que en vez de vectores de variables de 10000 dimensiones, ahora tenemos tal vez vectores de variables de mil dimensiones. Así que eso es como un ahorro de 10x, esto me da, si se quiere, un nuevo conjunto de entrenamiento. Mientras que anteriormente pude haber tenido un ejemplo x1, y1, mi primera entrada de entrenamiento, está ahora representada por z1. Entonces, tendremos una nueva especie de ejemplo de entrenamiento, que es z1 emparejado con y1 y de manera similar z2, y2 y así sucesivamente, hasta zm, ym, debido a que mis ejemplos de entrenamiento ahora son representados de esta forma con menos dimensiones z1, z2, hasta zm. Por último, puedo tomar este conjunto de entrenamiento de dimensión reducida y alimentarlo a un algoritmo de aprendizaje, puede ser una una red neuronal, una regresión logística y puedo aprender la hipótesis "h", que toma esta entrada, estas representaciones z de pocas dimensiones y trata de hacer predicciones. Así que, si estuviera usando regresión logística por ejemplo, entrenaría una hipótesis que diera como resultado, 1 sobre 1 + e a la transposición teta negativa "z", que lleva esta entrada a uno de estos vectores z y trata de hacer una predicción. Finalmente, si tiene un nuevo ejemplo, tal vez un nuevo ejemplo de prueba "x", lo que hace es que tomaría su ejemplo de prueba "x", lo asignaría por medio de la misma asignación encontrada por el ACP para obtener su "z" correspondiente y esa "z" luego se alimenta a esta hipótesis, y esta hipótesis a su vez hace una predicción de su entrada x. Una nota final, lo que hace el ACP es que define una asignación de "x" a "z" y esta asignación de "x" a "z" debe definirse mediante la ejecución del ACP,sólo en los conjuntos de entrenamiento y en particular, esta asignación que el ACP está aprendiendo, esta asignación, lo que hace es que calcula el conjunto de parámetros que son la escalación de variables y la normalización de media, también calcula esta matriz "u reducida" pero todas estas cosas, la "u reducida", esto es como un parámetro que ACP aprende y debemos estar ajustando nuestros parámetros sólo a nuestros conjuntos de entrenamiento y no a nuestra validación cruzada o la los conjuntos de prueba, así que estas cosas, la "u reducida" y demás, deben ser obtenidas mediante la ejecución de ACP sólo en su conjunto de entrenamiento y después de haber encontrado "u reducida", o haber encontrado los parámetros de escalación de variables donde se da la normalización de media y la escala entre la que se dividen las variables para obtenerlas en escalas comparables. Después de haber encontrado todos esos parámetros en el conjunto de entrenamiento, puede aplicar la misma asignación a otros ejemplos que pueden estar en sus conjuntos de validación cruzada o sus conjuntos de prueba, ¿de acuerdo? Sólo para resumir, cuando está ejecutando un ACP, ejecútelo sólo en la porción de conjunto de entrenamiento de los datos no en el conjunto de datos de validación cruzada o la parte de conjuntos de prueba de sus datos y eso define la asignación de "x" a "z" y posteriormente puede aplicar esa asignación a su conjunto de datos de validación cruzada y a su conjunto de prueba. Por cierto, en este ejemplo, hablé sobre la reducción de datos, de 10000 dimensiones a 1000 dimensiones, esto no es en realidad poco factible. Para muchos problemas, en realidad reducimos los datos dimensionales, ya sabe, por 5x, tal vez por 10 veces y todavía conservamos la mayor parte de la varianza y podemos hacer esto apenas afectando el rendimiento, en cuanto a la precisión de la clasificación, vamos a decir, afectando en forma mínima, la precisión de la clasificación del algoritmo de aprendizaje y al trabajar con datos en menores dimensiones nuestro algoritmo de aprendizaje a menudo se puede ejecutar mucho más rápido. En resumen, hemos hablado hasta ahora sobre las siguientes aplicaciones del ACP. La primera es la aplicación de compresión, que podríamos emplear para reducir la memoria o el espacio en disco necesario para almacenar los datos y hemos hablado de cómo usar esto para acelerar un algoritmo de aprendizaje. En estas aplicaciones, con el fin de elegir k, a menudo vamos a hacerlo de acuerdo con  determinar cuál es el porcentaje de la varianza retenida y así para este algoritmo de aprendizaje, la aplicación de velocidad, a menudo retendrá el 99% de la varianza. Esa sería una opción muy típica de cómo elegir k. Entonces, así es como usted elije k para estas aplicaciones de compresión; mientras que para las aplicaciones de visualización que por lo general sabemos cómo trazar, sólo datos de dos dimensiones o datos de tres dimensiones y para las aplicaciones de visualización, vamos a elegir usualmente, k= 2 o k=3, ya que podemos trazar sólo los conjuntos de datos 2D y 3D. Así que esto resume las principales aplicaciones del ACP, así como la forma de elegir el valor de k para estas diferentes aplicaciones. Debo mencionar que a menudo existe un mal uso frecuente del ACP y a veces se oye hablar de otros que cometen este error, espero que no tan a menudo. Sólo quiero mencionar esto para que sepa lo que no debe hacer, hay un mal uso del ACP, que consiste en tratar de usarlo para evitar un ajuste excesivo. He aquí el razonamiento: Esta no es una gran manera de utilizar el ACP pero hay una razón detrás de este método, que es, ya sabe, si tenemos xi, entonces, tal vez tengamos "n" variables pero si comprimimos los datos y mejor usamos zi, que reduce el número de variables para k, lo que podría minimizar las dimensiones y si tenemos una cantidad más pequeña de variables, si k es 1000 y n es 10000, si tenemos sólo datos de 1000 dimensiones, tal vez tenemos una menor tendencia al ajuste excesivo que si usáramos datos de 10000 dimensiones con un millar de funciones. Así que, algunas personas consideran al ACP como una manera de prevenir el exceso de ajustes pero sólo para enfatizar, esta es una mala aplicación del ACP y no recomiendo realizarla. Y no es que este método funcione mal, si quiere usar este método para reducir la dimensión de los datos, para tratar de prevenir el exceso de ajustes, tal vez funcione bien pero esta no es una buena forma de enfrentar el exceso de ajustes y en cambio, si usted está preocupado por el exceso de ajustes, hay una forma mucho mejor para hacer frente a este problema, el uso de regularización, en vez de usar el ACP para reducir la dimensión de los datos y la razón es que, si usted piensa acerca de cómo funciona el ACP, no utiliza los valores asignados "y", usted sólo mira sus entradas xi, y está utilizando esto para encontrar una aproximación dimensional inferior a sus datos. Entonces, lo que el ACP hace, es que desecha algo de información, elimina o reduce la dimensión de sus datos sin saber cuáles son los valores de "y", por lo que esto quizá es correcto; el usar el ACP de esta manera tal vez esté bien si, por ejemplo el 99% de la varianza se mantiene, si usted está reteniendo la mayor parte de la varianza pero también podría perder un poco de información valiosa. Resulta que si usted está reteniendo el 99% de de la varianza o el 95% de la varianza o la cantidad que sea, lo que sucede es que el simple uso de la regularización le dará con frecuencia un método al menos igual de efectivo para prevenir el exceso de ajustes y la regularización funcionará mejor porque cuando usted está aplicando la regresión lineal, la regresión logística o algún otro método con la regularización, bueno, este problema de minimización en realidad sabe cuáles son los valores de "y", por lo que es menos probable desechar alguna información valiosa, mientras que el ACP no hace uso de los valores asignados y es más probable que elimine información valiosa. Así que, para resumir, este es un buen uso del ACP, si su motivación principal es acelerar su algoritmo de aprendizaje pero el usar el ACP para tratar de prevenir el exceso de ajustes, no es un buen uso de ACP, el usar la regularización en vez de esto, es lo que en realidad mucha gente recomendaría hacer en su lugar. Por último, un último mal uso de ACP y debería decir que ACP es un algoritmo muy útil, con frecuencia lo uso para la compresión con propósitos de visualización pero, lo que a veces noto es que también la gente suele usar el ACP donde no debería. Por otro lado, algo que veo con frecuencia es que si alguien está diseñando un sistema de aprendizaje automático pueden anotar el plan de este modo: vamos a diseñar un sistema de aprendizaje, tomamos un conjunto de entrenamiento y luego, ya sabe, lo que haré es ejecutar ACP después entrenar regresión logística y luego lo pruebo en mis datos de prueba. Muy a menudo al inicio de un proyecto, alguien sólo escribirá un plan de proyecto que dirá: vamos a hacer estos cuatro pasos con incluyendo el ACP. Antes de escribir un plan de proyecto que incorpora el ACP de este modo, una muy buena pregunta que debemos hacernos es, bueno, ¿y si quisiéramos simplemente hacer todo sin usar el ACP? Y muchas veces la gente no considera este paso antes de dar con un plan de proyecto complicado e implementar ACP y así sucesivamente. Algunas veces y de forma muy específica, lo que suelo aconsejar a la gente es que antes de implementar el ACP, lo que sugeriría en primer lugar, ya sabe, al hacer cualquier acción, tomar lo que sea que quiera hacer, es primero considerar hacerlo con sus datos en bruto originales xi, y sólo si eso no funciona como usted quiere, entonces  implemente el ACP y considere usar Zi. Por lo tanto, antes de usar ACP, ya sabe, en vez de reducir la dimensión de los datos, yo consideraría, bueno, vamos a saltar este paso de ACP y pensaría, vamos a entrenar simplemente mi algoritmo de aprendizaje en mis datos originales. Vamos a usar sólo mis entradas originales xi, y recomendaría en lugar de poner el ACP en el algoritmo, sólo tratar de hacer lo que sea que esté haciendo, primero con xi y sólo si tiene una razón para creer que no funciona, si esto causa que su algoritmo de aprendizaje termine ejecutándose muy despacio, o sólo si el requisito de memoria o espacio de disco es demasiado grande, entonces usted querrá comprimir su representación pero sólo si el uso de xi no funciona, sólo si tiene pruebas o una gran razón para creer que no funciona el uso de xi , entonces aplique el ACP y considere el uso de la representación comprimida. Porque lo que veo es que a veces la gente comienza con un plan de proyecto que incorpora ACP y en ocasiones, sea lo que sea que estén haciendo, funcionará bien, aún sin usar el ACP. Entonces, sólo considérelo como una alternativa también, antes de desperdiciar tanto tiempo para obtener un ACP, calcule lo que será "k" y así sucesivamente. Eso es todo sobre ACP, a pesar de estos últimos comentarios, ACP es un algoritmo increíblemente útil, cuando se usa para las aplicaciones adecuadas y de hecho estoy muy acostumbrado a él, en mi caso, lo uso principalmente para acelerar el tiempo de ejecución de mis algoritmos de aprendizaje pero creo que una aplicación común del ACP, es utilizarlo para comprimir los datos, para reducir los requisitos de memoria o el espacio en disco o utilizarlo para visualizar los datos. El ACP es uno de los algoritmos más comúnmente usados y uno de los más poderosos algoritmos de aprendizaje no supervisado. Con lo que ha aprendido en estos videos, espero que sea capaz de poner en práctica el ACP y utilizarlo para todos estos fines también.