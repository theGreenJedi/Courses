1
00:00:00,340 --> 00:00:01,410
このビデオでは、

2
00:00:01,550 --> 00:00:03,020
主成分分析のアルゴリズムについて

3
00:00:03,340 --> 00:00:04,570
お話ししたい。

4
00:00:05,600 --> 00:00:06,560
このビデオが終わる頃には、

5
00:00:06,710 --> 00:00:09,200
あなたはPCAを自分自身で実装する方法を知る事になる。

6
00:00:10,170 --> 00:00:12,540
そしてそれを用いてあなたのデータの次元を削減する。

7
00:00:13,100 --> 00:00:14,690
PCAを適用する前に、

8
00:00:14,800 --> 00:00:17,760
必ずやらなくてはいけないデータの前処理のステップがある。

9
00:00:18,510 --> 00:00:20,220
トレーニングセットの手本が与えられたとして、

10
00:00:20,520 --> 00:00:22,290
必ずやらなくてはいけない事は、

11
00:00:22,600 --> 00:00:24,070
平均標準化だ。

12
00:00:25,330 --> 00:00:26,140
そして次にデータによっては、

13
00:00:26,840 --> 00:00:28,540
フィーチャースケーリングも実行する場合がある。

14
00:00:29,620 --> 00:00:30,950
これは教師あり学習での

15
00:00:31,650 --> 00:00:33,250
平均標準化とフィーチャースケーリングのプロセスと

16
00:00:34,080 --> 00:00:36,580
とても似た物だ。

17
00:00:36,910 --> 00:00:38,240
実のところ、それは

18
00:00:38,390 --> 00:00:40,160
ラベル無しデータのx1からxmに対して行う、という

19
00:00:40,310 --> 00:00:41,790
事以外は

20
00:00:42,930 --> 00:00:43,670
完全に同じ物だ。

21
00:00:44,180 --> 00:00:45,530
平均標準化の為に、

22
00:00:45,720 --> 00:00:47,080
各フィーチャーの平均を

23
00:00:47,390 --> 00:00:49,070
まず計算する必要がある。

24
00:00:49,340 --> 00:00:50,900
そして各フィーチャーxを

25
00:00:51,150 --> 00:00:52,680
x-平均 で置き換える。

26
00:00:52,810 --> 00:00:54,120
この結果、各フィーチャーは厳密に

27
00:00:54,520 --> 00:00:57,450
平均0となる。

28
00:00:58,690 --> 00:01:00,690
もしそれぞれのフィーチャーがとても異なるスケールを持つなら、

29
00:01:01,540 --> 00:01:03,050
例えば

30
00:01:03,080 --> 00:01:04,060
x1が家の大きさ、

31
00:01:04,100 --> 00:01:05,390
x2が寝室の数なら、

32
00:01:05,580 --> 00:01:07,370
以前の例を引っ張り出してみたが、

33
00:01:07,480 --> 00:01:08,680
そうすると各フィーチャーが

34
00:01:09,130 --> 00:01:10,540
比較可能な範囲になるように、スケールする必要もある。

35
00:01:10,980 --> 00:01:12,490
だから教師あり学習でやったのと

36
00:01:12,680 --> 00:01:13,860
同様に、

37
00:01:14,060 --> 00:01:16,200
x(i)の下付き添字jを

38
00:01:16,680 --> 00:01:17,620
これはjのフィーチャーだが、

39
00:01:23,250 --> 00:01:25,530
そこから

40
00:01:25,890 --> 00:01:27,610
平均を引いて、

41
00:01:28,370 --> 00:01:29,520
これが分子となる、そしてそれをsjで割る。

42
00:01:29,610 --> 00:01:30,020
ここでsjはフィーチャーjの値の範囲に関する、なんらかの指標だ。
つまり、max - minでも良いし、

43
00:01:30,080 --> 00:01:31,310
もっと良く使われている物としては、

44
00:01:31,890 --> 00:01:33,540
フィーチャーjの標準偏差がある。

45
00:01:33,640 --> 00:01:35,520
この種のデータの前処理を

46
00:01:36,230 --> 00:01:39,480
行った上で、PCAはこんな事をする。

47
00:01:40,620 --> 00:01:41,630
前回のビデオで我らは

48
00:01:41,960 --> 00:01:43,050
PCAがやる事は、

49
00:01:43,170 --> 00:01:44,520
より低い次元の部分空間で、

50
00:01:44,790 --> 00:01:46,080
そこにデータを射影すると

51
00:01:46,170 --> 00:01:47,500
射影誤差の二乗が

52
00:01:47,650 --> 00:01:49,780
最小になるような物を、

53
00:01:50,540 --> 00:01:51,660
探す、という事を見たのだった。

54
00:01:51,740 --> 00:01:53,080
射影誤差の二乗の和、

55
00:01:53,420 --> 00:01:54,800
これらの青い線の

56
00:01:54,870 --> 00:01:56,790
長さの二乗。

57
00:01:57,110 --> 00:01:58,510
つまり具体的には、

58
00:01:59,210 --> 00:02:02,730
この方向を示すベクトルu1を

59
00:02:03,280 --> 00:02:04,750
見つけたい。または

60
00:02:05,040 --> 00:02:06,630
2Dのケースでは二つのベクトル、

61
00:02:06,880 --> 00:02:08,760
u1とu2を見つけたい、

62
00:02:10,640 --> 00:02:12,980
データを射影するこの平面を

63
00:02:13,590 --> 00:02:14,610
定義するような。

64
00:02:16,620 --> 00:02:17,920
ではちょっと簡単に、

65
00:02:18,040 --> 00:02:19,160
データの次元を削減する、というのが

66
00:02:19,730 --> 00:02:20,820
何を意味するのかを振り返ってみよう。

67
00:02:21,490 --> 00:02:22,430
この例では、

68
00:02:22,470 --> 00:02:23,560
左側には手本xiが与えられていて、

69
00:02:23,680 --> 00:02:26,010
それはR 2に存在する。

70
00:02:26,300 --> 00:02:28,390
そして我らがやりたい事は、

71
00:02:28,660 --> 00:02:29,500
我らのデータを表す

72
00:02:29,970 --> 00:02:32,400
Rの数字ziを、

73
00:02:33,000 --> 00:02:34,950
探す事だ。

74
00:02:36,000 --> 00:02:37,820
以上が2Dから1Dへの削減、の意味する所だ。

75
00:02:39,020 --> 00:02:41,450
具体的には、この赤い直線へ

76
00:02:42,710 --> 00:02:44,080
データを射影する事で、

77
00:02:44,800 --> 00:02:46,320
この直線の上の点の位置を

78
00:02:46,450 --> 00:02:48,340
示すのは、数字一つで十分だ。

79
00:02:48,590 --> 00:02:49,380
その数字を、zとかz1と

80
00:02:50,700 --> 00:02:51,830
呼ぶ事にしよう。

81
00:02:52,020 --> 00:02:54,850
ここでzは実数だ。つまりこれは一次元ベクトルみたいな物だ。

82
00:02:55,380 --> 00:02:56,650
z1は単にこの

83
00:02:56,690 --> 00:02:58,080
1x1行列、または1次元ベクトルの

84
00:02:58,280 --> 00:03:00,430
最初の要素を表す。

85
00:03:01,670 --> 00:03:03,170
つまり点の位置を示すのに

86
00:03:03,490 --> 00:03:05,590
一つの数しか必要としない。

87
00:03:06,330 --> 00:03:07,940
つまりこの手本が

88
00:03:08,460 --> 00:03:09,510
手本x1だとすると、

89
00:03:10,610 --> 00:03:13,160
それはここにマップされるだろうか。

90
00:03:13,900 --> 00:03:15,450
そしてこの手本がx2なら、

91
00:03:15,680 --> 00:03:17,250
それはここにマップされるかな。

92
00:03:17,530 --> 00:03:18,790
つまりこのここの点は

93
00:03:19,060 --> 00:03:20,400
z1となり、

94
00:03:20,840 --> 00:03:21,920
ここのこの点はz2となる。

95
00:03:22,080 --> 00:03:24,240
同様に、これら他の点も、

96
00:03:24,620 --> 00:03:26,410
x3, x4, x5とすると、

97
00:03:26,840 --> 00:03:30,230
これらはz3, z4, z5に

98
00:03:30,510 --> 00:03:32,550
マップされるなど。

99
00:03:34,360 --> 00:03:35,940
つまりPCAの任務は、

100
00:03:36,050 --> 00:03:36,830
二つの事を計算する方法を

101
00:03:36,930 --> 00:03:38,920
考え出す必要がある、という事だ。

102
00:03:39,310 --> 00:03:40,710
一つ目はこれらのベクトル、

103
00:03:41,830 --> 00:03:44,970
u1と、こちらのケースではu1とu2。

104
00:03:45,230 --> 00:03:46,880
そしてもう一つは、

105
00:03:47,130 --> 00:03:48,140
これらの数、Zを計算する方法。

106
00:03:49,360 --> 00:03:51,200
つまり左側の例では、

107
00:03:51,430 --> 00:03:53,910
データを2Dから1Dへと削減した。

108
00:03:55,290 --> 00:03:56,100
右側の例では、

109
00:03:56,510 --> 00:03:58,100
データを3次元、R 3から、

110
00:03:58,450 --> 00:04:00,600
zi、これはここでは2次元へと

111
00:04:00,710 --> 00:04:04,840
削減している。

112
00:04:05,390 --> 00:04:07,790
つまりこれらのzベクトルは、いまは2次元だ。

113
00:04:08,450 --> 00:04:09,590
つまりそれはz1とz2、

114
00:04:10,150 --> 00:04:11,410
みたいな形。

115
00:04:11,640 --> 00:04:12,940
だから我らはこれらの新しい表現

116
00:04:13,670 --> 00:04:15,410
z1とz2を計算する方法を

117
00:04:15,570 --> 00:04:17,350
同様に知らなくてはならない。

118
00:04:18,280 --> 00:04:20,350
ではこれら全ての量を、どうやって計算したら良いだろうか？

119
00:04:20,520 --> 00:04:21,520
数学的な導出は、

120
00:04:22,490 --> 00:04:23,660
数学的な証明も、

121
00:04:24,300 --> 00:04:26,020
u1, u2, z1, z2などの

122
00:04:26,090 --> 00:04:27,970
正しい値は何か、を

123
00:04:28,290 --> 00:04:29,480
証明する事は、

124
00:04:29,690 --> 00:04:31,230
その数学的証明はとても複雑で、

125
00:04:31,480 --> 00:04:32,890
このコースの範囲を

126
00:04:32,950 --> 00:04:34,620
越える。

127
00:04:35,280 --> 00:04:37,290
だが一度その手順をマスターしてしばえば、

128
00:04:37,590 --> 00:04:38,590
実際に望みのu1の値を

129
00:04:39,350 --> 00:04:40,570
探す手続きというのは、

130
00:04:41,200 --> 00:04:42,210
そんなに大変でも

131
00:04:42,950 --> 00:04:43,950
無い事が分かる。

132
00:04:44,180 --> 00:04:45,640
この値が正しい値だ、と

133
00:04:45,840 --> 00:04:46,940
数学的に証明するのは、

134
00:04:47,260 --> 00:04:48,450
よりしっかりとやらないと分からない事で、

135
00:04:48,700 --> 00:04:49,960
それは私がこのコースでやりたいレベルを越えてしまう。

136
00:04:50,880 --> 00:04:52,070
だが、具体的な手順は、

137
00:04:52,480 --> 00:04:53,830
記述してみよう、

138
00:04:53,960 --> 00:04:55,250
これら全てのベクトル、

139
00:04:55,440 --> 00:04:56,450
u1, u2, ベクトルzを

140
00:04:56,570 --> 00:04:57,840
計算する為にやる必要のある事を。

141
00:04:58,910 --> 00:05:00,980
これがその手順だ。

142
00:05:02,070 --> 00:05:02,970
我らはデータを

143
00:05:03,170 --> 00:05:04,220
n次元からk次元へと

144
00:05:04,840 --> 00:05:05,760
削減したいとする。

145
00:05:06,760 --> 00:05:07,640
そこで我らがやるのは、

146
00:05:07,900 --> 00:05:09,400
まず、共分散行列と呼ばれる物を

147
00:05:09,830 --> 00:05:11,140
計算する。共分散行列は

148
00:05:11,700 --> 00:05:13,620
普通ギリシャ文字の

149
00:05:13,820 --> 00:05:15,050
大文字のギリシャ文字のシグマで

150
00:05:15,190 --> 00:05:16,880
表す慣例となっている。

151
00:05:18,000 --> 00:05:19,210
和のシグマと

152
00:05:19,310 --> 00:05:21,080
ギリシャ文字のシグマが

153
00:05:21,760 --> 00:05:22,710
まったく同じなのは、ちょっとした不幸だ。

154
00:05:23,210 --> 00:05:24,620
つまりこの

155
00:05:24,700 --> 00:05:26,220
ギリシャ文字シグマは

156
00:05:26,420 --> 00:05:29,540
行列を示すのに使われ、このこれは和の記号だ。

157
00:05:30,510 --> 00:05:32,330
これらのスライドにおいては、

158
00:05:32,680 --> 00:05:34,190
どれがSigma行列、行列か、

159
00:05:34,410 --> 00:05:36,340
それが和の記号か、

160
00:05:36,520 --> 00:05:37,850
どれがどちらか、

161
00:05:38,090 --> 00:05:39,620
その区別は、

162
00:05:39,940 --> 00:05:41,460
文脈から私がどっちを使ってるかは

163
00:05:41,820 --> 00:05:43,510
はっきり分かると思う。

164
00:05:43,740 --> 00:05:44,790
この行列をどう計算するか？

165
00:05:45,530 --> 00:05:46,550
Octaveの変数Sigmaに

166
00:05:47,135 --> 00:05:47,640
それが入っていると

167
00:05:48,120 --> 00:05:49,970
しよう。

168
00:05:50,840 --> 00:05:51,890
我らがやるべき事は、

169
00:05:52,030 --> 00:05:53,660
行列Sigmaの固有ベクトルと呼ばれる物を

170
00:05:54,130 --> 00:05:56,190
計算する事だ。

171
00:05:57,560 --> 00:05:58,450
Octaveでは、それをやる方法は、

172
00:05:58,590 --> 00:05:59,820
以下のコマンドを使う事だ：

173
00:05:59,970 --> 00:06:01,020
U S Vイコールの

174
00:06:01,350 --> 00:06:02,600
svdのSigma。

175
00:06:03,650 --> 00:06:06,090
ところで、svdは、Singular Value Decomposition（特異値分解）の略。

176
00:06:08,520 --> 00:06:10,590
特異値分解は、

177
00:06:10,790 --> 00:06:12,660
よりアドバンスドな、、、

178
00:06:14,450 --> 00:06:15,560
あなたが実際にしる必要がある範囲よりも

179
00:06:15,800 --> 00:06:16,950
よりアドバンスドな線形代数の範疇なのだが、

180
00:06:16,950 --> 00:06:18,770
知られている事として、

181
00:06:18,950 --> 00:06:20,250
Sigmaが共分散行列とする時、

182
00:06:20,480 --> 00:06:21,800
固有ベクトルを求める方法が

183
00:06:21,880 --> 00:06:23,420
幾つか存在する。

184
00:06:23,610 --> 00:06:25,810
そしてもしあなたが

185
00:06:25,960 --> 00:06:27,350
線形代数のエキスパートで、

186
00:06:27,700 --> 00:06:28,610
前から固有ベクトルを知ってたなら、

187
00:06:28,860 --> 00:06:30,170
ひょっとしたらoctaveの

188
00:06:30,350 --> 00:06:31,660
eigと呼ばれる関数を知ってるかもしれない。

189
00:06:31,990 --> 00:06:33,420
これもまた同じ物を

190
00:06:33,520 --> 00:06:35,030
計算するのに使う事が出来る。

191
00:06:35,950 --> 00:06:36,980
結局は、svd関数と

192
00:06:37,370 --> 00:06:39,180
eig関数は、

193
00:06:39,290 --> 00:06:40,310
同じベクトルを返す。

194
00:06:40,370 --> 00:06:42,170
でもsvdの方がちょっとだけ

195
00:06:42,840 --> 00:06:44,210
数値計算的に安定だが。

196
00:06:44,540 --> 00:06:45,890
だから私はsvdを使う事にしている、

197
00:06:46,140 --> 00:06:47,040
でも私には、同じ事をするのに

198
00:06:47,280 --> 00:06:48,720
eig関数を使う友人が

199
00:06:48,920 --> 00:06:50,050
何人かいるが。だが、これを

200
00:06:50,130 --> 00:06:51,270
共分散行列Sigmaに適用する場合、

201
00:06:51,750 --> 00:06:52,960
どちらも同じ結果を返す。

202
00:06:53,870 --> 00:06:55,070
これは共分散行列は、

203
00:06:55,500 --> 00:06:57,250
いつでも正定値で対称、

204
00:06:57,940 --> 00:07:00,560
という数学的性質を満たす為だ。

205
00:07:01,360 --> 00:07:02,140
それの意味する所は知る必要は無いが、

206
00:07:02,280 --> 00:07:03,890
svdとeig関数は、

207
00:07:05,340 --> 00:07:07,090
異なる関数だが、

208
00:07:07,400 --> 00:07:08,670
共分散行列に

209
00:07:08,780 --> 00:07:10,410
適用する時には、

210
00:07:10,550 --> 00:07:12,080
いつもこの数学的性質を満たす事が証明されていて、

211
00:07:13,190 --> 00:07:15,220
いつも同じ結果を返す、という事だ。

212
00:07:16,580 --> 00:07:19,180
まあいいや。以上はたぶん知る必要があるよりも大分たくさんの線形代数の詳細だろう。

213
00:07:19,260 --> 00:07:22,380
これら全部が何言ってるかさっぱり分からなくても、気にしなくてよろしい。

214
00:07:22,560 --> 00:07:23,490
知らなきゃいけない事の全ては、

215
00:07:24,130 --> 00:07:27,840
Octaveで、このシステムコマンドを

216
00:07:28,140 --> 00:07:29,690
実装しなくてはいけない、って事だけ。

217
00:07:30,080 --> 00:07:30,550
そしてもしOctaveやMATLAB以外の

218
00:07:30,710 --> 00:07:32,120
別の言語でこれを実装しなくてはいけない、としたら、

219
00:07:32,710 --> 00:07:33,790
その時はあなたは、数値計算の

220
00:07:34,190 --> 00:07:35,860
線形代数ライブラリで、svd、つまり特異値分解が

221
00:07:36,730 --> 00:07:37,960
計算出来る物を

222
00:07:38,230 --> 00:07:40,460
探すべきだ。

223
00:07:40,970 --> 00:07:42,680
そんなライブラリは、主要なプログラミング言語なら

224
00:07:43,570 --> 00:07:45,060
どれにもたくさんあるはず。

225
00:07:45,300 --> 00:07:46,920
人々はそれを用いて

226
00:07:47,050 --> 00:07:48,920
共分散行列シグマの行列U, S, Dを

227
00:07:49,200 --> 00:07:52,770
計算するのに使う事が出来る。

228
00:07:53,340 --> 00:07:54,490
ではより詳細を埋めていこう。

229
00:07:54,620 --> 00:07:56,090
この共分散行列シグマは、

230
00:07:56,660 --> 00:07:58,080
n掛けるnの

231
00:07:58,250 --> 00:08:01,480
行列だ。

232
00:08:02,250 --> 00:08:03,240
それを確認する一つの方法としては、

233
00:08:03,510 --> 00:08:04,220
定義を見ると、

234
00:08:05,250 --> 00:08:06,280
これはn掛ける1ベクトルで、

235
00:08:06,660 --> 00:08:08,680
そしてこれは

236
00:08:08,920 --> 00:08:10,830
xiの転置は

237
00:08:11,010 --> 00:08:13,260
1掛けるn。

238
00:08:13,380 --> 00:08:14,480
だからこれら二つの積は、

239
00:08:15,150 --> 00:08:15,800
n掛けるnの

240
00:08:16,570 --> 00:08:17,530
行列となる。

241
00:08:19,100 --> 00:08:22,130
1xNの転置と1xNだから、

242
00:08:22,280 --> 00:08:22,840
NxN行列となり、

243
00:08:22,910 --> 00:08:23,710
これらを全て足しあわせても、

244
00:08:23,840 --> 00:08:26,140
NxN行列のまま。

245
00:08:27,600 --> 00:08:29,920
そしてsvdの出力は、

246
00:08:30,500 --> 00:08:32,580
3つの行列U, S, Vだ。

247
00:08:32,830 --> 00:08:35,070
svdの結果でこの場合本当に必要とするのは、U行列のみだ。

248
00:08:36,230 --> 00:08:40,160
U行列もまたNxN行列だ。

249
00:08:41,510 --> 00:08:42,280
そしてもしU行列の列を

250
00:08:42,350 --> 00:08:43,260
見てみると、

251
00:08:43,480 --> 00:08:45,330
U行列の列は、

252
00:08:45,630 --> 00:08:47,210
ベクトルu1, u2, などなどと

253
00:08:48,570 --> 00:08:50,180
まったく同じ事が

254
00:08:50,350 --> 00:08:53,860
分かる。

255
00:08:54,260 --> 00:08:56,290
分かる。

256
00:08:57,640 --> 00:08:59,330
つまりUは行列。

257
00:09:00,910 --> 00:09:01,830
そしてN次元からk次元へと

258
00:09:02,230 --> 00:09:03,200
データを削減

259
00:09:03,800 --> 00:09:05,380
したい場合、

260
00:09:05,490 --> 00:09:07,950
やるべき事はまず最初のk本のベクトルを取り

261
00:09:09,800 --> 00:09:12,670
それによって我らがデータを射影したいと思う、

262
00:09:12,860 --> 00:09:14,700
u1からukまでの、

263
00:09:14,780 --> 00:09:16,930
k本の方向が

264
00:09:17,200 --> 00:09:19,770
得られる。

265
00:09:20,090 --> 00:09:21,640
そこからの手順としては、

266
00:09:22,410 --> 00:09:24,170
SVD数値計算線形代数ライブラリのルーチンから

267
00:09:24,490 --> 00:09:25,580
この行列Uが得られる。

268
00:09:25,840 --> 00:09:27,140
これらの列を

269
00:09:27,530 --> 00:09:29,080
u(1)からu(n)、と呼ぼう。

270
00:09:30,580 --> 00:09:31,620
さて、残りの手順を

271
00:09:31,830 --> 00:09:32,520
まとめて記述してみよう。

272
00:09:32,540 --> 00:09:34,550
SVD数値計算線形代数ルーチンから、

273
00:09:35,320 --> 00:09:36,940
これらの行列、

274
00:09:37,240 --> 00:09:38,650
U, S, Dを得る。

275
00:09:38,830 --> 00:09:41,320
この行列から、

276
00:09:41,900 --> 00:09:44,460
最初のk列を取り出し、

277
00:09:45,050 --> 00:09:46,310
u(1)-u(k)を得る。

278
00:09:48,710 --> 00:09:49,460
さて、次にやるべき事は、

279
00:09:49,700 --> 00:09:53,730
元になるデータセットのXを持ってきて、

280
00:09:54,110 --> 00:09:55,430
このXはR nだが、

281
00:09:55,630 --> 00:09:57,080
そしてより低じ次元の表現である

282
00:09:57,250 --> 00:09:59,210
zを見つけてくる、

283
00:09:59,420 --> 00:10:01,280
それはR kだ。

284
00:10:01,570 --> 00:10:02,800
それを行う方法としては、

285
00:10:02,900 --> 00:10:03,930
U行列の最初のk列を

286
00:10:04,180 --> 00:10:06,690
取り出して、

287
00:10:08,330 --> 00:10:09,790
この行列を構築する。

288
00:10:11,060 --> 00:10:13,040
u1, u2, ...とukまで

289
00:10:14,170 --> 00:10:16,690
列に積み上げる。

290
00:10:17,350 --> 00:10:19,120
それは基本的には、

291
00:10:19,280 --> 00:10:20,350
行列のこの部分を取り出す事だ、

292
00:10:20,530 --> 00:10:22,260
この行列の最初のk列を。

293
00:10:23,420 --> 00:10:25,370
だからこれは、

294
00:10:25,600 --> 00:10:26,920
n掛けるk行列と

295
00:10:27,200 --> 00:10:28,580
なる。

296
00:10:29,500 --> 00:10:30,690
この行列に名前を与えておこう。

297
00:10:30,880 --> 00:10:32,200
この行列を、Uの下付き添字reduce、と

298
00:10:32,930 --> 00:10:35,760
呼ぶ事にする、

299
00:10:36,090 --> 00:10:38,620
reduce（削減）されたバージョンのU、みたいな意味だ。

300
00:10:39,140 --> 00:10:41,250
これを私のデータの次元を削減するのに使っていく。

301
00:10:43,040 --> 00:10:43,950
そしてzを計算する方法は、

302
00:10:44,250 --> 00:10:45,960
zイコールの、

303
00:10:46,220 --> 00:10:49,570
このU reduce行列の転置に、掛ける事のx。

304
00:10:50,010 --> 00:10:52,030
または別の書き方をすると、

305
00:10:52,510 --> 00:10:53,860
この転置が意味する所を書きくだして、

306
00:10:54,630 --> 00:10:55,910
このU行列の転置を取ると、

307
00:10:56,010 --> 00:10:57,920
最終的に得られるのは、

308
00:10:58,010 --> 00:11:00,680
今や列に並んでいるこれらのベクトルだ。

309
00:11:00,950 --> 00:11:04,540
u1転置からuk転置まで。

310
00:11:07,060 --> 00:11:08,860
そしてそれに、掛けることx。

311
00:11:09,700 --> 00:11:10,740
これがベクトルzを

312
00:11:10,920 --> 00:11:12,670
得る方法だ。

313
00:11:12,740 --> 00:11:14,280
これらの次元を納得する為に確認してみよう。

314
00:11:15,370 --> 00:11:16,380
このここの行列は、

315
00:11:16,560 --> 00:11:17,450
k掛けるnとなり、

316
00:11:18,270 --> 00:11:19,350
ここのxは、

317
00:11:19,420 --> 00:11:20,530
n掛ける1となる。

318
00:11:20,750 --> 00:11:21,810
だからその積は、

319
00:11:22,320 --> 00:11:24,330
k掛ける1となる。

320
00:11:24,820 --> 00:11:27,920
つまりzはk次元の、、、

321
00:11:28,790 --> 00:11:29,810
k次元ベクトルで、

322
00:11:30,010 --> 00:11:31,230
それはまさに

323
00:11:32,000 --> 00:11:33,180
我らの求める物だ。

324
00:11:33,550 --> 00:11:34,640
そしてもちろんこれらのxは、

325
00:11:34,890 --> 00:11:36,010
トレーニングセットの

326
00:11:36,100 --> 00:11:36,970
手本でも良いし、

327
00:11:37,540 --> 00:11:38,750
クロスバリデーションセットの手本でも良いし、

328
00:11:38,980 --> 00:11:40,330
テストセットの手本でも良い。

329
00:11:40,500 --> 00:11:41,590
例えば、トレーニング手本の

330
00:11:41,930 --> 00:11:43,830
xiをとりたいとする。

331
00:11:44,260 --> 00:11:45,910
そうするとここをxiと書けば良くて、

332
00:11:47,270 --> 00:11:48,430
ここもxiで、するとここは

333
00:11:48,510 --> 00:11:50,080
ziとなる。

334
00:11:50,940 --> 00:11:53,140
ではまとめだ。

335
00:11:53,460 --> 00:11:54,820
これはPCAアルゴリズムを一つのスライドに納めた。

336
00:11:56,250 --> 00:11:58,200
平均標準化の後で、

337
00:11:58,420 --> 00:11:59,230
各フィーチャーの平均は0なのを保証した後で、

338
00:11:59,610 --> 00:12:01,420
さらにオプションでフィーチャースケーリングも、

339
00:12:02,280 --> 00:12:03,780
もし本当にフィーチャースケーリングが必要なら、

340
00:12:03,890 --> 00:12:05,820
もしあなたのフィーチャーがそれぞれとても異なるレンジの値を取るなら、行う。

341
00:12:06,620 --> 00:12:08,610
この前処理の後で、

342
00:12:09,130 --> 00:12:12,010
共分散行列Sigmaを計算する。

343
00:12:12,240 --> 00:12:14,070
ところで、

344
00:12:14,210 --> 00:12:16,340
こんな形で

345
00:12:16,610 --> 00:12:17,780
行列としてデータがある時に、

346
00:12:18,030 --> 00:12:18,960
こんな風にデータが

347
00:12:19,230 --> 00:12:22,580
行で与えられている時には、

348
00:12:22,780 --> 00:12:24,370
もし行列Xとして

349
00:12:24,960 --> 00:12:26,190
トレーニングセットが行の形で

350
00:12:27,030 --> 00:12:28,830
書かれていて、

351
00:12:29,210 --> 00:12:30,400
x1の転置から、x nの転置までが並んでいるとしたら、

352
00:12:31,530 --> 00:12:32,700
これの共分散行列Sigmaは実は、

353
00:12:33,020 --> 00:12:36,040
ナイスなベクトル化された実装が存在する。

354
00:12:37,390 --> 00:12:38,980
octaveではこんな風に実装出来る。

355
00:12:39,440 --> 00:12:41,130
Sigmaイコール、

356
00:12:41,670 --> 00:12:45,250
1/m 掛ける事の、

357
00:12:45,550 --> 00:12:46,440
ここにあるXに転置をとって、

358
00:12:47,250 --> 00:12:50,770
さらにXを掛ける。

359
00:12:50,980 --> 00:12:53,320
このシンプルな式が、

360
00:12:53,570 --> 00:12:55,070
行列Sigmaを計算する為の

361
00:12:55,220 --> 00:12:56,910
ベクトル化した実装だ。

362
00:12:58,020 --> 00:12:59,020
今日のところはこれを証明したりはしない。

363
00:12:59,160 --> 00:13:00,600
これは正しいベクトル化だ。

364
00:13:00,740 --> 00:13:02,460
もしやりたければ、簡単に自分で

365
00:13:02,870 --> 00:13:03,900
Octaveで試す事で、数値的に確認出来るし、

366
00:13:03,980 --> 00:13:05,100
つまりこれと、

367
00:13:05,840 --> 00:13:06,890
この実装が同じ結果を返す、と。

368
00:13:06,920 --> 00:13:10,050
または自分で数学的に証明する事も、やれば出来る。

369
00:13:11,250 --> 00:13:12,330
どちらにしろ、これは正しい

370
00:13:12,430 --> 00:13:14,580
ベクトル化した実装だ。計算量がより少ない。

371
00:13:16,480 --> 00:13:17,570
次にsvdルーチンを適用し、

372
00:13:17,920 --> 00:13:19,050
U、S、Dを取得する。

373
00:13:19,250 --> 00:13:20,840
そして次に、

374
00:13:21,100 --> 00:13:22,720
U行列の最初のk列を

375
00:13:23,050 --> 00:13:24,450
つかみとって、

376
00:13:24,660 --> 00:13:26,550
U reduceとし、

377
00:13:26,650 --> 00:13:28,540
そして最後に、これが

378
00:13:28,740 --> 00:13:29,980
フィーチャーベクトルxから、

379
00:13:30,290 --> 00:13:31,600
この削減された次元の表現zへと

380
00:13:31,850 --> 00:13:34,340
変換する方法だ。

381
00:13:34,540 --> 00:13:35,760
そしてK-meansのように、

382
00:13:36,090 --> 00:13:37,860
PCAを適用する時も、

383
00:13:38,030 --> 00:13:40,300
それを適用するベクトルxはR nだ。

384
00:13:41,100 --> 00:13:43,990
つまりx0 = 1となるx0無しで行う。

385
00:13:44,200 --> 00:13:46,080
以上がPCA

386
00:13:46,990 --> 00:13:48,680
アルゴリズムだ。

387
00:13:50,120 --> 00:13:51,380
ここまでで一つやっていない事として、

388
00:13:51,590 --> 00:13:53,190
以下の数学的証明を与えていない事だ。

389
00:13:53,520 --> 00:13:54,600
それはk次元部分空間への、

390
00:13:54,970 --> 00:13:56,560
k次元平面への

391
00:13:57,230 --> 00:13:58,730
データの射影が、実際に

392
00:13:58,870 --> 00:14:00,620
二乗射影誤差を

393
00:14:02,170 --> 00:14:04,800
最小化する、という事。

394
00:14:05,110 --> 00:14:07,170
それの証明はこのコースのスコープを越える。

395
00:14:07,700 --> 00:14:09,110
幸運な事に、PCAのアルゴリズムは

396
00:14:09,470 --> 00:14:10,940
そんなたくさんのコードにならずに

397
00:14:11,320 --> 00:14:12,510
実装する事が可能だ。

398
00:14:13,190 --> 00:14:14,510
そしてこのアルゴリズムを

399
00:14:14,640 --> 00:14:16,120
octaveで実装してしまえば、

400
00:14:16,520 --> 00:14:17,590
あなたはとても効率的な次元削減の

401
00:14:18,110 --> 00:14:19,710
アルゴリズムを得る事が出来る。

402
00:14:22,430 --> 00:14:23,850
以上がPCAアルゴリズムだ。

403
00:14:25,010 --> 00:14:26,290
一つまだやってない事としては、

404
00:14:26,840 --> 00:14:28,420
u1とかu2などや、zなどが、

405
00:14:29,170 --> 00:14:30,360
ここまでの手続きで得られる

406
00:14:30,720 --> 00:14:31,630
これらのベクトルが

407
00:14:31,770 --> 00:14:32,830
これらの二乗射影誤差を

408
00:14:32,980 --> 00:14:34,330
本当に最小化している、という

409
00:14:34,680 --> 00:14:35,870
数学的な証明を

410
00:14:36,500 --> 00:14:37,800
与える事だ。

411
00:14:38,140 --> 00:14:39,350
いいかい？思い出してみよう。

412
00:14:39,610 --> 00:14:40,660
PCAがやろうとしているのは、

413
00:14:40,960 --> 00:14:42,170
データを射影する

414
00:14:42,570 --> 00:14:43,690
平面とか直線で、

415
00:14:44,280 --> 00:14:46,340
二乗射影誤差を最小化する物を探す、という事だった。

416
00:14:46,700 --> 00:14:48,610
そしてこれが、その条件をみたしている、とは証明していない。

417
00:14:49,140 --> 00:14:50,680
そしてその数学的証明は

418
00:14:50,970 --> 00:14:52,520
このコースの範囲を超えちゃう。

419
00:14:53,170 --> 00:14:55,550
だが幸運な事に、PCAのアルゴリズムは

420
00:14:55,730 --> 00:14:58,890
Octaveのコードではそんなにたくさんの行をかけずに実装出来る。

421
00:14:59,350 --> 00:15:00,740
そしてもしこれを実装すれば、

422
00:15:01,430 --> 00:15:02,560
これは実際にうまく

423
00:15:02,770 --> 00:15:03,730
機能する。

424
00:15:04,710 --> 00:15:05,940
そしてこのアルゴリズムを実装する事で、

425
00:15:06,500 --> 00:15:09,220
とても有効な次元削減のアルゴリズムを得る事が出来るのだ。

426
00:15:09,780 --> 00:15:10,650
それは射影二乗誤差を最小化するという

427
00:15:11,050 --> 00:15:13,460
仕事を正しくこなす。