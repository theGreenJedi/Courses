इस वीडियो में, मैं चाहूँगा आपको बताना प्रिन्सिपल कम्पोनेंट अनालिसिस अल्गोरिद्म के बारे में. और अंत तक इस वीडीयो के आप इम्प्लमेंट कर पाएँगे PCA ख़ुद से. और इस्तेमाल कर पाएँगे इसे कम करने के लिए डिमेन्शन आपके डेटा की. PCA अप्लाई करने से पहले, होता है एक डेटा प्री-प्रॉसेसिंग सटेप जो आपको हमेशा करना चाहिए. दिया होने पर ट्रेनिंग सेट इग्ज़ाम्पल्ज़ का यह महत्वपूर्ण है हमेशा करना मीन नॉर्मलाइज़ेशन, और फिर निर्भर करते हुए आपके डेटा पर, शायद करना फ़ीचर स्केलिंग भी. यह बहुत ही समान है मीन नॉर्मलाइज़ेशन और फ़ीचर स्केलिंग प्रक्रिया के जो हमारे पास है सूपर्वायज़्ड लर्निंग के लिए. वास्तव में यह है बिल्कुल वही प्रक्रिया सिवाय कि हम कर रहे हैं इसे अब हमारे अनलेबल्ड डेटा को, x1 से xm तक. अत: मीन नॉर्मलाइज़ेशन के लिए हम पहले कम्प्यूट करते हैं मीन प्रत्येक फ़ीचर की और फिर हम बदल देते हैं प्रत्येक फ़ीचर, x को x घटा इसकी मीन से, और इसलिए इससे प्रत्येक फ़ीचर की मीन अब हो जाती है ज़ीरो विभिन्न फ़ीचर्ज़ के होते हैं भिन्न स्केल्ज़. अत: उदाहरण के लिए, यदि x1 है साइज़ एक घर का, और x2 है संख्या शयन कक्षों की, इस्तेमाल करते हुए हमारा पिछला उदाहरण, हम फिर स्केल भी करते हैं प्रत्येक फ़ीचर को ताकि उनकी हो तुलनात्मक रेंज वैल्यूज़ की. और इसी प्रकार जैसे हमारे पास था सूपर्वायज़्ड लर्निंग में, हम लेंगे x i,सबस्क्रिप्ट j, जो है फ़ीचर j और इसलिए हम करेंगे घटा मीन, अब वह हमारे पास है ऊपर और फिर विभाजित करेंगे sj से. यहाँ, sj है माप बीटा वैल्यूज़ का फ़ीचर j की. तो यह हो सकता है max माइनस min वैल्यू, या अधिक साधारणतया, यह है स्टैंडर्ड डीवीएशन फ़ीचर j का. कर लेने के बाद इस तरह की डेटा प्री-प्रासेसिंग, यहाँ है जो PCA अल्गोरिद्म करता है. हमने देखा पिछले वीडियो में कि PCA क्या करता है कि, यह कोशिश करता है ढूँढने की एक कम डिमेन्शन की सब-स्पेस जिस पर प्रोजेक्ट करें डेटा को, ताकि न्यूनतम हो जाए यह स्क्वेर्ड प्रोजेक्शन एरर, सम स्क्वेर्ड प्रोजेक्शन एरर का, स्क्वेर लम्बाई का उन नीली लाइन्स का और इसलिए हम क्या करना चाहते थे, विशेषतौर से ढूँढना एक वेक्टर, u1, जो निर्दिष्ट करता है वह दिशा या 2D के केस में हम चाहते हैं ढूँढना दो वेक्टर्स, u1 और u2, परिभाषित करने के लिए यह सरफ़ेस जिस पर प्रोजेक्ट कर सकते हैं डेटा. तो, बस एक जल्दी से स्मरण कराने के लिए क्या कम करने का मतलब है डिमेन्शन्स को, इस उदाहरण के लिए जो बाईं तरफ़ है हमें दिए गए थे इग्ज़ाम्पल xi जो हैं R2 में. और क्या हम चाहते हैं हैं ढूँढे एक सेट नम्बर्ज़ zi का R में दर्शाने के लिए हमारा डेटा. तो वह है कम करने का मतलब 2D से 1D में. तो विशेष रूप से प्रोजेक्ट करना डेटा को इस लाल लाइन पर वहाँ. हमें चाहिए केवल एक नम्बर निर्दिष्ट करने के लिए पोईँट्स को लाइन पर. तो मैं कहूँगा उस नम्बर को z या z1. z यहाँ है एक रियल नम्बर, तो वह है जैसे एक डिमेन्शन का वेक्टर. तो z1 रेफ़र करता है पहले कम्पोनेंट को इसका, आप जानते हैं, एक बाई एक मेट्रिक्स, या यह एक डिमेन्शन का वेक्टर. और इसलिए हमें चाहिए केवल एक नम्बर निर्दिष्ट करने के लिए पोज़िशन एक पोईँट की. तो यदि यह इग्ज़ाम्पल यहाँ था मेरा इग्ज़ाम्पल x1, तब शायद वह मैप होता है यहाँ. और यदि यह इग्ज़ाम्पल था x2 हो सकता है वह इग्ज़ाम्पल मैप होता है और इसलिए यह पोईँट यहाँ होगा z1 और यह पोईँट यहाँ होगा z2, और इसी प्रकार हमें मिलेंगे वे अन्य पोईँट्स. इनके लिए, शायद x3, x4, x5 मैप होते हैं z3, z4, z5 पर. तो PCA को क्या करना है कि हमें चाहिए बनाना एक ढंग कम्प्यूट करने का दो चीज़ें. एक है कम्प्यूट करना ये वेक्टर्स, u1, और इस केस में u1 और u2. और दूसरा है कैसे कम्प्यूट करते हैं हम ये नम्बर्स, z. तो उदाहरण में जो बाईं तरफ़ है हम कम कर रहे हैं डेटा को 2D से 1D में. उदाहरण में दाईं तरफ़ के, हम कम कर रहे हैं डेटा को 3 डिमेन्शन से जो हैं R3 से zi में जो है दो डिमेन्शन का. तो ये z वेक्टर्स अब होंगे दो डिमेन्शन के. तो यह होगा z1 z2 इस तरह, और इसलिए हमें चाहिए एक ढंग कम्प्यूट करने के लिये ये नई रेप्रेज़ेंटेशन्स, z1 z2 डेटा की भी. तो कैसे कम्प्यूट करते हैं ये सब संख्याएँ? ऐसा होता है कि एक गणितीय डेरिवेशन, गणितीय प्रूफ़ भी, कि क्या हैं सही वैल्यूज़ u1, u2, z1, z2 इत्यादि की. गणितीय प्रमाण है बहुत जटिल और बाहर है स्कोप से इस कोर्स के. लेकिन एक बार आपने कर लिया है तो ऐसा है कि प्रक्रिया है वास्तव में जानना वैल्यू u1 जो आप चाहते हैं उतनी मुश्किल नहीं है, भले ही गणितीय प्रमाण है कि यह वैल्यू है सही वैल्यू थोड़ा कठिन हैं और ज़्यादा है उससे जो मैं करना चाहता हूँ. लेकिन मैं सिर्फ़ वर्णन करता हूँ विशिष्ट प्रक्रिया का जो आपको इम्प्लमेंट करनी हैं करने के लिए कम्प्यूटर सारी ये चीज़ें, वेक्टर्स, u1, u2, वेक्टर z. यहाँ है प्रक्रिया. मान लो हम चाहते हैं कम करना डेटा को n डिमेन्शन से k डिमेन्शन पर. हम क्या करेंगे कि पहले कम्प्यूट करें कुछ जिसे कहते हैं को-वेरीयन्स मेट्रिक्स, और कोवेरीयन्स मेट्रिक्स को आमतौर पर डिनोट करते हैं ग्रीक वर्ण से जो है कैपिटल ग्रीक वर्ण सिग्मा. यह थोड़ा दुर्भाग्यपूर्ण है कि ग्रीक वर्ण सिग्मा दिखता हैं एकदम समेशन चिन्ह जैसे. तो यह है ग्रीक वर्ण सिग्मा जो इस्तेमाल करते हैं डिनोट करने के लिए एक मेट्रिक्स, और यह है समेशन चिन्ह. तो, उम्मीद है इन स्लाइड्स में कोई अस्पष्टता नहीं होगी कि कौन सा सिग्मा मेट्रिक्स, मेट्रिक्स, कौन सा है एक समेशन चिन्ह, और उम्मीद है यह स्पष्ट हो जाएगा संदर्भ से जब मैं प्रत्येक को इस्तेमाल करूँगा. कैसे कम्प्यूट करते हैं आप यह मेट्रिक्स? मान लो हम चाहते हैं स्टोर करना इसे ओकटेव के वेरीयबल में जिसे सिग्मा कहते हैं. हमें क्या करने की जरूरत है कि कम्प्यूट करें कुछ जिसे कहते हैं आइगन वेक्टर्स मेट्रिक्स सिग्मा के. और ओकटेव में जिस तरह आप वह करते हैं कि आप इस्तेमाल करते हैं यह कमांड u s v बराबर है s v d ऑफ़ सिग्मा. SVD, का मतलब है सिंगुलर वैल्यू डीकॉम्पज़िशन. यह है एक अधिक उन्नत सिंगुलर वैल्यू डीकॉम्पज़िशन. यह है बहुत अधिक एडवांस्ड लिनीअर ऐल्जेब्रा तुलना में जो वास्तव में आपको जानने की आवश्यकता है. लेकिन अब ऐसा होता है कि जब सिग्मा है बराबर मेट्रिक्स के, ऐसे कुछ ही ढंग हैं कम्प्यूट करने के ये आइगन वेक्टर्स और यदि आप अच्छी तरह से परिचित हैं लिनीअर ऐल्जेब्रा से और यदि अपने सुना है आइगन वेक्टर्स के बारे में पहले से आप शायद जानते होंगे कि एक और ओकटेव फ़ंक्शन है जिसे कहते हैं I, जो किया जा सकता इस्तेमाल कम्प्यूट करने के लिए यही चीज़. और यह होता है कि SVD फ़ंक्शन और I फ़ंक्शन ये देंगे आपको वही वेक्टर्स, हालाँकि SVD है थोड़ा अधिक नूमेरिक्ली स्थिर. तो मैं अक्सर SVD इस्तेमाल करता हूँ, जबकि मेरे कुछ मित्र हैं जो इस्तेमाल करते हैं I फ़ंक्शन करने के लिए इसे भी, लेकिन जब आप अप्लाई करते हैं इसे एक कोवेरीयन्स मेट्रिक्स सिग्मा पर यह देता है आपको वही चीज़. यह इसलिए क्योंकि कोवेरीयन्स मेट्रिक्स हमेशा संतुष्ट करती है एक गणितीय गुण जिसे कहते हैं सेमेट्रिक पॉज़िटिव डेफ़िनिट. आपको वास्तव में जरूरत नहीं है जानना उसका क्या मतलब है, लेकिन SVD I-फ़ंक्शन भिन्न फ़ंक्शन्स हैं लेकिन जब वे अप्लाई किए जाते हैं एक को-वेरीयन्स मेट्रिक्स को जो किया जा सकता है प्रमाणित कि हमेशा संतुष्ट करती हैं यह गणितीय गुण; वे हमेशा देंगे आपको वही चीज़. ठीक है, वह था शायद बहुत अधिक लिनीअर ऐल्जेब्रा 
तुलना में जितना आपको जानने की आवश्यकता है. यदि यह समझ नहीं आता है, तो इसकी चिंता न करें. आपको सिर्फ़ जानने की आवश्यकता है कि यह सिस्टम कमांड आपको करनी चाहिए इम्प्लमेंट ओकटेव में. और यदि आप इम्प्लमेंट कर रहे हैं इसे एक ओकटेव या मैटलैब के अलावा किसी और लैंग्विज में, आपको क्या करना चाहिए कि जाने नूमेरिकल लिनीअर ऐल्जेब्रा लाइब्रेरी कम्प्यूट कर सकती है SVD या सिंगुलर वैल्यू डीकॉम्पज़िशन, और ऐसी बहुत सी लाइब्रेरीस है शायद सभी प्रमुख प्रोग्रामिंग लैंग्विजेज़ के लिए. लोग इस्तेमाल कर सकते हैं उनका कम्प्यूट करने के लिए मेट्रिसीज़ u, s, और d कोवेरीयन्स मेट्रिक्स सिग्मा की. तो सिर्फ़ डालने के लिए कुछ और जानकारी, यह कोवेरीयन्स मैट्रिक्स सिग्मा होगी एक n बाई n मेट्रिक्स. एक तरीक़ा देखने का उसे है कि यदि आप देखते हैं परिभाषा यह है एक n बाई 1 वेक्टर और यह यहाँ I ट्रान्स्पोज़ है 1 बाई n सो गुणन इन दो चीज़ों का होगा एक n बाई n मेट्रिक्स. 1 x n ट्रान्स्पोज़, 1 x n, तो वह है एक n x n मेट्रिक्स और जब जोड़ते हैं ये सब आपके पास अभी भी है एक n x n मेट्रिक्स. और SVD आउट्पुट करता है क्या तीन मेट्रिसीज़, u, s, और v. जो चीज़ आपको वास्तव में चाहिए SVD से है u मेट्रिक्स. u मेट्रिक्स भी होगी एक n x n मेट्रिक्स. और यदि हम देखते हैं कॉलम्स पर u मेट्रिक्स के, ऐसा होता है कि कॉलम्स u मेट्रिक्स के होंगे बिल्कुल समान उन वेक्टर्स के, u1, u2 इत्यादि. तो u, होगी मेट्रिक्स. और यदि हम चाहते हैं कम करना डेटा को n डिमेन्शन से नीचे k डिमेन्शन्स तक, तब क्या हमें करना चाहिए कि लें पहले k वेक्टर्स. वह देता है हमें u1 से uk तक जो देता है हमें K दिशाएँ जिन पर हम प्रोजेक्ट करना चाहते हैं डेटा. बाक़ी की प्रक्रिया से इस SVD नूमेरिकल लिनीअर ऐल्जेब्रा रूटीन से हमें मिलती है यह मेट्रिक्स u. हम कहेंगे इन कॉलम्स को u1-uN. तो, समाप्त करते हुए वर्णन बाक़ी की प्रक्रिया का, SVD नूमेरिकल लिनीअर ऐल्जेब्रा रूटीन से हमें मिलती हैं ये मेट्रिसीज़ u, s, और d, हम करेंगे इस्तेमाल पहले K कॉलन्स का मेट्रिक्स के पाने के लिए u1-uK. अब दूसरी चीज़ हमें चाहिए कि लें मेरा प्रारम्भिक डेटा सेट, x जो है एक Rn और ढूँढे एक कम डिमेन्शन की रेप्रेज़ेंटेशन z, जो है एक RK इस डेटा के लिए. तो जिस तरह हम करंगे वह कि लेंगे पहले K कॉलम्स u मेट्रिक्स के. बनाएँगे यह मेट्रिक्स. जोड़ेंगे u1, u2 और इसी तरह uK तक कॉलम्स में. यह वास्तव में लेना, आप जानते हैं, यह हिस्सा मेट्रिक्स का, लेंगे पहले K कॉलम्स इस मेट्रिक्स के. और इसलिए यह है होगी एक n बाई K मेट्रिक्स. मैं दूँगा इस मेट्रिक्स को एक नाम. मैं कहूँगा इस मेट्रिक्स को U सब्स्क्रिप्ट "रेडूस", एक तरह से एक छोटा वर्ज़न U मेट्रिक्स का शायद. मैं करूँगा इस्तेमाल इसे कम करने के लिए डिमेन्शन मेरे डेटा की. और जिस तरह मैं कम्प्यूट करूँगा z होगा कि रखूँ z बराबर इस U reduce मेट्रिक्स ट्रान्स्पोज़ गुणा x. या वैकल्पिक रूप से, आप जानते हैं, लिखते हैं इस ट्रान्स्पोज़ का क्या मतलब है. जब मैं लेता हूँ ट्रान्स्पोज़ इस U मेट्रिक्स का, क्या मुझे मिलेगा यही वेक्टर्स अब रोज़ में. मेरे पास है u1 ट्रान्स्पोज़ से uK ट्रान्स्पोज़ तक. फिर ले वह गुणा X, और इस तरह मुझे मिलता है मेरा वेक्टर z. सिर्फ़ सुनिश्चित करें कि ये डिमेन्शन्स समझ आयी हैं, यह मेट्रिक्स यहाँ होगी k बाई n और x यहाँ होगा n बाई 1 और इसलिए गुणन यहाँ होगा k बाई 1. और इसलिए z है k डिमेन्शन्स का, है एक k डिमेन्शनल वेक्टर, जो है एकदम वही जो हम चाहते थे. और निश्चय ही ये x यहाँ, ठीक है, हो सकते हैं इग्ज़ाम्पल्ज़ हमारे ट्रेनिंग सेट में, हो सकते हैं इग्ज़ाम्पल्ज़ हमारे क्रॉस-वैलिडेशन सेट में, हो सकते हैं इग्ज़ाम्पल्ज़ हमारे टेस्ट सेट में, और उदाहरण के लिए यदि, आप जानते हैं, मैं चाहता हूँ लेना ट्रेनिंग सेट इग्ज़ाम्पल i, मैं लिख सकता हूँ इसे xi XI और वह है जो देगा मुझे ZI वहाँ पर. अत: सारांश में, यहाँ है PCA अल्गोरिद्म के स्लाइड पर. मीन नोर्मलाइज़ेशन के बाद, सुनिश्चित करने के लिए प्रत्येक फ़ीचर की है ज़ीरो मीन और वैकल्पिक फ़ीचर स्केलिंग जो आपको वास्तव में अवश्य करनी चाहिए फ़ीचर स्केलिंग यदि आपके फ़ीचर्ज़ लेते हैं बहुत भिन्न भिन्न रेंज वैल्यूज़ की. और इस प्री-प्रासेसिंग के बाद हम कम्प्यूट करते हैं को-वेरीयन्स मेट्रिक्स सिग्मा इस तरह, वैसे तो, यदि आपका डेटा दिया है एक मेट्रिक्स जैसे इस तरह यदि आपके पास है आपका डेटा दिया रोज़ में इस तरह. यदि आपके पास है एक मेट्रिक्स X जो है आपका ट्रेनिंग सेट लिखा हुआ रोज़ में जहाँ x1 ट्रैन्स्पोज़ से x n ट्रान्स्पोज़ तक, इस को-वेरीयन्स मेट्रिक्स सिग्मा में है वास्तव में एक अच्छी वेक्टराइज्ड इम्प्लमेंटेशन. आप इम्प्लमेंट कर सकते हैं ओकटेव में, आप रन भी कर सकते हैं सिग्मा बराबर 1 ओवर m, गुणा x, जो है यह मेट्रिक्स ऊपर यहाँ, ट्रान्स्पोज़ गुणा x और यह सरल इक्स्प्रेशन, वह है वेक्टराइज्ड इम्प्लमेंटेशन कि कैसे कम्प्यूट करते हैं मेट्रिक्स सिग्मा. मैं नहीं करूँगा उसे प्रूव / प्रमाणित आज. यह है सही वेक्टराइज़ेशन यदि आप चाहें, आप या तो नूमेरिक्ली टेस्ट कर सकते हैं इसे अपने आप ट्राई कर एक ओकटेव की और तय करने से कि दोनो यह और यह इम्प्लमेंटेशन देती हैं समान उत्तर या आप ख़ुद प्रयास कर सकते हैं प्रमाणित करने का उसे गणितीय रूप में. किसी भी तरह लेकिन यह है सही वेक्टराइज्ड इम्प्लमेंटेशन, बिना कम्प्यूट किए इसे. फिर हम अप्लाई कर सकते हैं SVD रूटीन पाने के लिए u, s, और d. और फिर हम लेते हैं पहले K कॉलम्स u मेट्रिक्स के U reduce में और अंत में यह परिभाषित करता है कैसे हम जाते हैं एक फ़ीचर x से इस कम डिमेन्शन की रेप्रेज़ेंटेशन z में. और K-मीन्स के समान यदि आप अप्लाई करते हैं PCA, जिस तरह आप अप्लाई करेंगे है कि वेक्टर्स x और Rn के साथ. तो, यह नहीं करते x01 के साथ. तो वह था PCA अल्गोरिद्म. एक काम जो मैंने नहीं किया है कि नहीं दिया है गणितीय प्रमाण कि यह वास्तव में देता है प्रजेक्शन डेटा का Kडिमेन्शन की सब-स्पेस K डिमेन्शन की सरफ़ेस पर जो वास्तव में न्यूनतम करता है स्क्वेर्ड प्रोजेक्शन एरर. प्रूफ़ उसका बाहर है स्कोप से इस कोर्स के. सौभाग्य से PCA अल्गोरिद्म किया जा सकता है इम्प्लमेंट बहुत कम लाइन्स से कोड की. और यदि आप इम्प्लमेंट करते हैं इसे ओकटेव में या मैटलैब में, आपको वास्तव में मिलता है एक बहुत प्रभावशाली डिमेन्शनैलिटी रिडक्शन अल्गोरिद्म की. तो वह था PCA अल्गोरिद्म. एक काम जो मैंने नहीं किया था कि नहीं दिया है गणितीय प्रमाण कि u1 और u2 इत्यादि और z इत्यादि जो आपको मिलते हैं इस प्रक्रिया से, वास्तव में है विकल्प, जो करेगा न्यूनतम/ मिनमायज़ इस स्क्वेर्ड प्रोजेक्शन एरर को. ठीक है, याद रखें कि हमने कहा है कि क्या PCA करने की कोशिश करता हैं कि ढूँढे एक सरफ़ेस या लाइन जिस पर प्रोजेक्ट कर सकते हैं डेटा ताकि यह स्क्वेर्ड प्रोजेक्शन एरर न्यूनतम हो जाए. तो मैंने नहीं साबित किया इसे कि, और गणितीय प्रमाण उसका बाहर है स्कोप से इस कोर्स के. लेकिन सौभाग्य से PCA अल्गोरिद्म किया जा सकता है इम्प्लमेंट बहुत कम लाइन्स से ओकटेव कोड की. और यदि आप इम्प्लमेंट करते हैं इसे, यह है वास्तव में जो करेगा काम, या यह काम करेगा सही, और यदि आप इम्प्लमेंट करते हैं यह अल्गोरिद्म, आपको मिलता है एक बहुत प्रभावी डिमेन्शनैलिटी रिडक्शन अल्गोरिद्म. जो करता है सही काम न्यूनतम करने का यह स्क्वेर्ड प्रोजेक्शन एरर.