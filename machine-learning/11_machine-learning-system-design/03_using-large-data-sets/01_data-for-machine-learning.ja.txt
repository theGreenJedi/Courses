前回のビデオで、我らは評価メトリクス(指標)に関して議論してきた。 このビデオでは トラックをちょっと変更して 機械学習のシステムのデザインにおいて しばしば表面化する もう一つの重要な一面であるところの、 どれだけのデータを試すか？という問題について 触れていきたい。 以前のビデオでは、 盲目的に外に出て 大量のデータを集めるという事を 戒めてきた。 何故ならそれは役に立つ場合と立たない場合が あるからだ。 しかし、ある条件下では、 そしてその条件が何なのかは このビデオで伝えるが、 ある種の学習アルゴリズムに対してなら 大量のデータを 得る事は、 学習アルゴリズムに とても良いパフォーマンスで動かす為の とても効率的な方法たりえる。 そしてこの事から、とてもしばしば あなたの問題において これらの条件を真のまま維持出来て そしてもしあなたが大量のデータを得る事が出来れば、 これはとても高いパフォーマンスの 学習アルゴリズムを得る とても良い方法になり得る。 だからこのビデオで、 この事についてもっと議論していこう。 まずこんなストーリーから始めよう。 何年も前の事、二人の研究者、 Michello BankoとEric Brillは 以下のような魅力的な研究を行った。 彼らは異なるアルゴリズムを使う事と 異なるトレーニングセットのサイズを 使う事の効果の 対決に興味があった。 彼らはややこしい単語間での 分類問題を検討した。 例えばこんな文の中では： For breakfast I ateなら、入る単語はtwoだろうか？tooだろうか？ この例の場合、 For breakfast I ateで「two」つまり「2」個の玉子を食べる。 つまり、これがややこしい単語の集合の一例で、 これもまた別の集合の例だ。 そして彼らはこのような 機械学習の問題、ある種の教師あり学習の問題であるところの、 英語の文の中の ある位置に来る単語は どの単語が適切かを 分類しようとする問題に対して、 彼らは幾つか異なる 学習アルゴリズムを用いてーー それらはその当時、 彼らが研究を行った2001年だが、 その当時最先端とみなされていた物達で、 彼らはだいたい ロジスティック回帰の 変種のような物である所のPerceptronと、 その当時は 結構良く使われてたが 昨今はあまり使われてないような Winnowアルゴリズムと、 これまたロジスティック回帰に 類似した物たが 多少違う物で たくさん使われていたが 今はあまり使われていない Memory-Basedと呼ばれる 学習アルゴリズムで、最近はあまり使われてないが あとでちょっとだけこれについては触れる。 そしてナイーブなベイズアルゴリズム、 これは彼らがこのコースで 実際に語ってくれる。 これらのアルゴリズムの正確な詳細は、重要では無い。 この事は、単に4つの異なる分類アルゴリズムを 選んだ、と考えるべきだ。アルゴリズムが実際になんなのかは重要では無い。 彼らがやった事は、 トレーニングセットのサイズを変えて、 これらの学習アルゴリズムを そのトレーニングセットサイズの範囲のトレーニングセット群に対して 試してみた。そしてその結果がこれだ。 その傾向ははっきりしてる。 まず、これらのアルゴリズムはほとんど、 驚くほど似たようなパフォーマンスを与える。 二番目に、トレーニングセットのサイズが 増加していくにつれて、 ここで横軸が100万を単位とした トレーニングセットのサイズで、 見ての通り10万から 1000の100万、つまり 10億のトレーニング手本までの範囲を とっている。 アルゴリズムのパフォーマンスは全て だいたい単調に増加していて、 そしてあなたが どんなアルゴリズムを選ぼうと、 たとえ、いわゆる「劣ったアルゴリズム」を選ぼうと、 その「劣ったアルゴリズム」に より多くのデータを与えさえすれば、 これらの例から分かる事は、 より「優れたアルゴリズム」を打ち負かすだろう。 この起源となる研究は とても影響力があったので、 この他に様々な研究が行われたが、 似たような結果を示した。 つまり、多くの異なる学習アルゴリズムは 時には詳細に依存する事もあるが、 傾向としてはだいたい 似たような範囲のパフォーマンスを示し、 本当にパフォーマンスを先導するのは アルゴリズムに大量のトレーニングデータを与える事が出来るかどうかだ、という結果を示している。 そこでこれらの結果は 機械学習においては こう言われる事になる： 機械学習においてしばしば勝者になるのは、 もっとも良いアルゴリズムを持つ者では無く、 もっとも多くのデータを持つ者だ、と。 ではそれが事実であるのはどういう時で、 それが事実で無いのはどういう時だろう？ 何故そんな事に興味を持つかといえば、 もしこの条件が真である学習アルゴリズムを持っているなら、 その時はたくさんのデータを 得る事は、しばしば とても高いパフォーマンスの アルゴリズムを得る為の ベストな方法である事が多いからだ、 これらのアルゴリズムのどれを使ったらいいか、にかかずらうよりは。 では大量のトレーニングセットを持つ事が 役に立ちそうと思えるような 一連の条件を並べてみよう。 我らの機械学習の問題においては、 フィーチャーxが yを正確に予測するのに 十分な情報を持っている事を仮定しよう。 例えば、もし前のスライドの ややこしい単語の例の場合を考えるとすると、 フィーチャーxが 我らが埋めようとしている空白の回りの 単語を捕捉しているとすると、 つまりフィーチャーは 「For breakfast, I have 空白 eggs」という文を捉えているとすると、 その場合は、うん、私がこの間に 欲しい単語はtwoである、と 分かるだけの そしてtoでもtooでも無いと分かるだけの 十分な情報がある。 だから、フィーチャーが これらの回りの単語を捉えているなら、 ラベルyが何なのか？という事を かなり曖昧さ無しで決める為に 十分な情報を持っている。 ラベルyが何かという事を言い換えると、 これら三つのややこしい単語の どれを使って空白を 埋めるべきか？という事だ。 つまりこれは、フィーチャーxが 特定のyについて十分な情報を 持っている例だ。 これの反対の例としては、 住宅の価格を予測する時に 住宅のサイズだけで 他のフィーチャーが何も無いような 予測の問題を考えてみよう。 私があなたに 住宅の価格は500平方フィートだ、とだけ伝えて それ以外の情報を 何も伝えなかったとする。 その住居が町の 高い地区にあるとも言わないし、 あるいは私はあなたに その住居の部屋の数も 言わないし、あるいは どれくらい素晴らしい家具を備えているかも言わないし、 その住居が新しいか古いかも言わない。 もし私が、この家が500平方フィート という情報以外を 何も言わなければ、 住居の価格に 影響を与える要因は 住居のサイズ以外にも あまりにもたくさんあるので、 あなたがサイズしか知らなければ、 その価格を正確に予測するのはとても困難だ。 だから以上は、この仮定、 フィーチャーが望む水準の正確さで 価格を推測するのに十分な情報を持っている、という仮定の 反例と言えると思う。 私がこの仮定をテストする方法は、 私が良くやる 方法の一つに、良く自分自身に問うのは、 入力のフィーチャーxが与えられた時に このフィーチャーが与えられた時、 学習アルゴリズムと同様の情報が入手可能だった時に、 仮にこのドメインの人間のエキスパートの元に赴いたとすると、 実際に人間のエキスパートが予想をする事が、 あるいは実際に人間のエキスパートが確信を持ってyの値を 予想する事が出来るだろうか？と。 この最初の例の場合、 人間の英語話者の専門家の所に行って、、、 英語をうまく話せる人の 所に行けば、 英語の専門家の人間なら、 単に読むだけで、あなたとか私みたいな 多くの人々なら、 ここに入るのが何であるのかを 予測出来るだろう、 英語の得意な話者なら、 これをうまく予測出来る。 つまりこれで私は、 xでyを正しく予測出来る、ということに、 確信が持てる。だがこれに対して 我らがもし住居の価格の専門家、 例えば住宅を売る不動産屋とか とにかく住居を売る事で生計を立ててる人の所に行き、 そしれ彼らに家のサイズを 伝えて、 そして彼らに価格は幾らか？と聞けば、 たとえ住宅の価格や販売の エキスパートであっても、 私に言う事は出来ないだろう、 つまりこれは、住宅の価格の例で、 サイズを知るだけでは 住宅の価格を予測するのに 十分な情報では無い、という サインである。 そこで、この前提を維持したままで、 大量のデータを得る事が 助けとなるかを見てみよう。 yの値を予測するのに 十分な情報を持つ フィーチャーを得ていたとしよう。 そしてたくさんのパラメータの 学習アルゴリズムを 用いる事にしよう。 それはロジスティック回帰かもしれないし、 たくさんのフィーチャーの線形回帰かもしれない。 あるいは、私が時々やる事として、、、 私が実際に良くやる事としては、 たくさんの隠れユニットを持ったニューラルネットワークを使う、というやり方もある。 これもまたたくさんのパラメータを持つ 学習アルゴリズムと言える。 つまり、これらは全て、 たくさんのパラメータを持つ強力なアルゴリズムであり、 とても複雑な関数にフィッティング出来る。 そこで私はこれらを、 低バイアスのアルゴリズムと呼び、 そうみなしていく事にする。何故なら とても複雑な関数にフィッティング出来るから。 我らはとても強力な 学習アルゴリズムを持っているから、 それらは複雑な関数にフィッティング出来るのだ。 たぶん、 これらのアルゴリズムを データセットに対して実行すると、 トレーニングセットに良くフィットするように出来るだろう。 つまり、 トレーニング誤差は小さくなる事が期待出来る。 ここで、大量の、本当に大量の トレーニングセットを用いる事にしよう。 その場合、我らに巨大な トレーニングセットがあれば、 たとえたくさんのパラメータがあっても、 パラメータの数に対してでさえ 十分に大量のトレーニングセットであれば、 これらのアルゴリズムは オーバーフィットしそうには無い。 何故なら我らは そんなにも巨大なトレーニングセットを持っているのだから。 そしてオーバーフィットしなさそう、という事は トレーニング誤差は テスト誤差と 近い事が期待される、という事を意味する。 最後に、これら二つをあわせると、 トレーニングセット誤差は 小さくて、 テストセット誤差はトレーニング誤差と 近くなる、 これら二つをあわせると、 テストセット誤差も小さくなるだろう事が 期待される。 これのもう一つ別の 考え方としては、 高いパフォーマンスの 学習アルゴリズムを得る為に、 それが高バイアスでも高バリアンスでも無い事を望む。 そこでバイアスの問題に対して、 我らは学習アルゴリズムが たくさんのパラメータを持つ事で 低バイアスのアルゴリズムとなるようにしつつ、 一方でとても大量のトレーニングセットを 用いる事で、 これはバリアンスの問題が無い事を 保証してくれる。 つまり我らのアルゴリズムに バリアンスの問題が無い事が期待出来て、 そしてこれら二つを合わせる事で、 結局は低バイアス、 低バリアンスの 学習アルゴリズムとなる。 そしてこれは、テストセットにおいて とても良く振舞ってくれる。 それは本質的には、鍵となる想定は、 フィーチャーが 十分な情報を持っている事、 そしてリッチなクラスの関数である事で 低バイアスである事を保証し、 そして次に大量のトレーニングセットを持つ事で 低バリアンスである事を保証する訳だ。 つまり、これが我らに 以下のような一連の条件を 持った問題： より多くのデータを持って たくさんのパラメータの 学習アルゴリズムを 訓練するような物。それは 高いパフォーマンスの学習アルゴリズムを 得る為の良い方法たりえる。 そして実際に、私がキーだと思うテストとして、 自分自身にも良く問う物としては、 まず一つ目の問いは、人間のエキスパートが フィーチャーxを見た時に、 yの値を確信を持って予測出来るか、という事。 何故ならそれは、 フィーチャーxからyが 正確に予測出来る、という 保証となるからだ。 そして二番目の問いは、我らは実際に 大量のトレーニングセットを得る事が出来て、 たくさんのパラメータの学習アルゴリズムを そのトレーニングセットでトレーニング出来るか？という事。 そしてもし両方が可能なら、 それらはきっと、とても高いパフォーマンスの 学習アルゴリズムを与えてくれる事となる。