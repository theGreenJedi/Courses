1
00:00:00,390 --> 00:00:03,570
前回のビデオで、我らは評価メトリクス(指標)に関して議論してきた。

2
00:00:04,730 --> 00:00:05,840
このビデオでは

3
00:00:06,080 --> 00:00:07,230
トラックをちょっと変更して

4
00:00:07,480 --> 00:00:08,900
機械学習のシステムのデザインにおいて

5
00:00:09,570 --> 00:00:10,990
しばしば表面化する

6
00:00:11,800 --> 00:00:13,290
もう一つの重要な一面であるところの、

7
00:00:13,470 --> 00:00:14,990
どれだけのデータを試すか？という問題について

8
00:00:15,270 --> 00:00:17,110
触れていきたい。

9
00:00:17,310 --> 00:00:18,440
以前のビデオでは、

10
00:00:18,620 --> 00:00:20,320
盲目的に外に出て

11
00:00:20,690 --> 00:00:21,660
大量のデータを集めるという事を

12
00:00:21,980 --> 00:00:23,300
戒めてきた。

13
00:00:23,420 --> 00:00:24,730
何故ならそれは役に立つ場合と立たない場合が

14
00:00:25,040 --> 00:00:26,360
あるからだ。

15
00:00:27,510 --> 00:00:28,580
しかし、ある条件下では、

16
00:00:28,820 --> 00:00:30,270
そしてその条件が何なのかは

17
00:00:30,550 --> 00:00:31,580
このビデオで伝えるが、

18
00:00:31,770 --> 00:00:33,590
ある種の学習アルゴリズムに対してなら

19
00:00:33,820 --> 00:00:35,440
大量のデータを

20
00:00:35,730 --> 00:00:36,730
得る事は、

21
00:00:37,010 --> 00:00:38,160
学習アルゴリズムに

22
00:00:38,240 --> 00:00:39,470
とても良いパフォーマンスで動かす為の

23
00:00:39,770 --> 00:00:41,320
とても効率的な方法たりえる。

24
00:00:42,810 --> 00:00:44,280
そしてこの事から、とてもしばしば

25
00:00:44,710 --> 00:00:45,930
あなたの問題において

26
00:00:46,310 --> 00:00:47,850
これらの条件を真のまま維持出来て

27
00:00:47,970 --> 00:00:48,770
そしてもしあなたが大量のデータを得る事が出来れば、

28
00:00:48,980 --> 00:00:50,070
これはとても高いパフォーマンスの

29
00:00:50,210 --> 00:00:51,330
学習アルゴリズムを得る

30
00:00:51,560 --> 00:00:52,970
とても良い方法になり得る。

31
00:00:53,990 --> 00:00:55,620
だからこのビデオで、

32
00:00:56,320 --> 00:00:58,960
この事についてもっと議論していこう。

33
00:00:59,110 --> 00:00:59,820
まずこんなストーリーから始めよう。

34
00:01:01,080 --> 00:01:02,620
何年も前の事、二人の研究者、

35
00:01:03,400 --> 00:01:05,380
Michello BankoとEric Brillは

36
00:01:05,520 --> 00:01:08,110
以下のような魅力的な研究を行った。

37
00:01:09,820 --> 00:01:11,290
彼らは異なるアルゴリズムを使う事と

38
00:01:11,550 --> 00:01:12,910
異なるトレーニングセットのサイズを

39
00:01:13,290 --> 00:01:15,210
使う事の効果の

40
00:01:15,380 --> 00:01:17,420
対決に興味があった。

41
00:01:18,020 --> 00:01:19,550
彼らはややこしい単語間での

42
00:01:20,170 --> 00:01:22,120
分類問題を検討した。

43
00:01:22,550 --> 00:01:23,610
例えばこんな文の中では：

44
00:01:24,410 --> 00:01:26,990
For breakfast I ateなら、入る単語はtwoだろうか？tooだろうか？

45
00:01:27,940 --> 00:01:28,890
この例の場合、

46
00:01:29,450 --> 00:01:32,390
For breakfast I ateで「two」つまり「2」個の玉子を食べる。

47
00:01:33,510 --> 00:01:34,530
つまり、これがややこしい単語の集合の一例で、

48
00:01:35,320 --> 00:01:37,800
これもまた別の集合の例だ。

49
00:01:38,240 --> 00:01:39,650
そして彼らはこのような

50
00:01:39,950 --> 00:01:41,580
機械学習の問題、ある種の教師あり学習の問題であるところの、

51
00:01:41,780 --> 00:01:43,190
英語の文の中の

52
00:01:43,970 --> 00:01:45,210
ある位置に来る単語は

53
00:01:45,400 --> 00:01:46,560
どの単語が適切かを

54
00:01:47,540 --> 00:01:48,140
分類しようとする問題に対して、

55
00:01:51,010 --> 00:01:52,110
彼らは幾つか異なる

56
00:01:52,340 --> 00:01:53,520
学習アルゴリズムを用いてーー

57
00:01:53,730 --> 00:01:55,210
それらはその当時、

58
00:01:55,310 --> 00:01:56,110
彼らが研究を行った2001年だが、

59
00:01:56,410 --> 00:01:57,670
その当時最先端とみなされていた物達で、

60
00:01:57,730 --> 00:01:59,220
彼らはだいたい

61
00:01:59,750 --> 00:02:01,140
ロジスティック回帰の

62
00:02:01,630 --> 00:02:03,180
変種のような物である所のPerceptronと、

63
00:02:03,760 --> 00:02:05,160
その当時は

64
00:02:05,250 --> 00:02:06,700
結構良く使われてたが

65
00:02:07,090 --> 00:02:08,620
昨今はあまり使われてないような

66
00:02:08,830 --> 00:02:10,600
Winnowアルゴリズムと、

67
00:02:10,750 --> 00:02:11,980
これまたロジスティック回帰に

68
00:02:12,380 --> 00:02:13,410
類似した物たが

69
00:02:13,660 --> 00:02:15,580
多少違う物で

70
00:02:16,140 --> 00:02:18,220
たくさん使われていたが

71
00:02:18,480 --> 00:02:19,380
今はあまり使われていない

72
00:02:20,180 --> 00:02:21,180
Memory-Basedと呼ばれる

73
00:02:21,430 --> 00:02:23,240
学習アルゴリズムで、最近はあまり使われてないが

74
00:02:23,610 --> 00:02:25,940
あとでちょっとだけこれについては触れる。

75
00:02:26,230 --> 00:02:27,230
そしてナイーブなベイズアルゴリズム、

76
00:02:27,690 --> 00:02:29,240
これは彼らがこのコースで

77
00:02:29,410 --> 00:02:32,380
実際に語ってくれる。

78
00:02:32,690 --> 00:02:34,400
これらのアルゴリズムの正確な詳細は、重要では無い。

79
00:02:35,040 --> 00:02:36,080
この事は、単に4つの異なる分類アルゴリズムを

80
00:02:36,430 --> 00:02:40,380
選んだ、と考えるべきだ。アルゴリズムが実際になんなのかは重要では無い。

81
00:02:41,980 --> 00:02:42,990
彼らがやった事は、

82
00:02:43,140 --> 00:02:44,160
トレーニングセットのサイズを変えて、

83
00:02:44,500 --> 00:02:45,390
これらの学習アルゴリズムを

84
00:02:45,450 --> 00:02:47,070
そのトレーニングセットサイズの範囲のトレーニングセット群に対して

85
00:02:47,210 --> 00:02:49,640
試してみた。そしてその結果がこれだ。

86
00:02:50,300 --> 00:02:51,310
その傾向ははっきりしてる。

87
00:02:51,470 --> 00:02:53,170
まず、これらのアルゴリズムはほとんど、

88
00:02:53,290 --> 00:02:55,470
驚くほど似たようなパフォーマンスを与える。

89
00:02:56,200 --> 00:02:57,760
二番目に、トレーニングセットのサイズが

90
00:02:58,150 --> 00:02:59,760
増加していくにつれて、

91
00:02:59,860 --> 00:03:00,970
ここで横軸が100万を単位とした

92
00:03:01,280 --> 00:03:02,510
トレーニングセットのサイズで、

93
00:03:04,070 --> 00:03:05,360
見ての通り10万から

94
00:03:05,420 --> 00:03:07,440
1000の100万、つまり

95
00:03:07,720 --> 00:03:09,060
10億のトレーニング手本までの範囲を

96
00:03:09,330 --> 00:03:10,980
とっている。

97
00:03:11,090 --> 00:03:11,860
アルゴリズムのパフォーマンスは全て

98
00:03:12,870 --> 00:03:15,360
だいたい単調に増加していて、

99
00:03:15,740 --> 00:03:16,610
そしてあなたが

100
00:03:16,650 --> 00:03:18,600
どんなアルゴリズムを選ぼうと、

101
00:03:19,000 --> 00:03:21,320
たとえ、いわゆる「劣ったアルゴリズム」を選ぼうと、

102
00:03:21,490 --> 00:03:22,650
その「劣ったアルゴリズム」に

103
00:03:23,190 --> 00:03:26,150
より多くのデータを与えさえすれば、

104
00:03:26,390 --> 00:03:27,570
これらの例から分かる事は、

105
00:03:27,670 --> 00:03:30,330
より「優れたアルゴリズム」を打ち負かすだろう。

106
00:03:32,200 --> 00:03:33,270
この起源となる研究は

107
00:03:33,720 --> 00:03:35,850
とても影響力があったので、

108
00:03:36,360 --> 00:03:37,500
この他に様々な研究が行われたが、

109
00:03:37,830 --> 00:03:39,020
似たような結果を示した。

110
00:03:39,550 --> 00:03:40,840
つまり、多くの異なる学習アルゴリズムは

111
00:03:41,150 --> 00:03:42,270
時には詳細に依存する事もあるが、

112
00:03:42,630 --> 00:03:44,290
傾向としてはだいたい

113
00:03:44,460 --> 00:03:46,060
似たような範囲のパフォーマンスを示し、

114
00:03:46,490 --> 00:03:48,320
本当にパフォーマンスを先導するのは

115
00:03:48,520 --> 00:03:51,570
アルゴリズムに大量のトレーニングデータを与える事が出来るかどうかだ、という結果を示している。

116
00:03:53,190 --> 00:03:54,640
そこでこれらの結果は

117
00:03:55,010 --> 00:03:56,030
機械学習においては

118
00:03:56,130 --> 00:03:57,360
こう言われる事になる：

119
00:03:57,510 --> 00:03:58,920
機械学習においてしばしば勝者になるのは、

120
00:03:59,180 --> 00:04:00,460
もっとも良いアルゴリズムを持つ者では無く、

121
00:04:00,600 --> 00:04:01,720
もっとも多くのデータを持つ者だ、と。

122
00:04:02,810 --> 00:04:04,260
ではそれが事実であるのはどういう時で、

123
00:04:04,460 --> 00:04:06,240
それが事実で無いのはどういう時だろう？

124
00:04:06,560 --> 00:04:07,710
何故そんな事に興味を持つかといえば、

125
00:04:07,850 --> 00:04:09,000
もしこの条件が真である学習アルゴリズムを持っているなら、

126
00:04:09,150 --> 00:04:10,590
その時はたくさんのデータを

127
00:04:10,820 --> 00:04:11,970
得る事は、しばしば

128
00:04:12,620 --> 00:04:13,830
とても高いパフォーマンスの

129
00:04:14,180 --> 00:04:15,700
アルゴリズムを得る為の

130
00:04:15,900 --> 00:04:17,360
ベストな方法である事が多いからだ、

131
00:04:17,520 --> 00:04:20,080
これらのアルゴリズムのどれを使ったらいいか、にかかずらうよりは。

132
00:04:21,710 --> 00:04:23,200
では大量のトレーニングセットを持つ事が

133
00:04:23,330 --> 00:04:25,130
役に立ちそうと思えるような

134
00:04:25,660 --> 00:04:28,230
一連の条件を並べてみよう。

135
00:04:29,780 --> 00:04:31,310
我らの機械学習の問題においては、

136
00:04:31,410 --> 00:04:33,210
フィーチャーxが

137
00:04:34,080 --> 00:04:36,560
yを正確に予測するのに

138
00:04:36,830 --> 00:04:38,600
十分な情報を持っている事を仮定しよう。

139
00:04:40,380 --> 00:04:41,490
例えば、もし前のスライドの

140
00:04:41,790 --> 00:04:44,860
ややこしい単語の例の場合を考えるとすると、

141
00:04:45,740 --> 00:04:47,040
フィーチャーxが

142
00:04:47,520 --> 00:04:48,360
我らが埋めようとしている空白の回りの

143
00:04:49,090 --> 00:04:51,620
単語を捕捉しているとすると、

144
00:04:51,840 --> 00:04:53,630
つまりフィーチャーは

145
00:04:54,220 --> 00:04:56,440
「For breakfast, I have 空白 eggs」という文を捉えているとすると、

146
00:04:57,350 --> 00:04:58,220
その場合は、うん、私がこの間に

147
00:04:58,480 --> 00:04:59,970
欲しい単語はtwoである、と

148
00:05:00,170 --> 00:05:01,050
分かるだけの

149
00:05:01,420 --> 00:05:03,640
そしてtoでもtooでも無いと分かるだけの

150
00:05:03,850 --> 00:05:06,640
十分な情報がある。

151
00:05:09,650 --> 00:05:11,270
だから、フィーチャーが

152
00:05:11,620 --> 00:05:13,390
これらの回りの単語を捉えているなら、

153
00:05:13,560 --> 00:05:15,360
ラベルyが何なのか？という事を

154
00:05:15,790 --> 00:05:17,640
かなり曖昧さ無しで決める為に

155
00:05:17,780 --> 00:05:18,830
十分な情報を持っている。

156
00:05:19,300 --> 00:05:20,190
ラベルyが何かという事を言い換えると、

157
00:05:20,750 --> 00:05:21,760
これら三つのややこしい単語の

158
00:05:22,100 --> 00:05:23,520
どれを使って空白を

159
00:05:23,930 --> 00:05:25,610
埋めるべきか？という事だ。

160
00:05:27,110 --> 00:05:28,320
つまりこれは、フィーチャーxが

161
00:05:28,460 --> 00:05:29,840
特定のyについて十分な情報を

162
00:05:30,410 --> 00:05:32,270
持っている例だ。

163
00:05:32,470 --> 00:05:33,240
これの反対の例としては、

164
00:05:34,690 --> 00:05:36,010
住宅の価格を予測する時に

165
00:05:36,470 --> 00:05:38,090
住宅のサイズだけで

166
00:05:38,340 --> 00:05:39,330
他のフィーチャーが何も無いような

167
00:05:39,390 --> 00:05:40,350
予測の問題を考えてみよう。

168
00:05:42,060 --> 00:05:42,060
私があなたに

169
00:05:42,820 --> 00:05:43,890
住宅の価格は500平方フィートだ、とだけ伝えて

170
00:05:44,150 --> 00:05:45,270
それ以外の情報を

171
00:05:45,370 --> 00:05:48,100
何も伝えなかったとする。

172
00:05:48,530 --> 00:05:49,520
その住居が町の

173
00:05:49,590 --> 00:05:51,990
高い地区にあるとも言わないし、

174
00:05:52,590 --> 00:05:53,710
あるいは私はあなたに

175
00:05:53,840 --> 00:05:55,290
その住居の部屋の数も

176
00:05:55,500 --> 00:05:57,030
言わないし、あるいは

177
00:05:57,180 --> 00:05:58,400
どれくらい素晴らしい家具を備えているかも言わないし、

178
00:05:58,790 --> 00:06:00,540
その住居が新しいか古いかも言わない。

179
00:06:01,090 --> 00:06:02,290
もし私が、この家が500平方フィート

180
00:06:02,540 --> 00:06:03,360
という情報以外を

181
00:06:03,520 --> 00:06:05,440
何も言わなければ、

182
00:06:05,720 --> 00:06:07,160
住居の価格に

183
00:06:07,340 --> 00:06:08,280
影響を与える要因は

184
00:06:08,470 --> 00:06:09,940
住居のサイズ以外にも

185
00:06:10,320 --> 00:06:11,330
あまりにもたくさんあるので、

186
00:06:11,440 --> 00:06:12,910
あなたがサイズしか知らなければ、

187
00:06:13,050 --> 00:06:14,610
その価格を正確に予測するのはとても困難だ。

188
00:06:16,220 --> 00:06:16,860
だから以上は、この仮定、

189
00:06:17,280 --> 00:06:18,230
フィーチャーが望む水準の正確さで

190
00:06:18,880 --> 00:06:20,300
価格を推測するのに十分な情報を持っている、という仮定の

191
00:06:20,800 --> 00:06:23,260
反例と言えると思う。

192
00:06:24,090 --> 00:06:25,180
私がこの仮定をテストする方法は、

193
00:06:25,540 --> 00:06:26,730
私が良くやる

194
00:06:26,940 --> 00:06:29,160
方法の一つに、良く自分自身に問うのは、

195
00:06:30,260 --> 00:06:31,660
入力のフィーチャーxが与えられた時に

196
00:06:32,180 --> 00:06:33,320
このフィーチャーが与えられた時、

197
00:06:33,380 --> 00:06:35,440
学習アルゴリズムと同様の情報が入手可能だった時に、

198
00:06:36,510 --> 00:06:38,690
仮にこのドメインの人間のエキスパートの元に赴いたとすると、

199
00:06:39,680 --> 00:06:41,570
実際に人間のエキスパートが予想をする事が、

200
00:06:41,720 --> 00:06:43,160
あるいは実際に人間のエキスパートが確信を持ってyの値を

201
00:06:43,490 --> 00:06:45,390
予想する事が出来るだろうか？と。

202
00:06:45,630 --> 00:06:46,730
この最初の例の場合、

203
00:06:46,980 --> 00:06:49,420
人間の英語話者の専門家の所に行って、、、

204
00:06:49,810 --> 00:06:51,260
英語をうまく話せる人の

205
00:06:51,390 --> 00:06:53,740
所に行けば、

206
00:06:53,940 --> 00:06:55,230
英語の専門家の人間なら、

207
00:06:55,940 --> 00:06:57,260
単に読むだけで、あなたとか私みたいな

208
00:06:57,450 --> 00:06:59,730
多くの人々なら、

209
00:07:00,160 --> 00:07:01,080
ここに入るのが何であるのかを

210
00:07:01,170 --> 00:07:02,370
予測出来るだろう、

211
00:07:02,620 --> 00:07:03,960
英語の得意な話者なら、

212
00:07:04,290 --> 00:07:05,550
これをうまく予測出来る。

213
00:07:05,850 --> 00:07:06,710
つまりこれで私は、

214
00:07:07,470 --> 00:07:08,640
xでyを正しく予測出来る、ということに、

215
00:07:08,810 --> 00:07:10,550
確信が持てる。だがこれに対して

216
00:07:11,240 --> 00:07:13,550
我らがもし住居の価格の専門家、

217
00:07:14,040 --> 00:07:16,390
例えば住宅を売る不動産屋とか

218
00:07:16,950 --> 00:07:18,090
とにかく住居を売る事で生計を立ててる人の所に行き、

219
00:07:18,610 --> 00:07:19,450
そしれ彼らに家のサイズを

220
00:07:19,550 --> 00:07:20,440
伝えて、

221
00:07:20,530 --> 00:07:21,860
そして彼らに価格は幾らか？と聞けば、

222
00:07:22,240 --> 00:07:23,410
たとえ住宅の価格や販売の

223
00:07:23,600 --> 00:07:25,210
エキスパートであっても、

224
00:07:25,600 --> 00:07:26,520
私に言う事は出来ないだろう、

225
00:07:26,550 --> 00:07:28,280
つまりこれは、住宅の価格の例で、

226
00:07:29,000 --> 00:07:31,060
サイズを知るだけでは

227
00:07:31,600 --> 00:07:33,300
住宅の価格を予測するのに

228
00:07:33,460 --> 00:07:34,960
十分な情報では無い、という

229
00:07:35,920 --> 00:07:36,870
サインである。

230
00:07:37,690 --> 00:07:39,890
そこで、この前提を維持したままで、

231
00:07:41,200 --> 00:07:42,650
大量のデータを得る事が

232
00:07:43,040 --> 00:07:44,230
助けとなるかを見てみよう。

233
00:07:45,020 --> 00:07:46,370
yの値を予測するのに

234
00:07:46,650 --> 00:07:47,870
十分な情報を持つ

235
00:07:48,050 --> 00:07:49,380
フィーチャーを得ていたとしよう。

236
00:07:49,540 --> 00:07:50,750
そしてたくさんのパラメータの

237
00:07:50,960 --> 00:07:52,380
学習アルゴリズムを

238
00:07:52,600 --> 00:07:54,430
用いる事にしよう。

239
00:07:54,580 --> 00:07:56,020
それはロジスティック回帰かもしれないし、

240
00:07:56,280 --> 00:07:58,090
たくさんのフィーチャーの線形回帰かもしれない。

241
00:07:58,550 --> 00:07:59,490
あるいは、私が時々やる事として、、、

242
00:07:59,950 --> 00:08:00,740
私が実際に良くやる事としては、

243
00:08:00,960 --> 00:08:03,300
たくさんの隠れユニットを持ったニューラルネットワークを使う、というやり方もある。

244
00:08:03,860 --> 00:08:05,230
これもまたたくさんのパラメータを持つ

245
00:08:05,500 --> 00:08:07,420
学習アルゴリズムと言える。

246
00:08:08,470 --> 00:08:10,280
つまり、これらは全て、

247
00:08:10,350 --> 00:08:12,350
たくさんのパラメータを持つ強力なアルゴリズムであり、

248
00:08:13,040 --> 00:08:14,810
とても複雑な関数にフィッティング出来る。

249
00:08:16,750 --> 00:08:17,550
そこで私はこれらを、

250
00:08:18,630 --> 00:08:19,720
低バイアスのアルゴリズムと呼び、

251
00:08:20,510 --> 00:08:21,970
そうみなしていく事にする。何故なら

252
00:08:22,140 --> 00:08:23,540
とても複雑な関数にフィッティング出来るから。

253
00:08:25,480 --> 00:08:26,740
我らはとても強力な

254
00:08:27,260 --> 00:08:28,920
学習アルゴリズムを持っているから、

255
00:08:29,380 --> 00:08:30,590
それらは複雑な関数にフィッティング出来るのだ。

256
00:08:31,680 --> 00:08:33,470
たぶん、

257
00:08:34,070 --> 00:08:35,790
これらのアルゴリズムを

258
00:08:35,940 --> 00:08:37,250
データセットに対して実行すると、

259
00:08:37,430 --> 00:08:38,770
トレーニングセットに良くフィットするように出来るだろう。

260
00:08:39,200 --> 00:08:40,680
つまり、

261
00:08:40,940 --> 00:08:43,230
トレーニング誤差は小さくなる事が期待出来る。

262
00:08:44,520 --> 00:08:45,520
ここで、大量の、本当に大量の

263
00:08:46,020 --> 00:08:47,790
トレーニングセットを用いる事にしよう。

264
00:08:48,190 --> 00:08:49,370
その場合、我らに巨大な

265
00:08:49,430 --> 00:08:51,460
トレーニングセットがあれば、

266
00:08:51,630 --> 00:08:53,490
たとえたくさんのパラメータがあっても、

267
00:08:53,760 --> 00:08:56,080
パラメータの数に対してでさえ

268
00:08:56,360 --> 00:08:57,450
十分に大量のトレーニングセットであれば、

269
00:08:57,840 --> 00:08:59,450
これらのアルゴリズムは

270
00:08:59,640 --> 00:09:01,490
オーバーフィットしそうには無い。

271
00:09:02,590 --> 00:09:03,660
何故なら我らは

272
00:09:03,710 --> 00:09:05,680
そんなにも巨大なトレーニングセットを持っているのだから。

273
00:09:06,070 --> 00:09:07,870
そしてオーバーフィットしなさそう、という事は

274
00:09:08,070 --> 00:09:09,090
トレーニング誤差は

275
00:09:09,390 --> 00:09:10,860
テスト誤差と

276
00:09:11,050 --> 00:09:13,270
近い事が期待される、という事を意味する。

277
00:09:13,960 --> 00:09:15,160
最後に、これら二つをあわせると、

278
00:09:15,350 --> 00:09:16,770
トレーニングセット誤差は

279
00:09:16,990 --> 00:09:18,590
小さくて、

280
00:09:18,700 --> 00:09:19,870
テストセット誤差はトレーニング誤差と

281
00:09:20,360 --> 00:09:22,290
近くなる、

282
00:09:22,460 --> 00:09:24,510
これら二つをあわせると、

283
00:09:24,710 --> 00:09:26,630
テストセット誤差も小さくなるだろう事が

284
00:09:27,780 --> 00:09:28,450
期待される。

285
00:09:30,000 --> 00:09:32,610
これのもう一つ別の

286
00:09:32,720 --> 00:09:33,930
考え方としては、

287
00:09:34,700 --> 00:09:35,740
高いパフォーマンスの

288
00:09:35,880 --> 00:09:37,630
学習アルゴリズムを得る為に、

289
00:09:37,930 --> 00:09:40,470
それが高バイアスでも高バリアンスでも無い事を望む。

290
00:09:42,060 --> 00:09:43,270
そこでバイアスの問題に対して、

291
00:09:43,350 --> 00:09:44,700
我らは学習アルゴリズムが

292
00:09:44,880 --> 00:09:45,910
たくさんのパラメータを持つ事で

293
00:09:46,170 --> 00:09:47,670
低バイアスのアルゴリズムとなるようにしつつ、

294
00:09:47,840 --> 00:09:48,930
一方でとても大量のトレーニングセットを

295
00:09:50,110 --> 00:09:51,460
用いる事で、

296
00:09:51,610 --> 00:09:53,240
これはバリアンスの問題が無い事を

297
00:09:53,760 --> 00:09:55,590
保証してくれる。

298
00:09:55,840 --> 00:09:57,280
つまり我らのアルゴリズムに

299
00:09:57,430 --> 00:09:59,100
バリアンスの問題が無い事が期待出来て、

300
00:09:59,340 --> 00:10:00,940
そしてこれら二つを合わせる事で、

301
00:10:01,870 --> 00:10:02,830
結局は低バイアス、

302
00:10:02,900 --> 00:10:03,990
低バリアンスの

303
00:10:04,990 --> 00:10:06,920
学習アルゴリズムとなる。

304
00:10:07,140 --> 00:10:08,300
そしてこれは、テストセットにおいて

305
00:10:08,710 --> 00:10:10,150
とても良く振舞ってくれる。

306
00:10:10,430 --> 00:10:12,140
それは本質的には、鍵となる想定は、

307
00:10:13,020 --> 00:10:14,560
フィーチャーが

308
00:10:14,940 --> 00:10:16,750
十分な情報を持っている事、

309
00:10:16,900 --> 00:10:17,960
そしてリッチなクラスの関数である事で

310
00:10:18,400 --> 00:10:19,580
低バイアスである事を保証し、

311
00:10:20,760 --> 00:10:21,750
そして次に大量のトレーニングセットを持つ事で

312
00:10:22,110 --> 00:10:25,010
低バリアンスである事を保証する訳だ。

313
00:10:27,150 --> 00:10:28,310
つまり、これが我らに

314
00:10:28,410 --> 00:10:29,820
以下のような一連の条件を

315
00:10:30,090 --> 00:10:31,610
持った問題：

316
00:10:31,870 --> 00:10:33,730
より多くのデータを持って

317
00:10:33,860 --> 00:10:34,790
たくさんのパラメータの

318
00:10:34,960 --> 00:10:36,150
学習アルゴリズムを

319
00:10:36,380 --> 00:10:38,930
訓練するような物。それは

320
00:10:39,120 --> 00:10:39,870
高いパフォーマンスの学習アルゴリズムを

321
00:10:40,060 --> 00:10:42,490
得る為の良い方法たりえる。

322
00:10:43,480 --> 00:10:44,140
そして実際に、私がキーだと思うテストとして、

323
00:10:44,230 --> 00:10:45,520
自分自身にも良く問う物としては、

324
00:10:45,820 --> 00:10:47,100
まず一つ目の問いは、人間のエキスパートが

325
00:10:47,200 --> 00:10:48,360
フィーチャーxを見た時に、

326
00:10:48,880 --> 00:10:49,890
yの値を確信を持って予測出来るか、という事。

327
00:10:50,030 --> 00:10:51,080
何故ならそれは、

328
00:10:51,210 --> 00:10:53,050
フィーチャーxからyが

329
00:10:53,320 --> 00:10:55,040
正確に予測出来る、という

330
00:10:55,140 --> 00:10:57,010
保証となるからだ。

331
00:10:57,510 --> 00:10:58,630
そして二番目の問いは、我らは実際に

332
00:10:58,820 --> 00:11:00,150
大量のトレーニングセットを得る事が出来て、

333
00:11:00,350 --> 00:11:01,470
たくさんのパラメータの学習アルゴリズムを

334
00:11:01,540 --> 00:11:03,290
そのトレーニングセットでトレーニング出来るか？という事。

335
00:11:03,520 --> 00:11:04,420
そしてもし両方が可能なら、

336
00:11:04,870 --> 00:11:06,300
それらはきっと、とても高いパフォーマンスの

337
00:11:06,460 --> 00:11:08,570
学習アルゴリズムを与えてくれる事となる。