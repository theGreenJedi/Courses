1
00:00:00,290 --> 00:00:01,690
在前面的课程中

2
00:00:02,060 --> 00:00:03,900
我提到了误差分析

3
00:00:04,350 --> 00:00:06,070
以及设定误差度量值的重要性

4
00:00:06,330 --> 00:00:07,480
那就是

5
00:00:08,210 --> 00:00:10,200
设定某个实数来评估你的学习算法

6
00:00:11,020 --> 00:00:13,290
并衡量它的表现

7
00:00:14,310 --> 00:00:15,670
有了算法的评估

8
00:00:16,700 --> 00:00:18,320
和误差度量值

9
00:00:18,430 --> 00:00:20,290
有一件重要的事情要注意

10
00:00:20,480 --> 00:00:22,180
就是使用一个合适的误差度量值

11
00:00:22,510 --> 00:00:24,430
这有时会对于你的学习算法

12
00:00:24,930 --> 00:00:26,990
造成非常微妙的影响

13
00:00:28,040 --> 00:00:29,140
这件重要的事情就是

14
00:00:29,610 --> 00:00:31,310
偏斜类（skewed classes）的问题

15
00:00:32,610 --> 00:00:33,480
让我告诉你这是什么意思

16
00:00:36,170 --> 00:00:37,550
想一想之前的癌症分类问题

17
00:00:38,180 --> 00:00:40,040
我们拥有

18
00:00:40,300 --> 00:00:41,960
内科病人的特征变量

19
00:00:42,070 --> 00:00:44,050
我们希望知道他们是否患有癌症

20
00:00:44,630 --> 00:00:45,790
因此这就像恶性

21
00:00:46,350 --> 00:00:48,290
与良性肿瘤的分类问题

22
00:00:48,930 --> 00:00:50,070
我们之前讲过这个

23
00:00:51,140 --> 00:00:52,360
我们假设 y=1 表示患者患有癌症

24
00:00:52,550 --> 00:00:53,780
假设 y=0

25
00:00:54,280 --> 00:00:56,530
表示他们没有得癌症

26
00:00:56,810 --> 00:00:57,460
我们训练逻辑回归模型

27
00:00:57,940 --> 00:00:59,780
假设我们用测试集

28
00:01:00,000 --> 00:01:01,520
检验了这个分类模型

29
00:01:01,660 --> 00:01:04,470
并且发现它只有1%的错误

30
00:01:04,790 --> 00:01:05,720
因此我们99%会做出正确诊断

31
00:01:06,530 --> 00:01:09,610
看起来是非常不错的结果

32
00:01:09,910 --> 00:01:10,920
我们99%的情况都是正确的

33
00:01:12,560 --> 00:01:13,630
但是 假如我们发现

34
00:01:13,940 --> 00:01:15,660
在测试集中

35
00:01:16,510 --> 00:01:17,950
只有0.5%的患者

36
00:01:18,160 --> 00:01:19,590
真正得了癌症

37
00:01:20,400 --> 00:01:21,900
因此

38
00:01:21,950 --> 00:01:23,460
在我们的筛选程序里

39
00:01:23,580 --> 00:01:25,500
只有0.5%的患者患了癌症

40
00:01:26,560 --> 00:01:27,970
因此在这个例子中

41
00:01:28,270 --> 00:01:30,010
1%的错误率就不再显得那么好了

42
00:01:31,130 --> 00:01:32,510
举个具体的例子

43
00:01:32,670 --> 00:01:33,730
这里有一行代码

44
00:01:33,850 --> 00:01:35,730
不是机器学习代码

45
00:01:36,080 --> 00:01:38,260
它忽略了输入值X

46
00:01:38,480 --> 00:01:39,820
它让y总是等于0

47
00:01:39,950 --> 00:01:41,640
因此它总是预测

48
00:01:41,720 --> 00:01:43,920
没有人得癌症

49
00:01:44,170 --> 00:01:45,720
那么这个算法实际上只有

50
00:01:46,000 --> 00:01:47,840
0.5%的错误率

51
00:01:48,830 --> 00:01:50,280
因此这甚至比

52
00:01:50,400 --> 00:01:51,140
我们之前得到的1%的错误率更好

53
00:01:51,240 --> 00:01:52,960
这是一个

54
00:01:53,160 --> 00:01:54,600
非机器学习算法

55
00:01:54,800 --> 00:01:56,950
因为它只是预测y总是等于0

56
00:01:57,990 --> 00:01:59,430
这种情况发生在

57
00:02:00,060 --> 00:02:01,980
正例和负例的比率

58
00:02:02,180 --> 00:02:04,130
非常接近于

59
00:02:04,810 --> 00:02:06,480
一个极端

60
00:02:07,040 --> 00:02:08,620
在这个例子中

61
00:02:08,710 --> 00:02:10,050
正样本的数量

62
00:02:10,350 --> 00:02:11,310
与负样本的数量相比

63
00:02:11,620 --> 00:02:13,180
非常非常少

64
00:02:13,480 --> 00:02:15,500
因为y=1非常少

65
00:02:15,730 --> 00:02:16,850
我们把这种情况叫做

66
00:02:17,000 --> 00:02:18,600
偏斜类

67
00:02:20,790 --> 00:02:21,710
一个类中的样本数

68
00:02:22,000 --> 00:02:23,140
与另一个类的数据相比

69
00:02:23,570 --> 00:02:25,040
多很多

70
00:02:25,220 --> 00:02:26,560
通过总是预测y=0

71
00:02:26,920 --> 00:02:28,270
或者

72
00:02:28,650 --> 00:02:29,650
总是预测y=1

73
00:02:29,790 --> 00:02:32,080
算法可能表现非常好

74
00:02:32,980 --> 00:02:34,050
因此使用分类误差

75
00:02:34,670 --> 00:02:36,210
或者分类精确度

76
00:02:36,590 --> 00:02:39,240
来作为评估度量可能会产生如下问题

77
00:02:40,430 --> 00:02:41,360
假如说你有一个算法

78
00:02:41,700 --> 00:02:43,570
它的精确度是99.2%

79
00:02:46,530 --> 00:02:47,200
因此它只有0.8%的误差

80
00:02:47,330 --> 00:02:50,850
假设

81
00:02:51,000 --> 00:02:52,000
你对你的算法做出了一点改动

82
00:02:52,810 --> 00:02:53,890
现在你得到了

83
00:02:54,280 --> 00:02:56,080
99.5%的精确度

84
00:02:59,280 --> 00:03:02,110
只有0.5%的误差

85
00:03:04,230 --> 00:03:06,460
这到底是不是算法的一个提升呢

86
00:03:06,770 --> 00:03:07,930
用某个实数来

87
00:03:08,300 --> 00:03:09,990
作为评估度量值

88
00:03:10,120 --> 00:03:11,480
的一个好处就是

89
00:03:11,650 --> 00:03:13,080
它可以帮助我们迅速决定

90
00:03:13,240 --> 00:03:15,530
我们是否需要对算法做出一些改进

91
00:03:16,370 --> 00:03:20,160
将精确度从99.2%提高到99.5%

92
00:03:21,430 --> 00:03:22,490
但是我们的改进到底是有用的

93
00:03:22,780 --> 00:03:23,640
还是说

94
00:03:23,770 --> 00:03:25,150
我们只是把代码替换成了

95
00:03:25,320 --> 00:03:26,690
例如总是预测y=0

96
00:03:27,000 --> 00:03:28,830
这样的东西

97
00:03:29,300 --> 00:03:30,430
因此如果你有一个偏斜类

98
00:03:31,340 --> 00:03:33,280
用分类精确度

99
00:03:33,640 --> 00:03:36,000
并不能很好地衡量算法

100
00:03:36,120 --> 00:03:37,730
因为你可能会获得一个很高的精确度

101
00:03:38,420 --> 00:03:40,950
非常低的错误率

102
00:03:41,110 --> 00:03:42,880
但是我们并不知道

103
00:03:43,070 --> 00:03:44,190
我们是否真的提升了

104
00:03:44,770 --> 00:03:45,780
分类模型的质量

105
00:03:46,400 --> 00:03:48,320
因为总是预测y=0

106
00:03:48,380 --> 00:03:50,710
并不是一个

107
00:03:51,570 --> 00:03:52,570
好的分类模型

108
00:03:53,900 --> 00:03:55,500
但是总是预测y=0

109
00:03:55,720 --> 00:03:57,300
会将你的误差降低至

110
00:03:57,830 --> 00:03:59,460
比如

111
00:03:59,650 --> 00:04:01,120
降低至0.5%

112
00:04:01,490 --> 00:04:02,590
当我们遇到

113
00:04:02,770 --> 00:04:04,990
这样一个偏斜类时

114
00:04:05,250 --> 00:04:06,350
我们希望有一个

115
00:04:06,470 --> 00:04:07,920
不同的误差度量值

116
00:04:08,320 --> 00:04:09,500
或者不同的评估度量值

117
00:04:10,290 --> 00:04:12,360
其中一种评估度量值

118
00:04:12,870 --> 00:04:14,240
叫做查准率（precision）和召回率（recall）

119
00:04:15,440 --> 00:04:16,410
让我来解释一下

120
00:04:17,520 --> 00:04:19,890
假设我们正在用测试集来评估一个分类模型

121
00:04:20,750 --> 00:04:21,800
对于

122
00:04:21,890 --> 00:04:23,890
测试集中的样本

123
00:04:25,450 --> 00:04:26,880
每个测试集中的样本

124
00:04:27,320 --> 00:04:28,440
都会等于

125
00:04:28,550 --> 00:04:29,810
0或者1

126
00:04:30,440 --> 00:04:32,520
假设这是一个二分问题

127
00:04:33,870 --> 00:04:34,960
我们的学习算法

128
00:04:35,360 --> 00:04:37,070
要做的是

129
00:04:37,930 --> 00:04:39,270
做出值的预测

130
00:04:39,450 --> 00:04:41,160
并且学习算法

131
00:04:41,560 --> 00:04:43,300
会为每一个

132
00:04:43,760 --> 00:04:44,830
测试集中的实例

133
00:04:44,910 --> 00:04:46,520
做出预测

134
00:04:46,920 --> 00:04:48,560
预测值也是等于0或1

135
00:04:50,050 --> 00:04:52,060
让我画一个

136
00:04:52,270 --> 00:04:53,340
2x2的表格

137
00:04:53,910 --> 00:04:55,870
基于所有这些值

138
00:04:56,320 --> 00:04:57,800
基于

139
00:04:57,960 --> 00:04:59,350
实际的类与预测的类

140
00:05:00,220 --> 00:05:01,270
如果

141
00:05:01,570 --> 00:05:02,890
有一个样本它实际所属的类是1

142
00:05:02,970 --> 00:05:03,950
预测的类也是1

143
00:05:04,240 --> 00:05:06,140
那么

144
00:05:07,620 --> 00:05:08,640
我们把这个样本叫做真阳性（true positive）

145
00:05:08,940 --> 00:05:10,300
意思是说我们的学习算法

146
00:05:10,730 --> 00:05:11,700
预测这个值为阳性

147
00:05:12,400 --> 00:05:15,780
实际上这个样本也确实是阳性

148
00:05:16,240 --> 00:05:17,300
如果我们的学习算法

149
00:05:17,490 --> 00:05:19,010
预测某个值是阴性 等于0

150
00:05:19,570 --> 00:05:20,620
实际的类也确实属于0

151
00:05:20,970 --> 00:05:23,650
那么我们把这个叫做真阴性（true negative）

152
00:05:24,070 --> 00:05:26,370
我们预测为0的值实际上也等于0

153
00:05:27,880 --> 00:05:28,740
还剩另外的两个单元格

154
00:05:29,470 --> 00:05:31,120
如果我们的学习算法

155
00:05:31,360 --> 00:05:33,210
预测某个值等于1

156
00:05:34,340 --> 00:05:36,370
但是实际上它等于0

157
00:05:36,670 --> 00:05:37,910
这个叫做假阳性（false positive）

158
00:05:39,350 --> 00:05:40,630
比如我们的算法

159
00:05:40,830 --> 00:05:41,970
预测某些病人患有癌症

160
00:05:42,190 --> 00:05:43,520
但是事实上他们并没有得癌症

161
00:05:44,730 --> 00:05:47,340
最后 这个单元格是 1和0

162
00:05:48,200 --> 00:05:50,330
这个叫做假阴性（false negative）

163
00:05:51,180 --> 00:05:52,690
因为我们的算法预测值为0

164
00:05:53,450 --> 00:05:56,170
但是实际值是1

165
00:05:57,230 --> 00:05:59,020
这样

166
00:05:59,150 --> 00:06:00,830
我们有了一个2x2的表格

167
00:06:00,990 --> 00:06:02,720
基于

168
00:06:03,250 --> 00:06:05,500
实际类与预测类

169
00:06:07,080 --> 00:06:08,380
这样我们有了一个

170
00:06:08,690 --> 00:06:10,310
另一种方式来

171
00:06:10,420 --> 00:06:11,940
评估算法的表现

172
00:06:12,550 --> 00:06:12,870
我们要计算两个数字

173
00:06:13,310 --> 00:06:14,780
第一个叫做查准率

174
00:06:14,940 --> 00:06:16,100
这个意思是

175
00:06:17,170 --> 00:06:18,330
对于所有我们预测

176
00:06:18,580 --> 00:06:19,580
他们患有癌症的病人

177
00:06:20,640 --> 00:06:23,140
有多大比率的病人是真正患有癌症的

178
00:06:24,560 --> 00:06:25,310
让我把这个写下来

179
00:06:26,020 --> 00:06:27,300
一个分类模型的查准率

180
00:06:27,680 --> 00:06:29,070
等于

181
00:06:29,310 --> 00:06:31,880
真阳性除以

182
00:06:32,940 --> 00:06:35,190
所有我们预测为阳性

183
00:06:37,140 --> 00:06:37,370
的数量

184
00:06:39,150 --> 00:06:40,660
对于那些病人

185
00:06:41,090 --> 00:06:43,590
我们告诉他们 "你们患有癌症"

186
00:06:43,890 --> 00:06:45,730
对于这些病人而言

187
00:06:45,890 --> 00:06:47,410
有多大比率是真正患有癌症的

188
00:06:47,500 --> 00:06:48,920
这个就叫做查准率

189
00:06:49,800 --> 00:06:50,680
另一个写法是

190
00:06:50,950 --> 00:06:54,920
分子是真阳性

191
00:06:55,010 --> 00:06:56,430
分母是

192
00:06:56,670 --> 00:06:59,050
所有预测阳性的数量

193
00:06:59,210 --> 00:07:00,160
那么这个等于

194
00:07:00,240 --> 00:07:01,730
表格第一行的值

195
00:07:02,410 --> 00:07:04,510
的和

196
00:07:04,720 --> 00:07:07,760
也就是真阳性除以真阳性...

197
00:07:08,670 --> 00:07:10,470
这里我把阳性简写为

198
00:07:11,220 --> 00:07:12,980
POS

199
00:07:13,130 --> 00:07:15,470
加上假阳性

200
00:07:15,890 --> 00:07:18,550
这里我还是把阳性简写为POS

201
00:07:20,030 --> 00:07:21,850
这个就叫做查准率

202
00:07:21,920 --> 00:07:23,490
查准率越高就越好

203
00:07:23,660 --> 00:07:24,680
这是说 对于那些病人

204
00:07:25,070 --> 00:07:27,100
我们告诉他们 "非常抱歉

205
00:07:27,510 --> 00:07:28,960
我们认为你得了癌症"

206
00:07:29,440 --> 00:07:31,750
高查准率说明

207
00:07:31,980 --> 00:07:33,160
对于这类病人

208
00:07:33,390 --> 00:07:34,460
我们对预测他们得了癌症

209
00:07:34,820 --> 00:07:36,630
有很高的准确率

210
00:07:38,840 --> 00:07:39,880
另一个数字我们要计算的

211
00:07:40,440 --> 00:07:41,730
叫做召回率

212
00:07:42,060 --> 00:07:44,230
召回率是

213
00:07:44,480 --> 00:07:46,100
如果所有的病人

214
00:07:46,190 --> 00:07:47,510
假设测试集中的病人

215
00:07:47,620 --> 00:07:48,830
或者交叉验证集中的

216
00:07:48,960 --> 00:07:49,980
如果所有这些在数据集中的病人

217
00:07:50,150 --> 00:07:51,550
确实得了癌症

218
00:07:52,670 --> 00:07:54,240
有多大比率

219
00:07:54,400 --> 00:07:56,250
我们正确预测他们得了癌症

220
00:07:56,950 --> 00:07:57,870
如果所有的病人

221
00:07:58,090 --> 00:07:59,170
都患了癌症

222
00:07:59,400 --> 00:08:01,130
有多少人我们能够

223
00:08:01,320 --> 00:08:03,850
正确告诉他们 你需要治疗

224
00:08:05,860 --> 00:08:07,010
把这个写下来

225
00:08:07,360 --> 00:08:08,970
召回率被定义为

226
00:08:09,040 --> 00:08:12,020
真阳性

227
00:08:12,470 --> 00:08:14,760
的数量

228
00:08:15,260 --> 00:08:16,320
意思是我们正确预测

229
00:08:16,520 --> 00:08:17,890
患有癌症的人

230
00:08:18,030 --> 00:08:19,280
的数量

231
00:08:20,310 --> 00:08:21,440
我们用这个来

232
00:08:21,790 --> 00:08:23,510
除以

233
00:08:23,740 --> 00:08:29,300
实际阳性

234
00:08:31,200 --> 00:08:32,070
这个值是

235
00:08:32,510 --> 00:08:35,190
所有患有癌症的人的数量

236
00:08:35,850 --> 00:08:37,000
有多大比率

237
00:08:37,430 --> 00:08:38,950
我们能正确发现癌症 并给予治疗

238
00:08:40,560 --> 00:08:41,780
把这个以另一种形式

239
00:08:41,930 --> 00:08:44,060
写下来

240
00:08:44,210 --> 00:08:45,160
分母是

241
00:08:45,430 --> 00:08:46,990
实际阳性的数量

242
00:08:47,220 --> 00:08:49,480
表格第一列值的和

243
00:08:50,600 --> 00:08:51,660
将这个以不同的形式写下来

244
00:08:52,160 --> 00:08:53,470
那就是

245
00:08:53,650 --> 00:08:57,120
真阳性除以

246
00:08:59,010 --> 00:09:01,340
真阳性

247
00:09:02,790 --> 00:09:05,430
加上

248
00:09:06,750 --> 00:09:07,690
假阴性

249
00:09:09,570 --> 00:09:12,180
同样地 召回率越高越好

250
00:09:14,180 --> 00:09:15,810
通过计算查准率

251
00:09:15,930 --> 00:09:17,100
和召回率

252
00:09:17,340 --> 00:09:18,740
我们能更好的知道

253
00:09:19,140 --> 00:09:20,560
分类模型到底好不好

254
00:09:21,620 --> 00:09:22,960
具体地说

255
00:09:23,330 --> 00:09:24,740
如果我们有一个算法

256
00:09:25,520 --> 00:09:27,020
总是预测y=0

257
00:09:27,190 --> 00:09:28,290
它总是预测

258
00:09:28,460 --> 00:09:30,080
没有人患癌症

259
00:09:30,250 --> 00:09:31,880
那么这个分类模型

260
00:09:32,070 --> 00:09:33,820
召回率等于0

261
00:09:34,370 --> 00:09:35,300
因为它不会有

262
00:09:35,570 --> 00:09:36,940
真阳性

263
00:09:37,190 --> 00:09:37,930
因此我们能会快发现

264
00:09:38,010 --> 00:09:40,290
这个分类模型

265
00:09:40,360 --> 00:09:41,570
总是预测y=0

266
00:09:42,050 --> 00:09:43,350
它不是一个好的模型

267
00:09:44,000 --> 00:09:46,660
总的来说

268
00:09:47,450 --> 00:09:48,830
即使我们有一个

269
00:09:48,950 --> 00:09:50,800
非常偏斜的类

270
00:09:51,050 --> 00:09:53,350
算法也不能够

271
00:09:53,440 --> 00:09:54,900
"欺骗"我们

272
00:09:55,450 --> 00:09:56,400
仅仅通过预测

273
00:09:56,750 --> 00:09:57,930
y总是等于0

274
00:09:58,010 --> 00:09:59,360
或者y总是等于1

275
00:09:59,620 --> 00:10:00,800
它没有办法得到

276
00:10:01,050 --> 00:10:02,680
高的查准率

277
00:10:02,720 --> 00:10:04,720
和高的召回率

278
00:10:04,960 --> 00:10:06,540
因此我们

279
00:10:06,680 --> 00:10:08,230
能够更肯定

280
00:10:08,840 --> 00:10:09,780
拥有高查准率或者高召回率的模型

281
00:10:10,610 --> 00:10:11,550
是一个好的分类模型

282
00:10:12,470 --> 00:10:13,940
这给予了我们一个

283
00:10:14,040 --> 00:10:15,660
更好的评估值

284
00:10:15,910 --> 00:10:16,960
给予我们一种更直接的方法

285
00:10:17,230 --> 00:10:20,360
来评估模型的好与坏

286
00:10:21,680 --> 00:10:23,000
最后一件需要记住的事

287
00:10:23,200 --> 00:10:24,960
在查准率和召回率的定义中

288
00:10:25,150 --> 00:10:26,190
我们定义

289
00:10:26,720 --> 00:10:28,720
查准率和召回率

290
00:10:29,100 --> 00:10:31,970
我们总是习惯性地用y=1

291
00:10:32,090 --> 00:10:33,700
如果这个类出现得非常少

292
00:10:34,160 --> 00:10:35,410
因此如果我们试图检测

293
00:10:35,880 --> 00:10:37,300
某种很稀少的情况 比如癌症

294
00:10:37,720 --> 00:10:38,610
我希望它是个很稀少的情况

295
00:10:39,340 --> 00:10:40,950
查准率和召回率

296
00:10:41,000 --> 00:10:42,440
会被定义为

297
00:10:42,790 --> 00:10:43,930
y=1

298
00:10:44,190 --> 00:10:45,690
而不是y=0

299
00:10:45,820 --> 00:10:47,100
作为某种我们希望检测的

300
00:10:47,250 --> 00:10:50,220
出现较少的类

301
00:10:50,450 --> 00:10:51,960
通过使用查准率和召回率

302
00:10:52,890 --> 00:10:54,250
我们发现

303
00:10:54,390 --> 00:10:55,400
即使我们拥有

304
00:10:55,610 --> 00:10:57,400
非常偏斜的类

305
00:10:57,590 --> 00:10:59,080
算法不能够

306
00:10:59,600 --> 00:11:01,060
通过总是预测y=1 

307
00:11:01,380 --> 00:11:02,400
来"欺骗"我们

308
00:11:02,760 --> 00:11:03,870
或者总是预测y=0

309
00:11:03,980 --> 00:11:05,750
因为它不能够获得高查准率和召回率

310
00:11:06,640 --> 00:11:07,830
具体地说 如果一个分类模型

311
00:11:08,480 --> 00:11:09,700
拥有高查准率和召回率

312
00:11:09,880 --> 00:11:11,160
那么

313
00:11:11,270 --> 00:11:13,040
我们可以确信地说

314
00:11:13,590 --> 00:11:15,120
这个算法表现很好

315
00:11:15,400 --> 00:11:16,620
即便我们拥有很偏斜的类

316
00:11:18,030 --> 00:11:20,360
因此对于偏斜类的问题

317
00:11:20,950 --> 00:11:22,560
查准率和召回率

318
00:11:22,780 --> 00:11:24,670
给予了我们更好的方法

319
00:11:24,910 --> 00:11:26,010
来检测学习算法表现如何

320
00:11:26,660 --> 00:11:27,980
这是一种

321
00:11:28,070 --> 00:11:29,360
更好地评估学习算法的标准

322
00:11:30,270 --> 00:11:32,200
当出现偏斜类时

323
00:11:32,510 --> 00:11:35,200
比仅仅只用分类误差或者分类精度好 【教育无边界字幕组】翻译: 御姐sama 校对/审核: 所罗门捷列夫