En el último vídeo hablamos hablamos de la precisión y la recuperación como métricas de evaluación para los problemas de clasificación con clases sesgadas. Para algunas aplicaciones, queremos controlar, de alguna manera, la compensación entre la precisión y la recuperación. Ahora les diré cómo hacerlo y les mostraré maneras aún más efectivas de utilizar la precisión y la recuperación como una métrica de evaluación para algoritmos de aprendizaje. Como recordatorio, aquí tenemos las definiciones de precisión y recuperación del video anterior. Continuemos con nuestro ejemplo de clasificación del cáncer en el que “y” es igual a 1 si el paciente tiene cáncer y “y” es igual a 0 si el paciente está sano, y digamos que entrenamos un clasificador con regresión logística que nos arroja posibilidades de entre cero y uno. Como de costumbre, supondremos que “y” es igual a 1 si “H” de “X” es mayor o igual a 0.5 y prediremos que “y” es igual a 0 si la hipótesis arroja un valor menor a 0.5. Este clasificador puede darnos un valor para la precisión y un valor para la recuperación. Por ahora, supongamos que queremos predecir que un paciente tiene cáncer sólo si estamos seguros de que en realidad lo padece, porque si vas con un paciente y le dices que tiene cáncer, tendrá un impacto enorme Realmente son muy malas noticias para el paciente y puede acabar soportando un proceso y un tratamiento muy dolor. Por lo tanto, sólo le queremos decir a un paciente que creemos que tiene cáncer cuando estamos muy seguros. Una manera de hacer esto es modificar el algoritmo para que, en vez de fijar el umbral en 0.5, supondremos que “y” es igual a 1 sólo si “H” de “X” es igual o mayor que 0.7. Entonces, sólo le diremos a alguien que tiene cáncer si hay una probabilidad igual o mayor al 70% de que lo padece. Si haces esto, puedes predecir el cáncer sólo cuando estás seguro y, por lo tanto, obtendrás un clasificador con una mayor precisión. Por esto, los pacientes a quienes les des la noticia de que tienen cáncer estarán seguros de que realmente lo padecen. En otras palabras, una fracción más alta de los pacientes que predijiste que tendrían cáncer tendrán cáncer realmente, porque cuando hiciste estas predicciones dejaste un margen de seguridad muy cerrado. Por el contrario, este clasificador tendrá una recuperación baja, porque ahora haremos una predicción de que “y” es igual a 1 en un número menor de pacientes. Podemos llevar esto más lejos. En vez de fijar el umbral en 0.7, podemos subirlo a 0.9 y predecir que “y” es igual a 1 sólo si tenemos más del 90% de seguridad de que el paciente tiene cáncer. Una fracción mayor de pacientes tendrá cáncer; por lo tanto, este será un clasificador con precisión alta y con una recuperación baja porque detectaremos correctamente sólo a los pacientes que tengan cáncer. Ahora, consideremos un ejemplo distinto. Supongamos que queremos evitar obviar muchos casos de cáncer. Queremos evitar falsos negativos. Especialmente, si un paciente realmente tiene cáncer pero no le dijimos que lo padece, puede tener consecuencias graves. Ya que, si no le dijimos al paciente que no tiene cáncer, no obtendrán tratamiento; es decir, si resulta que sí tiene cáncer pero no le dijimos, no recibirá su tratamiento. Esto puede ser un resultado trágico. El paciente podría morir porque le dijimos que no tenía cáncer y no tomó un tratamiento, pero resulta que sí tenía cáncer. Cuando haya dudas, lo que queremos predecir es que “y” es igual a 1. Así que, cuando tenemos dudas, queremos predecir que tienen cáncer para que, por lo menos, puedan investigar más y tratarse en caso de que realmente lo padezcan. En este caso, en vez de poner un umbral de probabilidad alto, tomaremos este valor y lo bajaremos hasta, digamos, 0.3 así. Al hacer esto, estamos decidiendo que si hay más del 30% de probabilidad de que el paciente tenga cáncer, seremos conservadores y le diremos que puede tener cáncer para que busque el tratamiento necesario. En este caso, lo que haremos es poner un clasificador con una recuperación más alta para marcar efectivamente una fracción mayor de los pacientes con cáncer, pero acabaremos con una precisión menor. Porque entre más grande sea la fracción de pacientes a los que les diagnostiquemos cáncer, mayor será la fracción de ellos que, finalmente, no padecen cáncer. Como paréntesis, cuando hablo de esto con otros estudiantes les resulta muy impresionante y algunos me preguntan cómo puedo contar la historia desde ambos puntos de vista. Ya sea si queremos tener una precisión o una recuperación más alta. Pero esto funciona en ambos casos. Espero que los detalles de mi algoritmo sean verdaderos. El principio más general es que, dependiendo de si quieres una precisión alta y una recuperación baja o una precisión baja y una recuperación alta, puedes terminar prediciendo que “y” es igual a 1 cuando “h(x)” es mayor que el umbral. En general, para la mayoría de los clasificadores, habrá una compensación entre la precisión y la recuperación. A medida que varía el valor del este umbral, el valor del umbral que tracé aquí, se puede trazar una curva que compensa entre la precisión y la recuperación en donde el valor de aquí arriba correspondería a un umbral con un valor muy alto, quizá mayor a 0.99. Digamos que predijimos que “y” es igual a 1 sólo cuando tenemos el 99 por ciento de probabilidad o por lo menos el 99 por ciento de certeza de que “y” es igual a 1. Esto nos daría una precisión alta y una recuperación relativamente baja. Por el contrario, el punto de aquí abajo corresponde a un valor de umbral mucho más bajo, tal vez 0.01. Cuando tengas duda, supón que “y” es igual a 1. Haciendo esto tenderemos con una precisión más baja y una recuperación más alta. A medida que varíes el umbral, puedes trazar la curva de tu clasificador para ver la gama de valores que puedes obtener para la precisión y la recuperación. Por cierto, la curva de precisión y recuperación puede tener muchas formas distintas. A veces se verá como esta, y otras como esta otra. Hay muchas formas posibles para la curva de precisión y recuperación que dependen de los detalles del clasificador. Esto nos lleva a otra pregunta interesante: ¿hay alguna manera de elegir el umbral automáticamente? o, si tenemos algoritmos diferentes o ideas diferentes para algoritmos ¿cómo comparamos los diferentes números de precisión y recuperación? Supongamos que tenemos tres algoritmos de aprendizaje distintos o tal vez son un sólo algoritmo de aprendizaje con umbrales de tres valores distintos. ¿Cómo decidimos cuál de estos algoritmos es el mejor? Antes, hablamos de la importancia de tener una métrica de evaluación con un número real simple. La idea de esto es tener un sólo número que te indique cómo se está desempeñando tu clasificador. Cuando, en vez de esto, utilizamos la métrica de precisión y recuperación, perdemos esta ventaja. Ahora tenemos dos números reales, por lo que a veces nos enfrentamos con situaciones en las que, si intentamos comparar el algoritmo 1 con el algoritmo 2, terminamos preguntándonos si tener una precisión de 0.5 y una recuperación de 0.4 es mejor o peor que tener una precisión de 0.7 y una recuperación de 0.1. Cada vez que vez que evalúes un algoritmo terminarás preguntándote si 0.5 y 0.4 son mejores valores que 0.7 y 0.1. No sé. Sentarte a pensar sobre estas decisiones puede retrasar tu proceso de toma de decisiones de los cambios útiles que puedes incorporar a tu algoritmo. Por el contrario, si tenemos una métrica de evaluación con un valor único; es decir, un número que nos diga si el algoritmo 1 es mejor que el 2 o al revés, nos será de mucha ayuda para decidir más rápidamente qué algoritmo debemos utilizar. También nos ayuda a evaluar más rápidamente los cambios que estamos contemplando para un algoritmo. Entonces ¿cómo podemos obtener una métrica de evaluación con un sólo número real? Una cosa que puedes intentar es ver el promedio entre la precisión y la recuperación. Utilizaremos P y R para denotar precisión y recuperación, respectivamente. Lo que puedes hacer es calcular el promedio y ver cuál clasificador tiene el valor promedio más alto. Esta no es una solución tan buena porque, al igual que en el ejemplo anterior, resulta que si tenemos un clasificador que predice que “y” es igual a 1 todo el tiempo, encontraremos una recuperación muy alta y terminaremos con un valor muy bajo para la precisión. Por el contrario, si tenemos un clasificador que predice que “y” es igual a 0 casi todo el tiempo, es decir, si la predicción de que “y” es igual a 1 aparece rara vez, indica que tenemos un umbral muy alto utilizando la notación de la línea anterior. Por lo tanto, podemos acabar con una precisión muy alta y con una recuperación baja. Los dos extremos son tener ya sea un umbral muy alto o un umbral bajo y ninguno de ellos nos dará un clasificador particularmente bueno. Podemos reconocer esto viendo si tenemos una precisión muy baja o una recuperación muy baja. Si sólo tomas el promedio de “p” más “r” sobre 2, en este ejemplo, el promedio más alto será el del algoritmo 3. Aunque puedes obtener este desempeño prediciendo “y” igual a 1 todo el tiempo, no tendrás un clasificador de buena calidad ¿cierto? Si predices que “y” es igual a 1 todo el tiempo, el clasificador no será muy útil si tu resultado siempre es “y” es igual a 1. Entonces, el algoritmo uno o el algoritmo dos serían más útiles que el algoritmo tres, pero en este ejemplo, el algoritmo número tres tiene un valor más alto de precisión y recuperación que los algoritmos uno o dos. Generalmente pensamos en el promedio de precisión y recuperación como una manera no muy efectiva de evaluar un algoritmo de aprendizaje. En contraste, hay una manera distinta de combinar la precisión y la recuperación. Se llama Valor F y utiliza esta fórmula. Aquí tenemos los valores F para este ejemplo. Con base en estos valores F podemos decir que el algoritmo 1 tiene el valor F más grande. El algoritmo 2 tiene el segundo más grande y el algoritmo 3 tiene el más bajo. Si nos guiamos por el valor F probablemente elegiremos el algoritmo 1 en vez de los otros. El valor F también se le llama valor F1 y que se escribe como valor F1 como lo tengo aquí, pero muchos le llaman solamente valor F. Se utiliza cualquiera de los dos nombres. El valor F es como la precisión y la recuperación promedio, pero usa el valor más bajo de precisión o de recuperación - el que sea más bajo - y arroja un peso más alto. En el numerador puedes ver que el valor F es un producto de la precisión y la recuperación. Si la precisión o la recuperación son iguales a cero, el valor también será igual a 0. En ese sentido, combina la precisión y la recuperación. para que el valor F sea mayor, entonces, la precisión y la recuperación también tendrán que ser mayores. Debo decir que hay muchas fórmulas posibles para combinar la precisión y la recuperación. La fórmula del valor F es una de muchas posibilidades pero, históricamente o tradicionalmente es la que se utiliza en el aprendizaje automático. El término valor F realmente no significa nada, así que no te preocupes por el nombre, ya sea valor F o valor F1. Este valor generalmente nos da el efecto que queremos porque si la posición o la recuperación son iguales a 0, obtendremos un valor F bajo. Si queremos un valor de F mayor, necesitará que la precisión o la recuperación sean iguales a 1. De manera específica, si “p” es igual a 0 o “r” es igual a 0 entonces indica que el valor F también es igual a 0. Un valor perfecto de F, es decir, una precisión igual a 1 o una recuperación igual a 1 nos dará un valor de F igual a 1 por 1 entre 2 por 2. El valor F será igual a 1 si tienes una precisión y una recuperación perfecta. Los valores intermedios entre 0 y 1 nos dan un orden por rangos de los diferentes clasificadores. En este video hablamos de la noción de compensación entre la precisión y la recuperación y de cómo podemos variar el umbral para decidir si debemos predecir “y” es igual a 1 o “y” es igual a 0. Este umbral nos indica que debemos tener una certeza del 70% o del 90% antes de predecir que “y” es igual a 1. Puedes controlar la compensación entre la precisión y la recuperación variando el umbral. También hablamos acerca del valor F, que toma la precisión y la recuperación y arroja el resultado como una métrica de evaluación con un número real simple. Por supuesto, si tu meta es ajustar ese umbral automáticamente para decidir si “y” es igual a 1 o “y” es igual a 0, una manera muy razonable de hacerlo es intentar una gama de valores para el umbral. Intenta aplicar un rango de valores para el umbral y evaluar cada valor, digamos, en el conjunto de validación cruzada. Luego elige el umbral que te de el valor de F más alto en el conjunto de validación cruzada. Esta sería una manera razonable de elegir automáticamente el umbral para tu clasificador.