No vídeo anterior nós falámos sobre análise de erro e a importância de termos métricas de erro, ou seja, de ter um único número como métrica de avaliação para o seu algoritmo de aprendizagem para ver o quão bem ele está funcionando. No contexto de avaliação e métricas de erro, existe um caso importante, onde se é particularmente difícil descobrir uma métrica de erro apropriada, ou métrica de avaliação, para o seu algoritmo de aprendizagem. Esse é o caso do que chamamos de classes desiquilibradas. Vou dizer o que isso significa. Considere o problema de classificação de câncer, onde temos informações de pacientes e queremos decidir se eles têm ou não câncer. Então, isso é como a classificação entre tumores malignos e benignos que tivemos como exemplo anteriormente. Digamos que y=1 se o paciente tiver câncer e y=0 se não tiverem. Nós treinamos o classificador por progressão e digamos que ao testar no conjunto de teste nós conseguimos um erro de 1%. Logo, temos 99% de acerto nos diagnósticos. Isso aparentemente é um resultado bem impressionante. Nós estamos certos 99% do tempo. Mas agora, digamos que descobrimos que apenas 0.5% dos pacientes no nosso conjunto de treino realmente tem câncer. Somente a metade de um porcento dos pacientes que passaram pelo processo de análise possuem câncer. Nesse caso, o 1% de erro já não parece tão impressionante. E, em particular, aqui está um pedaço de código que não vem de aprendizagem que pega as características de entrada e as ignora. Simplesmente define y=0 e sempre prediz que ninguém tem câncer, e esse algoritmo teria na realidade um erro de 0.5%. Isso é ainda melhor que o erro de 1% que estávamos alcançando e isso é um algoritmo que não usa aprendizagem, que é simplesmente predizer sempre y=0. Isso é o cenário onde a razão entre exemplos positivos e negativos é muito próxima de um dos extremos, e, nesse caso, o número de exemplos positivos é muito, muito menor que o número de exemplos negativos porque y é 1 muito raramente. Isso é o que chamamos de caso de classes desiquilibradas. Nós temos muito mais exemplares de uma classe do que da outra. E simplesmente predizendo sempre que y=0, ou talvez que y=1 sempre, um algoritmo pode-se sair muito bem. Então o problema em usar erro de classificação ou erro de precisão como métricas de avaliação é o seguinte. Digamos que você tenha um algoritmo de aprendizagem com precisão de 99.2%, ou seja, erro de 0.8%. Digamos que você faça uma modificação no seu algoritmo e agora tenha 99.5% de acerto, ou 0.5% de erro Isso é realmente uma melhoria no algoritmo ou não? Uma das coisas boas de ter um único número real como métrica de avaliação é que isso nos ajuda a decidir rapidamente se precisamos modificar o algoritmo ou não. Indo de 99.2% de acerto para 99.5%, será que fizemos algo útil ou simplesmente trocamos nosso código por algo que prediz y=0 mais frequentemente? Se você tiver classes muito desiquilibradas fica muito mais difícil de usar apenas precisão de classificação, porque se consegue precisões de classificação muito altas ou erros muito baixos, e não fica sempre claro se isso realmente está melhorando a qualidade do nosso classificador, por que predizer sempre que y=0 não me parece um classificador muito bom. Ao apenas escolher y=0 mais vezes pode-se diminuir seu erro, talvez em até 0.5%. Quando nos deparamos com classes tão desiquilibradas nós gostaríamos de encontrar uma métrica de erro diferente ou uma métrica de avaliação diferente. Uma métrica possível é o que chamamos de precisão de recuperação. Deixe-me explicar o que é isso. Digamos que eu esteja avaliando um classificador no conjunto de testes. Por exemplo no conjunto de teste a classe real do exemplo será ou 0 ou 1, se o problema for de classificação binária. E o nosso algoritmo de aprendizagem vai predizer algum valor para a classe, e nosso algoritmo de aprendizagem vai predizer o valor para cada exemplo no meu conjunto de teste, e esse valor será ou 0 ou 1. Eu vou desenhar uma tabela 2 por 2 dessa maneira, que depende dessas entradas, depende de qual era a classe real e qual foi a classe predita. Se tivermos um exemplo onde a classe real é um e a classe predita é 1 então isso é o que chamamos de um positivo verdadeiro, que significa que o algoritmo classificou como positivo e o exemplar é na realidade positivo. Se nosso algoritmo de aprendizagem disse que algo é negativo, classe 0, e a classe real também é 0, isso é o que chamamos de negativo verdadeiro. Predizemos 0 e é realmente 0. Para encontrar os outros quadrados, se nosso algoritmo de aprendizagem disser que a classe é 1 mas na verdade ela é 0, então isso é um positivo falso. Isso quer dizer que para o nosso algoritmo o paciente tem câncer mas na verdade ele não tem. E finalmente, na última caixa temos 0 e 1, que é chamado falso negativo por que nosso algoritmo previu 0, mas a classe real era 1. Assim nós temos essa tabela 2 por 2 baseada em qual era a classe verdadeira e qual foi a classe predita. Aqui está outra maneira de avaliar a performance do seu algoritmo. Vamos calcular dois números. O primeiro é chamado precisão, ou seja, de todos os pacientes que afirmamos ter câncer, qual a fração que realmente tinha câncer? Vou escrever isso aqui, A precisão de um classificador é o número de positivos verdadeiros dividido pelo número de positivos preditos. De todos os pacientes a quem nós dissémos "Nós achamos que você tem câncer", de todos esses pacientes, qual a fração que realmente tem câncer? Isso é o que se chama de precisão. Outra maneira de escrever isso seria positivos verdadeiros dividido pelo número de positivos preditos, e isso seria a soma das entradas da primeira linha da tabela. Seria positivos verdadeiros dividido por positivos verdadeiros, [Vou abreviar positivo por POS], somado com positivos falsos, abreviando positivo como pos. Então isso é a chamada precisão, e alta precisão é algo desejável. Significaria que para todos os pacientes que disséssemos "Infelizmente pensamos que você tenha câncer", alta precisão significa que para esse grupo de pacientes fizemos predições corretas e eles realmente tem câncer. O segundo valor que vamos calcular é chamado lembrança ("recall"), e lembrança é, de todos os pacientes no conjunto de testes ou no conjunto de validação, de todos os pacientes que realmente tem câncer, qual a porção que foram detectados como tendo câncer. Ou seja, de todos os pacientes que tem câncer, quantos deles nós realmente fomos e avisamos que eles precisam de tratamento. Escrevendo isso, lembrança é definido como o número de positivos verdadeiros, que é o número de pessoas que têm câncer e que predizemos corretamente como tendo câncer, divido pelo dividido pelo número de positivos, que é a quantidade de pessoas que realmente tem câncer. Qual a porção delas que identificamos e mandamos para tratamento. Para reescrever isso de outra maneira, o denominador seria o número de positivos reais, que é a soma das entradas dessa primeira coluna. Reescrevendo isso, isso seria o número de positivos verdadeiros divido pelo número de positivos verdadeiros mais o número de negativos falsos. Novamente, ter uma boa lembrança seria algo bom. Ao calcular precisão e lembrança nos dá uma melhor noção da performance do nosso classificador. E particularmente se tivermos um algoritmo que prediz y=0 todas as vezes, se prediz que ninguém tem câncer, esse classificador terá lembrança igual a zero, por que não haverá nenhum positivo verdadeiro, sendo uma maneira rápida de reconhecer que um classificador que prediz sempre 0 não é um bom classificador. Em geral, até para situações com classes bem desiquilibradas, é impossível que um algoritmo trapaceie e de alguma forma consiga uma precisão muito alta e uma lembrança muito alta ao simplesmente predizer y=0 sempre ou y=1 sempre. Assim temos muito mais certeza que um classificador com precisão alta ou lembrança alta realmente é um bom classificador, e isso nos dá uma medida de avaliação mais útil que é uma maneira mais direta para entender se o nosso algoritmo está funcionando. Um último comentário acerca da definição de precisão e lembrança: quando definimos precisão e lembrança, normalmente usamos a convenção de que y=1, na presença de uma classe mais rara. Assim, se estivermos tentando detectar condições raras como câncer, esperamos que isso seja raro, precisão e lembrança são definidos para y=1, em vez de para y=0, para representar a presença dessa classe rara que estamos tentando predizer. E usando precisão  e lembrança, percebemos que mesmo que tivéssemos classes muito desiquilibradas, não é possível que um algoritmo trapaceie e prediga sempre y=1. ou sempre que y=0, e conseguir boa precisão e lembrança. Particularmente, se o classificador tem boa precisão e lembrança, podemos ter confiança de que ele está funcionando bem, mesmo para classes desiquilibradas. Para o problema de classes desiquilibradas precisão e lembrança nos dão uma visão direta sobre o que o algoritmo está fazendo e é normalmente uma maneira muito melhor de avaliar os algoritmos, do que olhando para o erro de classificação ou precisão de classificação, caso as classes sejam muito desiquilibradas.
Tradução: Eduardo Bonet | Revisão: Inês Lopes da Fonseca