En el video anterior también de como cuando nos encontramos con un problema de aprendizaje automático tenemos muchas ideas de cómo mejorar el algoritmo. En este video me gustaría hablar del concepto de análisis de errores, que me ayudará a explicarte una manera más sistemática para tomar ciertas decisiones. Si estás empezando a trabajar en una aplicación de aprendizaje automático o estás construyendo una aplicación de aprendizaje automático, se considera una buena práctica empezar, no por construir un sistema muy complicado con muchas funciones complejas, sino empezar por construir un algoritmo simple que puedes implementar rápidamente. Cuando inicio con un problema de aprendizaje, lo que hago generalmente es pasar un día, literalmente casi 24 horas, produciendo algo muy rápido y desordenado. No será un sistema sofisticado, francamente, sino algo rápido y desordenado que implementaré y luego probaré en los datos de validación cruzada. Una vez hecho esto, puedes trazar las curvas de aprendizaje. De esto fue de lo que hablamos en el conjunto de video anterior. Pero trazar las curvas de aprendizaje de los errores de entrenamiento y de prueba para saber si el algoritmo tiene un alta oscilación  o una varianza alta o algo similar, y utilizar eso para tratar de para decidir si nos ayudará tener más funciones o más datos. La razón por la que este es un buen enfoque es que cuando inicias un problema de aprendizaje, no hay una manera de saber de antemano si necesitas funciones más complejas o más datos o algo más. Es difícil predecir sin la evidencia necesaria, sin tener una curva de aprendizaje es verdaderamente difícil predecir dónde debes invertir tu tiempo. Generalmente, implementar un algoritmo muy rápido y poco refinado y trazar las curvas de aprendizaje nos ayuda a tomar estas decisiones. Si gustas, puedes pensar en esto como una manera de evitar lo que se denomina optimización prematura en programación. Esta idea sólo nos sugiere que debemos dejar que la evidencia guíe nuestras decisiones sobre en qué debemos dedicar nuestro tiempo, en vez de confiar en presentimientos, que generalmente resultan mal. Además de trazar las curvas de aprendizaje, otra cosa útil es lo que llamamos análisis de errores. Con esto me refiero a que, al construir, digamos, un clasificador de spam, veré mi conjunto de validación cruzada y analizaré manualmente los correos en los que mi algoritmo arroja errores. Revisaré los correos spam y los correos normales que fueron mal clasificados por mi algoritmo y veré si puedo identificar patrones sistemáticos en el tipo de ejemplos mal clasificados. Este proceso, si lo seguimos, te inspirará a diseñar nuevas funciones, señalará los asuntos u oportunidades actuales del sistema y te dará sugerencias para implementar mejoras. Aquí tenemos un ejemplo concreto. Digamos que construiste un clasificador de spam y tienes 500 ejemplos en el conjunto de validación cruzada. Digamos que en este ejemplo el algoritmo tiene una tasa de error muy alta y clasifica mal cien de estos ejemplos de validación cruzada. Lo que haré es examinar y clasificar manualmente estos 100 errores y clasificarlos con base en aspectos como el tipo de correo y las acciones o qué funciones probablemente hicieron que el algoritmo los clasificara mal. Y de forma específica, por el tipo de correo que es. Si vemos estos cien errores, quizá encuentre que los tipos más frecuente de errores o de correos spam mal clasificados sean correos de medicinas. Estos correos que, básicamente, intentan vender medicamentos. O correos que intentan vender réplicas, como relojes falsos o cosas falsas en general. Quizá también encontremos correos que intentan robar contraseñas. A estos también se les llama correos de phishing y son otra categoría de correos. O quizá encontremos otras categorías. En cuanto a la clasificación de los tipos de correos, lo que haría sería revisar mis 100 correos para encontrar que 12 de los correos mal clasificados son correos de medicinas, cuatro de ellos son correos que intentan vender réplicas o relojes falsos o algo similar. Supongamos que encontramos también 53 correos de phishing que intentan persuadirte de que les des tu contraseña y, por último, 31 correos de otras categorías. Y es al contar el número de correos en estas categorías que podrás descubrir que el algoritmo se desempeña especialmente mal en los correos que intentan robar contraseñas. Esto sugiere que puede valer la pena revisar con más cuidado este tipo de correos y ver si podemos obtener funciones mejores para categorizarlos correctamente. Otra cosa que puedes hacer es ver las acciones o las variables adicionales que hicieron que el algoritmo clasificara mal estos correos. Digamos que una de las hipótesis de las funciones que nos pueden ayudar a clasificar mejor los correos es intentar detectar errores ortográficos intencionales y compararlo con un enrutamiento inusual o una puntuación inusual, como el uso de muchos signos de admiración. Digamos que, revisaré manualmente estos correos me encuentro con cinco casos de este tipo, 16 de este, 32 de este y un montón de otros tipos de correos. Si esto es lo que obtienes de tu conjunto de validación cruzada, indica que el fenómeno de los errores ortográficos intencionados quizá sea muy raro y no valga la pena invertir tiempo escribiendo algoritmos para intentar detectarlos. Por el contrario, si encuentras que de hecho, hay muchos spammers que utilizan una puntuación inusual, es un indicador de que tal vez valga la pena invertir tiempo desarrollando funciones más sofisticadas con base en la puntuación. Este tipo de análisis de errores, que es el proceso de examinar manualmente los errores que comete el algoritmo, nos puede guiar hacia los métodos más eficientes que podemos intentar. Esto también explica porqué recomiendo llevar a cabo la implementación rápida y desordenada de un algoritmo. Lo que queremos saber es cuáles son los ejemplos que resultan más difíciles de clasificar para el algoritmo. Y muy a menudo resulta que diferentes algoritmos, de diferentes algoritmos de aprendizaje, encuentran, generalmente, categorías similares de dificultad de ejemplos. Implementar un algoritmo rápido y desordenado es una manera rápida de identificar algunos errores y los ejemplos más difíciles para concentrar tus esfuerzos en ellos. Por último, cuando desarrollamos algoritmos de aprendizaje, otra cosa que es útil es asegurarte de que tienes una evaluación numérica de tu algoritmo de aprendizaje. Con esto me refiero a que si estás desarrollando un algoritmo de aprendizaje, a veces es increíblemente útil tener una manera de evaluar el algoritmo de aprendizaje que arroje como resultado un número real simple que indique ya sea la precisión o el error. Un número real simple que te indique qué tan bien se desempeña tu algoritmo de aprendizaje. Hablaré más acerca de estos conceptos en los videos siguientes, pero aquí presento un ejemplo específico. Supongamos que estamos intentando decidir si debemos tratar palabras como “descuento, descuentos, descontar, descontando” como una sola palabra. Una manera de hacerlo es buscar las primeras letras de una palabra. Es decir, sólo tomamos los primeros caracteres de la palabra porque suponemos que, quizá, todas estas palabras tendrán significados similares. En el procesamiento del lenguaje natural, una manera de hacer esto es utilizando un software llamado software de radicación. Si algún día quieres intentar esto tú mismo, utiliza un motor de Búsqueda con Porter Stemmer. Este sería un buen elemento de software para llevar a cabo este tipo de radicación, que te permitirá tratar todas estas palabras, descuento, descuentos, y similares, como la misma palabra. Utilizar un software de radicación que toma las primeras letras de la palabra, puede ayudar y a la vez puede estorbar. Puede estorbar porque, por ejemplo, este software puede confundir las palabras universo y universidad como la misma porque estas palabras inician con caracteres muy similares, o con las mismas letras. La decisión decides utilizar o no este software de radicación para un clasificador de raíces a veces es difícil. Particularmente, el análisis de errores quizá no sea de ayuda para decidir si la radicación es una buena idea. La mejor manera de saber si será bueno utilizar software de radicación para ayudar a tu clasificador es intentar rápidamente y ver si funciona. Para hacer esto, tener una manera de evaluar numéricamente el algoritmo será muy útil. Lo que resulta más natural es tomar el error de validación cruzada del desempeño del algoritmo con y sin radicación. Si ejecutas tu algoritmo con radicación y terminas con un error de clasificación del cinco por ciento, y después lo vuelves a ejecutar y obtienes un error de clasificación del tres por ciento, esta disminución del error nos permite decidir rápidamente que utilizar la radicación es, de hecho, una buena idea. En este problema en particular, hay una métrica de evaluación con un número real simple; es decir, el error de validación cruzada. Más delante veremos ejemplos en los que encontrar esta métrica de evaluación con un número real simple será un poco más complicado, pero, como veremos en el video siguiente, calcular esto también te permitiría tomar decisiones más rápidamente acerca de si debes usar radicación o no. Aquí pondré otro ejemplo rápido. Imaginemos que también decides utilizar o distinguir o no entre mayúsculas y minúsculas. Aquí tenemos la palabra Mamá con mayúscula y con minúscula. ¿Debemos tratarla como dos palabras diferentes o como la misma? ¿Debemos tratar esto como una variable o como variables diferentes? Una vez más, con nuestro método para evaluar un algoritmo, si intento esto; es decir, si dejo de distinguir entre mayúsculas y minúscula, quizá obtenga un 3.2% de error. Con esto me daré cuenta que se desempeña peor que si sólo utilizara la radicación y me permite decidir rápidamente si debo distinguir o no entre mayúsculas y minúsculas. Cuando desarrollas un algoritmo de aprendizaje, intentarás muchas nuevas versiones de tu algoritmo de aprendizaje. Cada vez que vez que idea nueva, acabas examinando manualmente un montón de ejemplos para ver si está mejor o peor, se volverá muy difícil tomar decisiones sobre si debes utilizar o no la radicación o si debes distinguir entre mayúsculas y minúsculas. Al tener una métrica de evaluación de un número real simple, puedes evaluar si el error subió o bajó y puedes llegar a un resultado más rápidamente e intentar nuevas ideas casi al instante sabiendo si tu nueva idea aumentó o disminuyó el desempeño de tu algoritmo de aprendizaje. Esto te permitirá tener un progreso más rápido. La vía más recomendada para realizar el análisis de errores es en el conjunto de validación cruzada en vez de en el conjunto de prueba. Hay personas que aplicarán esto al conjunto de prueba aunque es menos apropiado matemáticamente. Es menos apropiado que realizar el análisis de errores en el conjunto de validación cruzada. Para terminar con este video, cuando comienzas con un problema de aprendizaje automático, lo que recomiendo siempre es implementar una ejecución rápida e informal del algoritmo de aprendizaje. Rara vez he visto que alguien pase poco tiempo en esta implementación rápida. Casi siempre veo que ponen mucho tiempo construyendo el primer borrador supuestamente rápido para la implementación. Realmente, no te preocupes por hacerlo demasiado rápido o demasiado informal. Sólo implementa algo tan rápido como quieras y una vez que tengas la implementación inicial te servirá como una herramienta útil para decidir en dónde enfocar tus esfuerzos porque te permite ver el tipo de errores que comete y analizarlos para sacar ideas para tu futuro desarrollo. En segundo lugar, si asumimos que tu implementación rápida incorporó una medición de evaluación con un número real simple, esto será un vehículo para que implementes nuevas ideas y verifiques rápidamente si las ideas que estás intentando mejorarán el desempeño de tu algoritmo y, por lo tanto, te permitirán tomar decisiones más rápidamente acerca de las cosas que puedes incorporar a tu algoritmo de aprendizaje.