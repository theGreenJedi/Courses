1
00:00:00,260 --> 00:00:03,120
前回の動画では、バックプロパゲーションについて話した。

2
00:00:04,230 --> 00:00:05,090
多くの人にとっては

3
00:00:05,220 --> 00:00:06,140
最初に見たら

4
00:00:06,460 --> 00:00:07,610
第一印象は

5
00:00:08,070 --> 00:00:09,250
「うげぇ。こりゃすげー複雑な

6
00:00:09,380 --> 00:00:11,650
アルゴリズムだ！
そしてこんなたくさんの

7
00:00:11,970 --> 00:00:12,990
ステップがあるなんて！」と。

8
00:00:13,130 --> 00:00:13,980
そして「私、実はそれらがどう組み合わせて使うのか良く分かってないんだぁ、、、」とか、

9
00:00:14,180 --> 00:00:15,130
さらに「これらの込み入ったステップは

10
00:00:15,400 --> 00:00:17,830
なんだかブラックボックスみたいだ！」と。

11
00:00:18,130 --> 00:00:18,830
あなたがバックプロパゲーションを、

12
00:00:18,870 --> 00:00:20,460
もしそんな風に感じていたとしても、

13
00:00:20,860 --> 00:00:22,100
実は問題ありません。

14
00:00:22,740 --> 00:00:24,100
バックプロパゲーションは残念な事に

15
00:00:24,970 --> 00:00:26,920
線形回帰やロジスティック回帰に比べると

16
00:00:27,060 --> 00:00:28,520
数学的にクリーンという訳でも

17
00:00:28,860 --> 00:00:30,680
数学的にシンプルなアルゴリズムという訳でも

18
00:00:31,130 --> 00:00:32,850
ありません。

19
00:00:33,020 --> 00:00:35,560
でも実の所、私も長年、ひょっとしたら今日ですら、

20
00:00:36,080 --> 00:00:37,310
バックプロパゲーションが何やってるのか

21
00:00:37,530 --> 00:00:39,130
いまいち直感的に理解出来てないなぁ、と

22
00:00:39,510 --> 00:00:40,320
思う事はあるけれど、

23
00:00:40,430 --> 00:00:41,790
使う分には問題なく

24
00:00:42,130 --> 00:00:43,580
とてもしっかりと

25
00:00:43,830 --> 00:00:45,980
使えてきました。

26
00:00:46,740 --> 00:00:47,850
プログラミングの宿題ちゃんとやりさえすれば

27
00:00:48,250 --> 00:00:49,920
少なくとも機械的に

28
00:00:50,480 --> 00:00:51,970
どうやってバックプロパゲーションを実装するかを

29
00:00:52,280 --> 00:00:53,710
順番に見ていく事には

30
00:00:53,810 --> 00:00:54,910
なるから。

31
00:00:55,200 --> 00:00:56,860
そうすれば自分で動かす事は出来るようになるよ。

32
00:00:57,910 --> 00:00:58,850
そしてこのビデオでやりたい事は

33
00:00:58,970 --> 00:01:00,170
バックプロパゲーションの

34
00:01:00,460 --> 00:01:01,750
手順を、もうちょっとだけ

35
00:01:02,190 --> 00:01:03,640
機械的に見てみたい。

36
00:01:04,160 --> 00:01:05,620
そうする事で、もうちょっと感覚的に

37
00:01:05,840 --> 00:01:07,450
バックプロパゲーションを機械的に行う手順は

38
00:01:07,930 --> 00:01:09,080
どんな感じかを伝えたい。

39
00:01:09,250 --> 00:01:10,590
そうする事で

40
00:01:10,790 --> 00:01:12,530
これは少なくとも良さそうなアルゴリズムだな、と思ってもらえたら幸い。

41
00:01:14,680 --> 00:01:16,240
このビデオ見た後でも

42
00:01:16,380 --> 00:01:18,000
バックプロパゲーションがまだ

43
00:01:18,760 --> 00:01:19,920
すげーブラックボックスちっくで

44
00:01:20,160 --> 00:01:21,600
複雑でたくさんの手順が有り過ぎる！と思った君に、

45
00:01:22,150 --> 00:01:23,230
ちょっとだけ魔法をかけてあげよう。

46
00:01:23,330 --> 00:01:24,740
実際の所、それでも問題無いです！

47
00:01:24,930 --> 00:01:26,760
もしそう感じてたとしても、

48
00:01:27,050 --> 00:01:27,840
私はバックプロパゲーションを長年使ってきたよ。

49
00:01:28,070 --> 00:01:31,590
たまに理解の難しい事のあるアルゴリズムだけどね。

50
00:01:32,310 --> 00:01:34,140
でも願わくばこの動画が

51
00:01:36,410 --> 00:01:37,970
バックプロパゲーションを理解する助けにならんことを！

52
00:01:38,190 --> 00:01:39,660
まずフォワードプロパゲーションが何をしてるのか

53
00:01:40,100 --> 00:01:42,290
別の角度から詳しく見ていこう。

54
00:01:43,170 --> 00:01:44,420
ここにニューラルネットワークがある。

55
00:01:44,770 --> 00:01:46,070
2つの入力ユニットがある。

56
00:01:46,390 --> 00:01:48,480
バイアスユニットを数えない。

57
00:01:48,700 --> 00:01:50,300
そして2つの隠れユニットがこのレイヤーにあり

58
00:01:50,500 --> 00:01:51,590
さらに2つの隠れユニットが

59
00:01:52,030 --> 00:01:53,490
その次のレイヤーにある。

60
00:01:53,640 --> 00:01:55,090
そして最後に出力ユニット。

61
00:01:55,520 --> 00:01:57,800
そしてこれらのカウント、

62
00:01:57,920 --> 00:02:00,240
2、2、2は、このトップのバイアスユニットを数えていない。

63
00:02:01,520 --> 00:02:03,170
フォーワードプロパゲーションを

64
00:02:03,430 --> 00:02:04,570
わかりやすく説明するために

65
00:02:04,690 --> 00:02:06,080
このネットワークをちょっと違う風に描いてみよう。

66
00:02:08,040 --> 00:02:09,180
特に、このニューラルネットのノードを

67
00:02:09,370 --> 00:02:10,840
大きな楕円で描くことで、

68
00:02:10,930 --> 00:02:12,620
その中にテキストを

69
00:02:12,920 --> 00:02:15,010
書けるようにする。

70
00:02:15,840 --> 00:02:16,800
フォワードプロパゲーションを実行する時は

71
00:02:17,600 --> 00:02:18,900
ある手本に対して

72
00:02:19,760 --> 00:02:21,190
それを手本x(i)、y(i)としよう、

73
00:02:21,610 --> 00:02:22,990
そしてこのx(i)こそが

74
00:02:23,080 --> 00:02:24,550
入力レイヤーに

75
00:02:24,740 --> 00:02:26,460
食わせる物だ。

76
00:02:27,080 --> 00:02:28,850
つまり、この

77
00:02:29,110 --> 00:02:30,290
x(i)の1とx(i)の2の2つの値が

78
00:02:30,440 --> 00:02:31,360
入力レイヤーに

79
00:02:31,510 --> 00:02:32,870
セットする値で、

80
00:02:33,010 --> 00:02:34,350
そしてその値を最初の

81
00:02:34,650 --> 00:02:36,210
隠れレイヤーへとフォワードプロパゲートするには、

82
00:02:36,360 --> 00:02:38,070
z(2)の1とz(2)の2を計算し、

83
00:02:39,370 --> 00:02:42,900
ところで、これらは

84
00:02:43,770 --> 00:02:45,010
入力ユニットからの入力の

85
00:02:45,260 --> 00:02:47,000
重み付け和だ。で、

86
00:02:47,230 --> 00:02:48,680
ロジスティック関数のsigmoid関数を

87
00:02:48,940 --> 00:02:50,670
適用するーーー

88
00:02:51,940 --> 00:02:53,630
sigmoidアクティベーション関数を

89
00:02:54,050 --> 00:02:55,670
zの値に適用すると、

90
00:02:55,960 --> 00:02:57,520
これらのアクティベーションの値が得られる。

91
00:02:57,880 --> 00:02:59,670
つまり以上で、a(2)の1と

92
00:02:59,870 --> 00:03:01,160
a(2)の2が得られる。

93
00:03:01,260 --> 00:03:02,500
次にそれをまたフォワードプロパゲートして、

94
00:03:03,940 --> 00:03:05,570
ここのz(3)の1に

95
00:03:06,010 --> 00:03:07,500
sigmoidのロジスティック関数、

96
00:03:07,690 --> 00:03:09,500
アクティベーション関数を適用し、

97
00:03:10,080 --> 00:03:11,200
そしてa(3)の1を得る。

98
00:03:11,240 --> 00:03:14,310
同様に、

99
00:03:15,580 --> 00:03:17,850
z(4)の1を得て、そこに

100
00:03:18,080 --> 00:03:19,450
アクティベーション関数を適用してa(4)の1を得るまで

101
00:03:19,630 --> 00:03:20,940
続ける。これこそが、

102
00:03:21,630 --> 00:03:23,030
ネットワークの最終的な出力の値だ。

103
00:03:24,860 --> 00:03:25,920
ちょっとスペース開ける為に

104
00:03:26,040 --> 00:03:28,490
この矢印を消す。

105
00:03:28,620 --> 00:03:30,170
そしてこの計算が

106
00:03:30,610 --> 00:03:32,280
実際に何をやってるのか見てみよう。

107
00:03:32,780 --> 00:03:33,970
この隠れユニットにフォーカスしてみると、

108
00:03:34,400 --> 00:03:35,860
このウェイト、

109
00:03:36,090 --> 00:03:37,770
マゼンダで示したが

110
00:03:37,870 --> 00:03:39,500
ウェイト、

111
00:03:39,700 --> 00:03:42,820
シータ(2)10だとしよう。

112
00:03:43,090 --> 00:03:45,930
インデックスはそんな重要でも無いんだが。

113
00:03:46,140 --> 00:03:47,440
で、こんな風に、

114
00:03:47,570 --> 00:03:49,270
ここは赤で

115
00:03:49,630 --> 00:03:51,290
シータ(2)11、

116
00:03:52,870 --> 00:03:53,970
そしてここのウェイトは

117
00:03:54,050 --> 00:03:55,370
緑、、、というよりはシアンで描いたのが

118
00:03:55,720 --> 00:03:59,530
シータ(2)12。

119
00:04:00,410 --> 00:04:01,970
以上がz(3)1を

120
00:04:02,540 --> 00:04:05,230
z(3)1を計算する方法。

121
00:04:05,410 --> 00:04:09,120
このウェイトに

122
00:04:10,430 --> 00:04:11,840
この値を掛ける。

123
00:04:13,070 --> 00:04:14,970
つまり シータ(2)10 掛ける 1、

124
00:04:16,240 --> 00:04:19,190
足すことの

125
00:04:19,410 --> 00:04:21,480
赤のウェイト 掛ける この値、

126
00:04:21,670 --> 00:04:23,690
つまり シータ(2)11 掛ける a(2)1。

127
00:04:25,270 --> 00:04:28,520
そして最後にこのシアン、

128
00:04:28,860 --> 00:04:30,140
掛けるこの値。

129
00:04:30,660 --> 00:04:33,950
つまり、足すことの

130
00:04:35,120 --> 00:04:37,300
シータ(2)12 掛ける a(2)1。

131
00:04:38,870 --> 00:04:40,170
これがフォワードプロパゲーションだ！

132
00:04:42,410 --> 00:04:43,680
そしてこのビデオの後半で見ると

133
00:04:43,870 --> 00:04:44,730
明らかになるが、

134
00:04:44,790 --> 00:04:46,140
バックプロパゲーションでやる事も

135
00:04:46,530 --> 00:04:47,730
とてもこれと

136
00:04:47,780 --> 00:04:49,120
似たプロセスだったりする。

137
00:04:49,300 --> 00:04:50,860
違いは計算の流れが

138
00:04:50,950 --> 00:04:53,120
ネットワークの左から右へと

139
00:04:53,360 --> 00:04:54,270
流れる代わりに、

140
00:04:55,250 --> 00:04:56,510
そこでは計算は

141
00:04:56,940 --> 00:04:58,070
ネットワークの

142
00:04:58,220 --> 00:04:59,720
左から右へと流れる。

143
00:05:00,050 --> 00:05:02,170
そしてこれととても似た計算を用いて、

144
00:05:02,430 --> 00:05:03,710
二枚のスライドで

145
00:05:03,920 --> 00:05:05,260
ちゃんと説明する。

146
00:05:06,400 --> 00:05:07,880
バックプロパゲーションが

147
00:05:08,070 --> 00:05:09,710
何やってるのかより良く理解する為に、

148
00:05:09,780 --> 00:05:10,920
コスト関数を見てみよう。

149
00:05:11,070 --> 00:05:12,270
一つしか出力ユニットが無い時の

150
00:05:12,670 --> 00:05:14,950
コスト関数を。

151
00:05:15,350 --> 00:05:16,300
もし一つよりも多くの

152
00:05:16,400 --> 00:05:17,410
出力ユニットがある時は

153
00:05:17,820 --> 00:05:19,850
単に出力ユニットのインデックスについて

154
00:05:19,930 --> 00:05:22,170
足し合わせてやれば良い。

155
00:05:22,370 --> 00:05:25,990
もし出力ユニットが一つしかなければ

156
00:05:26,190 --> 00:05:27,490
これがコスト関数。

157
00:05:27,610 --> 00:05:30,340
フォワードプロパゲーションとバックプロパゲーションを一度に一つの手本データずつに対して行う。

158
00:05:30,560 --> 00:05:31,440
だから一つの手本、

159
00:05:31,770 --> 00:05:34,770
x(i)、y(i)にフォーカスしよう。

160
00:05:35,360 --> 00:05:36,480
そして出力ユニットは一つのケースについてフォーカスしよう。

161
00:05:36,810 --> 00:05:38,390
つまりここのy(i)は

162
00:05:38,660 --> 00:05:40,390
単なる実数。

163
00:05:40,680 --> 00:05:42,790
さらに正規化は無視しよう。

164
00:05:43,010 --> 00:05:44,300
つまりラムダは0。

165
00:05:44,640 --> 00:05:46,480
そうすればこの最後の正規化の項は消えるからね。

166
00:05:47,320 --> 00:05:48,220
今、この和の中を

167
00:05:48,730 --> 00:05:50,480
見てみれば、

168
00:05:50,780 --> 00:05:53,290
i番目のトレーニング手本に対応する

169
00:05:53,450 --> 00:05:54,980
コストの項は

170
00:05:55,190 --> 00:05:57,230
つまりx(i)とy(i)に対応した

171
00:05:58,040 --> 00:06:00,420
コストは

172
00:06:00,540 --> 00:06:01,820
この式で与えられる。

173
00:06:02,030 --> 00:06:03,270
これがi番目のトレーニング手本に対応した

174
00:06:03,810 --> 00:06:04,910
コストという事になる。

175
00:06:06,080 --> 00:06:07,320
そしてこのコスト関数が

176
00:06:07,650 --> 00:06:08,650
やってるのは

177
00:06:09,080 --> 00:06:10,580
誤差の二乗に似た感じの役割。

178
00:06:10,750 --> 00:06:11,530
だからこの複雑な式を

179
00:06:12,190 --> 00:06:14,050
見る代わりに

180
00:06:14,170 --> 00:06:15,380
i番目に対応したコストを

181
00:06:15,620 --> 00:06:17,600
ニューラルネットワークの出力と

182
00:06:18,020 --> 00:06:19,310
実際の値との

183
00:06:19,430 --> 00:06:20,870
差分の二乗みたいなもんだと

184
00:06:21,170 --> 00:06:22,980
考えても良い。

185
00:06:23,150 --> 00:06:24,340
ロジスティック回帰の時と同様に

186
00:06:24,620 --> 00:06:25,510
実際にはこちらの

187
00:06:25,830 --> 00:06:27,060
logを使ったちょびっと複雑なコスト関数の方がいいんだけど、

188
00:06:27,370 --> 00:06:28,580
感覚的に理解する、という点では

189
00:06:28,640 --> 00:06:30,230
誤差の二乗のコスト関数なんだと

190
00:06:30,570 --> 00:06:31,440
考えて

191
00:06:32,000 --> 00:06:32,750
差し支えない。

192
00:06:33,250 --> 00:06:35,000
つまり

193
00:06:35,220 --> 00:06:36,870
このコストのiは

194
00:06:37,110 --> 00:06:38,780
どのくらいネットワークが

195
00:06:38,880 --> 00:06:40,600
うまく手本iを予測しているかを測ってる。

196
00:06:40,840 --> 00:06:42,000
どのくらい出力が

197
00:06:42,810 --> 00:06:44,640
実際の観測値、y(i)と近いかを。

198
00:06:45,590 --> 00:06:47,610
ではバックプロパゲーションが何をやってるかを見ていこう。

199
00:06:48,420 --> 00:06:50,170
有用な直感的な説明としては、

200
00:06:51,190 --> 00:06:52,940
バックプロパゲーションはこれらの

201
00:06:53,610 --> 00:06:54,840
デルタ 上付き添字l

202
00:06:55,050 --> 00:06:57,440
下付き添字j の項を計算している、というのがある。

203
00:06:57,730 --> 00:06:58,520
これらをアクティベーションの値の

204
00:06:58,650 --> 00:07:00,070
「誤差」と

205
00:07:00,300 --> 00:07:02,460
考える事が出来る、

206
00:07:02,620 --> 00:07:03,980
l番目のレイヤーの

207
00:07:04,440 --> 00:07:05,750
j番目のユニットの

208
00:07:07,130 --> 00:07:07,400
アクティベーション。

209
00:07:07,660 --> 00:07:09,070
より正式には

210
00:07:09,340 --> 00:07:10,280
解析学が得意な人向け

211
00:07:10,360 --> 00:07:11,480
だろうけど、

212
00:07:12,690 --> 00:07:14,080
より正式には、デルタ項が

213
00:07:14,260 --> 00:07:15,820
実際になんなのかというと、これだ！

214
00:07:15,950 --> 00:07:17,810
それらはz(l)jによる

215
00:07:18,240 --> 00:07:20,000
偏微分係数。

216
00:07:20,150 --> 00:07:21,460
このzは入力の重み付き和を

217
00:07:21,650 --> 00:07:22,700
計算したもので、

218
00:07:23,410 --> 00:07:25,760
これらによるコスト関数の偏微分となる。

219
00:07:27,000 --> 00:07:28,650
具体的にはコスト関数は

220
00:07:28,900 --> 00:07:30,000
ラベルyと

221
00:07:30,250 --> 00:07:31,350
このh(x)の、

222
00:07:31,470 --> 00:07:32,680
ネットワークの

223
00:07:32,780 --> 00:07:35,060
出力した値の関数。

224
00:07:35,180 --> 00:07:36,430
そしてもしこのネットワークの中に入って

225
00:07:37,340 --> 00:07:39,200
それらのz(l)jの値を

226
00:07:39,860 --> 00:07:41,450
ちょっとずらしたら、

227
00:07:41,640 --> 00:07:44,250
これらの値がニューラルネットに影響を与えて

228
00:07:44,990 --> 00:07:47,290
最終的にはコスト関数も変わる。

229
00:07:48,340 --> 00:07:50,120
もう一度言っておくと

230
00:07:50,210 --> 00:07:51,690
これはほんと解析得意な人向けの話。

231
00:07:52,960 --> 00:07:55,580
偏微分に慣れ親しんでて、快適に使える人向け。

232
00:07:56,540 --> 00:07:57,860
これらのデルタの項は

233
00:07:57,950 --> 00:07:59,270
我らの計算している、これらの中間項による

234
00:07:59,370 --> 00:08:00,800
コスト関数の

235
00:08:00,870 --> 00:08:04,010
偏微分となっている。

236
00:08:05,500 --> 00:08:07,250
つまりそれらは、

237
00:08:07,910 --> 00:08:08,940
これらの中間の値の計算に影響を与えて、

238
00:08:09,140 --> 00:08:11,090
ニューラルネットワークの最終出力、h(x)に影響を与えて、

239
00:08:11,250 --> 00:08:13,620
結果として全体のコストに影響を与える為に

240
00:08:14,150 --> 00:08:16,110
どれだけ

241
00:08:16,240 --> 00:08:17,430
ニューラルネットワークのウェイトを

242
00:08:17,470 --> 00:08:18,980
変更すれば良いかの

243
00:08:19,160 --> 00:08:20,770
指標となっている。

244
00:08:21,510 --> 00:08:22,820
この最後の部分の

245
00:08:23,030 --> 00:08:25,290
偏微分の直感が

246
00:08:25,530 --> 00:08:26,920
いまいちピンと来て無くても、心配ご無用。

247
00:08:27,070 --> 00:08:28,230
ここから後は

248
00:08:28,390 --> 00:08:29,770
偏微分なんて計算出来なくても

249
00:08:30,280 --> 00:08:32,400
やっていけるから。

250
00:08:32,660 --> 00:08:33,780
でも、バックプロパゲーションが何をやっているのか

251
00:08:34,100 --> 00:08:36,020
もうちょっと詳しく見てみよう。

252
00:08:36,250 --> 00:08:37,440
出力レイヤについては、

253
00:08:37,890 --> 00:08:39,630
最初にセットされるデルタ項だが、

254
00:08:39,830 --> 00:08:41,400
それはデルタ(4)1をy(i)、、、

255
00:08:41,700 --> 00:08:44,430
もしこのトレーニング手本のiについて

256
00:08:44,890 --> 00:08:48,010
フォワードプロパゲーションを行い、

257
00:08:48,210 --> 00:08:50,180
さらにバックプロパゲーションを行うとすると、

258
00:08:51,030 --> 00:08:52,970
y(i) - a(4)1となる。

259
00:08:53,250 --> 00:08:54,370
つまり、それは本当に誤差だ。

260
00:08:54,560 --> 00:08:55,680
実際の値であるyから、引くことの

261
00:08:56,000 --> 00:08:57,210
予言された

262
00:08:57,630 --> 00:08:58,020
値なのだから。

263
00:08:58,530 --> 00:09:00,160
こんな風にデルタ(4)1を

264
00:09:00,670 --> 00:09:01,880
計算する。

265
00:09:03,510 --> 00:09:06,200
次に、これらの値を後ろ（バック）へと伝播（プロパゲート）させていく。

266
00:09:06,910 --> 00:09:07,820
すぐに説明する。

267
00:09:08,510 --> 00:09:10,810
で、一つ前のデルタ項を計算する事になる。

268
00:09:11,350 --> 00:09:12,450
結局、デルタ(3)1とデルタ(3)2

269
00:09:12,560 --> 00:09:13,720
になる。

270
00:09:13,990 --> 00:09:15,210
そしてその後に、

271
00:09:15,600 --> 00:09:17,940
これをさらに後ろへと

272
00:09:18,380 --> 00:09:19,340
伝播させていき、

273
00:09:19,470 --> 00:09:21,960
デルタ(2)1とデルタ(2)2を

274
00:09:22,690 --> 00:09:23,800
計算する事になる。

275
00:09:25,190 --> 00:09:27,290
ここまでくると、バックプロパゲーションの計算は

276
00:09:28,730 --> 00:09:30,050
かなりフォワードプロパゲーションのアルゴリズムを

277
00:09:30,140 --> 00:09:32,870
実行するのに似通ってくる。後ろにやるだけ。

278
00:09:33,260 --> 00:09:33,890
それの意味する所はこうだ。

279
00:09:34,160 --> 00:09:35,300
どうやってこのデルタ(2)2まで

280
00:09:35,460 --> 00:09:37,370
来たのか見てみよう。

281
00:09:38,060 --> 00:09:39,280
デルタ(2)2がある。

282
00:09:39,480 --> 00:09:42,330
フォワードプロパゲーションみたいに

283
00:09:42,600 --> 00:09:44,760
幾つかのウェイトにラベルをつけよう。

284
00:09:45,000 --> 00:09:47,620
このウェイトはシアンの色で、

285
00:09:47,890 --> 00:09:50,680
シータ(2)の1 2で、

286
00:09:51,190 --> 00:09:54,190
そしてこの下の

287
00:09:54,450 --> 00:09:55,970
ウェイトは、赤で書こう、

288
00:09:56,280 --> 00:09:57,740
これを以後、シータ(2)の2 2と

289
00:09:58,030 --> 00:09:59,760
呼ぼう。

290
00:10:01,510 --> 00:10:03,410
さて、デルタ(2)の2が

291
00:10:03,500 --> 00:10:05,450
どう計算されるか

292
00:10:05,800 --> 00:10:07,540
このノードはどう計算されるのか？
見てみよう。

293
00:10:08,390 --> 00:10:09,690
計算する為に

294
00:10:09,800 --> 00:10:10,830
やる事は

295
00:10:10,970 --> 00:10:12,030
この値を取って

296
00:10:12,350 --> 00:10:14,340
このウェイトを掛ける、

297
00:10:14,630 --> 00:10:16,770
そしてそれを足し合わせる事の

298
00:10:17,580 --> 00:10:18,660
この値掛けるそのウェイト。

299
00:10:18,930 --> 00:10:19,850
つまりそれは本当に

300
00:10:20,800 --> 00:10:22,880
これらのデルタの値の重み付き和だ。

301
00:10:23,280 --> 00:10:25,570
対応するエッジの重みで重みづけする。

302
00:10:25,960 --> 00:10:27,270
具体的に書き下してみよう。

303
00:10:28,430 --> 00:10:29,550
このデルタ(2)2はイコール、

304
00:10:30,270 --> 00:10:32,610
シータ(2)の1 2ーー

305
00:10:33,110 --> 00:10:34,660
これはマゼンダ色で描いた重みーー

306
00:10:34,980 --> 00:10:38,850
掛ける事のデルタ(3)1、 足すことの

307
00:10:38,990 --> 00:10:40,080
次は赤の奴。

308
00:10:41,230 --> 00:10:43,530
シータ(2)の2 2掛ける

309
00:10:43,860 --> 00:10:46,230
デルタ(3) 2。

310
00:10:46,700 --> 00:10:48,550
つまり本当に、文字通り、

311
00:10:48,800 --> 00:10:51,340
この赤のウェイト掛けるこの値、足すことの

312
00:10:51,570 --> 00:10:52,690
このマゼンダのウェイト掛けることのこの値。

313
00:10:53,540 --> 00:10:55,820
それがこの値、デルタを計算する方法。

314
00:10:56,880 --> 00:10:59,490
もう一つ見てみよう。この値を見てみる。

315
00:10:59,870 --> 00:11:00,750
この値はどうやったら得られるか？

316
00:11:01,320 --> 00:11:02,660
それは似た感じで、

317
00:11:02,890 --> 00:11:04,490
このウェイトをとりあえず

318
00:11:05,530 --> 00:11:07,000
緑で表しておくと、

319
00:11:07,100 --> 00:11:08,310
このウェイトを

320
00:11:08,440 --> 00:11:09,860
シータ(3)の1 2とすると、

321
00:11:10,450 --> 00:11:12,990
デルタ(3)2は

322
00:11:13,920 --> 00:11:15,360
その場合、

323
00:11:15,630 --> 00:11:17,010
イコール

324
00:11:17,910 --> 00:11:19,860
緑のウェイト、シータ(3) 1 2

325
00:11:20,800 --> 00:11:22,260
掛ける デルタ(4) 1だ。

326
00:11:22,930 --> 00:11:25,520
ところで、

327
00:11:25,610 --> 00:11:26,560
ここまでの所、

328
00:11:26,670 --> 00:11:28,310
デルタの値を隠れユニットにだけ

329
00:11:28,660 --> 00:11:30,390
書いてきた。

330
00:11:30,560 --> 00:11:32,750
そしてバイアスのユニットには書いて来なかった。

331
00:11:33,620 --> 00:11:34,610
バックプロパゲーションのアルゴリズムを

332
00:11:35,030 --> 00:11:37,170
どう定義するか、または

333
00:11:37,330 --> 00:11:38,610
どう実装するかによって、

334
00:11:38,710 --> 00:11:40,510
これらのバイアスユニットに対する

335
00:11:40,850 --> 00:11:42,390
デルタの値を計算する事に

336
00:11:42,900 --> 00:11:43,950
なったりする。

337
00:11:44,960 --> 00:11:46,230
バイアスユニットはいつも

338
00:11:46,620 --> 00:11:47,880
値、+1を出力する。

339
00:11:47,990 --> 00:11:48,980
それがまさにバイアスユニットという物だ。

340
00:11:49,220 --> 00:11:50,060
そしてその値を変更する方法は

341
00:11:50,210 --> 00:11:51,960
存在しない。

342
00:11:52,340 --> 00:11:53,440
だからバックプロパゲーションの実装方法によるが、

343
00:11:53,770 --> 00:11:54,960
私の普段の実装方法だと、

344
00:11:55,090 --> 00:11:56,180
これらのデルタの値は

345
00:11:56,340 --> 00:11:57,670
計算してる。でも、

346
00:11:57,760 --> 00:11:58,900
ただその結果を捨てていて、

347
00:11:58,990 --> 00:12:00,560
使っていない。

348
00:12:00,800 --> 00:12:02,130
何故ならそれらは結局のところ

349
00:12:02,220 --> 00:12:04,130
微分を計算するのに必要な計算に含まれていないから。

350
00:12:04,990 --> 00:12:06,720
さて、以上でバックプロパゲーションが

351
00:12:06,990 --> 00:12:08,360
何をしているか、感覚的な理解が

352
00:12:08,750 --> 00:12:10,380
ちょっとでも与えられたら幸い。

353
00:12:12,480 --> 00:12:13,290
もしこれらを見てもなお、

354
00:12:13,440 --> 00:12:14,670
全部魔法のようで

355
00:12:14,760 --> 00:12:16,090
あまりにもブラックボックスに感じられた場合は

356
00:12:16,240 --> 00:12:17,560
あとのビデオ、

357
00:12:17,770 --> 00:12:19,880
「Putting It Together」（ビデオのタイトル）の中で、

358
00:12:20,150 --> 00:12:22,650
バックプロパゲーションが何をしているかについて、さらなる直感を提供したいと思っている。

359
00:12:23,250 --> 00:12:24,360
でも残念なお知らせがある。

360
00:12:24,450 --> 00:12:26,370
これは、可視化したり、

361
00:12:26,510 --> 00:12:28,770
それが本当の所何をやっているのかを理解するのは難しいアルゴリズムだ。

362
00:12:29,500 --> 00:12:30,790
だが良い知らせもある。

363
00:12:30,990 --> 00:12:32,280
私の推測するところによると、

364
00:12:32,940 --> 00:12:33,930
たくさんの人がとてもうまく

365
00:12:34,420 --> 00:12:35,640
このアルゴリズムを使えていて、

366
00:12:35,730 --> 00:12:37,810
実装してみると、

367
00:12:37,990 --> 00:12:40,090
とても効率的な学習アルゴリズムだ、

368
00:12:40,340 --> 00:12:41,400
たとえ中がどうなってるのか、正確に何が起こるかを

369
00:12:41,900 --> 00:12:43,190
可視化するのが難しいにせよ。