1
00:00:00,260 --> 00:00:03,120
En el video anterior, hablamos sobre el algoritmo de retropropagación.

2
00:00:04,230 --> 00:00:05,090
Para mucha gente

3
00:00:05,220 --> 00:00:06,140
que lo esté viendo por primera vez,

4
00:00:06,460 --> 00:00:07,610
la primera impresión a menudo es

5
00:00:08,070 --> 00:00:09,250
¡Vaya!, este es

6
00:00:09,380 --> 00:00:11,650
un algoritmo en verdad muy complicado y mira todos

7
00:00:11,970 --> 00:00:12,990
estos diferentes pasos. No estoy

8
00:00:13,130 --> 00:00:13,980
muy seguro cómo encajan

9
00:00:14,180 --> 00:00:15,130
entre sí y es como si fuera

10
00:00:15,400 --> 00:00:17,830
una caja negra con todos estos pasos complicados.

11
00:00:18,130 --> 00:00:18,830
En caso de que así sea como tú te sientes

12
00:00:18,870 --> 00:00:20,460
respecto a la retropropagación,

13
00:00:20,860 --> 00:00:22,100
no te preocupes, está bien.

14
00:00:22,740 --> 00:00:24,100
La retropropagación quizás sea por desgracia

15
00:00:24,970 --> 00:00:26,920
un algoritmo matemáticamente menos limpio

16
00:00:27,060 --> 00:00:28,520
o menos simple

17
00:00:28,860 --> 00:00:30,680
en comparación con la regresión lineal o

18
00:00:31,130 --> 00:00:32,850
la regresión logística y yo en realidad he

19
00:00:33,020 --> 00:00:35,560
usado la retropropagación, ¿sabes?, con bastante

20
00:00:36,080 --> 00:00:37,310
éxito durante muchos años e

21
00:00:37,530 --> 00:00:39,130
incluso hoy en día, algunas veces todavía

22
00:00:39,510 --> 00:00:40,320
siento como que no tengo un sentido

23
00:00:40,430 --> 00:00:41,790
muy claro de qué es

24
00:00:42,130 --> 00:00:43,580
lo está haciendo, en su mayoría es intuición, acerca de

25
00:00:43,830 --> 00:00:45,980
qué está haciendo la propagación de fondo.

26
00:00:46,740 --> 00:00:47,850
Para aquellos de ustedes que estén haciendo

27
00:00:48,250 --> 00:00:49,920
los ejercicios de programación que

28
00:00:50,480 --> 00:00:51,970
al menos mecánicamente los guiarán

29
00:00:52,280 --> 00:00:53,710
a través de los diferentes pasos sobre

30
00:00:53,810 --> 00:00:54,910
cómo implementar la retropropagación,

31
00:00:55,200 --> 00:00:56,860
pues bien, ustedes serán capaces de hacer que esto funcione para si mismos.

32
00:00:57,910 --> 00:00:58,850
y lo que quiero hacer

33
00:00:58,970 --> 00:01:00,170
en este video es poner

34
00:01:00,460 --> 00:01:01,750
un poco más de atención sobre los

35
00:01:02,190 --> 00:01:03,640
pasos mecánicos de la retropropagación

36
00:01:04,160 --> 00:01:05,620
y tratar de darles una intuición

37
00:01:05,840 --> 00:01:07,450
un poco mejor acerca de qué es

38
00:01:07,930 --> 00:01:09,080
lo que están haciendo los pasos mecánicos

39
00:01:09,250 --> 00:01:10,590
de la retropropagación para con suerte convencerlos

40
00:01:10,790 --> 00:01:12,530
de que, bueno ya sabes, al menos de qué es un algoritmo razonable.

41
00:01:14,680 --> 00:01:16,240
En caso de que aún después de este video, la

42
00:01:16,380 --> 00:01:18,000
retropropagación todavía te parezca

43
00:01:18,760 --> 00:01:19,920
que es una caja muy negra y, que bueno,

44
00:01:20,160 --> 00:01:21,600
ya sabes, sean pasos demasiado complicados

45
00:01:22,150 --> 00:01:23,230
e incluso un tanto mágicos para ti,

46
00:01:23,330 --> 00:01:24,740
no te preocupes, todo está bien.

47
00:01:24,930 --> 00:01:26,760
Y aún cuando,

48
00:01:27,050 --> 00:01:27,840
ya sabes, he utilizado la retropropagación

49
00:01:28,070 --> 00:01:31,590
durante muchos años, a veces es un algoritmo difícil de entender.

50
00:01:32,310 --> 00:01:34,140
Pero espero que este video te ayude un poco.

51
00:01:36,410 --> 00:01:37,970
Con el fin de comprender mejor la

52
00:01:38,190 --> 00:01:39,660
retropropagación, echemos otro vistazo

53
00:01:40,100 --> 00:01:42,290
a qué está haciendo la propagación hacia adelante.

54
00:01:43,170 --> 00:01:44,420
Aquí se encuentra la red neuronal con dos

55
00:01:44,770 --> 00:01:46,070
unidades de entrada que no está

56
00:01:46,390 --> 00:01:48,480
tomando en cuenta la unidad de oscilación, y

57
00:01:48,700 --> 00:01:50,300
dos unidades ocultas en esta

58
00:01:50,500 --> 00:01:51,590
capa y dos unidades ocultas

59
00:01:52,030 --> 00:01:53,490
en la siguiente capa y luego

60
00:01:53,640 --> 00:01:55,090
tendríamos una unidad de salida.

61
00:01:55,520 --> 00:01:57,800
Y otra vez, estas cuentan 2,

62
00:01:57,920 --> 00:02:00,240
2, 2 no cuentan estas unidades de oscilación en la parte superior.

63
00:02:01,520 --> 00:02:03,170
Con el fin de ilustrar la propagación

64
00:02:03,430 --> 00:02:04,570
hacia adelante, voy a

65
00:02:04,690 --> 00:02:06,080
dibujar esta red un poco diferente.

66
00:02:08,040 --> 00:02:09,180
Y en particular, voy a

67
00:02:09,370 --> 00:02:10,840
dibujar esta red neuronal con los

68
00:02:10,930 --> 00:02:12,620
nodos dibujados como estas elipses

69
00:02:12,920 --> 00:02:15,010
muy gordas, de modo que pueda escribir texto en ellas.

70
00:02:15,840 --> 00:02:16,800
Cuando se realiza la propagación hacia adelante,

71
00:02:17,600 --> 00:02:18,900
puede que tengamos algún ejemplo concreto,

72
00:02:19,760 --> 00:02:21,190
digamos algún ejemplo con x(i) coma

73
00:02:21,610 --> 00:02:22,990
y(i) y será

74
00:02:23,080 --> 00:02:24,550
esta x(i) que introdujimos

75
00:02:24,740 --> 00:02:26,460
en la capa de entrada, para

76
00:02:27,080 --> 00:02:28,850
que esto pueda ser,

77
00:02:29,110 --> 00:02:30,290
x(i)1 y x(i)2 (i) que son los

78
00:02:30,440 --> 00:02:31,360
valores con los que establecemos la capa

79
00:02:31,510 --> 00:02:32,870
de entrada y cuando los

80
00:02:33,010 --> 00:02:34,350
propagamos hacia adelante en dirección

81
00:02:34,650 --> 00:02:36,210
a la primera capa oculta, lo que

82
00:02:36,360 --> 00:02:38,070
que hacemos es calcular z(2) 1 y

83
00:02:39,370 --> 00:02:42,900
z(2) 2, y así, éstos son la

84
00:02:43,770 --> 00:02:45,010
suma ponderada de las entradas de las

85
00:02:45,260 --> 00:02:47,000
unidades de entrada y luego

86
00:02:47,230 --> 00:02:48,680
aplicamos el sigmoide de

87
00:02:48,940 --> 00:02:50,670
la función logística y la

88
00:02:51,940 --> 00:02:53,630
función de activación sigmoidea aplicada

89
00:02:54,050 --> 00:02:55,670
al valor de z, y nos da

90
00:02:55,960 --> 00:02:57,520
estos valores de activación

91
00:02:57,880 --> 00:02:59,670
Bien, esto nos da a(2)1

92
00:02:59,870 --> 00:03:01,160
y a(2) 2 y luego propagamos

93
00:03:01,260 --> 00:03:02,500
hacia adelante otra vez para obtener,

94
00:03:03,940 --> 00:03:05,570
ya sabes, aquí, z(3) 1,

95
00:03:06,010 --> 00:03:07,500
aplicamos el sigmoideo de la

96
00:03:07,690 --> 00:03:09,500
función logística, la función de activación

97
00:03:10,080 --> 00:03:11,200
a esto, para obtener

98
00:03:11,240 --> 00:03:14,310
3,1 y asimismo, de este modo,

99
00:03:15,580 --> 00:03:17,850
hasta que lleguemos a z(4) 1, aplicamos la

100
00:03:18,080 --> 00:03:19,450
la función de activación a esto y

101
00:03:19,630 --> 00:03:20,940
nos da a(4) 1 que es el

102
00:03:21,630 --> 00:03:23,030
mejor valor de salida de la red neuronal.

103
00:03:24,860 --> 00:03:25,920
Voy a borrar esta flecha para

104
00:03:26,040 --> 00:03:28,490
darme un poco de espacio, y si

105
00:03:28,620 --> 00:03:30,170
miras lo que éste cálculo

106
00:03:30,610 --> 00:03:32,280
realmente está haciendo, enfocándonos

107
00:03:32,780 --> 00:03:33,970
en esta unidad oculta

108
00:03:34,400 --> 00:03:35,860
digamos que tenemos

109
00:03:36,090 --> 00:03:37,770
este peso, que se muestra en

110
00:03:37,870 --> 00:03:39,500
magenta, es mi

111
00:03:39,700 --> 00:03:42,820
peso «theta» 2(1)0 la

112
00:03:43,090 --> 00:03:45,930
indexación no es importante, y de esta

113
00:03:46,140 --> 00:03:47,440
manera aquí, que supongo

114
00:03:47,570 --> 00:03:49,270
estoy resaltando en rojo, eso

115
00:03:49,630 --> 00:03:51,290
es «theta» 2(1) 1 y

116
00:03:52,870 --> 00:03:53,970
este peso de aquí, que estoy

117
00:03:54,050 --> 00:03:55,370
dibujando en verde, en turquesa,

118
00:03:55,720 --> 00:03:59,530
es «theta» 2(1) 2, entonces,

119
00:04:00,410 --> 00:04:01,970
la forma en la que se calcula el valor de z(3) 1

120
00:04:02,540 --> 00:04:05,230
es z(3) 1 que es

121
00:04:05,410 --> 00:04:09,120
igual a este peso en magenta,

122
00:04:10,430 --> 00:04:11,840
tantas veces este valor, así que

123
00:04:13,070 --> 00:04:14,970
«theta» 2(1) 0 veces 1,

124
00:04:16,240 --> 00:04:19,190
y entonces + este peso

125
00:04:19,410 --> 00:04:21,480
en rojo por veces este valor, y así,

126
00:04:21,670 --> 00:04:23,690
eso es «theta» 2(1) 1 veces

127
00:04:25,270 --> 00:04:28,520
a(2) 1, y finalmente este

128
00:04:28,860 --> 00:04:30,140
turquesa rojo tantas veces este valor,

129
00:04:30,660 --> 00:04:33,950
que es, por lo tanto, + «theta»

130
00:04:35,120 --> 00:04:37,300
2(1) 2 veces a(2) 1.

131
00:04:38,870 --> 00:04:40,170
Y bien, eso es la propagación hacia adelante.

132
00:04:42,410 --> 00:04:43,680
Y resulta que, como

133
00:04:43,870 --> 00:04:44,730
veremos más adelante en este

134
00:04:44,790 --> 00:04:46,140
video, lo que la retropropagación

135
00:04:46,530 --> 00:04:47,730
está haciendo es, realizar un

136
00:04:47,780 --> 00:04:49,120
proceso muy similar a

137
00:04:49,300 --> 00:04:50,860
esto, excepto que en lugar de

138
00:04:50,950 --> 00:04:53,120
los cálculos fluyan de

139
00:04:53,360 --> 00:04:54,270
izquierda a derecha en esta red,

140
00:04:55,250 --> 00:04:56,510
el flujo de cálculos va

141
00:04:56,940 --> 00:04:58,070
de derecha a

142
00:04:58,220 --> 00:04:59,720
izquierda en la red y utiliza

143
00:05:00,050 --> 00:05:02,170
un cálculo muy similar a este,

144
00:05:02,430 --> 00:05:03,710
y diré en dos

145
00:05:03,920 --> 00:05:05,260
diapositivas más exactamente lo que quiero decir con esto.

146
00:05:06,400 --> 00:05:07,880
Para entender mejor lo que está haciendo

147
00:05:08,070 --> 00:05:09,710
la retropropagación, vamos ver

148
00:05:09,780 --> 00:05:10,920
la función de costo. Sólo es la

149
00:05:11,070 --> 00:05:12,270
función de costo que teníamos para

150
00:05:12,670 --> 00:05:14,950
cuando tuviéramos sólo una unidad de salida

151
00:05:15,350 --> 00:05:16,300
Si tenemos más de

152
00:05:16,400 --> 00:05:17,410
una unidad de salida, sólo

153
00:05:17,820 --> 00:05:19,850
tenemos una suma total, ya sabes, mayor a las

154
00:05:19,930 --> 00:05:22,170
unidades de salida indexadas mediante k allí, pero si sólo hay

155
00:05:22,370 --> 00:05:25,990
una unidad de salida entonces esta

156
00:05:26,190 --> 00:05:27,490
es una función de costos y

157
00:05:27,610 --> 00:05:30,340
hacemos una propagación hacia adelante y una retropropagación en un ejemplo a la vez.

158
00:05:30,560 --> 00:05:31,440
Así que, vamos a centrarnos en un

159
00:05:31,770 --> 00:05:34,770
único ejemplo x(i)y(i) y enfoquémonos

160
00:05:35,360 --> 00:05:36,480
en el caso en el que se tiene una unidad

161
00:05:36,810 --> 00:05:38,390
de salida como y(i) aquí

162
00:05:38,660 --> 00:05:40,390
que sólo es un número real, e

163
00:05:40,680 --> 00:05:42,790
ignoremos la regularización, y así lambda

164
00:05:43,010 --> 00:05:44,300
que sea igual a cero y este término

165
00:05:44,640 --> 00:05:46,480
final, este término de regularización desaparece.

166
00:05:47,320 --> 00:05:48,220
Ahora, si observamos

167
00:05:48,730 --> 00:05:50,480
esta suma total, descubrirás que

168
00:05:50,780 --> 00:05:53,290
el término del costo asociado con

169
00:05:53,450 --> 00:05:54,980
el ejemplo de entrenamiento “i-nésimo”, es decir

170
00:05:55,190 --> 00:05:57,230
el costo asociado con el ejemplo

171
00:05:58,040 --> 00:06:00,420
de entrenamiento x(i)y(i), que

172
00:06:00,540 --> 00:06:01,820
va a ser dado por esta expresión, en el que

173
00:06:02,030 --> 00:06:03,270
el costo es, digamos, del ejemplo de entrenamiento

174
00:06:03,810 --> 00:06:04,910
i que está escrito así.

175
00:06:06,080 --> 00:06:07,320
Y lo que esta función

176
00:06:07,650 --> 00:06:08,650
de costo hace es que juega

177
00:06:09,080 --> 00:06:10,580
un papel similar al error cuadrático.

178
00:06:10,750 --> 00:06:11,530
Bueno, en lugar de ver esta

179
00:06:12,190 --> 00:06:14,050
complicada expresión, si

180
00:06:14,170 --> 00:06:15,380
quieres puedes considerar el coseno

181
00:06:15,620 --> 00:06:17,600
de i para que sea aproximadamente, ya sabes, la diferencia

182
00:06:18,020 --> 00:06:19,310
cuadrada entre o las

183
00:06:19,430 --> 00:06:20,870
salidas de la red neuronal versus lo que

184
00:06:21,170 --> 00:06:22,980
es el valor real. Al igual que

185
00:06:23,150 --> 00:06:24,340
en la regresión logística en realidad podemos

186
00:06:24,620 --> 00:06:25,510
preferir usar esta función de costo

187
00:06:25,830 --> 00:06:27,060
ligeramente más complicada utilizando

188
00:06:27,370 --> 00:06:28,580
el registro, aunque para el

189
00:06:28,640 --> 00:06:30,230
propósito de la intuición, tómate la libertad

190
00:06:30,570 --> 00:06:31,440
de pensar en la función de costos

191
00:06:32,000 --> 00:06:32,750
como una clase de error cuadrático

192
00:06:33,250 --> 00:06:35,000
de la función de costo, y entonces

193
00:06:35,220 --> 00:06:36,870
este coseno de i mide cuán

194
00:06:37,110 --> 00:06:38,780
bien lo está haciendo la red para

195
00:06:38,880 --> 00:06:40,600
predecir correctamente el ejemplo i.

196
00:06:40,840 --> 00:06:42,000
¿Cuán cerca está la salida

197
00:06:42,810 --> 00:06:44,640
al valor real asignado a y(i) ?

198
00:06:45,590 --> 00:06:47,610
Echemos un vistazo a lo que está haciendo la retropropagación.

199
00:06:48,420 --> 00:06:50,170
Una intuición útil es que

200
00:06:51,190 --> 00:06:52,940
la retropropagación está calculando éstos

201
00:06:53,610 --> 00:06:54,840
términos «delta» superíndice l

202
00:06:55,050 --> 00:06:57,440
subíndice j, y no podemos

203
00:06:57,730 --> 00:06:58,520
pensar en ellos como

204
00:06:58,650 --> 00:07:00,070
el "error" del

205
00:07:00,300 --> 00:07:02,460
valor de activación que

206
00:07:02,620 --> 00:07:03,980
obtuvimos para la unidad j en

207
00:07:04,440 --> 00:07:05,750
la capa, en la

208
00:07:07,130 --> 00:07:07,400
capa “i-nésima”.

209
00:07:07,660 --> 00:07:09,070
De manera más formal, y esto quizá es

210
00:07:09,340 --> 00:07:10,280
sólo para aquellos

211
00:07:10,360 --> 00:07:11,480
de ustedes que están familiarizados con el cálculo,

212
00:07:12,690 --> 00:07:14,080
más formalmente, lo que los términos de «delta»

213
00:07:14,260 --> 00:07:15,820
son en realidad es lo siguiente:

214
00:07:15,950 --> 00:07:17,810
son una derivada parcial con respecto a

215
00:07:18,240 --> 00:07:20,000
j z (l), es decir

216
00:07:20,150 --> 00:07:21,460
esta suma ponderada de las entradas que

217
00:07:21,650 --> 00:07:22,700
estamos calculando para los términos de z,

218
00:07:23,410 --> 00:07:25,760
la derivada parcial con respecto a estos elementos de la función de costo.

219
00:07:27,000 --> 00:07:28,650
Bien, en concreto, la función de costo

220
00:07:28,900 --> 00:07:30,000
es una función del valor asignado a

221
00:07:30,250 --> 00:07:31,350
"y" y del

222
00:07:31,470 --> 00:07:32,680
valor, de esta h de

223
00:07:32,780 --> 00:07:35,060
la salida de x mediante nuestra red neuronal. Y

224
00:07:35,180 --> 00:07:36,430
si pudiéramos ir hacia adentro de la red neuronal

225
00:07:37,340 --> 00:07:39,200
y simplemente cambiar estos valores

226
00:07:39,860 --> 00:07:41,450
de z(l) j un poco, entonces

227
00:07:41,640 --> 00:07:44,250
eso afectaría a estos valores que salen de la red neuronal

228
00:07:44,990 --> 00:07:47,290
Y así, eso terminará por cambiar la función de costo.

229
00:07:48,340 --> 00:07:50,120
Y de nuevo, esto en realidad sólo es

230
00:07:50,210 --> 00:07:51,690
para aquellos de ustedes que sean expertos en cálculo.

231
00:07:52,960 --> 00:07:55,580
Si estás familiarizado con, o si te sientes cómodo con las derivadas parciales.

232
00:07:56,540 --> 00:07:57,860
¿Qué son estos términos de «delta»?,

233
00:07:57,950 --> 00:07:59,270
son, resulta que son

234
00:07:59,370 --> 00:08:00,800
la derivada parcial de la función de costos

235
00:08:00,870 --> 00:08:04,010
con respecto a estos términos intermedios que estamos calculando.

236
00:08:05,500 --> 00:08:07,250
Así que, ellos son la medición de

237
00:08:07,910 --> 00:08:08,940
cuánto nos gustaría

238
00:08:09,140 --> 00:08:11,090
cambiar los pesos de la red neuronal

239
00:08:11,250 --> 00:08:13,620
para afectar estos valores intermedios

240
00:08:14,150 --> 00:08:16,110
del cálculo, de modo que

241
00:08:16,240 --> 00:08:17,430
la afectación de la salida final de la

242
00:08:17,470 --> 00:08:18,980
red neuronal "h" de "x"

243
00:08:19,160 --> 00:08:20,770
afecta, por lo tanto, los costos totales.

244
00:08:21,510 --> 00:08:22,820
En el caso de esta última parte de

245
00:08:23,030 --> 00:08:25,290
esta intuición de la derivada parcial, en caso

246
00:08:25,530 --> 00:08:26,920
de que esto no haya tenido sentido, no te preocupes

247
00:08:27,070 --> 00:08:28,230
por eso, el resto

248
00:08:28,390 --> 00:08:29,770
podemos hacerlo sin realmente

249
00:08:30,280 --> 00:08:32,400
hablar de derivadas parciales pero

250
00:08:32,660 --> 00:08:33,780
vamos a ver con más detalle qué

251
00:08:34,100 --> 00:08:36,020
está haciendo la retropropagación.

252
00:08:36,250 --> 00:08:37,440
Para la capa de salida, primero

253
00:08:37,890 --> 00:08:39,630
se define este término de «delta», decimos

254
00:08:39,830 --> 00:08:41,400
«delta» 4(1), como y(i)

255
00:08:41,700 --> 00:08:44,430
si es que estamos haciendo una propagación hacia adelante

256
00:08:44,890 --> 00:08:48,010
y una retropropagación de este

257
00:08:48,210 --> 00:08:50,180
ejemplo de entrenamiento. Dice que es y(i)

258
00:08:51,030 --> 00:08:52,970
menos a(4) 1,

259
00:08:53,250 --> 00:08:54,370
así que es realmente el error, es

260
00:08:54,560 --> 00:08:55,680
la diferencia entre el valor real

261
00:08:56,000 --> 00:08:57,210
de "y" menos lo que era

262
00:08:57,630 --> 00:08:58,020
el valor predicho.

263
00:08:58,530 --> 00:09:00,160
Así que, vamos a calcular «delta»

264
00:09:00,670 --> 00:09:01,880
4(1) o algo similar.

265
00:09:03,510 --> 00:09:06,200
A continuación vamos a propagar estos valores hacia atrás.

266
00:09:06,910 --> 00:09:07,820
Explico esto en un momento

267
00:09:08,510 --> 00:09:10,810
y termino de calcular los términos «delta» de la capa anterior.

268
00:09:11,350 --> 00:09:12,450
Vamos a concluir

269
00:09:12,560 --> 00:09:13,720
con «delta» 3(1); «delta» 3(2);

270
00:09:13,990 --> 00:09:15,210
y luego vamos a

271
00:09:15,600 --> 00:09:17,940
propagar esto más

272
00:09:18,380 --> 00:09:19,340
hacia atrás y a terminar

273
00:09:19,470 --> 00:09:21,960
de calcular «delta» 2(1) y

274
00:09:22,690 --> 00:09:23,800
«delta» 2(2).

275
00:09:25,190 --> 00:09:27,290
Ahora, el cálculo de la retropropagación

276
00:09:28,730 --> 00:09:30,050
es como hacer correr el

277
00:09:30,140 --> 00:09:32,870
algoritmo de propagación hacia adelante, pero a la inversa.

278
00:09:33,260 --> 00:09:33,890
Bien, esto es lo que quiero decir.

279
00:09:34,160 --> 00:09:35,300
Echemos un vistazo a cómo hemos llegado

280
00:09:35,460 --> 00:09:37,370
a este valor de «delta» 2(2)

281
00:09:38,060 --> 00:09:39,280
Y entonces, tenemos que «delta»

282
00:09:39,480 --> 00:09:42,330
es 2(2) y similar a

283
00:09:42,600 --> 00:09:44,760
la propagación hacia adelante, déjenme asignar valores a un par de los pesos.

284
00:09:45,000 --> 00:09:47,620
Así que este peso debería estar en turquesa, digamos

285
00:09:47,890 --> 00:09:50,680
ese peso es «theta» 2

286
00:09:51,190 --> 00:09:54,190
de 1, 2 y este

287
00:09:54,450 --> 00:09:55,970
peso aquí abajo, permítanme resaltar

288
00:09:56,280 --> 00:09:57,740
esto en rojo. Esto va a ser, digamos,

289
00:09:58,030 --> 00:09:59,760
«theta» 2 de 2,2.

290
00:10:01,510 --> 00:10:03,410
Así que si

291
00:10:03,500 --> 00:10:05,450
vemos cómo se calcula

292
00:10:05,800 --> 00:10:07,540
«delta» 2(2). ¿Cómo se calcula para esta notación? Pues resulta

293
00:10:08,390 --> 00:10:09,690
que lo que vamos

294
00:10:09,800 --> 00:10:10,830
a hacer es que

295
00:10:10,970 --> 00:10:12,030
vamos a tomar este valor y

296
00:10:12,350 --> 00:10:14,340
a multiplicarlo por este peso y

297
00:10:14,630 --> 00:10:16,770
a agregarlo a este valor

298
00:10:17,580 --> 00:10:18,660
multiplicado por ese peso.

299
00:10:18,930 --> 00:10:19,850
Bien, en realidad es una suma ponderada

300
00:10:20,800 --> 00:10:22,880
de las nuevos, de estos valores nuevos de «delta»,

301
00:10:23,280 --> 00:10:25,570
ponderados por la fuerza del contorno correspondiente.

302
00:10:25,960 --> 00:10:27,270
Bueno, en concreto, déjame llenar esto.

303
00:10:28,430 --> 00:10:29,550
Esta «delta» 2,2 va a

304
00:10:30,270 --> 00:10:32,610
ser igual a «theta» 2(1)2,

305
00:10:33,110 --> 00:10:34,660
que es ese peso en magenta,

306
00:10:34,980 --> 00:10:38,850
veces «delta» (3)1 + y

307
00:10:38,990 --> 00:10:40,080
entonces lo que tengo en rojo es

308
00:10:41,230 --> 00:10:43,530
«theta» 2(2) 2

309
00:10:43,860 --> 00:10:46,230
veces «delta» 3(2)

310
00:10:46,700 --> 00:10:48,550
Así que, en realidad es, literalmente este peso

311
00:10:48,800 --> 00:10:51,340
en rojo veces este valor + este

312
00:10:51,570 --> 00:10:52,690
peso en magenta veces este valor

313
00:10:53,540 --> 00:10:55,820
y así es cómo terminamos con ese valor de «delta».

314
00:10:56,880 --> 00:10:59,490
Y nada más como otro ejemplo, echemos un vistazo a este valor.

315
00:10:59,870 --> 00:11:00,750
¿Cómo hemos llegado a ese valor?

316
00:11:01,320 --> 00:11:02,660
Bueno, es un proceso

317
00:11:02,890 --> 00:11:04,490
similar, si este peso,

318
00:11:05,530 --> 00:11:07,000
que voy a resaltar en

319
00:11:07,100 --> 00:11:08,310
verde, si este peso es

320
00:11:08,440 --> 00:11:09,860
igual a, digamos, «delta»

321
00:11:10,450 --> 00:11:12,990
3(1) 2, entonces tenemos

322
00:11:13,920 --> 00:11:15,360
que «delta» 3(2)

323
00:11:15,630 --> 00:11:17,010
será igual a

324
00:11:17,910 --> 00:11:19,860
ese peso en verde, «theta»  3(1)2

325
00:11:20,800 --> 00:11:22,260
veces «delta» 4(1).

326
00:11:22,930 --> 00:11:25,520
Por cierto,

327
00:11:25,610 --> 00:11:26,560
hasta ahora he estado

328
00:11:26,670 --> 00:11:28,310
escribiendo sólo los valores de «delta»

329
00:11:28,660 --> 00:11:30,390
para las unidades ocultas y,

330
00:11:30,560 --> 00:11:32,750
aunque no, aunque excluyo las unidades de oscilación.

331
00:11:33,620 --> 00:11:34,610
Dependiendo de cómo definas

332
00:11:35,030 --> 00:11:37,170
el algoritmo de retropropagación o dependiendo de

333
00:11:37,330 --> 00:11:38,610
cómo lo implementes, ya sabes,

334
00:11:38,710 --> 00:11:40,510
puedes terminar implementando algo

335
00:11:40,850 --> 00:11:42,390
que calcule los valores de «delta» para

336
00:11:42,900 --> 00:11:43,950
estas unidades de oscilación también.

337
00:11:44,960 --> 00:11:46,230
La unidad de oscilación son siempre los valores

338
00:11:46,620 --> 00:11:47,880
de salida + uno y son

339
00:11:47,990 --> 00:11:48,980
justo lo que son y no hay

340
00:11:49,220 --> 00:11:50,060
forma de que cambiemos

341
00:11:50,210 --> 00:11:51,960
su valor, así que, dependiendo de

342
00:11:52,340 --> 00:11:53,440
en tu implementación de la retropropagación,

343
00:11:53,770 --> 00:11:54,960
la manera en la que yo usualmente lo pongo en práctica,

344
00:11:55,090 --> 00:11:56,180
lo concluyo calculando estos

345
00:11:56,340 --> 00:11:57,670
valores de «delta», aunque sólo los

346
00:11:57,760 --> 00:11:58,900
desechamos y no los

347
00:11:58,990 --> 00:12:00,560
utilizamos, porque no

348
00:12:00,800 --> 00:12:02,130
terminan siendo parte del

349
00:12:02,220 --> 00:12:04,130
cálculo necesario para calcular las derivadas.

350
00:12:04,990 --> 00:12:06,720
Bien, pues ojalá esto te de un

351
00:12:06,990 --> 00:12:08,360
un poco de intuición

352
00:12:08,750 --> 00:12:10,380
acerca de lo que hace la retropropagación.

353
00:12:12,480 --> 00:12:13,290
En caso de que todo esto

354
00:12:13,440 --> 00:12:14,670
todavía te parezca muy mágico y

355
00:12:14,760 --> 00:12:16,090
una especie de caja negra, en un

356
00:12:16,240 --> 00:12:17,560
video posterior, en el

357
00:12:17,770 --> 00:12:19,880
video de resumen, voy a tratar

358
00:12:20,150 --> 00:12:22,650
de dar un poco más de intuición sobre lo está haciendo la retropropagación.

359
00:12:23,250 --> 00:12:24,360
Pero, por desgracia, este es, ya sabes

360
00:12:24,450 --> 00:12:26,370
un algoritmo que es difícil tratar

361
00:12:26,510 --> 00:12:28,770
de visualizarlo y de comprender qué es lo que realmente está haciendo.

362
00:12:29,500 --> 00:12:30,790
Aunque por fortuna, ya sabes,

363
00:12:30,990 --> 00:12:32,280
a menudo, supongo claro, muchas personas

364
00:12:32,940 --> 00:12:33,930
lo han estado usando con mucho éxito

365
00:12:34,420 --> 00:12:35,640
durante muchos años y si

366
00:12:35,730 --> 00:12:37,810
infieres el algoritmo, puedes tener

367
00:12:37,990 --> 00:12:40,090
un algoritmo de aprendizaje muy eficaz, incluso

368
00:12:40,340 --> 00:12:41,400
si resulta difícil visualizar las funciones

369
00:12:41,900 --> 00:12:43,190
internas que expliquen exactamente cómo funciona.