En el video anterior hablamos sobre una función de costo para la red neuronal. En este video, vamos a empezar a hablar de un algoritmo, para minimizar la función de costo. En particular, vamos a hablar sobre el algoritmo retropropagación. Aquí se encuentra la función de costo que anotamos en el video anterior. Lo que nos gustaría hacer es tratar de encontrar los parámetros de «theta» para tratar de minimizar J de «theta». Con el fin de utilizar ya sea el descenso de gradiente o uno de los algoritmos de optimización avanzados. Lo que tenemos que hacer, por lo tanto, es escribir el código que lleva esta entrada a los parámetros de «theta» y calcula j de «theta» y estos términos de la derivada parcial. Recuerda que los parámetros en la red neuronal de estos elementos, en «theta» superíndice l subíndice ij, ese es el número real y por eso, estos son los términos de la derivada parcial que necesitamos calcular. Con el fin de calcular la función de costo j de «theta» sólo tienes que utilizar esta fórmula de aquí arriba y por eso, lo que quiero hacer en la mayor parte de este video es enfocarme en hablar acerca de cómo podemos calcular estos términos de la derivada parcial. Vamos a empezar por hablar de un caso cuando sólo tenemos un ejemplo de entrenamiento, así que imagínate, si quieres que todo nuestro conjunto de entrenamiento conste de un solo ejemplo de entrenamiento que sea un par xy. no voy a escribir x1y1, sólo escribe esto. Escribe un ejemplo de entrenamiento como xy y pasemos a la secuencia de cálculos que íbamos a hacer con este ejemplo de entrenamiento. Lo primero que hacemos es aplicar la propagación hacia adelante para calcular si una hipótesis en realidad resulta dada esta entrada. En concreto, recordemos que, la llamamos a(1), que son los valores de activación de esta primera capa que era la entrada acá. Bien, voy a establecer eso para x y luego vamos a calcular z(2) igual a «theta»(1) a(1) y a(2) es igual a g, la función de activación sigmoidea aplicada a z(2) y esto nos daría nuestras activaciones para la primera capa interna. Eso es para la capa dos de la red y añadimos también estos términos de oscilación. A continuación aplicamos 2 pasos más de estos cuatro y la propagación para calcular a(3) y a(4) que es también la salida de una hipótesis h de x. Así que ésta es nuestra implementación vectorizada de la propagación hacia adelante y que nos permite calcular los valores de activación para todas las neuronas en nuestra red neuronal. A continuación, con el fin de calcular las derivadas, vamos a utilizar un algoritmo denominado Retropropagación. La intuición del algoritmo de retropropagación es que por cada notación vamos a calcular el término «delta» superíndice l subíndice j y eso de algún modo va a representar el error de la notación j en la capa l. Bien, recuerda que superíndice l subíndice j ésa es la activación de j de la unidad en la capa l así que, este término «delta» en cierto sentido va a capturar nuestro error en la activación de ese dúo neuronal. Entonces, ¿cómo podríamos desear que la activación de esa notación fuera un poco diferente? Pues simple, tomando el ejemplo de la red neuronal que tenemos a la derecha que tiene cuatro capas. y así L mayúscula es igual a 4. Por cada unidad de salida, vamos a calcular este término «delta». Así, «delta» para j de la unidad en la cuarta capa es igual a justo la activación de esa unidad menos el que era el valor real de 0 en nuestro ejemplo de entrenamiento. Bien, este término de aquí también se puede escribir como h x subíndice j, ¿correcto? Y así este término «delta» es justo la diferencia entre lo que la hipótesis da por resultado y el que era valor de "y" en nuestro conjunto de entrenamiento, donde esta "y" subíndice j es j del elemento del valor del vector "y" en nuestro conjunto de entrenamiento con valor asignado. Y, por cierto, si tú piensas en «delta» "a" y en "y" como vectores, entonces puedes también tomarlos y proponer desarrollar una implementación vectorizada de que es justo «delta» 4 que se establece como a4 menos y. Y aquí, cada uno de estos «delta» 4 a4 y "y", cada uno de estos es un vector cuya dimensión es igual al número de unidades de salida de nuestra red. Así que ahora hemos calculado los términos del error de «delta» 4 para nuestra red. Lo que debemos hacer después es calcular los términos «delta» para las capas anteriores de nuestra red. He aquí una fórmula para calcular «delta» 3, y es «delta» 3 es igual a «theta» 3 transposición punto veces «delta» 4. Y en estos punto veces, ésta es la operación de multiplicación de las "y" del elemento que conocemos de MATLAB. Así que «delta» 3 transpone a «delta» 4, ése es un vector; g prima z3 ése también es un vector así que punto veces es una multiplicación de las "y" del elemento entre estos dos vectores. Este término g prima de z3, que formalmente es en realidad la derivada de la función de activación de g evaluada en los valores de entrada dados por z3. Si sabes cálculo, puedes tratar de resolverlo tú mismo y ver si puedes simplificarlo hasta el mismo resultado al que llegué. Pero yo sólo te voy a decir pragmáticamente lo que eso significa. Lo que tú haces para calcular esta g prima, en estos términos derivados es justo a3 punto veces 1 menos a3 en donde a3 es el vector de las activaciones. 1 es el vector de los unos y a3 es de nuevo la activación del vector de los valores de la activación para esa capa. A continuación, aplicas una fórmula similar para calcular «delta» 2 en donde de nuevo ésta puede calcularse utilizando una fórmula similar. Sólo que ahora es a2 como tal y yo luego lo demuestro aquí, pero tú puedes en realidad, y es posible demostrarlo si sabes cálculo que esta expresión es igual a matemáticamente, la derivada de la función g, de la función de activación, que estoy señalando mediante g prima. y, finalmente, eso es todo y no hay ningún término «delta»1, porque la primera capa corresponde a la capa de entrada y esa es justo la variable que observamos en nuestros conjuntos de entrenamiento, que no tengan ningún error asociado. Esto no es, ya lo sabes, en realidad no queremos tratar de cambiar esos valores. Y así tenemos los términos de «delta» sólo para las capas 2, 3 y para este ejemplo. El nombre retropropagación proviene del hecho de que empezamos por calcular el término «delta» para la capa de salida y luego regresamos una capa y calculamos los términos «delta» para la tercera capa oculta y luego regresamos otro paso para calcular «delta» 2 y así sucesivamente, digamos que estamos retropropagando los errores de la capa de salida hacia la capa 3 y hacia la capa 2, de ahí el nombre de Retropropagación. Finalmente, la derivación es muy complicada y está sorprendentemente implicada pero si realizas estos pocos pasos de cálculo es posible que demuestres, y es francamente algo viral, una complicada demostración matemática. Es posible demostrar que si tú ignoras la regularización entonces los términos de la derivada parcial que quieres están exactamente dados por las activaciones y estos términos «delta». Esto es ignorar lambda o si lo quieres ver de otro modo, como si el término de regularización lambda fuese igual a 0. Arreglaremos este detalle más adelante con respecto al término de regularización, aunque bueno, al realizar la retropropagación y al calcular estos términos de «delta», puedes, y ya lo sabes, calcular bastante rápido estos términos de la derivada parcial para todos tus parámetros. Así que estos son un montón de detalles. Vamos a reunir todo y a poner todo en perspectiva para hablar acerca de cómo implementar la retropropagación para calcular las derivadas con respecto a tus parámetros. Y en caso de que tengamos un gran conjunto de entrenamiento no sólo un conjunto de entrenamiento de un ejemplo, esto es lo que hacemos. Vamos a suponer que tenemos un conjunto de entrenamiento de "m" ejemplos como el que se muestra aquí. Lo primero que vamos a hacer es que vamos a establecer estos «delta» l subíndice i j. ¿Y qué es este símbolo triangular? Esto de hecho es «delta» mayúscula en el alfabeto griego. El símbolo que teníamos en la diapositiva anterior era «delta» minúscula. De modo que el triángulo es la mayúscula de «delta». Vamos a igualar esto a cero para todos los valores de l i j. En algún momento, esta «delta» mayúscula l i j se utilizará para calcular el término de la derivada parcial, la derivada parcial con respecto a «theta» l i j de J de teta. Bien, como veremos en un momento, estos «delta»s se van a utilizar como acumuladores que lentamente agregarán elementos para calcular estas derivadas parciales. A continuación, vamos a recorrer nuestro conjunto de entrenamiento. Así que, vamos a decir que i es igual a 1 a través de m y entonces para la iteración de i, vamos a trabajar con el ejemplo de entrenamiento xi, yi. Entonces, lo primero que vamos a hacer es establecer a1, que son las activaciones de la capa de entrada, establecer que sea igual a xi, que son las entradas para nuestro ejemplo i de entrenamiento, y luego vamos a realizar la propagación hacia adelante para calcular las activaciones para la capa dos, la capa tres y así sucesivamente hasta la capa final, la capa L mayúscula. A continuación, vamos a utilizar el valor asignado de la salida "yi" de éste ejemplo específico que estamos viendo para calcular el término de error «delta» L para la salida de allí. Entonces, «delta» L es lo que resulta de la hipótesis menos lo que era el valor asignado meta Y luego vamos a usar el algoritmo de retropropagación para calcular «delta» l menos 1, «delta» l menos 2, y así hasta llegar a «delta» 2 y una vez más ahí está ahora «delta» 1 porque no asociamos un término de error con la capa de entrada. Y, por último, vamos a utilizar estos términos de «delta» mayúscula para acumular estos términos de la derivada parcial que anotamos en el rubro anterior. Y, por cierto, si tú miras esta expresión, es posible vectorizar esto también. Concretamente, si piensas en «delta» ij como una matriz, indexada mediante subíndice ij. Entonces, si «delta» l es una matriz, se puede reescribir esto como «delta» l, se actualiza como «delta» l + el caso de abajo de «delta» l + 1 vez a(l) transposición. Así que esa es una implementación vectorizada de esto que automáticamente realiza esta actualización de todos los valores de "i" y "j".
Finalmente, después de ejecutar el conjunto de los cuatro ciclo fors salimos entonces del cuarto ciclo for y calculamos el siguiente. Calculamos D mayúscula como a continuación y tenemos dos casos separados para j igual a cero y j no igual a cero. El caso en el que j es igual a cero corresponde al término de sesgo, así que cuando j es igual a cero esa es la razón por la que nos falta este término de regularización extra. Por último, a pesar de que la demostración formal es bastante complicada, lo que puedes mostrar es que una vez has calculado estos términos de D, esa es exactamente la derivada parcial de la función costo con respecto a cada uno de tus perímetros, así que puedes usarlos en cualquier descenso de gradiente o en uno de los algoritmos de optimización avanzada Así que ese es el algoritmo de la retropropagación y de cómo calculas las derivadas de tu función de costo para una red neuronal. Sé que esto parece como si estos fueran un montón de detalles y se tratara de un montón de pasos concatenados. Sin embargo, tanto en las tareas de programación escritas y, más tarde en este video, te daremos un resumen de todo ello de tal forma que podamos tener juntas todas las piezas del algoritmo para que sepas exactamente qué es lo que necesitas para poner en práctica, si así lo quieres, para implementar la retropropagación para calcular las derivadas de la función de costos de tu red neuronal con respecto a ésos parámetros