1
00:00:00,310 --> 00:00:04,060
पिछले कुछ वीडियोज़ में हमने बात की फ़ॉर्वर्ड प्रॉपगेशन की और

2
00:00:04,060 --> 00:00:08,800
बैक प्रॉपगेशन की न्यूरल नेटवर्क में कम्प्यूट करने के लिए डेरिवेटिव्स.

3
00:00:08,800 --> 00:00:12,560
लेकिन बैक प्रॉपगेशन अल्गोरिद्म में हैं बहुत सी विस्तृत जानकारी और

4
00:00:12,560 --> 00:00:14,840
हो सकता है थोड़ा कठिन इम्प्लमेंट करने के लिए.

5
00:00:14,840 --> 00:00:18,900
और एक और खेदजनक गुण है कि ऐसे बहुत से तरीक़े हैं जिससे

6
00:00:18,900 --> 00:00:21,070
बहुत से छिपे हुए बग हो सकते हैं बैक प्रॉपगेशन में.

7
00:00:21,070 --> 00:00:23,600
तो यदि आप रन करते हैं इसे ग्रेडीयंट डिसेंट के साथ या

8
00:00:23,600 --> 00:00:27,230
किसी और ऑप्टिमायज़ेशन अल्गोरिद्म के साथ, ऐसा वास्तव में लग सकता है कि यह काम कर रहा है.

9
00:00:27,230 --> 00:00:28,500
और आपका कॉस्ट फ़ंक्शन,

10
00:00:28,500 --> 00:00:32,920
जे ऑफ़ थीटा शायद कम होगा प्रत्येक इटरेशन्स के बाद ग्रेडीयंट डिसेंट की.

11
00:00:32,920 --> 00:00:36,240
लेकिन यह तभी भी हो सकता है जब शायद कोई

12
00:00:36,240 --> 00:00:38,380
बग है आपकी इम्प्लमेंटेशन में बैक प्रॉपगेशन की.

13
00:00:38,380 --> 00:00:40,820
ताकि ऐसा प्रतीत होगा कि जे ऑफ़ थीटा कम हो रहा है, लेकिन

14
00:00:40,820 --> 00:00:45,080
आपको शायद मिले एक न्यूरल नेटवर्क जिसमें है एक बहुत अधिक

15
00:00:45,080 --> 00:00:47,570
एरर तुलना में एक बग-फ़्री इम्प्लमेंटेशन के.

16
00:00:47,570 --> 00:00:50,890
और आपको शायद पता भी न हो कि वहाँ एक छिपा हुआ बग था जो आपको दे रहा था

17
00:00:50,890 --> 00:00:52,330
बदतर पर्फ़ॉर्मन्स.

18
00:00:52,330 --> 00:00:54,170
तो, हम क्या कर सकते हैं इस बारे में?

19
00:00:54,170 --> 00:00:56,810
यहाँ है एक सुझाव जिसे कहते हैं ग्रेडीयंट चेकिंग

20
00:00:56,810 --> 00:00:59,180
जो समाप्त करता है लगभग सभी इन समस्याओं को.

21
00:00:59,180 --> 00:01:02,160
तो, आजकल हर बार जब मैं इम्प्लमेंट करता हूँ बैक प्रॉपगेशन या

22
00:01:02,160 --> 00:01:04,780
एक इसी प्रकार का ग्रेडीयंट [सुनाई नहीं दिया] एक न्यूरल नेटवर्क पर या

23
00:01:04,780 --> 00:01:09,680
कोई और काफ़ी जटिल मॉडल, मैं हमेशा इम्प्लमेंट करता हूँ ग्रेडीयंट चेकिंग.

24
00:01:09,680 --> 00:01:13,570
और यदि आप इसे करते हैं, यह आपकी सहायता करेगा सुनिश्चित करने के लिए और एक तरह से उच्च विश्वास पाने के लिए कि

25
00:01:13,570 --> 00:01:17,360
आपकी इम्प्लमेंटेशन फ़ॉर्वर्ड प्रॉपगेशन और बैक प्रॉपगेशन या जो भी 100% सही है.

26
00:01:17,360 --> 00:01:22,320
और जो भी मैंने देखा है यह काफ़ी कुछ समाप्त करता है सारी समस्याएँ जो जुड़ी हैं

27
00:01:22,320 --> 00:01:25,860
इस तरह की बग वाली इम्प्लमेंटेशन में बैक प्रॉपगेशन की.

28
00:01:25,860 --> 00:01:31,570
और पिछले वीडियो में मैंने आपसे कहा था कि आप विश्वास करें कि फ़ॉर्म्युला जो मैंने दिया हैं

29
00:01:31,570 --> 00:01:34,910
कम्प्यूट करने के लिए डेल्टा और डेरिवेटिव्स और जो कुछ भी, मैंने आपको कहा था कि रखें

30
00:01:34,910 --> 00:01:39,480
विश्वास कि वे वास्तव में कम्प्यूट करते हैं ग्रेडीयंट्स कॉस्ट फ़ंक्शन के.

31
00:01:39,480 --> 00:01:43,120
लेकिन एक बार जब आप इम्प्लमेंट करते हैं नूमेरिकल ग्रेडीयंट चेकिंग, जो विषय है इस

32
00:01:43,120 --> 00:01:47,070
वीडियो का, आप पूर्ण सक्षम होंगे खुद के लिए सत्यापित करने में कि कोड जो आप लिख रहे हैं

33
00:01:47,070 --> 00:01:51,270
करता है वास्तव में, वास्तव में कम्प्यूट करता है डेरिवेटिव कॉस्ट फ़ंक्शन J के.

34
00:01:52,440 --> 00:01:55,480
तो यहाँ है विचार, निम्न उदाहरण पर ग़ौर करें.

35
00:01:55,480 --> 00:02:01,320
मान लो कि मेरे पास है फ़ंक्शन J ऑफ़ थीटा और मेरे पास कुछ वैल्यू थीटा की

36
00:02:01,320 --> 00:02:05,450
और इस उदाहरण के लिए मैं मानूँगा कि थीटा है सिर्फ़ एक रियल नम्बर.

37
00:02:05,450 --> 00:02:08,560
और मान लो मैं चाहता हूँ अनुमानित करना डेरिवेटिव इस फ़ंक्शन का इस पोईँट पर

38
00:02:08,560 --> 00:02:13,130
और इसलिए डेरिवेटिव है बराबर स्लोप के उस टैंजेंट / स्पर्श रेखा के.

39
00:02:14,300 --> 00:02:17,850
यहाँ है कि कैसे मैं नूमेरिक्ली अनुमान करूँगा डेरिवेटिव का, या

40
00:02:17,850 --> 00:02:21,770
यहाँ है विधि करने के लिए नूमेरिक्ली अनुमानित डेरिवेटिव को.

41
00:02:21,770 --> 00:02:26,320
मैं कम्प्यूट करूँगा थीटा प्लस एप्सिलोन, तो अब हम इसे करते हैं दाईं तरफ़.

42
00:02:26,320 --> 00:02:31,260
और मैं कम्प्यूट करूँगा थीटा माइनस एप्सिलोन और मैं देखूँगा इन दो

43
00:02:31,260 --> 00:02:36,183
पोईँट्स को और जोड़ूँगा उन्हें एक सीधी रेखा से

44
00:02:43,426 --> 00:02:47,586
मैं जोड़ूँगा इन दो पोईँट्स को एक सीधी लाइन से, और मैं इस्तेमाल करूँगा

45
00:02:47,586 --> 00:02:51,620
स्लोप का उस छोटी लाल लाइन का बतौर मेरे अनुमान डेरिवेटिव के.

46
00:02:51,620 --> 00:02:54,860
जो है, असली डेरिवेटिव है स्लोप उस नीली लाइन का वहाँ पर.

47
00:02:54,860 --> 00:02:56,719
तो, आप जानते हैं ऐसा लगता है कि यह होगा एक काफ़ी अच्छा अनुमान.

48
00:02:58,260 --> 00:03:03,060
गणितीय रूप में, इस लाल लाइन की स्लोप है यह वर्टिकल ऊँचाई

49
00:03:03,060 --> 00:03:05,470
विभाजित द्वारा इस हॉरिज़ॉंटल चौड़ाई से.

50
00:03:05,470 --> 00:03:10,650
तो यह पोईँट ऊपर है J ऑफ़ (थीटा प्लस एप्सिलोन).

51
00:03:10,650 --> 00:03:13,990
यह पोईँट यहाँ है J ऑफ़ (थीटा माइनस एप्सिलोन), तो

52
00:03:13,990 --> 00:03:17,870
यह वर्टिकल अंतर है J ऑफ़ (थीटा प्लस एप्सिलोन) माइनस J

53
00:03:17,870 --> 00:03:21,920
ऑफ़ (थीटा माइनस एप्सिलोन) और यह हॉरिज़ॉंटल अंतर है सिर्फ़ 2 एप्सिलोन.

54
00:03:23,620 --> 00:03:28,730
तो मेरा अनुमान होगा उस डेरिवेटिव का

55
00:03:28,730 --> 00:03:34,970
विद रिस्पेक्ट टु थीटा J ऑफ़ थीटा का इस वैल्यू पर थीटा कि, वह है लगभग

56
00:03:34,970 --> 00:03:41,319
J (थीटा +एप्सिलोन) - J(थीटा - एप्सिलोन) / 2 एप्सिलोन.

57
00:03:42,350 --> 00:03:44,430
आमतौर पर, मैं इस्तेमाल करता हूँ एक बहुत छोटी वैल्यू

58
00:03:44,430 --> 00:03:48,800
एप्सिलोन के लिए, सोचें एप्सिलोन को 10 की पॉवर -4 के क़रीब.

59
00:03:48,800 --> 00:03:53,060
आम तौर एक बड़ी रेंज होती है एप्सिलॉन की विभिन्न वैल्यूज़ के लिए जो सही काम करती है.

60
00:03:53,060 --> 00:03:58,010
और वास्तव में, यदि आप रखते हैं एप्सिलोन को बहुत छोटा, तब गणित के अनुसार

61
00:03:58,010 --> 00:04:02,000
यह टर्म यहाँ, वास्तव में गणित के अनुसार, यह बन जाता है डेरिवेटिव,

62
00:04:02,000 --> 00:04:05,090
यह बन जाता है वास्तव में स्लोप फ़ंक्शन का इस पोईँट पर.

63
00:04:05,090 --> 00:04:07,020
सिर्फ़ इतना है कि हम नहीं चाहते इस्तेमाल करना एप्सिलोन की एक बहुत ही

64
00:04:07,020 --> 00:04:10,110
छोटी वैल्यू, क्योंकि तब आपको शायद नूमेरिक्ली कठिनाई आ सकती है.

65
00:04:10,110 --> 00:04:13,900
तो मैं आमतौर पर एप्सिलोन को लगभग दस की पॉवर माइनस चार रखता हूँ.

66
00:04:13,900 --> 00:04:17,860
और वैसे भी आप में से कुछ ने शायद देखा होगा एक विकल्प इस फ़ॉर्म्युला का

67
00:04:17,860 --> 00:04:20,180
कम्प्यूट करने के लिए डेरिवेटिव जो है यह फ़ॉर्म्युला.

68
00:04:21,610 --> 00:04:24,000
यह दाईं तरफ इसे कहते हैं एक वन-साइडेड डिफ़्रेन्स,

69
00:04:24,000 --> 00:04:27,630
जबकि फ़ॉर्म्युला जो बाईं तरफ है, इसे कहते हैं एक टू-साइडेड डिफ़्रेन्स.

70
00:04:27,630 --> 00:04:30,360
टू-साइडेड डिफ़्रेन्स हमें देता है थोड़ा बेहतर अनुमान, तो

71
00:04:30,360 --> 00:04:33,920
मैं आमतौर पर उसका इस्तेमाल करता हूँ बजाय इस्तेमाल करने के वन-साइडेड डिफ़्रेन्स.

72
00:04:35,960 --> 00:04:39,560
तो, वास्तव में, जब इम्प्लमेंट करते हैं ओकटेव में, आप इम्प्लमेंट करते हैं निम्नलिखित,

73
00:04:39,560 --> 00:04:42,040
आप इम्प्लमेंट करते हैं कॉल कम्प्यूट करने के लिए gradApprox,

74
00:04:42,040 --> 00:04:46,840
जो होगा हमारा लगभग अनुमान डेरिवेटिव के जैसे यहाँ इस फ़ॉर्म्युला से,

75
00:04:46,840 --> 00:04:52,080
J (थीटा +एप्सिलोन) - J(थीटा - एप्सिलोन) / 2 एप्सिलोन.

76
00:04:52,080 --> 00:04:56,650
और यह देगा आपको एक नूमेरिकल अनुमान ग्रेडीयंट का उस पोईँट पर.

77
00:04:56,650 --> 00:04:59,290
और इस उदाहरण में ऐसा लगता है कि यह एक बहुत अच्छा अनुमान है.

78
00:05:01,913 --> 00:05:03,618
अब पिछली स्लाइड पर,

79
00:05:03,618 --> 00:05:08,060
हमने लिया था केस जब थीटा था एक रियल नम्बर.

80
00:05:08,060 --> 00:05:12,450
चलो अब देखते है अधिक सामान्य केस जब थीटा है एक वेक्टर पेरामिटर, तो

81
00:05:12,450 --> 00:05:14,000
मान लो थीटा है एक Rn.

82
00:05:14,000 --> 00:05:18,030
और यह शायद है एक अनरोल किया हुआ वर्ज़न पेरमिटर्स का हमारे न्यूरल नेटवर्क के.

83
00:05:18,030 --> 00:05:21,270
तो थीटा है एक वेक्टर जिसमें n एलिमेंट्स हैं थीटा 1 से थीटा n तक.

84
00:05:21,270 --> 00:05:25,720
हम तब कर सकते हैं

85
00:05:25,720 --> 00:05:30,260
इस्तेमाल एक समान विचार अनुमानित करने के लिए सारे पर्शियल डेरिवेटिव टर्म्ज़.

86
00:05:30,260 --> 00:05:35,140
वास्तव में पर्शियल डेरिवेटिव एक कॉस्ट फ़ंक्शन के विद रिस्पेक्ट टु पहले

87
00:05:35,140 --> 00:05:40,980
पेरामिटर, थीटा एक, वह प्राप्त किया जा सकता हैं लेकर J और बढ़ाने से थीटा एक.

88
00:05:40,980 --> 00:05:43,530
तो आपके पास है J ऑफ़ थीटा वन प्लस एप्सिलोन और इसी तरह आगे.

89
00:05:43,530 --> 00:05:48,130
माइनस J ऑफ़ थीटा वन माइनस एप्सिलोन और विभाजित करें इसे दो एप्सिलोन से.

90
00:05:48,130 --> 00:05:52,320
पर्शियल डेरिवेटिव विद रिस्पेक्ट टु दूसरे पेरामिटर थीटा दो, है फिर से यह

91
00:05:52,320 --> 00:05:56,620
चीज़ सिवाय कि आप लेंगे J यहाँ और बढ़ाएँगे थीटा दो को एप्सिलोन से,

92
00:05:56,620 --> 00:06:00,820
और यहाँ घटाएँगे थीटा दो को एप्सिलोन से और इसी प्रकार बाक़ी के डेरिवेटिव

93
00:06:00,820 --> 00:06:04,958
विद रिस्पेक्ट टु थीटा n तक देगा आपको बढ़ना और घटना थीटा का

94
00:06:04,958 --> 00:06:06,393
एप्सिलोन से वहाँ पर.

95
00:06:09,691 --> 00:06:15,380
तो, ये इक्वेज़न्स देती है आपको एक तरीक़ा नूमेरिक्ली अनुमानित करने का पर्शियल

96
00:06:15,380 --> 00:06:20,450
डेरिवेटिव J के विद रिस्पेक्ट टु किसी भी आपके पेरामिटर थीटा j.

97
00:06:23,590 --> 00:06:26,450
वास्तव में जो आप इम्प्लमेंट करते हैं वह है निम्नलिखित.

98
00:06:27,930 --> 00:06:32,230
हम इम्प्लमेंट करते हैं निम्न ओकटेव में नूमेरिक्ली कम्प्यूट करने के लिए डेरिवेटिव्स.

99
00:06:32,230 --> 00:06:33,000
हम कहते हैं, फ़ॉर

100
00:06:33,000 --> 00:06:37,780
i=1:n, जहाँ n है डिमेन्शन हमारे पेरामिटर वेक्टर थीटा की.

101
00:06:37,780 --> 00:06:41,260
और प्रायः मैं करता हूँ इसे अनरोल किए हुए पेरमिटर्स के साथ.

102
00:06:41,260 --> 00:06:46,250
तो थीटा है सिर्फ़ एक लम्बी लिस्ट मेरे सारे पेरमिटर्स की मेरे न्यूरल नेटवर्क में, मान लो.

103
00:06:46,250 --> 00:06:48,050
मैं सेट करूँगा थीटाप्लस= थीटा,

104
00:06:48,050 --> 00:06:51,700
फिर बढ़ाऊँगा थीटाप्लस (i) एलिमेंट का एप्सिलोन से.

105
00:06:51,700 --> 00:06:55,785
और यह है मूलरूप में थीटाप्लस बराबर थीटा के सिवाय

106
00:06:55,785 --> 00:06:58,260
थीटाप्लस(i) के जो बढ़ाया है एप्सिलोन से.

107
00:06:58,260 --> 00:07:03,390
एप्सिलोन, तो थीटाप्लस है बराबर, ठीक है, थीटा 1, थीटा 2 और आगे.

108
00:07:03,390 --> 00:07:07,250
फिर थीटा i में है जोड़ा हुआ एप्सिलोन और हम जाते हैं थीटा n तक.

109
00:07:07,250 --> 00:07:09,670
तो यह है जो थीटाप्लस है.

110
00:07:09,670 --> 00:07:15,070
और इसी प्रकार ये दो लाइन सेट करती हैं थीटामाइनस को इसी समान सिवाय

111
00:07:15,070 --> 00:07:19,329
कि यह बजाय थीटा i प्लस एप्सिलोन, यह अब बन जाता है थीटा i माइनस एप्सिलोन.

112
00:07:20,670 --> 00:07:25,690
और फिर बाद में आप इम्प्लमेंट करते हो यह gradApprox(i) और

113
00:07:25,690 --> 00:07:29,840
यह देगा आपको आपके अनुमान पर्शियल डेरिवेटिव के

114
00:07:29,840 --> 00:07:32,770
विद रिस्पेक्ट टु थीटा i, J ऑफ़ थीटा के.

115
00:07:35,310 --> 00:07:38,900
और जिस तरह हम इस्तेमाल करेंगे इसे हमारे न्यूरल नेटवर्क इम्प्लमेंटेशन में है,

116
00:07:38,900 --> 00:07:45,250
हम इम्प्लमेंट करेंगे यह फ़ॉर लूप कम्प्यूट करने के लिए पर्शियल डेरिवेटिव

117
00:07:45,250 --> 00:07:49,650
कॉस्ट फ़ंक्शन का विद रिस्पेक्ट टु पेरमिटर्स जो सब हैं उस नेटवर्क के, और

118
00:07:49,650 --> 00:07:53,720
हम तब ले सकते हैं ग्रेडीयंट जो हमें मिला बैक प्रॉपगेशन से.

119
00:07:53,720 --> 00:07:58,382
तो Dvec था डेरिवेटिव जो हमें मिला बैक प्रॉपगेशन से.

120
00:07:58,382 --> 00:08:00,640
ठीक है, तो बैक प्रॉपगेशन,

121
00:08:00,640 --> 00:08:04,810
था एक अपेक्षाकृत कुशल ढंग कम्प्यूट करने के लिए एक डेरिवेटिव या एक पर्शियल डेरिवेटिव.

122
00:08:04,810 --> 00:08:07,850
एक कॉस्ट फ़ंक्शन का विद रिस्पेक्ट टु सभी हमारे पेरामिटर्स.

123
00:08:07,850 --> 00:08:12,670
और अक्सर मैं क्या करता हूँ तब, लेता हूँ मेरे नूमेरिक्ली कम्प्यूट किए हुए डेरिवेटिव

124
00:08:12,670 --> 00:08:15,820
जो है यह gradApprox जो हमें मिला था ऊपर यहाँ.

125
00:08:15,820 --> 00:08:20,780
और सुनिश्चित करता हूँ कि वह है बराबर या लगभग बराबर

126
00:08:20,780 --> 00:08:24,110
नूमेरिकल राउंड ऑफ़ की छोटी वैल्यू तक, वह हैं काफ़ी क़रीब.

127
00:08:24,110 --> 00:08:26,540
तो Dvec जो मुझे मिला बैक प्रॉपगेशन से.

128
00:08:26,540 --> 00:08:30,850
और यदि कम्प्यूट करने के ये दोनो तरीक़ों से मुझे मिलता है एक ही उत्तर, या

129
00:08:30,850 --> 00:08:34,750
देते हैं मुझे समान उत्तर, कुछ डेसिमल स्थानों तक,

130
00:08:34,750 --> 00:08:39,850
तब मुझे विश्वास हो जाता है कि मेरी इम्प्लमेंटेशन बैक प्रॉपगेशन की सही है.

131
00:08:39,850 --> 00:08:43,920
और फिर मैं प्लग करता हूँ ये DVec वेक्टर ग्रेडीयंट डिसेंट या

132
00:08:43,920 --> 00:08:47,280
किसी एडवांस्ड ऑप्टिमायज़ेशन अल्गोरिद्म में, मुझे तब है और अधिक

133
00:08:47,280 --> 00:08:51,640
विश्वास कि मैं कम्प्यूट कर रहा हूँ सही डेरिवेटिव्स, और इसलिए

134
00:08:51,640 --> 00:08:55,779
उम्मीद है मेरा कोड सही चलेगा और अच्छे से ऑप्टिमायज़ करेगा J ऑफ़ थीटा.

135
00:08:57,680 --> 00:08:59,870
अंत में, मैं रखना चाहता हूँ सब चीज़ एक साथ और

136
00:08:59,870 --> 00:09:03,670
बताना चाहता हूँ आपको कि कैसे इम्प्लमेंट करना है इस नूमेरिकल ग्रेडीयंट चेकिंग को.

137
00:09:03,670 --> 00:09:05,070
यहाँ है कि मैं अक्सर क्या करता हूँ.

138
00:09:05,070 --> 00:09:08,460
पहला काम मैं करता हूँ कि इम्प्लमेंट करता हूँ बैक प्रॉपगेशन कम्प्यूट करने के लिए DVec.

139
00:09:08,460 --> 00:09:11,290
तो एक विधि है जिसकी हमने बात की थी पिछले वीडियो में

140
00:09:11,290 --> 00:09:14,230
कम्प्यूट करने के लिए DVec जो शायद हमारा अनरोल किया हुआ वर्ज़न था इन मेट्रिसीज़ का.

141
00:09:14,230 --> 00:09:16,280
तो फिर मैं क्या करता हूँ,

142
00:09:16,280 --> 00:09:20,220
इम्प्लमेंट करता हूँ नूमेरिकल ग्रेडीयंट चेकिंग, कम्प्यूट करने के लिए gradApprox.

143
00:09:20,220 --> 00:09:23,830
तो यह है जो मैंने बताया था पिछली स्लाइड में इस वीडियो में.

144
00:09:24,930 --> 00:09:29,410
फिर सुनिश्चित करें कि DVec और gradApprox दे रहे हैं समान वैल्यूज़,

145
00:09:29,410 --> 00:09:31,079
आप जानते हैं मान लो कुछ डेसिमल स्थानों तक.

146
00:09:32,270 --> 00:09:36,740
और अंत में, और यह है महत्वपूर्ण सटेप, इससे पहले कि शुरू करें आपका

147
00:09:36,740 --> 00:09:40,390
कोड लर्निंग के लिए, ट्रेनिंग के लिए आपके नेटवर्क की, यह महत्वपूर्ण है कि बंद

148
00:09:40,390 --> 00:09:45,100
करें ग्रेडीयंट चेकिंग और अब नहीं करना है कम्प्यूट gradApprox इस्तेमाल करके

149
00:09:45,100 --> 00:09:49,119
नूमेरिकल डेरिवेटिव फ़ॉर्म्युला जिनकी हमने पहले बात की थी इस वीडियो में.

150
00:09:50,530 --> 00:09:54,160
और उसका कारण है नूमेरिक कोड ग्रेडीयंट चेकिंग कोड,

151
00:09:54,160 --> 00:09:58,400
जिसकी हमने बात की इस वीडियो में, वह है एक बहुत कॉम्प्यूटेशनली महँगा,

152
00:09:58,400 --> 00:10:02,030
वह हैं एक बहुत धीमी गति का ढंग अनुमानित करने के लिए डेरिवेटिव.

153
00:10:02,030 --> 00:10:05,730
जबकि इसके विपरीत, बैक प्रॉपगेशन एल्गोरिद्म जिसके बारे में हमने पहले बात की थी,

154
00:10:05,730 --> 00:10:08,190
वह है जिसके बारे में हमने पहले बात की थी कम्प्यूट करने के लिए

155
00:10:08,190 --> 00:10:11,030
आप जानते हैं D1, D2, D3 DVec के लिए.

156
00:10:11,030 --> 00:10:14,970
बैक प्रॉपगेशन अधिक कॉम्प्यूटेशनली कुशल ढंग हैं कम्प्यूट करने के लिए

157
00:10:14,970 --> 00:10:15,660
डेरिवेटिव्स.

158
00:10:17,050 --> 00:10:20,770
एक बार आपने देख लिया कि आपकी इम्प्लमेंटेशन बैक प्रॉपगेशन की

159
00:10:20,770 --> 00:10:25,090
सही है, आपको बंद कर देनी चाहिए ग्रेडीयंट चेकिंग और उसका इस्तेमाल बंद कर देना चाहिए.

160
00:10:25,090 --> 00:10:28,690
तो सिर्फ़ दोहराने के लिए, आपको निश्चय ही निष्क्रिय कर देना चाहिए ग्रेडीयंट चेकिंग कोड

161
00:10:28,690 --> 00:10:32,910
चलाने से पहले आपका अल्गोरिद्म ग्रेडीयंट डिसेंट की बहुत सी इटरेशन्स के लिए या

162
00:10:32,910 --> 00:10:35,880
एडवांसड ऑप्टिमायज़ेशन अल्गोरिद्म्स की बहुत सी इटरेशन्स के लिए.

163
00:10:35,880 --> 00:10:38,020
ट्रेन करने के लिए आपके क्लैसिफ़ायअर को.

164
00:10:38,020 --> 00:10:41,600
वास्तव में, यदि आपको रन करना होता नूमेरिकल ग्रेडीयंट चेकिंग

165
00:10:41,600 --> 00:10:43,800
प्रत्येक इटरेशन में ग्रेडीयंट डिसेंट की,

166
00:10:43,800 --> 00:10:46,690
या यदि आप होते अंदर के लूप में आपके कॉस्ट फ़ंक्शन के,

167
00:10:46,690 --> 00:10:48,370
तब आपका कोड चलेगा बहुत धीमे.

168
00:10:48,370 --> 00:10:52,000
क्योंकि नूमेरिकल ग्रेडीयंट चेकिंग काफ़ी धीरे है

169
00:10:52,000 --> 00:10:56,270
तुलना में बैक प्रॉपगेशन अल्गोरिद्म का, तुलना में बैक प्रॉपगेशन विधि के जहाँ,

170
00:10:56,270 --> 00:11:00,440
आपको याद होगा, हम कम्प्यूट कर रहे थे डेल्टा(4), डेल्टा(3), डेल्टा(2) और आगे.

171
00:11:00,440 --> 00:11:02,460
वह था बैक प्रॉपगेशन अल्गोरिद्म.

172
00:11:02,460 --> 00:11:06,610
वह है एक अधिक तीव्र ढंग कम्प्यूट करने के लिए डेरिवेटिव तुलना में ग्रेडीयंट चेकिंग के.

173
00:11:06,610 --> 00:11:10,880
तो जब आप तैयार है, एक बार आपने देख लिया कि आपकी इम्प्लमेंटेशन बैक प्रॉपगेशन

174
00:11:10,880 --> 00:11:15,130
सही है, आपको निश्चय ही निष्क्रिय कर देना चाहिए ग्रेडीयंट चेकिंग कोड

175
00:11:15,130 --> 00:11:18,220
जब आप ट्रेन करें आपका अल्गोरिद्म, वरना आपका कोड बहुत धीरे चलेगा.

176
00:11:20,430 --> 00:11:24,390
तो, ऐसे लेते हैं आप ग्रेडीयंट नूमेरिक्ली, और ऐसे आप चेक करते हैं

177
00:11:24,390 --> 00:11:27,260
आपकी इम्प्लमेंटेशन बैक प्रॉपगेशन सही है.

178
00:11:27,260 --> 00:11:31,210
जब मैं इम्प्लमेंट करता हूँ बैक प्रॉपगेशन या ऐसा कोई ग्रेडीयंट डिसेंट अल्गोरिद्म

179
00:11:31,210 --> 00:11:33,970
एक जटिल मॉडल के लिए, मैं हमेशा इस्तेमाल करता हूँ ग्रेडीयंट चेकिंग और

180
00:11:33,970 --> 00:11:36,750
यह वास्तव में सहायता करता है तय करने में कि मेरा कोड सही है.