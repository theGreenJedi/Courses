1
00:00:00,250 --> 00:00:01,530
No vídeo anterior, falamos

2
00:00:01,850 --> 00:00:02,870
sobre como usar retropropagação

3
00:00:03,980 --> 00:00:05,810
para calcular as derivadas da sua função de custo.

4
00:00:06,780 --> 00:00:07,770
Neste vídeo eu quero

5
00:00:08,030 --> 00:00:10,260
rapidamente falar sobre um detalhe na implementação de

6
00:00:11,220 --> 00:00:13,110
transformar seus parâmetros 

7
00:00:13,670 --> 00:00:15,500
de matrizes para vetores, 

8
00:00:15,610 --> 00:00:17,870
que precisaremos para usar nas rotinas de otimização avançada.

9
00:00:20,230 --> 00:00:21,470
Digamos que

10
00:00:21,640 --> 00:00:23,120
você implementou uma função de custo

11
00:00:23,660 --> 00:00:24,870
que recebe este parâmetro ϴ

12
00:00:25,420 --> 00:00:28,690
e retorna a função custo e retorna as suas derivadas.

13
00:00:30,050 --> 00:00:31,260
Então você pode passar isto para

14
00:00:31,510 --> 00:00:33,820
um algoritmo de otimização avançada com fminunc,

15
00:00:34,080 --> 00:00:34,790
porém fminunc

16
00:00:34,890 --> 00:00:35,900
não é a única forma.

17
00:00:36,060 --> 00:00:38,660
Existem outros algoritmos de otimização avançados

18
00:00:39,710 --> 00:00:40,910
mas o que todos eles

19
00:00:41,030 --> 00:00:41,970
fazem é pegar esses parâmetros,

20
00:00:42,730 --> 00:00:43,560
claramente a função custo,

21
00:00:44,490 --> 00:00:45,730
a algum valor inicial de ϴ.

22
00:00:47,010 --> 00:00:48,490
E ambas

23
00:00:48,730 --> 00:00:51,600
rotinas assumem que ϴ e 

24
00:00:51,740 --> 00:00:53,360
o valor inicial de ϴ

25
00:00:53,580 --> 00:00:55,410
sejam vetores de parâmetros,

26
00:00:55,640 --> 00:00:57,040
seja ℝⁿ ou ℝ⁽ⁿ⁺¹⁾.

27
00:00:57,870 --> 00:01:00,440
Mas estes são vetores e

28
00:01:00,530 --> 00:01:01,880
também assumimos que a sua 

29
00:01:02,150 --> 00:01:03,770
função custo vai retornar 

30
00:01:03,960 --> 00:01:05,640
um segundo valor, 

31
00:01:05,830 --> 00:01:07,410
este gradiente que também é 

32
00:01:07,640 --> 00:01:09,860
ℝⁿ ou  ℝ⁽ⁿ⁺¹⁾, são também vetores.

33
00:01:10,840 --> 00:01:11,890
Isto servia muito bem quando nós

34
00:01:12,040 --> 00:01:14,030
usávamos regressão logística, 

35
00:01:14,220 --> 00:01:15,120
mas agora que estamos usando redes neurais

36
00:01:15,280 --> 00:01:17,160
nosso parametros não

37
00:01:17,220 --> 00:01:18,370
são mais vetores, mas no lugar

38
00:01:18,980 --> 00:01:21,110
eles são estas matrizes, que para 

39
00:01:21,310 --> 00:01:22,670
uma rede neural completa nós

40
00:01:22,830 --> 00:01:26,050
teríamos matrizes ϴ⁽¹⁾, ϴ⁽²⁾, ϴ⁽³⁾ como parâmetros.,

41
00:01:26,700 --> 00:01:28,080
que podemos representar no Octave

42
00:01:28,680 --> 00:01:30,660
como as matrizes ϴ⁽¹⁾, ϴ⁽²⁾ e ϴ⁽³⁾.

43
00:01:31,450 --> 00:01:33,160
E igualmente estes termos gradientes

44
00:01:33,760 --> 00:01:35,030
que eram esperados como retorno.

45
00:01:35,720 --> 00:01:36,890
Bem, no vídeo anterior nós

46
00:01:36,980 --> 00:01:38,430
mostramos como computar estas

47
00:01:38,840 --> 00:01:40,520
matrizes de gradiente, que foram

48
00:01:40,980 --> 00:01:42,290
D⁽¹⁾, D⁽²⁾ e

49
00:01:42,560 --> 00:01:43,950
D⁽³⁾, que nós

50
00:01:44,080 --> 00:01:46,130
representamos no Octave como matrizes D⁽¹⁾, D⁽²⁾, D⁽³⁾.

51
00:01:48,080 --> 00:01:49,150
Neste vídeo, quero falar

52
00:01:49,480 --> 00:01:50,420
falar brevemente sobre a 

53
00:01:50,510 --> 00:01:51,480
a ideia de como pegar

54
00:01:51,980 --> 00:01:54,060
estas matrizes e estender elas em vetores.

55
00:01:54,590 --> 00:01:55,750
Para que elas fiquem

56
00:01:55,910 --> 00:01:57,790
se transformando numa forma compatível,

57
00:01:57,930 --> 00:02:00,090
permitindo passar como ϴ aqui, e para 

58
00:02:00,460 --> 00:02:01,850
retornar como um gradiente aqui.

59
00:02:03,220 --> 00:02:04,540
Na prática, vamos dizer

60
00:02:04,670 --> 00:02:06,740
que temos uma rede neural com uma

61
00:02:06,950 --> 00:02:08,250
camada de entrada com dez unidades,

62
00:02:09,010 --> 00:02:10,000
uma camada intermediaria com dez unidades

63
00:02:10,540 --> 00:02:11,870
e uma camada de saída com

64
00:02:12,020 --> 00:02:13,090
apenas uma unidade, então s1

65
00:02:13,270 --> 00:02:14,030
é o número de unidades na camada um

66
00:02:14,440 --> 00:02:15,710
e s2 é o 

67
00:02:15,860 --> 00:02:18,220
número de unidades na camadas dois, e s3 o número 

68
00:02:18,520 --> 00:02:20,700
de unidades na camada três.

69
00:02:21,560 --> 00:02:23,200
Neste caso, a dimensão de 

70
00:02:23,460 --> 00:02:25,240
suas matrizes ϴ e 

71
00:02:25,350 --> 00:02:26,380
D vão ser

72
00:02:26,570 --> 00:02:28,110
dadas por estas expressões.

73
00:02:28,520 --> 00:02:30,300
Por exemplo, ϴ⁽¹⁾

74
00:02:30,630 --> 00:02:33,220
vai ser uma matriz 10 por 11 e assim por diante.

75
00:02:34,420 --> 00:02:35,740
Então no Octave, se você quer

76
00:02:35,950 --> 00:02:37,960
converter entre estas matrizes

77
00:02:38,580 --> 00:02:38,580
e vetores,

78
00:02:39,330 --> 00:02:40,590
o que você pode fazer é pegar

79
00:02:40,830 --> 00:02:42,130
seu parametro Theta1, Theta2,

80
00:02:42,350 --> 00:02:44,220
Theta3, e escrever este

81
00:02:44,410 --> 00:02:45,470
pedaço de código e isso irá

82
00:02:45,610 --> 00:02:46,820
pegar todos os elementos de 

83
00:02:46,900 --> 00:02:48,540
suas três matrizes.

84
00:02:48,770 --> 00:02:49,400
Todos os elementos

85
00:02:49,860 --> 00:02:51,150
de Theta1, todos os

86
00:02:51,260 --> 00:02:52,290
elementos de Theta2, 

87
00:02:52,400 --> 00:02:53,840
todos os elementos de Theta3,

88
00:02:54,130 --> 00:02:55,510
e estender todos eles, colocando-os

89
00:02:55,770 --> 00:02:57,420
em um grande e longo vetor.

90
00:02:58,540 --> 00:02:59,880
Que é o nosso thetaVec, e igualmente

91
00:03:00,960 --> 00:03:02,510
o segundo comando vai pegar

92
00:03:02,830 --> 00:03:04,350
todas as suas matrizes D e 

93
00:03:04,490 --> 00:03:05,600
estender em um grande

94
00:03:05,930 --> 00:03:07,340
e longo vetor o qual chamamos de 

95
00:03:07,510 --> 00:03:08,810
DVec. E finalmente

96
00:03:09,370 --> 00:03:10,330
se você quer voltar de

97
00:03:10,520 --> 00:03:13,380
seus vetores para a representação original em matrizes.

98
00:03:14,620 --> 00:03:15,630
O que nós fazemos para ter de volta

99
00:03:15,840 --> 00:03:17,720
ϴ⁽¹⁾ é pegar 

100
00:03:17,940 --> 00:03:19,250
thetaVec e remover

101
00:03:19,530 --> 00:03:20,980
os primeiros 110 elementos.

102
00:03:21,470 --> 00:03:22,930
ϴ⁽¹⁾ tem 110

103
00:03:23,390 --> 00:03:24,650
elementos porque é

104
00:03:24,720 --> 00:03:26,420
uma matriz 10 por 11, 

105
00:03:26,810 --> 00:03:28,200
então nós pegamos os primeiros 110 elementos

106
00:03:28,540 --> 00:03:30,200
e então você pode

107
00:03:30,370 --> 00:03:32,960
usar o comando 'reshape' para redimensionar os elementos de volta em Theta1.

108
00:03:33,010 --> 00:03:34,730
E igualmente para ter

109
00:03:34,900 --> 00:03:35,850
de volta Theta2, você remove

110
00:03:36,280 --> 00:03:39,010
os próximos 110 elementos e reconfigura eles.

111
00:03:39,670 --> 00:03:41,410
E para Theta3, você remove os

112
00:03:41,450 --> 00:03:43,320
últimos 11 elementos e executar o 

113
00:03:43,500 --> 00:03:45,210
comando 'reshape' para ter de volta ϴ⁽³⁾.

114
00:03:48,840 --> 00:03:50,700
Aqui está um pequeno demo do processo no Octave.

115
00:03:51,270 --> 00:03:52,370
Neste exemplo

116
00:03:53,010 --> 00:03:54,530
vamos usar Theta1 igual 

117
00:03:55,340 --> 00:03:57,440
'ones(10, 11)'

118
00:03:57,670 --> 00:03:59,580
e temos uma matriz só de 1's.

119
00:04:00,360 --> 00:04:01,400
E para ficar fácil de ver

120
00:04:01,750 --> 00:04:03,060
vamos setar este para ser 2

121
00:04:03,280 --> 00:04:05,150
vezes 'ones', 10 por

122
00:04:05,310 --> 00:04:07,390
11 e vamos

123
00:04:07,600 --> 00:04:09,570
setar theta3 igual 3

124
00:04:10,290 --> 00:04:12,110
vezes 1's de tamanho 1 por 11.

125
00:04:12,390 --> 00:04:13,680
Temos então estas 3

126
00:04:13,980 --> 00:04:17,030
matrizes separadas: theta1, theta2, theta3.

127
00:04:17,770 --> 00:04:19,010
Nós queremos colocar todas elas juntas em um vetor.

128
00:04:19,670 --> 00:04:22,740
thetaVec recebe theta1, ponto e virgula

129
00:04:23,380 --> 00:04:26,660
theta2, 

130
00:04:28,540 --> 00:04:28,990
theta3

131
00:04:29,260 --> 00:04:32,060
Exato, são dois pontos

132
00:04:32,540 --> 00:04:34,220
no meio dos parenteses e 

133
00:04:35,350 --> 00:04:37,420
agora thetaVec vai

134
00:04:37,590 --> 00:04:40,090
ser um longo vetor.

135
00:04:41,050 --> 00:04:41,910
São 231 elementos.

136
00:04:42,970 --> 00:04:46,000
Se eu mostrar na tela, eu vejo

137
00:04:46,290 --> 00:04:47,640
que é um vetor longo com 

138
00:04:47,780 --> 00:04:48,610
todos os elementos da primeira

139
00:04:48,880 --> 00:04:49,630
matriz, todos os elementos

140
00:04:50,090 --> 00:04:52,360
da segunda matriz, e todos os elementos da terceira matriz.

141
00:04:53,480 --> 00:04:54,450
E se eu quero ter de volta

142
00:04:54,930 --> 00:04:56,420
minhas matrizes originais, eu posso

143
00:04:56,500 --> 00:05:00,040
usar o comando 'reshape' em thetaVec.

144
00:05:01,400 --> 00:05:02,580
Vamos remover os primeiros 110

145
00:05:03,100 --> 00:05:05,640
elementos e reorganizar eles em uma matriz 10 por 11.

146
00:05:06,810 --> 00:05:08,240
E isto me retorna Theta1.

147
00:05:08,690 --> 00:05:09,770
E se então eu removo

148
00:05:10,280 --> 00:05:12,220
os próximos 110 elementos

149
00:05:12,720 --> 00:05:14,690
que vai dar os indices 111 até 220,

150
00:05:14,850 --> 00:05:16,470
eu tenho de volta todos os meus 2's

151
00:05:18,030 --> 00:05:19,330
E se eu vou 

152
00:05:20,850 --> 00:05:22,110
de 221 até 

153
00:05:22,280 --> 00:05:24,240
o último elemento que é 

154
00:05:24,440 --> 00:05:25,970
o elemento 231, e reorganizo para 

155
00:05:26,070 --> 00:05:28,130
uma matriz 1x11 eu tenho novamente theta3.

156
00:05:30,810 --> 00:05:32,110
Para mostrar este processo na prática,

157
00:05:32,950 --> 00:05:34,750
nós usamos esta ideia de

158
00:05:35,320 --> 00:05:36,990
estender matrizes para implementar nosso algoritmos assim:

159
00:05:38,200 --> 00:05:39,180
Digamos você tem alguns

160
00:05:39,490 --> 00:05:40,600
valores iniciais para os parametros

161
00:05:41,170 --> 00:05:42,410
theta1, theta2, theta3.

162
00:05:42,950 --> 00:05:43,740
O que nós vamos fazer

163
00:05:44,020 --> 00:05:45,880
pegar estes e estender eles

164
00:05:46,290 --> 00:05:47,610
em um longo vetor

165
00:05:47,960 --> 00:05:50,380
que vamos chamar de ϴ inicial

166
00:05:50,600 --> 00:05:52,170
e passar para a função fminunc

167
00:05:52,360 --> 00:05:54,900
como a configuração inicial dos parâmetros ϴ.

168
00:05:56,160 --> 00:05:58,310
A outra coisa que precisamos fazer é implementar a função custo.

169
00:05:59,310 --> 00:06:01,510
Aqui está minha implementação da função custo.

170
00:06:02,900 --> 00:06:04,070
A função custo 

171
00:06:04,160 --> 00:06:05,500
terá como entrada nosso thetaVec

172
00:06:05,980 --> 00:06:07,090
que é todos os nossos

173
00:06:07,350 --> 00:06:08,770
parâmetros que foram

174
00:06:08,870 --> 00:06:10,680
transformados em um único vetor.

175
00:06:11,960 --> 00:06:12,800
A primeira coisa que eu vou 

176
00:06:13,000 --> 00:06:13,890
fazer é usar

177
00:06:14,100 --> 00:06:16,580
thetaVec e aplicar as funções 'reshape'.

178
00:06:17,040 --> 00:06:18,120
Eu pego os elementos

179
00:06:18,320 --> 00:06:19,440
de thetaVec e uso 'reshape'

180
00:06:19,750 --> 00:06:20,950
para ter de volta meus

181
00:06:21,320 --> 00:06:23,560
parâmetros originais, matrizes theta1, theta2, theta3.

182
00:06:24,120 --> 00:06:26,530
Essas são as matrizes resultantes.

183
00:06:26,620 --> 00:06:28,000
Isto me dá uma

184
00:06:28,060 --> 00:06:29,920
forma mais fácil para que

185
00:06:30,130 --> 00:06:31,580
possa usar estas matrizes para

186
00:06:31,750 --> 00:06:33,590
poder rodar propagação adiante e

187
00:06:33,880 --> 00:06:35,400
retropropagação para computar minhas

188
00:06:35,570 --> 00:06:38,140
derivadas, e para computar minha função custo J( ϴ ).

189
00:06:39,710 --> 00:06:40,900
E finalmente eu posso então

190
00:06:41,120 --> 00:06:42,620
pegar minhas derivadas e estender elas,

191
00:06:43,030 --> 00:06:44,530
para manter os elementos

192
00:06:45,140 --> 00:06:47,440
na mesma ordem que eu fiz quando estendi os meus Tetas.

193
00:06:48,390 --> 00:06:49,780
Mas eu vou estender D1, D2 e D3

194
00:06:50,030 --> 00:06:51,330
 para ter meu gradientVec

195
00:06:52,190 --> 00:06:55,180
que minha função custo pode retornar.

196
00:06:55,490 --> 00:06:57,420
Ela pode retornar um vetor dessas derivadas.

197
00:06:59,150 --> 00:07:00,310
Finalmente, espero que agora você tenha

198
00:07:00,490 --> 00:07:01,650
uma boa noção de como

199
00:07:01,890 --> 00:07:03,200
converter entre

200
00:07:03,360 --> 00:07:04,970
uma representação em matriz dos

201
00:07:05,090 --> 00:07:08,220
parâmetros versus a representação em vetores dos parâmetros.

202
00:07:09,360 --> 00:07:10,290
A vantagem da representação em 

203
00:07:10,760 --> 00:07:12,330
matriz é que quando

204
00:07:12,470 --> 00:07:13,530
são guardados como 

205
00:07:13,670 --> 00:07:15,670
matrizes é mais conveniente para 

206
00:07:15,830 --> 00:07:17,430
executar propagação adiantes e 

207
00:07:17,530 --> 00:07:19,110
retropropagação e é mais facil

208
00:07:19,850 --> 00:07:21,160
quando seus parâmetros são guardados como

209
00:07:21,360 --> 00:07:22,770
matrizes ter vantagem

210
00:07:23,400 --> 00:07:24,780
nesses tipos de implementações vetorizadas.

211
00:07:26,230 --> 00:07:27,900
Em contraste a vantagem de 

212
00:07:28,090 --> 00:07:30,250
usar a representação em vetor, 

213
00:07:30,320 --> 00:07:31,820
quando você tem thetaVec ou DVec é quando

214
00:07:32,500 --> 00:07:34,540
você vai usar os algoritmos de otimização avançada.

215
00:07:34,770 --> 00:07:36,640
Estes algoritmos tendem 

216
00:07:36,760 --> 00:07:37,730
a assumir que você já tem

217
00:07:38,090 --> 00:07:40,730
todos os parâmetros em um único grande vetor.

218
00:07:41,720 --> 00:07:42,930
E com isso nós terminamos.

219
00:07:43,140 --> 00:07:44,650
Espero que agora você possa facilmente

220
00:07:45,410 --> 00:07:47,020
converter entre os dois como precisar.
Tradução: Danimar Ribeiro | Revisão: Eduardo Bonet