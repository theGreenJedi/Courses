En los videos anteriores,  reunimos casi todas las piezas que ustedes necesitan para implementar y entrenar una red neuronal. Esta es una última idea que tengo que compartir con ustedes, la cual es la idea de la inicialización aleatoria. Cuando están ejecutando un algoritmo como el gradiente de descenso o también los algoritmos de optimización avanzada es necesario que elijamos un valor inicial para los parámetros «theta». Así que para el algoritmo de optimización avanzada, como saben, se asume que ustedes pasarán algún valor inicial para los parámetros «theta». Ahora consideremos el gradiente de descenso. Para eso, como saben, también tenemos que inicializar «theta» con algo. Y entonces podemos gradualmente seguir los pasos para ir hacia abajo, utilizando el gradiente de descenso, para ir hacia abajo a fin de minimizar la función J de «theta». Entonces, ¿Cómo podemos establecer el valor inicial de «theta»? Es posible establecer el valor inicial de «theta» al vector de todos cero. Considerando que esto funcionó bien cuando estuvimos utilizando la regresión logística. Inicializar todos los parámetros en cero en realidad no funciona cuando se está entrenando una red neuronal. Consideren el entrenamiento de la siguiente red neuronal. Y digamos que hemos inicializado todos los parámetros de la red a cero. Y si lo llevan a cabo entonces lo que eso significa es que en la inicialización este peso en azul, que estoy marcando en azul va a ser igual a ese peso. Por lo tanto, ambos son cero. Y este peso que estoy marcando en rojo, es igual a ese peso. Están en rojo. Y también este peso, bueno, el cual estoy marcando con verde va a ser igual al valor de ese peso. Y lo que eso significa es que ambas unidades ocultas: a1 y a2 estarán ejecutando la misma función de sus entradas. Y así, terminarán con, en cada uno de sus ejemplos de entrenamiento terminarán  con a (2)1 que es igual a a(2)2. y además no voy a mostrar esto en mucho detalle, sin embargo debido a que estos pesos salientes son iguales,  ustedes pueden demostrar que los valores «delta» también serán los mismos. Así concretamente, terminarán con «delta» 11, «delta» 2 1, que es igual a «delta» 2 2. Y si trabajan con el mapa más a fondo, lo que pueden demostrar es que las derivadas parciales con respecto a sus parámetros cumplirán con lo siguiente. Que la derivada parcial de la función de costo con respecto a- Estoy anotando las derivadas respecto a estos pesos en azul en sus redes. Descubrirán que estas dos derivadas parciales serán iguales entre sí. Y entonces, lo que esto significa es que incluso después de una actualización de gradiente de descenso. Ustedes actualizarán, digamos que el primer peso en azul con, como saben, los ciclos de velocidad de aprendizaje, que es esto. Y actualizarán el segundo peso en azul para la suma de los ciclos de velocidad de aprendizaje,  esto. Pero lo que esto significa es que incluso después de la actualización de un gradiente de descenso, esos dos pesos en azul, esos dos parámetros de color azul terminarán siendo iguales entre sí. Así que ahora serán algo distintos al valor cero, pero este valor será igual a ese valor. Y del mismo modo, incluso después de la actualización del gradiente de descenso. Este valor será igual a ese valor. Habrá algunos valores distintos a cero. Sólo que los dos valores en rojo serán iguales entre sí. Y de forma similar los dos pesos en verde, cambiarán de valor pero ambos terminarán teniendo el mismo valor entre sí. Así que después de cada actualización, los parámetros que corresponden a las entradas que van a cada de las dos unidades ocultas serán idénticos. Es decir que los dos pesos en verde siguen siendo iguales, los dos pesos en rojo siguen siendo iguales, los dos pesos en azul siguen siendo iguales y lo que eso significa es que aún después de una iteración de, digamos,  la gradiente de descenso, descubrirán que las dos unidades ocultas siguen ejecutando exactamente las mismas funciones que la entrada. Así que todavía tienen a(1)2 que es igual a a (2)2.  Así que han vuelto a este caso. Y como siguen ejecutando la gradiente de descenso Los pesos en azul, los pesos en azul permanecerán iguales entre sí. Los dos pesos en rojo permanecerán iguales entre sí. Los dos pesos en verde permanecerán iguales entre sí. Y lo que esto significa es que su red neuronal en realidad no puede ejecutar funciones muy interesantes. Imaginen que no sólo tienen dos unidades ocultas sino que tienen muchas, muchas unidades ocultas. Entonces lo que esto nos indica es que todas sus unidades ocultas están ejecutando exactamente la misma variable todas sus unidades ocultas están ejecutando exactamente la misma función de entrada. Y esta es una representación altamente redundante. Porque eso significa que la unidad de regresión logística final, saben, en realidad sólo llega a ver una variable. Debido a que todas estas son iguales y esto impide que la red neuronal aprenda algo interesante. Con el fin de evitar este problema, por lo tanto la forma en que inicializamos los parámetros de una red neuronal es con la inicialización aleatoria. En concreto, el problema que vimos en la diapositiva anterior es algunas veces llamado el problema de los pesos simétricos, es decir, si todos los pesos son iguales. Y así, esta inicialización aleatoria es la forma en que realizamos la ruptura de la simetría. De forma que lo que hacemos es inicializar cada valor de «theta» a un número aleatorio entre menos «épsilon» y «épsilon». Entonces esta es una anotación para referirme a los números entre menos «épsilon» y mayor a «épsilon». De forma que todos los pesos para mis parámetros se van a inicializar aleatoriamente entre menos «épsilon» y mayor a «épsilon». La forma en que escribo el código para hacer esto es en Octave, es decir,  que «theta» 1 sea igual a este. Y este aleatorio 10 por 11. Así es como ejecutan una matriz dimensional aleatoria de 10 por 11, y todos los valores están entre 0 y 1. De forma que estos van a ser números reales que adquieren cualquier valor continuo entre 0 y 1. Y así, si ustedes toman un número entre 0 y 1, multiplíquenlo por 2 veces un «épsilon» y menos «épsilon», entonces terminarán con un número que se encuentra entre menos «épsilon» y mayor a «épsilon». Y a propósito, este «épsilon» aquí no tiene nada que ver con el «épsilon» que estábamos utilizando cuando hicimos la comprobación de gradiente. De forma que cuando hicimos la comprobación numérica de gradiente, allí añadimos algunos valores de «épsilon» a «theta». Esto es, como saben, un valor no relacionado de «épsilon». Razón por la que lo estoy indicando como “init_epsilon”, sólo para distinguirlo del valor de «épsilon» que estábamos utilizando en la comprobación de gradiente. Y del mismo modo si desean inicializar «theta» 2 a una matriz aleatoria de 1 por 11, ustedes pueden hacerlo a través de esta pieza de código. Así que, para resumir, para entrenar una red neuronal,  lo que ustedes deben hacer es inicializar de forma aleatoria los pesos con,  ya saben, con valores pequeños cercanos a 0, entre menos «épsilon» y mayor a «épsilon», digamos, y luego implementar la retropropagación;  hacer la comprobación de gradiente y utilizar ya sea un gradiente de de descenso o uno de los optimización avanzados para tratar de minimizar J de «theta» como una función de los parámetros «theta» empezando únicamente a partir de valores iniciales elegidos al aleatoriamente para los parámetros. Y al hacer la ruptura de simetría, que es este proceso. Con suerte, la gradiente de descenso o los algoritmos de optimización avanzados serán capaces de encontrar un buen valor de «theta».