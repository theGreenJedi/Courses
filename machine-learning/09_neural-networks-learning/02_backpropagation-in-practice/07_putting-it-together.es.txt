Bueno pues, nos ha tomado varios videos explicar el tema del algoritmo del aprendizaje de redes neuronales En este video, lo que me gustaría hacer es tratar de unir todas las piezas para dar un resumen general o un panorama más amplio de cómo todas las piezas encajan y del proceso global de cómo implementar un algoritmo de aprendizaje de redes neuronales. Al entrenar una red neuronal, lo primero que debemos hacer es elegir una arquitectura de red y por arquitectura solamente quiero decir un patrón de conectividad entre las neuronas. Así, podemos elegir entre, digamos, una red neuronal con tres unidades de entrada y cinco unidades ocultas y cuatro unidades de salida contra una de 3, 5 ocultas, 5 ocultas, 4 de salida y aquí son 3, 5, 5, 5 unidades en cada una de las tres capas ocultas y cuatro unidades abiertas, y así estas opciones de cuántas unidades ocultas en cada capa y cuántas capas ocultas, son opciones de arquitectura. Entonces, ¿cómo hacemos estas elecciones? Bueno, primero, el número de unidades de entrada está muy bien definido. Y una vez que decidan la configuración específica de variables de «x», el número de unidades de entrada, simplemente será, digamos, la dimensión de sus variables de «x(i)» sería determinado por ello. Y si están haciendo clasificaciones multiclase, el número de  salidas de esto será determinado por el número de clases en su problema de clasificación. Y sólo como recordatorio, si tienen una clasificación multiclase en donde «y» toma valores de, digamos, entre 1 y 10 para que tengan diez clases posibles. Entonces, recuerden sobreescribir sus salidas «y» como este tipo de vectores. Entonces, en lugar de clase uno, la recodifican como un vector de ese tipo, o para la segunda clase la recodifican como un vector de ese tipo. Así que si uno de los ejemplos toma el valor de la quinta clase, digamos, «y» es igual a 5, entonces lo que están mostrando a su red neuronal no es en realidad un valor de «y» igual a 5, sino que en la capa superior que tendría diez unidades de salida, entonces alimentarán al vector que conocen con uno de la quinta posición y varios ceros acá abajo. Entonces, la elección del número de unidades de entrada y el número de unidades de salida es, quizá, algo bastante sencillo. Y en cuanto al número de unidades ocultas y al número de capas ocultas, un estándar razonable es usar una única capa oculta y así, este tipo de red neuronal mostrada a la izquierda con sólo una capa oculta es probablemente lo más común. O si usan más de una capa oculta, igualmente, un estándar razonable será tener el mismo número de unidades ocultas en cada una de las capas. Entonces, aquí tenemos dos capas ocultas y cada una de estas capas ocultas tiene las mismas cinco unidades ocultas y aquí tenemos, tres capas ocultas y cada una de ellas tiene el mismo número, es decir, cinco unidades ocultas. En lugar de hacer esta clase de arquitectura como la de la izquierda esto sería un estándar perfectamente razonable, Y en cuanto al número de unidades ocultas, normalmente, entre más unidades ocultas haya, es mejor; sólo que si tienen muchas unidades ocultas, puede llegar a ser computacionalmente más costoso , pero a menudo, el tener más unidades ocultas es bueno. Y normalmente, el número de unidades ocultas en cada capa será tal vez, comparable a la dimensión de «x», comparable al número de variables o podría ubicarse en cualquier punto a partir del mismo número de unidades ocultas como variables de entrada, hasta tal vez el doble, o hasta tres o cuatro veces ese valor. Así que tener un número de unidades ocultas es comparable, varias veces, o en cierto modo mayor al número de variables de entrada que normalmente es bueno. Así que, esperamos que esto les dé un juego de opciones estándar de elección para la arquitectura de la red y si siguen estos lineamientos, probablemente, conseguirán algo que funcione bien, pero en otros videos en los que más adelante hablaré específicamente de consejos sobre cómo aplicar algoritmos de aprendizaje , trataré más a fondo el cómo elegir una arquitectura de red neuronal. De hecho, explicaré mucho más sobre cómo hacer buenas elecciones para el número de unidades ocultas, número de capas ocultas y demás. A continuación, esto es lo que necesitamos implementar para practicar una red neuronal, en realidad, son seis los pasos que utilizo, tengo cuatro en esta diapositiva y dos más en la siguiente. El primer paso es configurar la red neuronal e iniciar aleatoriamente los valores de los pesos. Y normalmente iniciamos los pesos con valores bajos, cercanos a cero. Entonces implementamos una propagación hacia adelante para que podamos fijar cualquier entrada «x» en una red neuronal y hacer el cálculo de «h» de «x» que es este vector de salida de los valores «y». Entonces, también implementamos un código para hacer el cálculo de la función de costos de J de «theta». Y después implementamos la retropropagación o su algoritmo, para calcular estos términos de la derivada parcial la derivada parcial de J de «theta» con respecto a los parámetros. En concreto, para implementar la retropropagación. Normalmente haremos esos con un ciclo for en los ejemplos de entrenamiento. Puede que algunos de ustedes hayan escuchado sobre los métodos de factorización avanzada, francamente, muy avanzada en donde ustedes no tienen un ciclo for en los ejemplos de entrenamiento «m» la primera vez que implementen la retropropagación casi siempre debería haber un ciclo for en su código en donde estén repitiendo los ejemplos, es decir, «x1», «y1» entonces hacen la propagación hacia adelante y la retropropagación en el primer ejemplo, y entonces en la segunda repetición del ciclo for, hacen la propagación hacia adelante y la retropropagación en el segundo ejemplo, y así sucesivamente. Hasta que lleguen al ejemplo final. Entonces, debe haber un ciclo for en su implementación de propagación hacia adelante, el menos la primera vez que lo estén implementando. Y, francamente, hay maneras más complicadas de hacer esto sin un ciclo for, pero definitivamente, no recomiendo que intenten hacer la versión mucho más complicada la primera vez que implementen la retropropagación Entonces, en concreto, tenemos un ciclo for en mis ejemplos de entrenamiento «m» y dentro del ciclo de for vamos a llevar a cabo la propagación hacia adelante y la retropropagación usando únicamente este ejemplo. Y lo que significa es que vamos a tomar «x(i)» y a alimentar eso en mi capa de entrada hacer la propagación hacia adelante y la retropropagación y eso me dará todas estas activaciones y todos estos términos «delta» para todas las capas de todas mis unidades en la red neuronal, entonces aún dentro de este ciclo for, déjenme dibujar algunos corchetes sólo para mostrarles el campo del ciclo for, esto es en Código Octave, pero es más bien una secuencia de código Java y un ciclo for abarca todo esto. Vamos a calcular los términos de «delta» que son, aquí está la fórmula que dimos antes, más «delta» a la «l + 1» multiplicado por a matriz traspuesta y entonces la suma del código. Y, finalmente, fuera del ciclo for, habiendo calculado estos términos de «delta», estos términos acumulados entonces tendríamos otro código y eso nos permitirá calcular la derivada parcial. Bien, y esta derivada parcial tiene que tomar en cuenta también el término lambda de regularización. Y así, esas fórmulas se dan en el video anterior. Entonces, después de haber hecho eso esperemos tener el código para calcular los términos de la derivada parcial. El siguiente es el paso cinco, lo que hago es usar la verificación de la gradiente para comparar los términos de la derivada parcial que fueron calculados. Entonces, he comparado las versiones calculadas usando la retropropagación contra la derivada parcial calculada usando los estimaciones numéricas de la derivada. Entonces, hagan la verificación de la gradiente para asegurarnos que ambas les den valores muy similares. El haber hecho la verificación de la gradiente nos asegura que nuestra implementación de la retropropagación es correcta, y entonces es muy importante que deshabilitemos la verificación de la gradiente porque el código de la verificación de la gradiente es computacionalmente muy lento. Finalmente, usamos un algoritmo de optimización como la pendiente de la gradiente, o uno de los métodos de optimización como como LB de GS, gradiente de contrato expresada dentro del mínimo de la función multivariable no restringida «fminunc» Usamos éstas junto con la retropropagación, de modo que ésta es lo que calcula esta derivada parcial por nosotros. Y así, ya sabemos cómo calcular la función de costos, sabemos cómo calcular la derivada parcial usando la retropropagación, de modo que podemos usar uno de estos métodos de optimización para intentar minimizar J de «theta» como una función de los parámetros de «theta». Y por cierto, para redes neuronales, esta función de costos J de «theta» no es convexa, o es no convexa y así puede ser susceptible, teóricamente, a los mínimos locales, y de hecho, los algoritmos como la gradiente de descenso y y los métodos de optimización avanzada en teoría, se atoran en las óptimas locales pero resulta que en la práctica, esto no representa normalmente un gran problema y aún cuando no podemos garantizar que estos algoritmos encontrarán una óptimo global, normalmente los algoritmos como la gradiente de descenso harán un muy buen trabajo minimizando esta función de costos J de «theta» y conseguirá un mínimo local muy bueno, incluso si no llega al óptimo global. Finalmente, la gradiente de descenso para una red neuronal podría aun parecer un poco mágica. Entonces, sólo permítanme enseñar una figura más para intentar obtener esa intuición sobre lo que está haciendo la gradiente de descenso para un red neuronal. De hecho, esta fue similar a la figura que usé antes para explicar la gradiente de descenso. De esta manera, tenemos alguna función de costos y tenemos una cantidad de parámetros en nuestra red neuronal. ¿correcto? Aquí sólo he puesto dos de los valores parámetro. En realidad, por supuesto, en la red neuronal podemos tener muchos parámetros con éstos. «theta» uno, «theta» dos, todas estas son matrices, ¿cierto? Así, podemos tener parámetros dimensionales altos, pero debido a las limitaciones de la fuente de partes que podemos dibujar. Supongamos que tenemos sólo dos parámetros en esta red neuronal. Aunque obviamente tengamos muchos más en la práctica Ahora, esta función de costos J de «theta» mide qué tan bien se ajusta la red neuronal con los datos de entrenamiento. Así que si tomamos un punto como este de aquí abajo, ese es el punto en donde J de «theta» es bastante bajo, y así, esto corresponde a una configuración de los parámetros. Hay una configuración de los parámetros de «theta» en donde para la mayoría de los ejemplos de entrenamiento, la salida de mi hipótesis, que puede estar muy cerca de «y(i)» y si esto es correcto entonces eso es lo que causa que mi función de costos sea bastante baja. Por el contrario, si fueran a tomar un valor como ese, un punto así corresponde a, en donde en muchos ejemplos de entrenamiento, la salida de mi red neuronal está lejos del valor real de «y(i)», eso se observó en el conjunto de entrenamiento. Así que, puntos como este de la derecha corresponden a lo que la hipótesis en donde la red neuronal está sacando valores que en el conjunto de entrenamiento, están lejos de «y(i)». Así que no está ajustando el conjunto de entrenamiento bien, mientras que puntos así con bajos valores de la función de costos corresponden donde “J” de «theta» es bajo y por lo tanto corresponde a donde la red neuronal ajusta el conjunto de entrenamiento de manera adecuada, porque me refiero a que esto es lo que se necesita que esté correcto para que J de «theta» sea pequeño. Así que lo que la gradiente de descenso hace es que se iniciará desde un punto inicial aleatorio como ese de aquí, y de forma repetitiva ira hacia abajo. Y lo que la retropropagación hace es calcular la dirección de la gradiente y lo que la gradiente de descenso hace es que está dando pequeños pasos hacia abajo hasta que, esperemos que en este caso, llegue a un óptimo local muy bueno. Entonces, cuando implementen la retropropagación y usen la gradiente de descenso o uno de los métodos de optimización avanzados, este diagrama explica lo que hace el algoritmo. Está intentando encontrar un valor de los parámetros en donde los valores de salida en la red neuronal concuerdan estrechamente con los valores de las «y(i)» observadas en su conjunto de entrenamiento. Pero espero que esto les haya dado una mejor concepción de cómo los distintos componentes del aprendizaje de redes neuronales se ajustan cuando se interactúan juntos. En caso de que aún después de este video, la este video todavía sientan que hay muchos componentes y no queda muy claro lo que algunos de esos componentes hacen o cómo interactúan estos componentes, no hay mucho problema. El aprendizaje de redes neuronales y retropropagación es un algoritmo complicado. Y aun cuando he visto  las matemáticas detrás de la retropropagación durante muchos años y la he usado, creo yo, exitosamente por muchos años, al día de hoy aún siento que no siempre tengo la suma comprensión de lo que la retropropagación hace exactamente en algunos casos. Y cómo el proceso de optmización es al minimizar J de «theta». Y este es un algoritmo mucho más complicado de entender, como si lo manejara con menor entendimiento sobre lo que hace comparado con, digamos, la regresión lineal o la logística. las cuales eran matemática y conceptualmente mucho más simples y con algoritmos menos complicados. Pero si se sienten de la misma manera, ya saben que es perfectamente normal, pero si implementan la retroprogresion, esperemos que lo que encuentren es que es uno de los más poderosos algoritmos de aprendizaje y si implementan estos algoritmos, implementen la retropropagación, implementen uno de estos métodos de optimización y encuentren que la retropropagación será capaz de ajustarse de manera muy compleja, poderosa, con funciones no lineares con sus datos, y este es uno de los algoritmos de aprendizaje más efectivos que tenemos hoy en día.