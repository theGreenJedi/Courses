1
00:00:00,560 --> 00:00:05,200
在之前的视频里，我们总结了所有内容

2
00:00:05,200 --> 00:00:07,240
来帮助你应用

3
00:00:07,240 --> 00:00:10,010
这是最后一个视频

4
00:00:10,010 --> 00:00:12,180
关于随机初始化。

5
00:00:13,260 --> 00:00:15,480
当你使用梯度下降算法，

6
00:00:15,480 --> 00:00:19,900
或者其他高级的优化算法，我们需要设置初始值

7
00:00:19,900 --> 00:00:21,620
恩

8
00:00:21,620 --> 00:00:23,840
所以，对于高级的优化算法

9
00:00:23,840 --> 00:00:27,880
假设你是有一个初始值

10
00:00:29,060 --> 00:00:31,280
现在我们假设就是梯度下降

11
00:00:31,280 --> 00:00:34,690
为此，

12
00:00:34,690 --> 00:00:38,910
通过初值，我们之后一步步通过梯度下降走到山坡底部

13
00:00:38,910 --> 00:00:41,980
当然，这里就是求最小值

14
00:00:41,980 --> 00:00:45,490
所以，我们怎么设置呢

15
00:00:45,490 --> 00:00:51,900
能不能就全部是零呢

16
00:00:51,900 --> 00:00:55,660
这在之前的逻辑回归里可行

17
00:00:55,660 --> 00:00:59,210
全部为零是可以的

18
00:00:59,210 --> 00:01:01,390
恩。

19
00:01:01,390 --> 00:01:03,820
假设我们现在有这么一个网络，

20
00:01:03,820 --> 00:01:07,580
假设全部参数为0

21
00:01:07,580 --> 00:01:12,940
恩，如果你这么做

22
00:01:12,940 --> 00:01:18,620
可以看到蓝色的权值，全是0

23
00:01:18,620 --> 00:01:21,040
我用红色标记的，

24
00:01:21,040 --> 00:01:25,640
等于这个权值

25
00:01:25,640 --> 00:01:30,030
用绿色标记的也等于它

26
00:01:30,030 --> 00:01:32,770
所以，对于A1和A2隐层单元

27
00:01:32,770 --> 00:01:37,830
将会用同一个函数计算

28
00:01:37,830 --> 00:01:42,744
结果，

29
00:01:42,744 --> 00:01:45,480
A21等于A22

30
00:01:46,940 --> 00:01:50,860
此外，因为

31
00:01:50,860 --> 00:01:54,360
这输出的权值

32
00:01:54,360 --> 00:01:56,770
你可以发现他们的误差值也一样

33
00:01:56,770 --> 00:02:02,536
所以，结果delta11 delta21等于delta22

34
00:02:02,536 --> 00:02:08,582
所以，如果继续下去

35
00:02:08,582 --> 00:02:14,538
我们可以发现他满足下述情况

36
00:02:14,538 --> 00:02:19,831
即所有的偏导数

37
00:02:19,831 --> 00:02:26,103
就编程这两条蓝色的波浪线

38
00:02:26,103 --> 00:02:29,911
你会发现他们都一样。

39
00:02:29,911 --> 00:02:30,660
得知植物能闻到彼此时一定很惊讶恩

40
00:02:31,930 --> 00:02:35,906
也就是说，

41
00:02:35,906 --> 00:02:40,469
你会发现，

42
00:02:40,469 --> 00:02:44,990
更新的时候

43
00:02:44,990 --> 00:02:50,386
通过计算梯度，更新的结果

44
00:02:50,386 --> 00:02:55,183
这两个参数是一样。

45
00:02:55,183 --> 00:03:00,550
所以，会得到非零的值，但这个值会相等

46
00:03:00,550 --> 00:03:01,420
相似的，

47
00:03:01,420 --> 00:03:06,150
即使是通过梯度下降算法，结果也是相等

48
00:03:06,150 --> 00:03:07,818
可能有一些非零的结果

49
00:03:07,818 --> 00:03:10,230
就是红色的箱单

50
00:03:10,230 --> 00:03:12,500
类似绿色也相等

51
00:03:12,500 --> 00:03:14,010
他们都改变结果

52
00:03:14,010 --> 00:03:17,590
但是结果都是一样的

53
00:03:17,590 --> 00:03:21,447
所以每一次更新，参数对应的结果

54
00:03:21,447 --> 00:03:23,656
都是完全一致

55
00:03:23,656 --> 00:03:27,101
这和前面所说的一样，

56
00:03:27,101 --> 00:03:30,758
红色、绿色、蓝色都一样，

57
00:03:30,758 --> 00:03:34,270
这意味着什么呢

58
00:03:34,270 --> 00:03:39,114
你会发现，两个单元仍然计算同样的结果

59
00:03:39,114 --> 00:03:40,897
恩

60
00:03:40,897 --> 00:03:44,092
你仍然有a1(2)=a2(2)

61
00:03:44,092 --> 00:03:45,729
回到原点。

62
00:03:45,729 --> 00:03:49,634
所以，你不断计算

63
00:03:49,634 --> 00:03:51,470
不断计算，都是一样

64
00:03:51,470 --> 00:03:53,410
红色的情况也是

65
00:03:53,410 --> 00:03:54,889
绿色的也是

66
00:03:56,030 --> 00:03:59,220
所以，

67
00:03:59,220 --> 00:04:00,740
你的神经网络实际上进入很有意思的情况

68
00:04:00,740 --> 00:04:04,960
相信，你不仅有两个隐层，

69
00:04:04,960 --> 00:04:08,070
二是有很多很多层

70
00:04:08,070 --> 00:04:11,670
那么

71
00:04:11,670 --> 00:04:13,150
这将是同样的特性。

72
00:04:13,150 --> 00:04:17,060
所有你的隐层的结果都一样

73
00:04:17,060 --> 00:04:20,190
这是非常冗余的

74
00:04:20,190 --> 00:04:22,620
因为，你发现是逻辑回归

75
00:04:22,620 --> 00:04:26,320
本质上只有一个特征

76
00:04:26,320 --> 00:04:29,190
这就使得你的神经网络性能下降

77
00:04:31,640 --> 00:04:35,350
无法进行更有意义的功能。

78
00:04:35,350 --> 00:04:38,449
所以我们需要随机初始化

79
00:04:41,264 --> 00:04:45,370
具体来说，我们之前看到的问题

80
00:04:45,370 --> 00:04:49,990
叫做对称现象

81
00:04:49,990 --> 00:04:55,510
所以，初始化也被称作打破对称

82
00:04:55,510 --> 00:05:00,313
所以我们进行初始化的操作目的就是

83
00:05:00,313 --> 00:05:02,177
打破对称，而初始区间就是在特定范围内

84
00:05:02,177 --> 00:05:06,290
这是一种我们用的标记。

85
00:05:06,290 --> 00:05:08,794
所以，我的权值参数

86
00:05:08,794 --> 00:05:12,183
将会在这个范围内生成。

87
00:05:12,183 --> 00:05:16,782
这是我们写代码采用的方式1

88
00:05:16,782 --> 00:05:17,369
恩

89
00:05:17,369 --> 00:05:19,749
rand10通过11

90
00:05:19,749 --> 00:05:26,750
这是你如何计算随机的10乘11矩阵

91
00:05:26,750 --> 00:05:31,740
所有的值都在0到1

92
00:05:31,740 --> 00:05:35,460
这是连续的0到1的值

93
00:05:35,460 --> 00:05:37,140
所以，

94
00:05:37,140 --> 00:05:40,940
你再乘以这两个参数

95
00:05:40,940 --> 00:05:44,530
你会得到最后满足区间要求的结果

96
00:05:45,640 --> 00:05:48,490
这是生成特定区间随机数常用的计算操作

97
00:05:48,490 --> 00:05:52,590
这里的epsilon和梯度检验的epsilon是两码事情

98
00:05:52,590 --> 00:05:54,870
不要混淆

99
00:05:54,870 --> 00:05:57,420
这只是一个符号数字而已

100
00:05:57,420 --> 00:05:59,860
完全没有关联。

101
00:05:59,860 --> 00:06:02,940
只是喜欢用epsilon来表示而已

102
00:06:02,940 --> 00:06:06,490
这里我们可以区别他们。

103
00:06:06,490 --> 00:06:11,240
类似的，如果你想要初始化theta2为一个1乘11

104
00:06:11,240 --> 00:06:13,650
的矩阵，你可以用这个代码

105
00:06:16,120 --> 00:06:19,625
原理是一样的

106
00:06:19,625 --> 00:06:23,552
不再赘述

107
00:06:23,552 --> 00:06:25,879
-epsilon到+epsilon范围

108
00:06:25,879 --> 00:06:29,699
然后你再使用反向传播，

109
00:06:29,699 --> 00:06:34,694
使用梯度检验，1b

110
00:06:34,694 --> 00:06:39,470
在()从头开始进行计算

111
00:06:39,470 --> 00:06:42,716
随机初始化结果

112
00:06:42,716 --> 00:06:44,377
也就是打破对称

113
00:06:44,377 --> 00:06:47,403
希望，

114
00:06:47,403 --> 00:06:51,452
这个梯度下降算法或者更高级的优化算法能够找到这个理想的theta值。