Temos levado muitos videos para terminar o algoritmo de aprendizagem da rede neural. Neste vídeo, o que eu gostaria de fazer é tentar juntar todas as peças, para fazer um resumo geral ou dar uma perspetiva global de como todas as peças se encaixam e do processo completo de como implementar um algoritmo de aprendizagem da rede neural. Quando treinar uma rede neural, a primeira coisa que você precisa fazer é escolher uma arquitetura de rede e arquitetura significa apenas o padrão de conectividade entre os neurônios. Assim, podemos escolher entre dizer, uma rede neural com três unidades de entrada e cinco unidades escondidas e quatro unidades de saída contra um de 3, 5 escondidas, 5 escondidas 4 de saída e aqui são 3, 5, 5, 5 unidades em cada uma das três camadas escondidas e quatro unidades de saída, e então  estas escolhas de quantas unidades escondidas em cada camada e quantas camadas ocultas, são as escolhas de arquitetura Então, como você deve fazer essas escolhas? Primeiro, o número de unidades de entrada  que está muito bem definido. E uma vez que você decide sobre o conjunto de características de x, o número de unidades de entrada será apenas, o número de características x(i) que assim as determinam. E se você está fazendo uma classificação multiclasse, o número de unidades de saída vai ser determinado pelo número de classes em seu problema de classificação. E apenas um lembrete, se você tem uma classificação multiclasse  onde y assume valores entre 1 e 10, de modo que você tem dez classes possíveis. Então lembre-se de re-escrever as suas saídas y como este tipo de vetores. Então, ao invés da primeira classe, você recodifica como um vetor assim, ou para a segunda classe você recodifica como um vetor assim. Então, se um desses exemplos assume a quinta classe, y é igual a 5, e o que você está mostrando para  sua rede neural não é na verdade um valor de y igual a 5, ao invés na camada de saída, a qual teria dez unidades de saída, você vai alimentá-la com o vetor que você sabe que tem um na quinta posição e um monte de zeros aqui. Assim, a escolha do número de unidades de entrada e de unidades de saída talvez seja razoavelmente simples. E quanto ao número de unidades escondidas e o número de camadas ocultas, um padrão razoável é utilizar uma única camada oculta e então esse tipo de rede neural que é mostrada à esquerda, com apenas uma camada escondida é provavelmente a mais comum Ou se você usar mais de uma camada oculta, novamente, o padrão razoável será ter o mesmo número de unidades escondidas em cada camada. Então, aqui temos duas camadas ocultas e cada uma destas camadas ocultas tem cinco unidades escondidas e aqui temos três camadas ocultas e cada uma tem o mesmo número, que é de cinco unidades escondidas. Ao invés de fazer esse tipo de arquitetura de rede, a da esquerda poderia ser um padrão perfeitamente aceitável. E quanto ao número de unidades ocultas - normalmente, quanto maior o número de unidades mais escondidas, melhor. Porém, se você tiver muitas unidades escondidas, isto pode tornar-se mais pesado do ponto de vista computacional, mas muitas vezes, ter mais unidades escondidas é uma coisa boa. E normalmente o numero de unidades escondidas em cada camada vai ser comparável à dimensão de x, comparável ao número de caraterísticas de entrada, ou poderia ser de qualquer valor igual ao número de unidades ocultas, de caracteristicas entrada para talvez três ou quatro vezes esse número. Assim, ter o número de unidades escondidas comparável. a várias vezes, ou um pouco mais, que o número de características de entrada é geralmente uma coisa útil de se fazer. Então, talvez isto te dê um conjunto razoável de escolhas padrões para a arquitetura neural e se você seguir estes guias, você irá ter provavelmente, algo que funciona bem mas em um conjunto de vídeos posterior quando eu falar especificamente sobre conselhos sobre como aplicar algorítmos, eu irei dizer realmente mais coisas sobre como escolher arquiteturas de redes neurais. Na realidade eu tenho muitas coisas que eu quero dizer depois para fazer boas escolhas para o número de unidades escondidas, o número de camadas ocultas, e assim por diante. Depois, isto é o que nós precisamos de implementar para treinar a rede neural, existem seis passos que eu tenho eu tenho quatro neste slide e mais dois passos no próximo slide. O primeiro passo é estabelecer a rede neural e aleatoriamente inicializar os valores dos pesos. E geralmente nós inicializamos os pesos com valores pequenos, próximos a zero. Então nós implementamos a propagação para a frente então nós podemos dar entrada a qualquer rede neural e computar h(x), o qual é o vetor de saída dos valores de y. Nós então implementamos o código para computar esta função de custo J(Θ). Depois nós implementamos o algorítmo de retro-propagação para computar estas derivadas parciais, derivadas parciais de J(Θ) em relação aos parâmetros. Concretamente, para implementar retro-propagação geralmente, nós iremos fazer isto com um for-loop sobre os dados de treino. Alguns de vocês devem ter ouvido falar de fatorização avançada, e muito avançada. Francamente, métodos em que você não tem for-loops sobre os m dados de treino. Mas na primeira vez que você implementar retro-propagação deverá haver for-loops no seu código, onde se faz a iteração sobre os dados, você sabe, x1, y1, e assim por diante você faz a propagação para frente e retro-propagação no primeiro exemplo, e então na segunda iteração dos for-loops, você faz a propagação para frente e retro-propagação no segundo exemplo, e assim por diante. Até você chegar no exemplo final. Então devem existir for-loops na sua implementação da retro-propagação, no mínimo na primeira implementação. E então há formas complicadas de se fazer isso sem for-loops, mas eu definitivamente não recomendo tentar fazer estas versões muito mais complicadas na primeira vez que você implementa retro-propagação. Então concretamente, nós temos for-loops sobre os m dados de treino e dentro dos for-loops nós vamos fazer uma propagação para a frente e retro-propagação usando apenas este exemplo. E o que isto significa é que nós iremos pegar x(i), e alimentar a minha camada de entrada com ele, realizar a propagação para a frente e depois para trás. E isto irá fazer isso se todas estas ativações e todos estes deltas para todas as camadas das minhas unidades na rede neural. Então, ainda dentro deste for-loop, deixe-me desenhar algumas chaves apenas para mostrar o escopo com o for-loop, isto está código do Octave, mas é mais uma sequência Java e for-loop engloba isto. Nós iremos computar estes deltas, que estão na fórmula que nós vimos anteriormente. Mais δ(l+1), vezes a(l) transposto. E então finalmente, além de ter computado estes deltas, estes termos acumulados, nós teríamos outro código e então aquilo irá nos permitir computar estas derivadas parciais. E estas derivadas parciais têm que levar em conta o termo de regularização lambda também. E então, estas fórmulas foram dadas no vídeo anterior. Então, como você fez aquilo você agora tem o código para computar estas derivadas parciais. O próximo é o passo cinco, o que eu faço é usar a verificação do gradiente para comparar estas derivadas parciais que foram computadas. Então, eu comparei as versões computadas usando a retro-propagação versus a derivada parcial computada usando a estimativa numérica das derivadas. Então, eu faço a verificação de gradiente para verificar que ambas dão valores similares. Fazer a verificação do gradiente agora nos tranquiliza de que nossa implementação da retro-propagação está correta, e então é muito importante que nós desativemos a verificação do gradiente, porque o código é muito lento. E finalmente, nós usamos um algorítmo de otimização como o de Gradiente Descendente, ou um método de otimização avançado, tal como o L-BFGS, ou de gradiente conjugado, que foi incorporado no fminunc, ou então outros métodos de otimização. Nós usamos isto junto com retro-propagação. Então, a retro-propagação é o que computa estas derivadas parciais para nós. Então, nós sabemos como computar a função de custo, nós sabemos como computar as derivadas parciais usando retro-propagação. Então nós podemos usar um destes métodos de otimização para tentar minimizar J(Θ), como uma função dos parâmetros Θ. A propósito, para redes neurais, esta função de custo J(Θ) não é convexa, ou não é convexa e então ela pode ser, teoricamente, suscetível a um mínimo local, e de fato, algorítmos como o de descida de gradiente e os métodos avançados de otimização podem, na teoria, ficar presos em um ótimo local, mas acontece que na prática, isto não é, geralmente, um grande problema. E mesmo não podendo garantir que estes algoritmos irão encontrar um ótimo global, geralmente algoritmos como o de Gradiente Descendente irão fazer um trabalho muito bom minimizando esta função custo J(Θ), e chegar a um mínimo local muito bom, mesmo que ele não chegue a um ótimo global. Finalmente, as descidas de gradiente para uma rede neural pode ainda parecer um pouco de magia. Então, deixe-me mostrar mais uma imagem para tentar dar a intuição sobre o que o Gradiente Descendente para redes neurais faz. Na verdade, isto foi similar à figura que eu estava usando anteriormente para explicar o Gradiente Descendente. Então, nós temos uma função custo, e nós temos um número de parâmetros na nossa rede neural. Escrevi aqui dois dos valores dos parâmetros. Na realidade, claro, na rede neural nós podemos ter muitos parâmetros com estes Θ(1), Θ(2). Todos estes são matrizes. Então nós podemos ter parâmetros com dimensões muito altas, mas por causa da limitação no que é possível representar graficamente, eu finjo que nós temos apenas dois parâmetros nesta rede neural. Embora, obviamente, na prática nós tenhamos muito mais. Agora, esta função custo J(Θ) mede quão bem a rede neural se ajusta aos dados de treino. Então, se você tiver um ponto como este, bem aqui, este é um ponto onde J(Θ) é muito baixo, e isto corresponde a um conjunto de parâmetros. Há uma configuração dos parâmetros theta, onde, para a maior parte dos exemplos de treino, o resultado da minha hipótese, pode ser muito próxima a y(i) e se isto é verdade, então isso é o que faz a minha função custo ser muito baixa. Enquanto que ao contrário, se fosse pegar um valor como aquele, um ponto como aquele corresponde a, onde para muitos exemplos de treino, o resultado da minha rede neural está longe do valor verdadeiro de y(i) que foi observado do conjunto de dados de treino. Então pontos como este na linha correspondem a onde a hipótese, onde a rede neural está produzindo valores sobre os dados de treino que estão longe de y(i). Então, não está se ajustando bem ao conjunto de treino, no entanto, pontos como este com valores baixos da função custo correspondem a onde J(Θ) é baixo, e portando, corresponde a onde a rede neural se ajusta bem ao conjunto de dados de treino, porque eu quero dizer: isto é o que é necessário ser verdadeiro para J(Θ) ser pequeno. Então o que o Gradiente Descendente faz é começarmos de algum ponto aleatório inicial como aquele ali, e ele irá repetidamente mover-se para baixo. E então o que a retro-propagação está fazendo é computar a direção do gradiente, e o que o Gradiente Descendente está fazendo é dar pequenos passos para baixo até que, esperemos, ele chegue neste caso, a um ótimo local muito bom. Então, quando você implementa a retro-propagação e usa o Gradiente Descendente ou um dos métodos avançados de otimização, esta figura explica o que o algoritmo está fazendo. Está tentando encontrar um valor dos parâmetros onde os valores de saída na rede neural correspondem ao valores dos y(i) observados no seu conjunto de dados de treino. Então, esperemos que isto te dê uma melhor compreensão de como muitas peças diferentes da aprendizagem da rede neural se juntam. Se mesmo após ver este vídeo, caso você ainda sinta que há muitas peças diferentes e não esteja totalmente claro o que algumas delas fazem ou como todas estas peças se juntam, está tudo bem. A aprendizagem de rede neural e retro-propagação são algoritmos complicados. E mesmo que eu tenha visto a matemática por trás da retro-propagação por muitos anos e eu tenha usado a retro-propagação, eu penso que com sucesso e por muitos anos, mesmo hoje eu ainda sinto que não tenho uma grande compreensão do que, por vezes, a retro-propagação está fazendo. E o que o processo de otimização pareça minimizando J(Θ). Este é um algoritmo muito mais difícil para sentir que eu tenho um muito menor controle sobre o que ele está fazendo exatamente comparado com a regressão linear ou regressão logística. Que são matematicamente e conceitualmente muito mais simples e claros. Mas, em caso de você se sentir da mesma forma, isto é perfeitamente aceitável, mas se você implementar a retro-propagação, esperamos que o que você vai encontrar é que este é um dos algoritmos de aprendizagem mais poderosos e se você implementar a retro-propagação e implementar um destes métodos de otimização, você vai verificar que a retro-propagação será capaz de se ajustar a funções muito complexas, poderosas, e não-lineares ao seus dados, e este é um dos algoritmos de aprendizagem mais efetivos que nós temos hoje.
Tradução: Filipe Ferminiano Rodrigues | Revisão: Inês Lopes da Fonseca