Всем привет. И снова здравствуйте. Сегодня разговор пойдет о "Большом О", особом типе асимптотического представления, который мы будем весьма часто использовать дальше. Поэтому сейчас есть смысл познакомиться со значением Большого О и частично охарактеризовать его преимущества и недостатки. Итак, начнем с определения. Основная идея в том, что нам нужен механизм обработки больших объемов информации, когда мы можем как бы игнорировать константы. Давайте попробуем найти определение. Пусть f и g - две функции. g(n) равна "О" Большому от g(n) при условии, что существуют заглавная N и строчная с - две константы, при которых для всех n равных или больше N f(n) меньше или равна g(n), умноженной на c. Смысл этого в том, что, по крайней мере, при достаточно больших входных данных для f существует верхнее ограничение в виде некого константного кратного g. Что по сути и есть идея, которую мы постулировали вначале. Ну, к примеру, 3 на n в квадрате плюс 5 на n, плюс 2 равно О от n в квадрате, потому что, если взять любое n, равное или больше 1, то 3n в квадрате + 5n + 2 меньше или равно 3n в квадрате + 5n в квадрате + 2n в квадрате, что равно 10 на n в квадрате. Некое кратное n в квадрате. Теперь, в частности, если вы посмотрите на эти две функции, они, действительно, в некотором смысле, возрастают с одинаковой прогрессией. Если рассматривать соотношение между ними, оно, конечно, большое, 10n к 1, но по мере возрастания n оно, фактически, падает до 3. А когда вы начинаете вводить данные, при n равному 100, n в квадрате - миллион, 3 на n в квадрате + 5n + 2 это чуть больше трех миллионов. Таким образом, функции не равны. Одна из них значительно больше другой, но она больше не на много, не больше, чем примерно в 3 раза. На протяжении этого курса мы будем использовать "О" Большое, в основном, для выражения времени работы наших алгоритмов. И это даст нам несколько преимуществ. Во-первых, это прояснит для нас геометрическую прогрессию. Как я уже говорил, часто нам важно, как наше время работы соотносится с размером входной информации. И это, можно сказать, артефакт того факта, что на самом деле нас зачастую волнует, что происходит, когда мы вводим в алгоритм реально, реально объемные данные. Насколько много мы можем себе позволить, прежде, чем все начнет ломаться? И, если вы дали мне некоторое сложное выражение со множеством разных условий, для использования его в качестве входных данных то сравнить два алгоритма может быть действительно сложно. Я имею ввиду, то, какой алгоритм работает дольше будет зависеть
от того, что именно я подаю ему на вход. Это потребует раздражающих вычислений 
для определения, при каких именно значениях один алгоритм лучше другого. Но, если мы посмотрим на это ассимптотически,
что происходит, когда n становится большим? Часто становится значительно понятнее,
после того, как n стало очень, очень большим, что алгоритм a лучше алгоритма b. Вторая вещь - таким образом проясняются обозначения. Мы можем написать O(n²)
вместо 3n² + 5n + 2. Это намного понятнее и с этим проще работать. Мы можем написать O(n) вместо n + log₂(n) + sin(n). Мы можем написать O(n log(n)) вместо of 4n log₂(n) + 7. И заметьте, что в терминах большого O нам, вообще-то, не нужно определять
основания логарифмов, которые мы используем. Потому что log₂(n) и log₃(n) и log₁₀(n), и log₇(n).  Отличаются только в константе, 
на которую происходит умножение. А что до умножения на константу -
в большом О это нас не особо волнует. Другое последствие этого - так как наша нотация
стала чище, потому что мы значительно снизили количество
условий, с которыми приходится иметь дело, и это делает алгебраические вычисления,
с которыми приходится иметь дело значительно проще. Это делает манипуляции с большим О проще,
потому что они не в беспорядке. И последнее - нотация большого О действительно решает проблемы, о которых мы говорили 
несколько лекций назад. Чтобы вычислять время выполнения, используя подход
большой О, нам на самом деле не нужно знать такие вещи, как насколько быстр компьютер, или
как выглядит организация памяти, или какой используется компилятор,
 поскольку, в общем и целом, хотя эти сведения и будут иметь
значительное влияние на ваше конечное время выполнения, это влияние, как правило,
будет всего лишь константным множителем. А если два выражения отличаются только
константным множителем, у них одна и та же О. Вот и всё. Теперь я должен предупредить. О невероятно полезна, мы будем
использовать её для почти всех задач в этом курсе, но из-за неё вы теряете много
информации о вашем времени выполнения. Она не обращает внимания на любые константные множители. То есть, если у вас есть 2 алгоритма, и
один из них в 100 раз быстрее, они будут иметь одну и ту же О. Но на практике, 
если вы хотите ускорить работу, ускорение в 100 весьма значительно. Даже ускорение в 2 раза значительно. И поэтому, если вы действительно хотите
ускорить работу, как только вы получили хорошее асимптотическое время выполнения, вы захотите
углубиться в детали. Могу ли я ускорить это в 2 раза? Могу ли я каким-то образом изменить это, чтобы
выполнение шло более гладко? Могу ли я добиться лучшего
взаимодействия с памятью? Могу ли я сделать x, y и z, чтобы ускорить работу на константные множители,
которых мы не увидели ранее? Ещё одна вещь, на которую
вам также следует обратить внимание, это что О только асимптотична. В каком-то смысле, всё, что она говорит вам - это
что происходит, когда вы запускаете алгоритм на очень, очень, очень, очень,
очень больших объёмах входных данных. И, собственно, если вы на самом деле хотите,
чтобы ваш алгоритм работал на конкретных данных, О не скажет вам ничего о том,
как долго это займёт. Я имею в виду, что обычно константы,
скрытые за О, достаточно невелики, и, следовательно, это даёт вам какую-то полезную информацию. Но иногда они велики. Иногда алгоритм
с худшим временем выполнения по О, который хуже асимптотически на
очень больших объёмах данных, на самом деле, для всех используемых на практике объёмов,
уступает какому-то другому алгоритму. И есть случаи, когда
вы находите 2 алгоритма, а работает лучше, чем б, на очень, очень, очень больших объёмах данных. Но иногда очень, очень, очень большие означает больше, чем вы могли бы
вообще хранить на своём компьютере. И поэтому, для любых реальных входных данных
вам стоит использовать алгоритм б. Однако, в любом случае, несмотря на эти 
предостережения, О невероятно полезна. Мы будем её использовать
на протяжении всего этого курса. И поэтому на следующей лекции мы немного поговорим 
о том, как обращаться с О-выражениями, как использовать их
для вычисления времени выполнения, но как только мы справимся с этим, мы действительно
будем готовы к тому, чтобы заняться алгоритмами. В любом случае, это всё по 
данной лекции, возвращайтесь снова, и мы поговорим об этом.