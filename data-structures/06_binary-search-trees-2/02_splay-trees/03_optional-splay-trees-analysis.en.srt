1
00:00:00,340 --> 00:00:01,460
Hello everybody.

2
00:00:01,460 --> 00:00:03,050
Welcome back.

3
00:00:03,050 --> 00:00:06,500
Today we're still talking about splay
trees and we're actually going to go into

4
00:00:06,500 --> 00:00:09,480
a little bit of the math behind
analyzing their run times.

5
00:00:10,720 --> 00:00:15,415
So remember last time we analyzed
splay trees and in order to do so

6
00:00:15,415 --> 00:00:17,705
we needed the following important result,

7
00:00:17,705 --> 00:00:22,785
that the amortized cost of doing O(D)
work and then splaying a node of depth

8
00:00:22,785 --> 00:00:26,855
D is actually O(log(n)) where n is
the total number of nodes in the tree.

9
00:00:28,085 --> 00:00:29,685
And today we're going to prove that.

10
00:00:30,870 --> 00:00:34,530
So to do this of course we need
to amortize, we need to pay for

11
00:00:34,530 --> 00:00:39,140
this extra work by doing something
to make the tree simpler.

12
00:00:39,140 --> 00:00:42,320
And the way we talk about this being
simple is we're going to pick a potential

13
00:00:42,320 --> 00:00:46,200
function, and so that if we do
a lot of work it's going to pay for

14
00:00:46,200 --> 00:00:48,190
itself by decreasing this potential.

15
00:00:49,710 --> 00:00:54,020
And it takes some cleverness to find
the right one and it turns out more or

16
00:00:54,020 --> 00:00:57,060
less the right potential
function is the following.

17
00:00:57,060 --> 00:01:01,735
We define the rank of a node N to be
the log of the size of it's subtree,

18
00:01:01,735 --> 00:01:06,330
where the size of it's subtree is just the
number of nodes that are descendants of

19
00:01:06,330 --> 00:01:07,140
N in that tree.

20
00:01:08,320 --> 00:01:10,681
Then the potential function for

21
00:01:10,681 --> 00:01:15,760
the tree is P is just the sum over all
nodes N in the tree of the rank of N.

22
00:01:15,760 --> 00:01:19,770
Now to get a feel for what this
means if your tree is balanced, or

23
00:01:19,770 --> 00:01:21,814
even approximately balanced,

24
00:01:21,814 --> 00:01:27,300
potential function should be approximately
linear in the total number of the nodes.

25
00:01:27,300 --> 00:01:29,520
But if on the other hand,
it's incredibly unbalanced,

26
00:01:29,520 --> 00:01:35,630
say just one big chain of nodes, then the
potential could be as biggest N(log(n)).

27
00:01:35,630 --> 00:01:39,679
And so, a very large potential function
means that your tree is very unbalanced.

28
00:01:39,679 --> 00:01:41,829
And so,
if you are decreasing the potential,

29
00:01:41,829 --> 00:01:43,939
it means that you're rebalancing the tree.

30
00:01:46,150 --> 00:01:50,859
So what we need to do is we need to see
what happens when you perform a splay

31
00:01:50,859 --> 00:01:53,250
operation, what does it do
to the potential function.

32
00:01:54,730 --> 00:01:58,050
Now, to do that,
the splay operation is composed of

33
00:01:58,050 --> 00:02:02,790
a bunch of these little operations,
zig, zig zigs and zig zags and

34
00:02:02,790 --> 00:02:06,480
we want to know for each operation
what does that do to the potential.

35
00:02:07,920 --> 00:02:08,750
So for

36
00:02:08,750 --> 00:02:13,040
example when you perform a zig operation
how does the potential function change?

37
00:02:14,338 --> 00:02:18,870
Well you'll note that other than N and
P, these two nodes that were

38
00:02:18,870 --> 00:02:23,530
directly affected, none of the nodes
have their subtrees change at all.

39
00:02:23,530 --> 00:02:27,160
And therefore the ranks of all
the other nodes stay exactly the same.

40
00:02:28,560 --> 00:02:31,550
So the change in potential
function is just the new rank of

41
00:02:31,550 --> 00:02:36,070
N plus the new rank of P, minus the old
rank of N and the old rank of P.

42
00:02:37,410 --> 00:02:41,380
Now, the new rank of N and
the old rank of P are actually the same,

43
00:02:41,380 --> 00:02:45,100
because each of those had subtrees
that were just the entire tree.

44
00:02:46,450 --> 00:02:50,200
And so this is just the new rank
of P minus the old rank of N and

45
00:02:50,200 --> 00:02:54,110
it's easy to see that's at most, the newer
rank of N minus the old rank of N.

46
00:02:55,190 --> 00:02:55,940
That's not so bad.

47
00:02:57,620 --> 00:03:00,510
Now let's look at the zig-zig analysis
which is a little bit trickier.

48
00:03:01,600 --> 00:03:05,410
So here the change in the potential is
the new rank of N plus the new rank of

49
00:03:05,410 --> 00:03:08,650
P plus the new rank of Q
minus the old rank of N, and

50
00:03:08,650 --> 00:03:11,380
the old rank of P and the old rank of Q.

51
00:03:11,380 --> 00:03:14,444
So the new ranks minus all the old ranks.

52
00:03:14,444 --> 00:03:18,742
Now the claim here is that
this is at most 3 times

53
00:03:18,742 --> 00:03:23,050
the new rank of N minus
the old rank of N minus 2.

54
00:03:23,050 --> 00:03:26,270
And to prove this we
need a few observations.

55
00:03:27,560 --> 00:03:32,790
The first thing is that the rank of
N is equal to the old rank of Q and

56
00:03:32,790 --> 00:03:37,080
that this term is actually bigger than
any other term in our expression.

57
00:03:37,080 --> 00:03:41,010
And that's simply because, I mean, both
of these nodes what are their subtrees?

58
00:03:41,010 --> 00:03:43,140
Well, it's N, P and Q.

59
00:03:43,140 --> 00:03:46,460
And then the red, green,
blue and black subtrees.

60
00:03:46,460 --> 00:03:49,065
They're the same subtrees, the same size.

61
00:03:49,065 --> 00:03:50,588
They've got the same rate.

62
00:03:50,588 --> 00:03:55,834
But the next thing to note is that the old
size of N's subtree and the new size of

63
00:03:55,834 --> 00:04:01,163
Q's subtree, when you add them together,
it's going to be the red subtree,

64
00:04:01,163 --> 00:04:06,770
the green subtree, the blue subtree, and
the black subtree plus two more nodes.

65
00:04:07,800 --> 00:04:12,400
And that's actually one less than the size
of either of these two big terms.

66
00:04:14,310 --> 00:04:16,460
And what that says,
when you take logarithms,

67
00:04:16,460 --> 00:04:21,610
you can actually get that the size,
the rank of N, the old rank of N

68
00:04:21,610 --> 00:04:27,349
plus the new rank of Q is at most
twice the new rank of N minus 2.

69
00:04:28,590 --> 00:04:30,240
Because they're sort
of half the size each.

70
00:04:31,360 --> 00:04:35,287
And therefore, if you combine
these inequalities together,

71
00:04:35,287 --> 00:04:39,373
you can actually get the one that
we wanted on the previous slide.

72
00:04:39,373 --> 00:04:42,680
Now, the zig-zag analysis
is pretty similar to this.

73
00:04:42,680 --> 00:04:46,980
Here, you can show the change in
potential is at most twice the new rank

74
00:04:46,980 --> 00:04:49,980
of N minus the old rank of N minus 2.

75
00:04:49,980 --> 00:04:51,770
Okay, great.

76
00:04:51,770 --> 00:04:54,680
So now we perform
an entire splay operation.

77
00:04:54,680 --> 00:04:58,050
So we splay once, and then again,
and then again, and then again,

78
00:04:58,050 --> 00:05:02,650
all the way up until we finally have
the final version of N that's the root.

79
00:05:03,910 --> 00:05:07,220
And we want to know what the total
change in the potential function is over

80
00:05:07,220 --> 00:05:08,370
all of these little teeny steps.

81
00:05:10,350 --> 00:05:12,370
Well what is it?

82
00:05:12,370 --> 00:05:16,880
Well it's at most the sum of the changes
in potentials from each steps.

83
00:05:16,880 --> 00:05:20,700
The last one you have three
times the final rank of N

84
00:05:20,700 --> 00:05:24,590
minus the rank of N one step before that,
minus two.

85
00:05:25,890 --> 00:05:30,890
You add to that the rank of N one step
before the N minus the rank of N two steps

86
00:05:30,890 --> 00:05:33,160
before the N minus 2.

87
00:05:33,160 --> 00:05:37,966
Then you add three times the rank of N two
steps before the end minus the rank three

88
00:05:37,966 --> 00:05:40,924
steps before the N minus 2 and
so on and so forth.

89
00:05:40,924 --> 00:05:43,796
And this sum actually telescopes.

90
00:05:43,796 --> 00:05:47,905
The rank of N one step before the end
there are two versions of it and

91
00:05:47,905 --> 00:05:49,170
they cancel.

92
00:05:49,170 --> 00:05:50,620
The rank two steps before the end,

93
00:05:50,620 --> 00:05:53,640
there are two terms that cancel and
so on and so forth.

94
00:05:53,640 --> 00:05:58,568
And the only terms that are left is well
you've got three times the rank of N at

95
00:05:58,568 --> 00:06:02,880
the very end of your splay operation,
minus the rank of N at the very

96
00:06:02,880 --> 00:06:07,654
beginning of your splay operation,
and then for each of these steps, for

97
00:06:07,654 --> 00:06:11,902
each two levels the N went up the tree,
you have this copy of -2.

98
00:06:11,902 --> 00:06:14,620
So that's minus the depth of the node app.

99
00:06:16,580 --> 00:06:20,950
And so the change in potential is
just O of log(n) minus the depth,

100
00:06:20,950 --> 00:06:22,680
which is minus the work that you did.

101
00:06:23,840 --> 00:06:26,850
And note it's O of log(n)
because the rank of n is at most

102
00:06:26,850 --> 00:06:28,600
log of the total number
of nodes in the tree.

103
00:06:30,280 --> 00:06:35,330
And so if you add the change in potential
to the amount of work that you did,

104
00:06:35,330 --> 00:06:37,160
you get out O of log(n).

105
00:06:37,160 --> 00:06:41,597
And so the amortized cost of
your O of D work plus your splay

106
00:06:41,597 --> 00:06:44,193
operation is just O of log(n).

107
00:06:46,257 --> 00:06:51,013
Now, that shows there our splay trees
runs an O of log(n) amortized time per

108
00:06:51,013 --> 00:06:51,830
operation.

109
00:06:52,910 --> 00:06:57,160
And if that was all you could say there is
nothing really to be too excited about.

110
00:06:57,160 --> 00:06:59,670
I mean it gets about the same run time,

111
00:07:00,770 --> 00:07:03,370
maybe it's a little bit
easier to implement.

112
00:07:03,370 --> 00:07:06,210
It's a little bit more annoying
because it's only amortized rather

113
00:07:06,210 --> 00:07:07,430
than worst case.

114
00:07:07,430 --> 00:07:10,915
Some operations will be
much more expensive than

115
00:07:10,915 --> 00:07:14,460
log(n) even if on average
the operations are pretty cheap.

116
00:07:15,790 --> 00:07:18,710
But another great thing is that
splay tree has also have many

117
00:07:18,710 --> 00:07:20,430
other wonderful properties.

118
00:07:22,010 --> 00:07:26,328
For example, if you assign weights
to the nodes in any way such

119
00:07:26,328 --> 00:07:30,229
that the sum of all nodes of
their weight is equal to one,

120
00:07:30,229 --> 00:07:36,146
the amortized cost of accessing a node
is actually just O(log(1/wt (N))).

121
00:07:36,146 --> 00:07:40,745
And that means that if you spend a lot of
time accessing high weight nodes it might

122
00:07:40,745 --> 00:07:44,260
actually be much quicker that
log(N) time per operation.

123
00:07:46,220 --> 00:07:52,370
And so, and note that this run time bound
holds no matter what weights you assign.

124
00:07:52,370 --> 00:07:55,740
You don't need to change
the algorithm based on the weights.

125
00:07:55,740 --> 00:07:57,850
This bound happens automatically.

126
00:07:57,850 --> 00:08:01,820
And so if there are certain nodes that get
accessed much more frequently than others,

127
00:08:01,820 --> 00:08:06,030
you could just sort of artificially
assign them very high weights and

128
00:08:06,030 --> 00:08:09,860
then that actually means that your
display tree automatically runs

129
00:08:09,860 --> 00:08:13,880
faster than log(n) per operation.

130
00:08:13,880 --> 00:08:15,844
Another bound is the dynamic finger bound.

131
00:08:15,844 --> 00:08:20,629
The amortized cost of accessing
a node is O(log(D + 1)) where here,

132
00:08:20,629 --> 00:08:25,954
D is the distance in terms of the ordering
between nodes between the last access and

133
00:08:25,954 --> 00:08:28,120
the current access.

134
00:08:28,120 --> 00:08:32,926
So if say you want to list all the nodes
in order or search for all the nodes

135
00:08:32,926 --> 00:08:37,914
in order, it's actually pretty fast
to do a display tree because D is 1.

136
00:08:37,914 --> 00:08:41,890
It's a constant per operation
rather than O of log(n).

137
00:08:43,680 --> 00:08:45,910
Another bound is the working set bound.

138
00:08:45,910 --> 00:08:50,850
The amortized cost of accessing
a node N is O(log(t+1)) where t is

139
00:08:50,850 --> 00:08:55,500
the amount of time that has elapsed
since that node N was last accessed.

140
00:08:56,850 --> 00:09:01,601
And what that means, for
example, is that if you tend

141
00:09:01,601 --> 00:09:06,600
to access nodes that you've
accessed recently a lot.

142
00:09:06,600 --> 00:09:09,890
So you access one node
pretty frequently and

143
00:09:09,890 --> 00:09:13,590
then they move to accessing
a different node pretty frequently,

144
00:09:13,590 --> 00:09:17,761
then this actually does a lot better
again than O of log(n) per operation.

145
00:09:19,930 --> 00:09:23,660
Finally we've got what's known as
the dynamic optimality conjecture.

146
00:09:24,710 --> 00:09:29,560
And this says if you give me any list of
splay tree operations, inserts, finds,

147
00:09:29,560 --> 00:09:30,880
deletes whatever.

148
00:09:32,205 --> 00:09:36,277
And then you build the best
possible dynamic search tree for

149
00:09:36,277 --> 00:09:39,215
that particular sequence of operations.

150
00:09:39,215 --> 00:09:44,375
You can have it completely optimized to
perform those operations as best possible.

151
00:09:46,185 --> 00:09:50,365
The conjecture says that if you run
a splay tree on those operations it does

152
00:09:50,365 --> 00:09:52,275
worse by at most a constant factor.

153
00:09:53,370 --> 00:09:54,430
And that's pretty amazing.

154
00:09:54,430 --> 00:09:59,590
It would say that if there is any binary
search three that does particularly well

155
00:09:59,590 --> 00:10:04,460
on a sequence of operations than at
least conjecturally a splay tree does.

156
00:10:04,460 --> 00:10:08,054
So the conclusion here is that
splay trees, they're pretty fast,

157
00:10:08,054 --> 00:10:12,343
they require only O of log(n) amortized
time per operation which, remember,

158
00:10:12,343 --> 00:10:16,506
it can be a problem if you're worried
that the occasional operation might take

159
00:10:16,506 --> 00:10:17,220
a long time.

160
00:10:18,540 --> 00:10:23,180
But in addition to this, splay trees can
actually be much better if your input

161
00:10:23,180 --> 00:10:27,000
queries have extra structure, if you call
some nodes more frequently than others, or

162
00:10:27,000 --> 00:10:31,690
you tend to call nearby nodes to the ones
that you most recently accessed, and

163
00:10:31,690 --> 00:10:33,220
things like that.

164
00:10:33,220 --> 00:10:38,070
But that's actually it for today.

165
00:10:38,070 --> 00:10:41,010
That's a splay tree, that's why
they're considered to be useful.

166
00:10:42,650 --> 00:10:46,900
And that's this course,
I really hope that you've enjoyed it,

167
00:10:46,900 --> 00:10:51,160
I hope you'll come back for
our next course and best of luck.